[2018-07-11 11:57:23,593 INFO] Start training...
[2018-07-11 11:57:23,593 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=4, every_n_epoch_save=4, input_embeddings_trainable=True, log_file='log', lr=1.0, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, vector_type='glove.6B.100d')
[2018-07-11 11:57:36,856 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-11 11:58:35,398 INFO] | epoch   1 | train_loss  5.36 | val_ppl   162.03 | time  53.9s
[2018-07-11 11:59:29,589 INFO] | epoch   2 | train_loss  4.91 | val_ppl   141.38 | time  54.2s
[2018-07-11 12:00:23,862 INFO] | epoch   3 | train_loss  4.76 | val_ppl   135.60 | time  54.3s
[2018-07-11 12:01:17,954 INFO] | epoch   4 | train_loss  4.67 | val_ppl   132.10 | time  54.1s
[2018-07-11 12:01:17,954 INFO] start to save model on nnlm.model
[2018-07-11 12:01:20,663 INFO] test_ppl: 121.5
[2018-07-11 12:01:52,326 INFO] Start training...
[2018-07-11 12:01:52,326 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=4, every_n_epoch_save=4, input_embeddings_trainable=True, log_file='log', lr=1.0, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, vector_type='glove.6B.100d')
[2018-07-11 12:02:04,668 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-11 12:03:03,107 INFO] | epoch   1 | train_loss  5.36 | val_ppl   162.03 | time  54.1s
[2018-07-11 12:03:57,274 INFO] | epoch   2 | train_loss  4.91 | val_ppl   141.38 | time  54.2s
[2018-07-11 12:04:51,551 INFO] | epoch   3 | train_loss  4.76 | val_ppl   135.60 | time  54.3s
[2018-07-11 12:05:45,834 INFO] | epoch   4 | train_loss  4.67 | val_ppl   132.10 | time  54.3s
[2018-07-11 12:05:45,835 INFO] start to save model on nnlm.model
[2018-07-11 12:05:48,531 INFO] test_ppl: 121.5
[2018-07-11 12:13:51,900 INFO] Start training...
[2018-07-11 12:13:51,901 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=4, every_n_epoch_save=4, input_embeddings_trainable=True, log_file='log', lr=1.0, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=True, vector_type='glove.6B.100d')
[2018-07-11 12:14:03,920 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-11 12:14:30,772 INFO] Start training...
[2018-07-11 12:14:30,773 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=4, every_n_epoch_save=4, input_embeddings_trainable=True, log_file='log', lr=1.0, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=True, vector_type='glove.6B.100d')
[2018-07-11 12:14:44,150 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-11 12:15:15,018 INFO] Start training...
[2018-07-11 12:15:15,018 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=4, every_n_epoch_save=4, input_embeddings_trainable=True, log_file='log', lr=1.0, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=True, vector_type='glove.6B.100d')
[2018-07-11 12:15:28,133 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-11 12:16:25,528 INFO] | epoch   1 | train_loss  5.97 | val_ppl   227.08 | time  52.2s
[2018-07-11 12:17:17,273 INFO] | epoch   2 | train_loss  5.30 | val_ppl   198.76 | time  51.7s
[2018-07-11 12:18:08,877 INFO] | epoch   3 | train_loss  5.18 | val_ppl   185.42 | time  51.6s
[2018-07-11 12:19:00,652 INFO] | epoch   4 | train_loss  5.10 | val_ppl   175.43 | time  51.8s
[2018-07-11 12:19:00,652 INFO] start to save model on nnlm.model
[2018-07-11 12:19:03,120 INFO] test_ppl: 161.4
[2018-07-28 22:55:08,800 INFO] Start training...
[2018-07-28 22:55:08,800 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=4, input_embeddings_trainable=1, log_file='log', lr=0.5, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-07-28 22:55:24,865 INFO] train token: 2127402
[2018-07-28 22:55:24,866 INFO] test token: 250140
[2018-07-28 22:55:24,866 INFO] valid token: 221606
[2018-07-28 22:55:25,372 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-28 22:56:28,014 INFO] | epoch   1 | train_loss  5.48 | val_ppl   174.45 | time  58.2s
[2018-07-28 22:57:26,507 INFO] | epoch   2 | train_loss  5.03 | val_ppl   148.51 | time  58.5s
[2018-07-28 22:58:25,131 INFO] | epoch   3 | train_loss  4.89 | val_ppl   137.81 | time  58.6s
[2018-07-28 22:59:23,791 INFO] | epoch   4 | train_loss  4.80 | val_ppl   132.02 | time  58.7s
[2018-07-28 22:59:23,791 INFO] start to save model on nnlm.model
[2018-07-28 23:00:23,383 INFO] | epoch   5 | train_loss  4.73 | val_ppl   128.47 | time  58.9s
[2018-07-28 23:01:22,137 INFO] | epoch   6 | train_loss  4.68 | val_ppl   126.19 | time  58.8s
[2018-07-28 23:02:20,923 INFO] | epoch   7 | train_loss  4.63 | val_ppl   124.58 | time  58.8s
[2018-07-28 23:03:19,775 INFO] | epoch   8 | train_loss  4.59 | val_ppl   123.33 | time  58.9s
[2018-07-28 23:03:19,775 INFO] start to save model on nnlm.model
[2018-07-28 23:05:54,299 INFO] test_ppl: 113.9

(explanation: during testing, I changed the trained emb both input and output to the raw
pre-trained word emb. And get 2554 ppl on test data)
[2018-07-31 14:09:14,392 INFO] Start training...
[2018-07-31 14:09:14,392 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, input_embeddings_trainable=1, log_file='log', lr=0.5, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-07-31 14:09:25,980 INFO] train token: 2127402
[2018-07-31 14:09:25,980 INFO] test token: 250140
[2018-07-31 14:09:25,980 INFO] valid token: 221606
[2018-07-31 14:09:26,425 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-31 14:10:37,426 INFO] | epoch   1 | train_loss  5.62 | val_ppl   202.87 | time  67.0s
[2018-07-31 14:11:45,479 INFO] | epoch   2 | train_loss  5.26 | val_ppl   182.92 | time  68.1s
[2018-07-31 14:12:53,601 INFO] | epoch   3 | train_loss  5.17 | val_ppl   173.45 | time  68.1s
[2018-07-31 14:14:02,259 INFO] | epoch   4 | train_loss  5.11 | val_ppl   167.48 | time  68.7s
[2018-07-31 14:15:10,687 INFO] | epoch   5 | train_loss  5.07 | val_ppl   163.20 | time  68.4s
[2018-07-31 14:16:19,743 INFO] | epoch   6 | train_loss  5.03 | val_ppl   159.85 | time  69.1s
[2018-07-31 14:17:27,937 INFO] | epoch   7 | train_loss  5.00 | val_ppl   157.40 | time  68.2s
[2018-07-31 14:18:36,343 INFO] | epoch   8 | train_loss  4.97 | val_ppl   155.19 | time  68.4s
[2018-07-31 14:18:38,957 INFO] test_ppl: 2554.4

(explanation: during testing, I only changed the output train emb to the input and raw pre-trained)
[2018-07-31 14:30:17,872 INFO] Start training...
[2018-07-31 14:30:17,872 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, input_embeddings_trainable=1, log_file='log', lr=0.5, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-07-31 14:30:29,691 INFO] train token: 2127402
[2018-07-31 14:30:29,692 INFO] test token: 250140
[2018-07-31 14:30:29,692 INFO] valid token: 221606
[2018-07-31 14:30:30,120 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-31 14:31:41,477 INFO] | epoch   1 | train_loss  5.62 | val_ppl   202.87 | time  67.3s
[2018-07-31 14:32:49,501 INFO] | epoch   2 | train_loss  5.26 | val_ppl   182.92 | time  68.0s
[2018-07-31 14:33:57,168 INFO] | epoch   3 | train_loss  5.17 | val_ppl   173.45 | time  67.7s
[2018-07-31 14:35:05,325 INFO] | epoch   4 | train_loss  5.11 | val_ppl   167.48 | time  68.2s
[2018-07-31 14:36:13,854 INFO] | epoch   5 | train_loss  5.07 | val_ppl   163.20 | time  68.5s
[2018-07-31 14:37:22,128 INFO] | epoch   6 | train_loss  5.03 | val_ppl   159.85 | time  68.3s
[2018-07-31 14:38:30,394 INFO] | epoch   7 | train_loss  5.00 | val_ppl   157.40 | time  68.3s
[2018-07-31 14:39:38,630 INFO] | epoch   8 | train_loss  4.97 | val_ppl   155.19 | time  68.2s
[2018-07-31 14:39:41,242 INFO] out emb from pre-trained emb, test_ppl: 1557.8
[2018-07-31 14:39:43,849 INFO] out emb from input trained emb, test_ppl: 1864.3

(explanation: both input and output emb are randomly inited. but latter poor similarity on input
emb is observed, but good performance on output emb)
[2018-07-31 14:54:30,371 INFO] Start training...
[2018-07-31 14:54:30,371 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, input_embeddings_trainable=1, log_file='log', lr=0.5, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-07-31 14:54:42,263 INFO] train token: 2127402
[2018-07-31 14:54:42,263 INFO] test token: 250140
[2018-07-31 14:54:42,263 INFO] valid token: 221606
[2018-07-31 14:54:42,697 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-31 14:55:53,816 INFO] | epoch   1 | train_loss  5.73 | val_ppl   217.15 | time  67.2s
[2018-07-31 14:57:01,955 INFO] | epoch   2 | train_loss  5.30 | val_ppl   191.46 | time  68.1s
[2018-07-31 14:58:09,843 INFO] | epoch   3 | train_loss  5.16 | val_ppl   179.09 | time  67.9s
[2018-07-31 14:59:18,046 INFO] | epoch   4 | train_loss  5.07 | val_ppl   172.12 | time  68.2s
[2018-07-31 15:00:26,312 INFO] | epoch   5 | train_loss  5.01 | val_ppl   167.67 | time  68.3s
[2018-07-31 15:01:34,973 INFO] | epoch   6 | train_loss  4.95 | val_ppl   164.24 | time  68.7s
[2018-07-31 15:02:43,250 INFO] | epoch   7 | train_loss  4.91 | val_ppl   161.55 | time  68.3s
[2018-07-31 15:03:51,422 INFO] | epoch   8 | train_loss  4.87 | val_ppl   159.90 | time  68.2s
[2018-07-31 15:03:54,032 INFO] test_ppl: 146.8
[2018-07-31 15:28:57,698 INFO] Start training...

(explanation: change random seed to observe above xianxiang)
[2018-07-31 15:28:57,698 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, input_embeddings_trainable=1, log_file='log', lr=0.5, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=2, tied=False, vector_type='glove.6B.100d')
[2018-07-31 15:29:09,650 INFO] train token: 2127402
[2018-07-31 15:29:09,650 INFO] test token: 250140
[2018-07-31 15:29:09,650 INFO] valid token: 221606
[2018-07-31 15:29:10,092 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-31 15:30:21,567 INFO] | epoch   1 | train_loss  5.72 | val_ppl   211.07 | time  67.5s
[2018-07-31 15:31:29,211 INFO] | epoch   2 | train_loss  5.30 | val_ppl   188.27 | time  67.6s
[2018-07-31 15:32:37,209 INFO] | epoch   3 | train_loss  5.16 | val_ppl   177.49 | time  68.0s
[2018-07-31 15:33:44,926 INFO] | epoch   4 | train_loss  5.07 | val_ppl   171.14 | time  67.7s
[2018-07-31 15:34:53,238 INFO] | epoch   5 | train_loss  5.01 | val_ppl   166.88 | time  68.3s
[2018-07-31 15:36:01,612 INFO] | epoch   6 | train_loss  4.96 | val_ppl   163.86 | time  68.4s
[2018-07-31 15:37:09,962 INFO] | epoch   7 | train_loss  4.91 | val_ppl   161.72 | time  68.4s
[2018-07-31 15:38:18,200 INFO] | epoch   8 | train_loss  4.87 | val_ppl   160.12 | time  68.2s
[2018-07-31 15:38:20,809 INFO] test_ppl: 147.1

(explanation: tied, randomly inited)
[2018-07-31 16:04:23,671 INFO] Start training...
[2018-07-31 16:04:23,672 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, input_embeddings_trainable=1, log_file='log', lr=0.5, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=True, vector_type='glove.6B.100d')
[2018-07-31 16:04:35,709 INFO] train token: 2127402
[2018-07-31 16:04:35,709 INFO] test token: 250140
[2018-07-31 16:04:35,710 INFO] valid token: 221606
[2018-07-31 16:04:36,135 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-31 16:05:44,870 INFO] | epoch   1 | train_loss  6.71 | val_ppl   513.26 | time  64.8s
[2018-07-31 16:06:49,821 INFO] | epoch   2 | train_loss  6.21 | val_ppl   405.96 | time  65.0s
[2018-07-31 16:07:55,041 INFO] | epoch   3 | train_loss  6.04 | val_ppl   357.50 | time  65.2s
[2018-07-31 16:08:59,693 INFO] | epoch   4 | train_loss  5.93 | val_ppl   328.33 | time  64.7s
[2018-07-31 16:10:05,344 INFO] | epoch   5 | train_loss  5.85 | val_ppl   308.08 | time  65.7s
[2018-07-31 16:11:10,503 INFO] | epoch   6 | train_loss  5.79 | val_ppl   292.92 | time  65.2s
[2018-07-31 16:12:16,001 INFO] | epoch   7 | train_loss  5.74 | val_ppl   281.16 | time  65.5s
[2018-07-31 16:13:21,448 INFO] | epoch   8 | train_loss  5.70 | val_ppl   271.68 | time  65.4s
[2018-07-31 16:13:24,054 INFO] test_ppl: 250.3


(explanation: input will be updated. output is fixed using pre-trained emb)
[2018-07-31 19:49:39,046 INFO] Start training...
[2018-07-31 19:49:39,046 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, input_embeddings_trainable=1, log_file='log', lr=0.5, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-07-31 19:49:50,588 INFO] train token: 2127402
[2018-07-31 19:49:50,589 INFO] test token: 250140
[2018-07-31 19:49:50,589 INFO] valid token: 221606
[2018-07-31 19:49:51,008 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-31 19:51:03,078 INFO] | epoch   1 | train_loss  5.62 | val_ppl   202.87 | time  68.1s
[2018-07-31 19:52:11,188 INFO] | epoch   2 | train_loss  5.26 | val_ppl   182.92 | time  68.1s
[2018-07-31 19:53:19,355 INFO] | epoch   3 | train_loss  5.17 | val_ppl   173.45 | time  68.2s
[2018-07-31 19:54:28,062 INFO] | epoch   4 | train_loss  5.11 | val_ppl   167.48 | time  68.7s
[2018-07-31 19:55:36,061 INFO] | epoch   5 | train_loss  5.07 | val_ppl   163.20 | time  68.0s
[2018-07-31 19:56:45,114 INFO] | epoch   6 | train_loss  5.03 | val_ppl   159.85 | time  69.1s
[2018-07-31 19:57:53,615 INFO] | epoch   7 | train_loss  5.00 | val_ppl   157.40 | time  68.5s
[2018-07-31 19:59:01,928 INFO] | epoch   8 | train_loss  4.97 | val_ppl   155.19 | time  68.3s
[2018-07-31 19:59:04,521 INFO] test_ppl: 143.7

(explanation: I disabled both input and output embeddings from pre-trained. it still works)
[2018-07-31 21:58:56,589 INFO] Start training...
[2018-07-31 21:58:56,589 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=True, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-07-31 21:59:08,303 INFO] train token: 2127402
[2018-07-31 21:59:08,303 INFO] test token: 250140
[2018-07-31 21:59:08,303 INFO] valid token: 221606
[2018-07-31 21:59:08,747 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-31 22:00:20,066 INFO] | epoch   1 | train_loss  5.62 | val_ppl   202.87 | time  67.3s
[2018-07-31 22:01:27,876 INFO] | epoch   2 | train_loss  5.26 | val_ppl   182.92 | time  67.8s
[2018-07-31 22:02:36,551 INFO] | epoch   3 | train_loss  5.17 | val_ppl   173.45 | time  68.7s
[2018-07-31 22:03:45,416 INFO] | epoch   4 | train_loss  5.11 | val_ppl   167.48 | time  68.9s
[2018-07-31 22:04:53,778 INFO] | epoch   5 | train_loss  5.07 | val_ppl   163.20 | time  68.4s
[2018-07-31 22:06:02,175 INFO] | epoch   6 | train_loss  5.03 | val_ppl   159.85 | time  68.4s
[2018-07-31 22:07:10,262 INFO] | epoch   7 | train_loss  5.00 | val_ppl   157.40 | time  68.1s
[2018-07-31 22:08:18,607 INFO] | epoch   8 | train_loss  4.97 | val_ppl   155.19 | time  68.3s
[2018-07-31 22:08:21,205 INFO] test_ppl: 143.7

(explanation: I disabled output update, enable input, but result is same. strange mark here)
[2018-07-31 22:16:48,673 INFO] Start training...
[2018-07-31 22:16:48,673 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-07-31 22:17:00,997 INFO] train token: 2127402
[2018-07-31 22:17:00,997 INFO] test token: 250140
[2018-07-31 22:17:00,997 INFO] valid token: 221606
[2018-07-31 22:17:01,473 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-31 22:17:05,825 INFO] embeddings input emb requries_grad:True
[2018-07-31 22:18:12,708 INFO] | epoch   1 | train_loss  5.62 | val_ppl   202.87 | time  66.9s
[2018-07-31 22:19:20,513 INFO] | epoch   2 | train_loss  5.26 | val_ppl   182.92 | time  67.8s
[2018-07-31 22:20:28,542 INFO] | epoch   3 | train_loss  5.17 | val_ppl   173.45 | time  68.0s
[2018-07-31 22:21:36,978 INFO] | epoch   4 | train_loss  5.11 | val_ppl   167.48 | time  68.4s
[2018-07-31 22:22:44,891 INFO] | epoch   5 | train_loss  5.07 | val_ppl   163.20 | time  67.9s
[2018-07-31 22:23:53,138 INFO] | epoch   6 | train_loss  5.03 | val_ppl   159.85 | time  68.2s
[2018-07-31 22:25:01,365 INFO] | epoch   7 | train_loss  5.00 | val_ppl   157.40 | time  68.2s
[2018-07-31 22:26:10,235 INFO] | epoch   8 | train_loss  4.97 | val_ppl   155.19 | time  68.9s
[2018-07-31 22:26:12,711 INFO] test_ppl: 143.7
[2018-08-03 16:20:08,523 INFO] Start training...

(explanation: using trained cbow on same training data. the output emb is fixed, input is updating.
al most obtain the best result)
[2018-08-03 16:20:08,523 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:1', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-03 16:20:19,495 INFO] train token: 2127402
[2018-08-03 16:20:19,495 INFO] test token: 250140
[2018-08-03 16:20:19,495 INFO] valid token: 221606
[2018-08-03 16:20:19,683 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt
[2018-08-03 16:20:19,687 WARNING] Skipping token 23380 with 1-dimensional vector ['100']; likely a header
[2018-08-03 16:20:20,509 INFO] Saving vectors to /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-03 16:20:28,049 INFO] embeddings input emb requries_grad:True
[2018-08-03 16:20:52,152 INFO] | epoch   1 | train_loss  5.28 | val_ppl   164.29 | time  24.1s
[2018-08-03 16:21:16,072 INFO] | epoch   2 | train_loss  4.96 | val_ppl   145.30 | time  23.9s
[2018-08-03 16:21:40,427 INFO] | epoch   3 | train_loss  4.84 | val_ppl   136.03 | time  24.4s
[2018-08-03 16:22:04,642 INFO] | epoch   4 | train_loss  4.75 | val_ppl   130.40 | time  24.2s
[2018-08-03 16:22:28,586 INFO] | epoch   5 | train_loss  4.68 | val_ppl   126.64 | time  23.9s
[2018-08-03 16:22:53,095 INFO] | epoch   6 | train_loss  4.62 | val_ppl   124.04 | time  24.5s
[2018-08-03 16:23:17,185 INFO] | epoch   7 | train_loss  4.58 | val_ppl   122.21 | time  24.1s
[2018-08-03 16:23:41,889 INFO] | epoch   8 | train_loss  4.53 | val_ppl   120.94 | time  24.7s
[2018-08-03 16:23:42,887 INFO] test_ppl: 116.5
[2018-08-04 16:38:43,055 INFO] -------------
explanation: val_ppl and test_ppl are -consine. wiki2 trained cbow to fix out emb and update in emb
[2018-08-04 16:38:43,056 INFO] Start training...
[2018-08-04 16:38:43,056 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-04 16:38:54,264 INFO] train token: 2127402
[2018-08-04 16:38:54,264 INFO] test token: 250140
[2018-08-04 16:38:54,265 INFO] valid token: 221606
[2018-08-04 16:38:54,482 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-04 16:39:22,428 INFO] | epoch   1 | train_loss  5.28 | val_ppl    -0.21 | time  23.7s
[2018-08-04 16:39:45,128 INFO] | epoch   2 | train_loss  4.96 | val_ppl    -0.22 | time  22.7s
[2018-08-04 16:40:08,614 INFO] | epoch   3 | train_loss  4.84 | val_ppl    -0.23 | time  23.5s
[2018-08-04 16:40:32,137 INFO] | epoch   4 | train_loss  4.75 | val_ppl    -0.23 | time  23.5s
[2018-08-04 16:40:55,733 INFO] | epoch   5 | train_loss  4.68 | val_ppl    -0.23 | time  23.6s
[2018-08-04 16:41:19,158 INFO] | epoch   6 | train_loss  4.62 | val_ppl    -0.23 | time  23.4s
[2018-08-04 16:41:42,629 INFO] | epoch   7 | train_loss  4.58 | val_ppl    -0.24 | time  23.5s
[2018-08-04 16:42:05,937 INFO] | epoch   8 | train_loss  4.53 | val_ppl    -0.24 | time  23.3s
[2018-08-04 16:42:06,589 INFO] test_ppl:  -0.2
[2018-08-04 16:49:32,227 INFO] -------------
(explanation: the same as above one. I changed the float point of cosine)
[2018-08-04 16:49:32,227 INFO] Start training...
[2018-08-04 16:49:32,227 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-04 16:49:43,473 INFO] train token: 2127402
[2018-08-04 16:49:43,473 INFO] test token: 250140
[2018-08-04 16:49:43,474 INFO] valid token: 221606
[2018-08-04 16:49:43,619 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-04 16:50:10,367 INFO] | epoch   1 | train_loss  5.28 | val_ppl -0.21334 | time  23.3s
[2018-08-04 16:50:33,777 INFO] | epoch   2 | train_loss  4.96 | val_ppl -0.22230 | time  23.4s
[2018-08-04 16:50:56,918 INFO] | epoch   3 | train_loss  4.84 | val_ppl -0.22630 | time  23.1s
[2018-08-04 16:51:20,258 INFO] | epoch   4 | train_loss  4.75 | val_ppl -0.22975 | time  23.3s
[2018-08-04 16:51:43,789 INFO] | epoch   5 | train_loss  4.68 | val_ppl -0.23230 | time  23.5s
[2018-08-04 16:52:07,929 INFO] | epoch   6 | train_loss  4.62 | val_ppl -0.23413 | time  24.1s
[2018-08-04 16:52:31,161 INFO] | epoch   7 | train_loss  4.58 | val_ppl -0.23547 | time  23.2s
[2018-08-04 16:52:54,546 INFO] | epoch   8 | train_loss  4.53 | val_ppl -0.23652 | time  23.4s
[2018-08-04 16:52:55,215 INFO] test_ppl: -0.23469


(explanation: full-softmax norm hidden output and pretrained norm out emb from the start, all is same as before
the result shows it performs a slightly bad than non-norm one. But note fixing out emb, still works)
[2018-08-11 10:11:52,834 INFO] -------------
[2018-08-11 10:11:52,834 INFO] Start training...
[2018-08-11 10:11:52,834 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 10:12:03,779 INFO] train token: 2127402
[2018-08-11 10:12:03,779 INFO] test token: 250140
[2018-08-11 10:12:03,779 INFO] valid token: 221606
[2018-08-11 10:12:03,918 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 10:12:31,943 INFO] | epoch   1 | train_loss  5.69 | val_ppl 212.15373 | time  24.6s
[2018-08-11 10:12:56,157 INFO] | epoch   2 | train_loss  5.32 | val_ppl 180.26816 | time  24.2s
[2018-08-11 10:13:21,018 INFO] | epoch   3 | train_loss  5.18 | val_ppl 164.25467 | time  24.9s
[2018-08-11 10:13:45,154 INFO] | epoch   4 | train_loss  5.10 | val_ppl 154.49554 | time  24.1s
[2018-08-11 10:14:09,838 INFO] | epoch   5 | train_loss  5.03 | val_ppl 147.72783 | time  24.7s
[2018-08-11 10:14:35,549 INFO] | epoch   6 | train_loss  4.98 | val_ppl 142.51899 | time  25.7s
[2018-08-11 10:15:00,965 INFO] | epoch   7 | train_loss  4.94 | val_ppl 138.56315 | time  25.4s
[2018-08-11 10:15:25,451 INFO] | epoch   8 | train_loss  4.91 | val_ppl 135.48768 | time  24.5s
[2018-08-11 10:15:26,474 INFO] test_ppl: 131.53229


(explanation: randomly out emb, updating. this is the PPL result)
[2018-08-11 10:40:34,481 INFO] -------------
[2018-08-11 10:40:34,481 INFO] Start training...
[2018-08-11 10:40:34,481 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 10:40:45,832 INFO] train token: 2127402
[2018-08-11 10:40:45,832 INFO] test token: 250140
[2018-08-11 10:40:45,832 INFO] valid token: 221606
[2018-08-11 10:40:45,972 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 10:41:13,416 INFO] | epoch   1 | train_loss  5.21 | val_ppl 154.21461 | time  23.9s
[2018-08-11 10:41:37,165 INFO] | epoch   2 | train_loss  4.85 | val_ppl 134.51386 | time  23.7s
[2018-08-11 10:42:01,007 INFO] | epoch   3 | train_loss  4.73 | val_ppl 124.98321 | time  23.8s
[2018-08-11 10:42:25,112 INFO] | epoch   4 | train_loss  4.64 | val_ppl 119.01536 | time  24.1s
[2018-08-11 10:42:48,558 INFO] | epoch   5 | train_loss  4.58 | val_ppl 115.04513 | time  23.4s
[2018-08-11 10:43:12,139 INFO] | epoch   6 | train_loss  4.53 | val_ppl 112.35071 | time  23.6s
[2018-08-11 10:43:35,855 INFO] | epoch   7 | train_loss  4.49 | val_ppl 110.55550 | time  23.7s
[2018-08-11 10:43:59,139 INFO] | epoch   8 | train_loss  4.45 | val_ppl 109.30011 | time  23.3s
[2018-08-11 10:44:00,116 INFO] test_ppl: 105.30712


(explanation: randomly out emb, fixed, the totally same result!. any bug? how it could be!)
[2018-08-11 10:52:13,115 INFO] -------------
[2018-08-11 10:52:13,115 INFO] Start training...
[2018-08-11 10:52:13,116 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 10:52:24,324 INFO] train token: 2127402
[2018-08-11 10:52:24,324 INFO] test token: 250140
[2018-08-11 10:52:24,324 INFO] valid token: 221606
[2018-08-11 10:52:24,464 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 10:52:51,258 INFO] | epoch   1 | train_loss  5.21 | val_ppl 154.21461 | time  23.8s
[2018-08-11 10:53:14,410 INFO] | epoch   2 | train_loss  4.85 | val_ppl 134.51386 | time  23.2s
[2018-08-11 10:53:37,993 INFO] | epoch   3 | train_loss  4.73 | val_ppl 124.98321 | time  23.6s
[2018-08-11 10:54:01,673 INFO] | epoch   4 | train_loss  4.64 | val_ppl 119.01536 | time  23.7s
[2018-08-11 10:54:25,475 INFO] | epoch   5 | train_loss  4.58 | val_ppl 115.04513 | time  23.8s
[2018-08-11 10:54:48,660 INFO] | epoch   6 | train_loss  4.53 | val_ppl 112.35071 | time  23.2s
[2018-08-11 10:55:12,417 INFO] | epoch   7 | train_loss  4.49 | val_ppl 110.55550 | time  23.8s
[2018-08-11 10:55:35,869 INFO] | epoch   8 | train_loss  4.45 | val_ppl 109.30011 | time  23.5s
[2018-08-11 10:55:36,836 INFO] test_ppl: 105.30712


----------------
-  split line  -
----------------

After I found the reason of a bug in my program. The above result have to be ignored for
non-updating setting.
------------------------------------------
-----------------------------------------


(explanation: standard. pretrained out in, updating both)
[2018-08-11 11:42:02,033 INFO] -------------
[2018-08-11 11:42:02,033 INFO] Start training...
[2018-08-11 11:42:02,033 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 11:42:13,059 INFO] train token: 2127402
[2018-08-11 11:42:13,060 INFO] test token: 250140
[2018-08-11 11:42:13,060 INFO] valid token: 221606
[2018-08-11 11:42:13,294 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 11:42:40,425 INFO] | epoch   1 | train_loss  5.28 | val_ppl 164.29145 | time  23.7s
[2018-08-11 11:43:03,660 INFO] | epoch   2 | train_loss  4.96 | val_ppl 145.29785 | time  23.2s
[2018-08-11 11:43:28,005 INFO] | epoch   3 | train_loss  4.84 | val_ppl 136.03464 | time  24.3s
[2018-08-11 11:43:51,476 INFO] | epoch   4 | train_loss  4.75 | val_ppl 130.40298 | time  23.5s
[2018-08-11 11:44:15,149 INFO] | epoch   5 | train_loss  4.68 | val_ppl 126.63874 | time  23.7s
[2018-08-11 11:44:38,460 INFO] | epoch   6 | train_loss  4.62 | val_ppl 124.03754 | time  23.3s
[2018-08-11 11:45:01,810 INFO] | epoch   7 | train_loss  4.58 | val_ppl 122.20709 | time  23.3s
[2018-08-11 11:45:25,251 INFO] | epoch   8 | train_loss  4.53 | val_ppl 120.94260 | time  23.4s
[2018-08-11 11:45:26,214 INFO] test_ppl: 116.48836
[2018-08-11 11:47:09,263 INFO] -------------
[2018-08-11 11:47:09,263 INFO] Start training...
[2018-08-11 11:47:09,263 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 11:47:20,770 INFO] train token: 2127402
[2018-08-11 11:47:20,771 INFO] test token: 250140
[2018-08-11 11:47:20,771 INFO] valid token: 221606
[2018-08-11 11:47:20,914 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt

(explanation: no bias term in softmax output)
[2018-08-11 11:53:32,440 INFO] -------------
[2018-08-11 11:53:32,440 INFO] Start training...
[2018-08-11 11:53:32,440 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 11:53:43,587 INFO] train token: 2127402
[2018-08-11 11:53:43,587 INFO] test token: 250140
[2018-08-11 11:53:43,587 INFO] valid token: 221606
[2018-08-11 11:53:43,730 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 11:54:09,951 INFO] | epoch   1 | train_loss  5.27 | val_ppl 167.26648 | time  22.9s
[2018-08-11 11:54:32,207 INFO] | epoch   2 | train_loss  4.96 | val_ppl 146.64552 | time  22.3s
[2018-08-11 11:54:54,706 INFO] | epoch   3 | train_loss  4.84 | val_ppl 137.08501 | time  22.5s
[2018-08-11 11:55:17,098 INFO] | epoch   4 | train_loss  4.75 | val_ppl 131.19981 | time  22.4s
[2018-08-11 11:55:39,398 INFO] | epoch   5 | train_loss  4.68 | val_ppl 127.14218 | time  22.3s
[2018-08-11 11:56:02,100 INFO] | epoch   6 | train_loss  4.63 | val_ppl 124.31848 | time  22.7s
[2018-08-11 11:56:24,560 INFO] | epoch   7 | train_loss  4.58 | val_ppl 122.25929 | time  22.5s
[2018-08-11 11:56:46,903 INFO] | epoch   8 | train_loss  4.53 | val_ppl 120.73668 | time  22.3s
[2018-08-11 11:56:47,783 INFO] test_ppl: 116.25565
[2018-08-11 11:58:12,622 INFO] -------------

explanation: this not updating pretrained emb
[2018-08-11 11:58:12,622 INFO] Start training...
[2018-08-11 11:58:12,622 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 11:58:23,951 INFO] train token: 2127402
[2018-08-11 11:58:23,951 INFO] test token: 250140
[2018-08-11 11:58:23,951 INFO] valid token: 221606
[2018-08-11 11:58:24,093 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 11:58:47,852 INFO] | epoch   1 | train_loss  5.69 | val_ppl 252.04634 | time  20.5s
[2018-08-11 11:59:07,940 INFO] | epoch   2 | train_loss  5.42 | val_ppl 230.61994 | time  20.1s
[2018-08-11 11:59:28,003 INFO] | epoch   3 | train_loss  5.33 | val_ppl 221.23442 | time  20.1s
[2018-08-11 11:59:48,386 INFO] | epoch   4 | train_loss  5.27 | val_ppl 215.90383 | time  20.4s
[2018-08-11 12:00:08,196 INFO] | epoch   5 | train_loss  5.23 | val_ppl 213.32098 | time  19.8s
[2018-08-11 12:00:28,499 INFO] | epoch   6 | train_loss  5.19 | val_ppl 211.77433 | time  20.3s
[2018-08-11 12:00:48,346 INFO] | epoch   7 | train_loss  5.16 | val_ppl 211.10733 | time  19.8s
[2018-08-11 12:01:08,003 INFO] | epoch   8 | train_loss  5.13 | val_ppl 210.85058 | time  19.7s
[2018-08-11 12:01:08,865 INFO] test_ppl: 202.07194
[2018-08-11 12:10:28,346 INFO] -------------

(explanation: following above setting ,updating bias)
[2018-08-11 12:10:28,346 INFO] Start training...
[2018-08-11 12:10:28,346 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 12:10:39,566 INFO] train token: 2127402
[2018-08-11 12:10:39,566 INFO] test token: 250140
[2018-08-11 12:10:39,566 INFO] valid token: 221606
[2018-08-11 12:10:39,710 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 12:11:04,395 INFO] | epoch   1 | train_loss  5.50 | val_ppl 205.60689 | time  21.4s
[2018-08-11 12:11:25,967 INFO] | epoch   2 | train_loss  5.23 | val_ppl 184.87383 | time  21.6s
[2018-08-11 12:11:47,460 INFO] | epoch   3 | train_loss  5.13 | val_ppl 176.79595 | time  21.5s
[2018-08-11 12:12:08,994 INFO] | epoch   4 | train_loss  5.07 | val_ppl 172.47004 | time  21.5s
[2018-08-11 12:12:30,035 INFO] | epoch   5 | train_loss  5.02 | val_ppl 169.36231 | time  21.0s
[2018-08-11 12:12:51,509 INFO] | epoch   6 | train_loss  4.98 | val_ppl 167.69087 | time  21.5s
[2018-08-11 12:13:12,369 INFO] | epoch   7 | train_loss  4.95 | val_ppl 166.89307 | time  20.9s
[2018-08-11 12:13:33,561 INFO] | epoch   8 | train_loss  4.92 | val_ppl 166.55194 | time  21.2s
[2018-08-11 12:13:34,523 INFO] test_ppl: 160.89592
[2018-08-11 12:23:11,616 INFO] -------------

(explanation: norm hidden, and norm fixed out emb)
[2018-08-11 12:23:11,616 INFO] Start training...
[2018-08-11 12:23:11,616 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 12:23:23,430 INFO] train token: 2127402
[2018-08-11 12:23:23,430 INFO] test token: 250140
[2018-08-11 12:23:23,431 INFO] valid token: 221606
[2018-08-11 12:23:23,664 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 12:23:48,735 INFO] | epoch   1 | train_loss  9.15 | val_ppl 9215.55642 | time  21.1s
[2018-08-11 12:24:09,707 INFO] | epoch   2 | train_loss  9.13 | val_ppl 9158.74265 | time  21.0s
[2018-08-11 12:24:30,987 INFO] | epoch   3 | train_loss  9.13 | val_ppl 9132.80471 | time  21.3s
[2018-08-11 12:24:51,834 INFO] | epoch   4 | train_loss  9.12 | val_ppl 9107.43428 | time  20.8s
[2018-08-11 12:25:13,540 INFO] | epoch   5 | train_loss  9.12 | val_ppl 9082.90436 | time  21.7s
[2018-08-11 12:25:34,020 INFO] | epoch   6 | train_loss  9.12 | val_ppl 9064.22266 | time  20.5s
[2018-08-11 12:25:54,297 INFO] | epoch   7 | train_loss  9.12 | val_ppl 9051.11456 | time  20.3s
[2018-08-11 12:26:15,181 INFO] | epoch   8 | train_loss  9.11 | val_ppl 9039.41527 | time  20.9s
[2018-08-11 12:26:16,114 INFO] test_ppl: 8990.28242

(same as above, updating normed emb. norm is only done at start)
[2018-08-11 12:27:20,148 INFO] -------------
[2018-08-11 12:27:20,148 INFO] Start training...
[2018-08-11 12:27:20,148 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 12:27:31,261 INFO] train token: 2127402
[2018-08-11 12:27:31,261 INFO] test token: 250140
[2018-08-11 12:27:31,261 INFO] valid token: 221606
[2018-08-11 12:27:31,405 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 12:27:57,805 INFO] | epoch   1 | train_loss  5.74 | val_ppl 220.63858 | time  23.0s
[2018-08-11 12:28:20,458 INFO] | epoch   2 | train_loss  5.36 | val_ppl 187.76345 | time  22.7s
[2018-08-11 12:28:43,665 INFO] | epoch   3 | train_loss  5.23 | val_ppl 171.58674 | time  23.2s
[2018-08-11 12:29:07,140 INFO] | epoch   4 | train_loss  5.15 | val_ppl 161.98186 | time  23.5s
[2018-08-11 12:29:30,515 INFO] | epoch   5 | train_loss  5.09 | val_ppl 155.08981 | time  23.4s
[2018-08-11 12:29:53,424 INFO] | epoch   6 | train_loss  5.04 | val_ppl 149.91193 | time  22.9s
[2018-08-11 12:30:16,597 INFO] | epoch   7 | train_loss  5.00 | val_ppl 145.86725 | time  23.2s
[2018-08-11 12:30:39,851 INFO] | epoch   8 | train_loss  4.97 | val_ppl 142.65083 | time  23.3s
[2018-08-11 12:30:40,802 INFO] test_ppl: 138.79193
[2018-08-11 13:00:50,147 INFO] -------------

(explanation: very standard. but norm pretrained out emb only at the start. note it's better than
non-norm)
[2018-08-11 13:00:50,148 INFO] Start training...
[2018-08-11 13:00:50,148 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 13:01:01,498 INFO] train token: 2127402
[2018-08-11 13:01:01,498 INFO] test token: 250140
[2018-08-11 13:01:01,498 INFO] valid token: 221606
[2018-08-11 13:01:01,641 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 13:01:27,496 INFO] | epoch   1 | train_loss  5.02 | val_ppl 134.90114 | time  22.5s
[2018-08-11 13:01:49,384 INFO] | epoch   2 | train_loss  4.75 | val_ppl 121.95061 | time  21.9s
[2018-08-11 13:02:11,900 INFO] | epoch   3 | train_loss  4.64 | val_ppl 116.06429 | time  22.5s
[2018-08-11 13:02:34,016 INFO] | epoch   4 | train_loss  4.57 | val_ppl 112.46828 | time  22.1s
[2018-08-11 13:02:56,513 INFO] | epoch   5 | train_loss  4.51 | val_ppl 110.15242 | time  22.5s
[2018-08-11 13:03:19,218 INFO] | epoch   6 | train_loss  4.47 | val_ppl 108.63990 | time  22.7s
[2018-08-11 13:03:41,388 INFO] | epoch   7 | train_loss  4.43 | val_ppl 107.69256 | time  22.2s
[2018-08-11 13:04:03,769 INFO] | epoch   8 | train_loss  4.39 | val_ppl 107.06490 | time  22.4s
[2018-08-11 13:04:04,630 INFO] test_ppl: 102.58162
[2018-08-11 13:12:22,848 INFO] -------------

(explanation: using the above pretrained out emb. convergence is faster but the final result keeps
same, the random seed is 0 at default)
[2018-08-11 13:12:22,848 INFO] Start training...
[2018-08-11 13:12:22,848 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 13:12:34,108 INFO] train token: 2127402
[2018-08-11 13:12:34,108 INFO] test token: 250140
[2018-08-11 13:12:34,108 INFO] valid token: 221606
[2018-08-11 13:12:34,251 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 13:13:00,180 INFO] | epoch   1 | train_loss  4.65 | val_ppl 115.26202 | time  22.0s
[2018-08-11 13:13:22,113 INFO] | epoch   2 | train_loss  4.50 | val_ppl 110.10633 | time  21.9s
[2018-08-11 13:13:44,565 INFO] | epoch   3 | train_loss  4.44 | val_ppl 107.72182 | time  22.5s
[2018-08-11 13:14:07,534 INFO] | epoch   4 | train_loss  4.39 | val_ppl 106.52273 | time  23.0s
[2018-08-11 13:14:29,769 INFO] | epoch   5 | train_loss  4.36 | val_ppl 105.91639 | time  22.2s
[2018-08-11 13:14:52,266 INFO] | epoch   6 | train_loss  4.33 | val_ppl 105.59615 | time  22.5s
[2018-08-11 13:15:14,607 INFO] | epoch   7 | train_loss  4.30 | val_ppl 105.50029 | time  22.3s
[2018-08-11 13:15:37,100 INFO] | epoch   8 | train_loss  4.27 | val_ppl 105.59313 | time  22.5s
[2018-08-11 13:15:38,098 INFO] test_ppl: 101.27162
[2018-08-11 13:17:06,753 INFO] -------------
[2018-08-11 13:17:06,753 INFO] Start training...

(explanation: using the above pretrained out emb. but keep fixed out emb. good result. preprae to
change the seed)
[2018-08-11 13:17:06,753 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 13:17:18,100 INFO] train token: 2127402
[2018-08-11 13:17:18,100 INFO] test token: 250140
[2018-08-11 13:17:18,100 INFO] valid token: 221606
[2018-08-11 13:17:18,242 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 13:17:42,749 INFO] | epoch   1 | train_loss  4.68 | val_ppl 112.72466 | time  20.4s
[2018-08-11 13:18:02,840 INFO] | epoch   2 | train_loss  4.53 | val_ppl 107.48921 | time  20.1s
[2018-08-11 13:18:23,101 INFO] | epoch   3 | train_loss  4.47 | val_ppl 105.31551 | time  20.3s
[2018-08-11 13:18:43,373 INFO] | epoch   4 | train_loss  4.44 | val_ppl 104.21897 | time  20.3s
[2018-08-11 13:19:03,549 INFO] | epoch   5 | train_loss  4.42 | val_ppl 103.66151 | time  20.2s
[2018-08-11 13:19:23,560 INFO] | epoch   6 | train_loss  4.40 | val_ppl 103.42313 | time  20.0s
[2018-08-11 13:19:44,342 INFO] | epoch   7 | train_loss  4.38 | val_ppl 103.29771 | time  20.8s
[2018-08-11 13:20:03,684 INFO] | epoch   8 | train_loss  4.37 | val_ppl 103.26707 | time  19.3s
[2018-08-11 13:20:04,560 INFO] test_ppl: 99.43876
[2018-08-11 13:21:46,779 INFO] -------------


(explanation: change seed. also keep fixed)
[2018-08-11 13:21:46,779 INFO] Start training...
[2018-08-11 13:21:46,780 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=10, tied=False, vector_type='glove.6B.100d')
[2018-08-11 13:21:57,939 INFO] train token: 2127402
[2018-08-11 13:21:57,939 INFO] test token: 250140
[2018-08-11 13:21:57,939 INFO] valid token: 221606
[2018-08-11 13:21:58,084 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 13:22:22,159 INFO] | epoch   1 | train_loss  4.69 | val_ppl 113.21638 | time  20.1s
[2018-08-11 13:22:42,222 INFO] | epoch   2 | train_loss  4.53 | val_ppl 107.68032 | time  20.1s
[2018-08-11 13:23:02,361 INFO] | epoch   3 | train_loss  4.48 | val_ppl 105.51221 | time  20.1s
[2018-08-11 13:23:22,120 INFO] | epoch   4 | train_loss  4.44 | val_ppl 104.41606 | time  19.8s
[2018-08-11 13:23:41,592 INFO] | epoch   5 | train_loss  4.42 | val_ppl 103.77690 | time  19.5s
[2018-08-11 13:24:01,753 INFO] | epoch   6 | train_loss  4.40 | val_ppl 103.42696 | time  20.2s
[2018-08-11 13:24:21,934 INFO] | epoch   7 | train_loss  4.38 | val_ppl 103.27184 | time  20.2s
[2018-08-11 13:24:41,712 INFO] | epoch   8 | train_loss  4.37 | val_ppl 103.23466 | time  19.8s
[2018-08-11 13:24:42,595 INFO] test_ppl: 99.29384

(continue to change the seed)
[2018-08-11 13:27:20,508 INFO] -------------
[2018-08-11 13:27:20,508 INFO] Start training...
[2018-08-11 13:27:20,508 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=100, tied=False, vector_type='glove.6B.100d')
[2018-08-11 13:27:31,661 INFO] train token: 2127402
[2018-08-11 13:27:31,661 INFO] test token: 250140
[2018-08-11 13:27:31,661 INFO] valid token: 221606
[2018-08-11 13:27:31,804 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 13:27:55,863 INFO] | epoch   1 | train_loss  4.69 | val_ppl 113.05575 | time  20.1s
[2018-08-11 13:28:15,902 INFO] | epoch   2 | train_loss  4.53 | val_ppl 107.66544 | time  20.0s
[2018-08-11 13:28:31,819 INFO] -------------
[2018-08-11 13:28:31,820 INFO] Start training...
[2018-08-11 13:28:31,820 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=4, tied=False, vector_type='glove.6B.100d')
[2018-08-11 13:28:43,686 INFO] train token: 2127402
[2018-08-11 13:28:43,687 INFO] test token: 250140
[2018-08-11 13:28:43,687 INFO] valid token: 221606
[2018-08-11 13:28:43,917 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 13:29:08,846 INFO] | epoch   1 | train_loss  4.69 | val_ppl 113.29452 | time  20.0s
[2018-08-11 13:29:29,050 INFO] | epoch   2 | train_loss  4.53 | val_ppl 107.81881 | time  20.2s
[2018-08-11 13:35:34,447 INFO] -------------


(explanation: norm pretrained out emb at the start. and keep fixed)
[2018-08-11 13:35:34,448 INFO] Start training...
[2018-08-11 13:35:34,448 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=3, tied=False, vector_type='glove.6B.100d')
[2018-08-11 13:35:45,395 INFO] train token: 2127402
[2018-08-11 13:35:45,395 INFO] test token: 250140
[2018-08-11 13:35:45,395 INFO] valid token: 221606
[2018-08-11 13:35:45,538 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 13:36:09,685 INFO] | epoch   1 | train_loss  5.94 | val_ppl 359.35717 | time  19.9s
[2018-08-11 13:36:29,654 INFO] | epoch   2 | train_loss  5.82 | val_ppl 340.28645 | time  20.0s
[2018-08-11 13:36:50,377 INFO] | epoch   3 | train_loss  5.77 | val_ppl 329.54376 | time  20.7s
[2018-08-11 13:37:10,706 INFO] | epoch   4 | train_loss  5.74 | val_ppl 322.69101 | time  20.3s
[2018-08-11 13:37:30,906 INFO] | epoch   5 | train_loss  5.72 | val_ppl 317.95991 | time  20.2s
[2018-08-11 13:37:50,825 INFO] | epoch   6 | train_loss  5.70 | val_ppl 314.86632 | time  19.9s
[2018-08-11 13:38:10,834 INFO] | epoch   7 | train_loss  5.69 | val_ppl 312.33242 | time  20.0s
[2018-08-11 13:38:30,577 INFO] | epoch   8 | train_loss  5.68 | val_ppl 310.29353 | time  19.7s
[2018-08-11 13:38:31,589 INFO] test_ppl: 307.08927


(explanation: loss is simple dot product. output emb is that nnlm pretrained one and fixed. out emb
normed at the start)
[2018-08-12 13:38:36,794 INFO] -------------
[2018-08-12 13:38:36,795 INFO] Start training...
[2018-08-12 13:38:36,795 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=3, tied=False, vector_type='glove.6B.100d')
[2018-08-12 13:38:48,458 INFO] train token: 2127402
[2018-08-12 13:38:48,458 INFO] test token: 250140
[2018-08-12 13:38:48,458 INFO] valid token: 221606
[2018-08-12 13:38:48,601 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-12 13:39:11,139 INFO] | epoch   1 | train_loss -3.55 | val_ppl 902.03348 | time  18.6s
[2018-08-12 13:39:28,424 INFO] | epoch   2 | train_loss -3.70 | val_ppl 866.56355 | time  17.3s
[2018-08-12 13:39:45,747 INFO] | epoch   3 | train_loss -3.76 | val_ppl 845.51901 | time  17.3s
[2018-08-12 13:40:03,768 INFO] | epoch   4 | train_loss -3.80 | val_ppl 841.61535 | time  18.0s
[2018-08-12 13:40:22,131 INFO] | epoch   5 | train_loss -3.82 | val_ppl 819.03383 | time  18.4s
[2018-08-12 13:40:40,539 INFO] | epoch   6 | train_loss -3.84 | val_ppl 818.78845 | time  18.4s
[2018-08-12 13:40:58,867 INFO] | epoch   7 | train_loss -3.85 | val_ppl 809.34811 | time  18.3s
[2018-08-12 13:41:15,157 INFO] | epoch   8 | train_loss -3.87 | val_ppl 801.43664 | time  16.3s
[2018-08-12 13:41:16,123 INFO] test_ppl: 795.94193

(explanation: not norm compared with above. it seems norm is better. But for full softmax version,
when fixing, norm is bad. for this experiment, i guess when norming, the stride for a hidden unit
will be small and more suitable if you compare when full softmax when back-prop)
[2018-08-12 13:53:27,821 INFO] -------------
[2018-08-12 13:53:27,822 INFO] Start training...
[2018-08-12 13:53:27,822 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=3, tied=False, vector_type='glove.6B.100d')
[2018-08-12 13:53:39,090 INFO] train token: 2127402
[2018-08-12 13:53:39,091 INFO] test token: 250140
[2018-08-12 13:53:39,091 INFO] valid token: 221606
[2018-08-12 13:53:39,236 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-12 13:53:59,210 INFO] | epoch   1 | train_loss -10.42 | val_ppl 4703.98806 | time  16.0s
[2018-08-12 13:54:16,775 INFO] | epoch   2 | train_loss -10.78 | val_ppl 3909.26306 | time  17.6s
[2018-08-12 13:54:34,432 INFO] | epoch   3 | train_loss -10.89 | val_ppl 3547.13782 | time  17.7s

(explanation: norm both hidden and out emb at start. the result goes bwteen the two.)
[2018-08-12 14:00:25,822 INFO] -------------
[2018-08-12 14:00:25,823 INFO] Start training...
[2018-08-12 14:00:25,823 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=3, tied=False, vector_type='glove.6B.100d')
[2018-08-12 14:00:37,250 INFO] train token: 2127402
[2018-08-12 14:00:37,250 INFO] test token: 250140
[2018-08-12 14:00:37,250 INFO] valid token: 221606
[2018-08-12 14:00:37,395 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-12 14:00:59,944 INFO] | epoch   1 | train_loss -0.36 | val_ppl 1092.42733 | time  18.4s
[2018-08-12 14:01:18,524 INFO] | epoch   2 | train_loss -0.37 | val_ppl 1024.11733 | time  18.6s
[2018-08-12 14:01:38,811 INFO] | epoch   3 | train_loss -0.37 | val_ppl 990.05335 | time  20.3s
[2018-08-12 14:01:57,473 INFO] | epoch   4 | train_loss -0.37 | val_ppl 979.25515 | time  18.7s
[2018-08-12 14:02:16,616 INFO] | epoch   5 | train_loss -0.37 | val_ppl 965.26287 | time  19.1s
[2018-08-12 14:02:35,281 INFO] | epoch   6 | train_loss -0.37 | val_ppl 955.85656 | time  18.7s
[2018-08-12 14:02:53,052 INFO] | epoch   7 | train_loss -0.38 | val_ppl 931.40796 | time  17.8s
[2018-08-12 14:03:12,398 INFO] | epoch   8 | train_loss -0.38 | val_ppl 919.60420 | time  19.3s
[2018-08-12 14:03:13,277 INFO] test_ppl: 913.41454


-------------------back to full softmax

(explanation: randomly inited out emb but updating)
[2018-08-12 15:10:43,158 INFO] Start training...
[2018-08-12 15:10:43,158 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=3, tied=False, vector_type='glove.6B.100d')
[2018-08-12 15:10:54,353 INFO] train token: 2127402
[2018-08-12 15:10:54,354 INFO] test token: 250140
[2018-08-12 15:10:54,354 INFO] valid token: 221606
[2018-08-12 15:10:54,498 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-12 15:11:20,834 INFO] | epoch   1 | train_loss  5.22 | val_ppl 152.47683 | time  23.1s
[2018-08-12 15:11:43,099 INFO] | epoch   2 | train_loss  4.86 | val_ppl 133.09695 | time  22.3s
[2018-08-12 15:13:25,405 INFO] -------------

(explanation: randomly inited out emb and fixed)
[2018-08-12 15:13:25,405 INFO] Start training...
[2018-08-12 15:13:25,406 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=3, tied=False, vector_type='glove.6B.100d')
[2018-08-12 15:13:36,460 INFO] train token: 2127402
[2018-08-12 15:13:36,461 INFO] test token: 250140
[2018-08-12 15:13:36,461 INFO] valid token: 221606
[2018-08-12 15:13:36,603 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-12 15:13:59,873 INFO] | epoch   1 | train_loss  9.09 | val_ppl 8095.25724 | time  20.0s
[2018-08-12 15:14:19,652 INFO] | epoch   2 | train_loss  9.01 | val_ppl 7807.98528 | time  19.8s
[2018-08-12 15:14:38,841 INFO] | epoch   3 | train_loss  8.98 | val_ppl 7628.68300 | time  19.2s
[2018-08-12 15:14:58,953 INFO] | epoch   4 | train_loss  8.96 | val_ppl 7494.81667 | time  20.1s
[2018-08-12 15:15:18,921 INFO] | epoch   5 | train_loss  8.95 | val_ppl 7407.63110 | time  20.0s
[2018-08-12 15:15:39,257 INFO] | epoch   6 | train_loss  8.93 | val_ppl 7335.21253 | time  20.3s
[2018-08-12 15:15:59,558 INFO] | epoch   7 | train_loss  8.92 | val_ppl 7282.63652 | time  20.3s
[2018-08-12 15:16:19,543 INFO] | epoch   8 | train_loss  8.91 | val_ppl 7235.73265 | time  20.0s
[2018-08-12 15:16:20,424 INFO] test_ppl: 7238.00396
[2018-08-13 16:24:38,947 INFO] -------------


(using cbow pretrained, and updating. we see the iteration and convergence is not as good as
self-pretrained out emb)
[2018-08-13 16:24:38,947 INFO] Start training...
[2018-08-13 16:24:38,947 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=3, tied=False, vector_type='glove.6B.100d')
[2018-08-13 16:24:50,271 INFO] train token: 2127402
[2018-08-13 16:24:50,272 INFO] test token: 250140
[2018-08-13 16:24:50,272 INFO] valid token: 221606
[2018-08-13 16:24:50,416 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-13 16:25:15,438 INFO] | epoch   1 | train_loss  5.27 | val_ppl 165.04891 | time  21.7s
[2018-08-13 16:25:37,089 INFO] | epoch   2 | train_loss  4.95 | val_ppl 144.93556 | time  21.7s
[2018-08-13 16:25:58,673 INFO] | epoch   3 | train_loss  4.83 | val_ppl 135.73802 | time  21.6s
[2018-08-13 16:26:20,276 INFO] | epoch   4 | train_loss  4.75 | val_ppl 130.26771 | time  21.6s
[2018-08-13 16:26:41,811 INFO] | epoch   5 | train_loss  4.68 | val_ppl 126.51464 | time  21.5s
[2018-08-13 16:27:03,395 INFO] | epoch   6 | train_loss  4.63 | val_ppl 123.82593 | time  21.6s
[2018-08-13 16:27:25,024 INFO] | epoch   7 | train_loss  4.58 | val_ppl 121.83505 | time  21.6s
[2018-08-13 16:27:46,537 INFO] | epoch   8 | train_loss  4.54 | val_ppl 120.44894 | time  21.5s
[2018-08-13 16:27:47,502 INFO] test_ppl: 116.50455
[2018-08-13 16:52:38,523 INFO] -------------

(see the param, batch_size and bptt_len are changed. self-pretrained out emb is fixed. bad news. it
 is my falut. bug. ignore this log)
[2018-08-13 16:52:38,523 INFO] Start training...
[2018-08-13 16:52:38,523 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=13, tied=False, vector_type='glove.6B.100d')
[2018-08-13 16:52:49,536 INFO] train token: 2127402
[2018-08-13 16:52:49,536 INFO] test token: 250140
[2018-08-13 16:52:49,536 INFO] valid token: 221606
[2018-08-13 16:52:49,679 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-13 16:53:07,622 INFO] | epoch   1 | train_loss  9.18 | val_ppl 8721.82832 | time  13.8s
[2018-08-13 16:53:21,387 INFO] | epoch   2 | train_loss  9.09 | val_ppl 8403.62200 | time  13.8s
[2018-08-13 16:53:35,386 INFO] | epoch   3 | train_loss  9.06 | val_ppl 8196.37181 | time  14.0s
[2018-08-13 16:53:49,355 INFO] | epoch   4 | train_loss  9.04 | val_ppl 8035.85206 | time  14.0s
[2018-08-13 16:55:14,810 INFO] -------------

(strange. using cbow, fixing. better. so strange)
[2018-08-13 16:55:14,810 INFO] Start training...
[2018-08-13 16:55:14,810 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=13, tied=False, vector_type='glove.6B.100d')
[2018-08-13 16:55:25,824 INFO] train token: 2127402
[2018-08-13 16:55:25,824 INFO] test token: 250140
[2018-08-13 16:55:25,824 INFO] valid token: 221606
[2018-08-13 16:55:26,046 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-13 16:55:43,578 INFO] | epoch   1 | train_loss  5.80 | val_ppl 293.62222 | time  14.1s
[2018-08-13 16:55:57,461 INFO] | epoch   2 | train_loss  5.48 | val_ppl 251.13946 | time  13.9s
[2018-08-13 16:56:11,362 INFO] | epoch   3 | train_loss  5.37 | val_ppl 232.11815 | time  13.9s
[2018-08-13 16:56:25,285 INFO] | epoch   4 | train_loss  5.30 | val_ppl 222.09285 | time  13.9s
[2018-08-13 16:56:39,367 INFO] | epoch   5 | train_loss  5.25 | val_ppl 215.73520 | time  14.1s
[2018-08-13 16:56:53,416 INFO] | epoch   6 | train_loss  5.22 | val_ppl 211.88669 | time  14.0s
[2018-08-13 16:57:07,516 INFO] | epoch   7 | train_loss  5.18 | val_ppl 209.26152 | time  14.1s
[2018-08-13 16:57:21,564 INFO] | epoch   8 | train_loss  5.16 | val_ppl 207.60089 | time  14.0s
[2018-08-13 16:57:22,227 INFO] test_ppl: 199.19498
[2018-08-13 16:59:22,997 INFO] -------------

(self-pretrained out emb. fixed. normed at start)
[2018-08-13 16:59:22,997 INFO] Start training...
[2018-08-13 16:59:22,997 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=13, tied=False, vector_type='glove.6B.100d')
[2018-08-13 16:59:34,302 INFO] train token: 2127402
[2018-08-13 16:59:34,302 INFO] test token: 250140
[2018-08-13 16:59:34,302 INFO] valid token: 221606
[2018-08-13 16:59:34,446 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-13 16:59:52,571 INFO] | epoch   1 | train_loss  5.97 | val_ppl 364.23271 | time  14.3s
[2018-08-13 17:00:06,687 INFO] | epoch   2 | train_loss  5.85 | val_ppl 346.86880 | time  14.1s
[2018-08-13 17:00:20,755 INFO] | epoch   3 | train_loss  5.81 | val_ppl 336.85057 | time  14.1s
[2018-08-13 17:00:34,858 INFO] | epoch   4 | train_loss  5.78 | val_ppl 329.78721 | time  14.1s
[2018-08-13 17:05:20,052 INFO] -------------


(this using non-normed out pretrained emb. fixed. this exp can shows even though bptt and batch is
changed. pretrained out emb is still usefull)
[2018-08-13 17:05:20,052 INFO] Start training...
[2018-08-13 17:05:20,052 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=13, tied=False, vector_type='glove.6B.100d')
[2018-08-13 17:05:31,079 INFO] train token: 2127402
[2018-08-13 17:05:31,079 INFO] test token: 250140
[2018-08-13 17:05:31,080 INFO] valid token: 221606
[2018-08-13 17:05:31,304 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-13 17:05:49,265 INFO] | epoch   1 | train_loss  4.73 | val_ppl 112.73530 | time  13.8s
[2018-08-13 17:06:03,141 INFO] | epoch   2 | train_loss  4.56 | val_ppl 105.95881 | time  13.9s
[2018-08-13 17:06:17,245 INFO] | epoch   3 | train_loss  4.51 | val_ppl 102.51871 | time  14.1s
[2018-08-13 17:06:31,180 INFO] | epoch   4 | train_loss  4.47 | val_ppl 100.56969 | time  13.9s
[2018-08-13 17:06:45,098 INFO] | epoch   5 | train_loss  4.44 | val_ppl 99.31948 | time  13.9s
[2018-08-13 17:06:58,934 INFO] | epoch   6 | train_loss  4.42 | val_ppl 98.47506 | time  13.8s
[2018-08-13 17:07:12,717 INFO] | epoch   7 | train_loss  4.40 | val_ppl 97.88738 | time  13.8s
[2018-08-13 17:07:26,792 INFO] | epoch   8 | train_loss  4.39 | val_ppl 97.47671 | time  14.1s
[2018-08-13 17:07:27,471 INFO] test_ppl: 94.64213
[2018-08-13 17:09:44,318 INFO] -------------

(explanation: randomly update out emb)
[2018-08-13 17:09:44,319 INFO] Start training...
[2018-08-13 17:09:44,319 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=13, tied=False, vector_type='glove.6B.100d')
[2018-08-13 17:09:55,422 INFO] train token: 2127402
[2018-08-13 17:09:55,422 INFO] test token: 250140
[2018-08-13 17:09:55,422 INFO] valid token: 221606
[2018-08-13 17:09:55,565 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-13 17:10:14,933 INFO] | epoch   1 | train_loss  5.37 | val_ppl 182.90919 | time  16.0s
[2018-08-13 17:10:31,049 INFO] | epoch   2 | train_loss  4.98 | val_ppl 155.57486 | time  16.1s
[2018-08-13 17:10:47,181 INFO] | epoch   3 | train_loss  4.85 | val_ppl 140.24403 | time  16.1s
[2018-08-13 17:11:03,209 INFO] | epoch   4 | train_loss  4.76 | val_ppl 130.84001 | time  16.0s
[2018-08-13 17:11:19,271 INFO] | epoch   5 | train_loss  4.70 | val_ppl 124.66550 | time  16.1s
[2018-08-13 17:11:35,406 INFO] | epoch   6 | train_loss  4.64 | val_ppl 119.58827 | time  16.1s
[2018-08-13 17:11:51,487 INFO] | epoch   7 | train_loss  4.60 | val_ppl 115.53022 | time  16.1s
[2018-08-13 17:12:07,420 INFO] | epoch   8 | train_loss  4.56 | val_ppl 112.59746 | time  15.9s
[2018-08-13 17:12:08,084 INFO] test_ppl: 110.07493
[2018-08-14 00:26:35,867 INFO] -------------

(out emb updating. almost same with non-updating)
[2018-08-14 00:26:35,867 INFO] Start training...
[2018-08-14 00:26:35,867 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=13, tied=False, vector_type='glove.6B.100d')
[2018-08-14 00:26:46,793 INFO] train token: 2127402
[2018-08-14 00:26:46,793 INFO] test token: 250140
[2018-08-14 00:26:46,793 INFO] valid token: 221606
[2018-08-14 00:26:46,953 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 00:27:06,921 INFO] | epoch   1 | train_loss  4.70 | val_ppl 114.00223 | time  16.0s
[2018-08-14 00:27:22,702 INFO] | epoch   2 | train_loss  4.53 | val_ppl 106.66522 | time  15.8s
[2018-08-14 00:27:38,743 INFO] | epoch   3 | train_loss  4.46 | val_ppl 102.97266 | time  16.0s
[2018-08-14 00:27:54,870 INFO] | epoch   4 | train_loss  4.42 | val_ppl 100.83983 | time  16.1s
[2018-08-14 00:28:10,811 INFO] | epoch   5 | train_loss  4.38 | val_ppl 99.36605 | time  15.9s
[2018-08-14 00:28:26,703 INFO] | epoch   6 | train_loss  4.36 | val_ppl 98.32752 | time  15.9s
[2018-08-14 00:28:42,841 INFO] | epoch   7 | train_loss  4.33 | val_ppl 97.56077 | time  16.1s
[2018-08-14 00:28:58,964 INFO] | epoch   8 | train_loss  4.31 | val_ppl 96.98207 | time  16.1s
[2018-08-14 00:28:59,627 INFO] test_ppl: 94.79493
[2018-08-14 00:46:50,244 INFO] -------------

(change opt. validate)
[2018-08-14 01:03:04,358 INFO] Start training...
[2018-08-14 01:03:04,358 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=13, tied=False, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-14 01:03:15,982 INFO] train token: 2127402
[2018-08-14 01:03:15,982 INFO] test token: 250140
[2018-08-14 01:03:15,982 INFO] valid token: 221606
[2018-08-14 01:03:16,204 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 01:03:34,764 INFO] | epoch   1 | train_loss  4.73 | val_ppl 112.73530 | time  14.0s
[2018-08-14 01:03:48,707 INFO] | epoch   2 | train_loss  4.56 | val_ppl 105.95881 | time  13.9s
[2018-08-14 01:04:02,874 INFO] | epoch   3 | train_loss  4.51 | val_ppl 102.51871 | time  14.2s
[2018-08-14 01:04:16,761 INFO] | epoch   4 | train_loss  4.47 | val_ppl 100.56969 | time  13.9s
[2018-08-14 01:06:47,582 INFO] -------------
[2018-08-14 01:08:03,300 INFO] -------------
[2018-08-14 01:13:50,533 INFO] -------------
[2018-08-14 01:13:50,533 INFO] Start training...
[2018-08-14 01:13:50,533 INFO] Namespace(batch_size=50, bidirectional=False, bptt_len=3, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-14 01:14:02,070 INFO] train token: 2127402
[2018-08-14 01:14:02,071 INFO] test token: 250140
[2018-08-14 01:14:02,071 INFO] valid token: 221606
[2018-08-14 01:14:02,218 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 01:14:29,242 INFO] | epoch   1 | train_loss  5.27 | val_ppl 156.47944 | time  23.6s
[2018-08-14 01:14:52,701 INFO] | epoch   2 | train_loss  4.95 | val_ppl 140.95941 | time  23.5s
[2018-08-14 01:15:16,191 INFO] | epoch   3 | train_loss  4.84 | val_ppl 134.11807 | time  23.5s
[2018-08-14 01:15:40,139 INFO] | epoch   4 | train_loss  4.77 | val_ppl 130.37092 | time  23.9s
[2018-08-14 01:16:03,617 INFO] | epoch   5 | train_loss  4.72 | val_ppl 128.05745 | time  23.5s
[2018-08-14 01:16:27,464 INFO] | epoch   6 | train_loss  4.67 | val_ppl 126.60108 | time  23.8s
[2018-08-14 01:16:51,434 INFO] | epoch   7 | train_loss  4.64 | val_ppl 125.73044 | time  24.0s
[2018-08-14 01:17:15,374 INFO] | epoch   8 | train_loss  4.60 | val_ppl 125.26940 | time  23.9s
[2018-08-14 01:17:16,320 INFO] test_ppl: 122.01947
[2018-08-14 01:27:48,938 INFO] -------------

(3bpt trained, good result)
[2018-08-14 01:27:48,938 INFO] Start training...
[2018-08-14 01:27:48,938 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./3bptt_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=13, tied=False, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-14 01:27:59,994 INFO] train token: 2127402
[2018-08-14 01:27:59,995 INFO] test token: 250140
[2018-08-14 01:27:59,995 INFO] valid token: 221606
[2018-08-14 01:28:00,215 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 01:28:18,434 INFO] | epoch   1 | train_loss  4.77 | val_ppl 118.58513 | time  14.1s
[2018-08-14 01:28:32,339 INFO] | epoch   2 | train_loss  4.62 | val_ppl 111.69263 | time  13.9s
[2018-08-14 01:28:46,220 INFO] | epoch   3 | train_loss  4.57 | val_ppl 108.31642 | time  13.9s
[2018-08-14 01:29:00,198 INFO] | epoch   4 | train_loss  4.53 | val_ppl 106.34086 | time  14.0s
[2018-08-14 01:29:14,212 INFO] | epoch   5 | train_loss  4.51 | val_ppl 104.97084 | time  14.0s
[2018-08-14 01:29:28,159 INFO] | epoch   6 | train_loss  4.49 | val_ppl 104.04239 | time  13.9s
[2018-08-14 01:29:42,201 INFO] | epoch   7 | train_loss  4.47 | val_ppl 103.41987 | time  14.0s
[2018-08-14 01:29:56,000 INFO] | epoch   8 | train_loss  4.46 | val_ppl 102.98950 | time  13.8s
[2018-08-14 01:29:56,737 INFO] test_ppl: 100.35828
[2018-08-14 01:33:07,994 INFO] -------------

(change seed validate)
[2018-08-14 01:33:07,995 INFO] Start training...
[2018-08-14 01:33:07,995 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./3bptt_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=90, tied=False, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-14 01:33:19,014 INFO] train token: 2127402
[2018-08-14 01:33:19,014 INFO] test token: 250140
[2018-08-14 01:33:19,014 INFO] valid token: 221606
[2018-08-14 01:33:19,158 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 01:33:37,219 INFO] | epoch   1 | train_loss  4.78 | val_ppl 118.63744 | time  14.1s
[2018-08-14 01:33:51,135 INFO] | epoch   2 | train_loss  4.63 | val_ppl 111.69728 | time  13.9s
[2018-08-14 01:34:05,183 INFO] | epoch   3 | train_loss  4.57 | val_ppl 108.26682 | time  14.0s
[2018-08-14 01:34:19,139 INFO] | epoch   4 | train_loss  4.54 | val_ppl 106.25249 | time  14.0s
[2018-08-14 01:34:33,313 INFO] | epoch   5 | train_loss  4.51 | val_ppl 104.86318 | time  14.2s
[2018-08-14 01:34:46,999 INFO] | epoch   6 | train_loss  4.49 | val_ppl 103.95396 | time  13.7s
[2018-08-14 01:35:00,760 INFO] | epoch   7 | train_loss  4.47 | val_ppl 103.32631 | time  13.8s
[2018-08-14 01:35:14,692 INFO] | epoch   8 | train_loss  4.46 | val_ppl 102.86615 | time  13.9s
[2018-08-14 01:35:15,348 INFO] test_ppl: 100.31762
[2018-08-14 01:38:36,077 INFO] -------------

(updating out emb)
[2018-08-14 01:38:36,077 INFO] Start training...
[2018-08-14 01:38:36,077 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./3bptt_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=90, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-14 01:38:46,739 INFO] train token: 2127402
[2018-08-14 01:38:46,739 INFO] test token: 250140
[2018-08-14 01:38:46,739 INFO] valid token: 221606
[2018-08-14 01:38:46,881 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 01:39:06,903 INFO] | epoch   1 | train_loss  4.74 | val_ppl 120.00567 | time  16.0s
[2018-08-14 01:39:22,948 INFO] | epoch   2 | train_loss  4.57 | val_ppl 111.88744 | time  16.0s
[2018-08-14 01:39:38,970 INFO] | epoch   3 | train_loss  4.51 | val_ppl 108.00286 | time  16.0s
[2018-08-14 01:39:55,005 INFO] | epoch   4 | train_loss  4.46 | val_ppl 105.65375 | time  16.0s
[2018-08-14 01:40:11,221 INFO] | epoch   5 | train_loss  4.43 | val_ppl 103.91337 | time  16.2s
[2018-08-14 01:40:27,237 INFO] | epoch   6 | train_loss  4.40 | val_ppl 102.61590 | time  16.0s
[2018-08-14 01:40:43,376 INFO] | epoch   7 | train_loss  4.37 | val_ppl 101.64003 | time  16.1s
[2018-08-14 01:40:59,414 INFO] | epoch   8 | train_loss  4.35 | val_ppl 100.88852 | time  16.0s
[2018-08-14 01:41:00,161 INFO] test_ppl: 98.33608
[2018-08-14 01:44:12,508 INFO] -------------

(for generating)
[2018-08-14 01:44:12,508 INFO] Start training...
[2018-08-14 01:44:12,508 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=2, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=11, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-14 01:44:23,573 INFO] train token: 2127402
[2018-08-14 01:44:23,574 INFO] test token: 250140
[2018-08-14 01:44:23,574 INFO] valid token: 221606
[2018-08-14 01:44:23,717 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 01:45:23,474 INFO] | epoch   1 | train_loss  5.13 | val_ppl 159.03160 | time  56.3s
[2018-08-14 01:46:18,650 INFO] | epoch   2 | train_loss  4.86 | val_ppl 148.82331 | time  55.2s
[2018-08-14 01:47:13,750 INFO] | epoch   3 | train_loss  4.76 | val_ppl 146.30748 | time  55.1s
[2018-08-14 01:48:09,485 INFO] | epoch   4 | train_loss  4.69 | val_ppl 145.77872 | time  55.7s
[2018-08-14 01:49:05,616 INFO] | epoch   5 | train_loss  4.64 | val_ppl 146.43325 | time  56.1s
[2018-08-14 01:50:01,385 INFO] | epoch   6 | train_loss  4.60 | val_ppl 147.95566 | time  55.8s
[2018-08-14 01:50:56,995 INFO] | epoch   7 | train_loss  4.56 | val_ppl 149.79260 | time  55.6s
[2018-08-14 01:51:53,227 INFO] | epoch   8 | train_loss  4.52 | val_ppl 152.01536 | time  56.2s
[2018-08-14 01:51:55,161 INFO] test_ppl: 149.65753
[2018-08-14 01:53:08,285 INFO] -------------

(2bptt pretrained)
[2018-08-14 01:53:08,285 INFO] Start training...
[2018-08-14 01:53:08,285 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./2bptt_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=190, tied=False, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-14 01:53:19,366 INFO] train token: 2127402
[2018-08-14 01:53:19,366 INFO] test token: 250140
[2018-08-14 01:53:19,366 INFO] valid token: 221606
[2018-08-14 01:53:19,511 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 01:53:37,261 INFO] | epoch   1 | train_loss  4.77 | val_ppl 126.87310 | time  13.8s
[2018-08-14 01:53:50,993 INFO] | epoch   2 | train_loss  4.61 | val_ppl 118.57411 | time  13.7s
[2018-08-14 01:54:04,890 INFO] | epoch   3 | train_loss  4.55 | val_ppl 114.36236 | time  13.9s
[2018-08-14 01:54:19,013 INFO] | epoch   4 | train_loss  4.50 | val_ppl 112.01659 | time  14.1s
[2018-08-14 01:54:33,152 INFO] | epoch   5 | train_loss  4.47 | val_ppl 110.38251 | time  14.1s
[2018-08-14 01:54:47,151 INFO] | epoch   6 | train_loss  4.44 | val_ppl 109.36511 | time  14.0s
[2018-08-14 01:55:01,183 INFO] | epoch   7 | train_loss  4.42 | val_ppl 108.61115 | time  14.0s
[2018-08-14 01:55:15,054 INFO] | epoch   8 | train_loss  4.40 | val_ppl 108.11990 | time  13.9s
[2018-08-14 01:55:15,712 INFO] test_ppl: 106.21488
[2018-08-14 02:00:59,366 INFO] -------------
[2018-08-14 02:00:59,366 INFO] Start training...
[2018-08-14 02:00:59,366 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=3, device='cuda:0', dropout=0.0, epoch=2, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=11, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-14 02:01:10,404 INFO] train token: 2127402
[2018-08-14 02:01:10,404 INFO] test token: 250140
[2018-08-14 02:01:10,404 INFO] valid token: 221606
[2018-08-14 02:01:10,548 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 02:01:54,832 INFO] | epoch   1 | train_loss  5.14 | val_ppl 154.96312 | time  40.9s
[2018-08-14 02:02:36,001 INFO] | epoch   2 | train_loss  4.84 | val_ppl 141.18390 | time  41.2s
[2018-08-14 02:02:37,586 INFO] test_ppl: 138.59411
[2018-08-14 02:05:52,816 INFO] -------------
[2018-08-14 02:05:52,816 INFO] Start training...

(2epoch pretrained. good result)
[2018-08-14 02:05:52,816 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./3bptt_2epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=190, tied=False, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-14 02:06:04,327 INFO] train token: 2127402
[2018-08-14 02:06:04,327 INFO] test token: 250140
[2018-08-14 02:06:04,328 INFO] valid token: 221606
[2018-08-14 02:06:04,473 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 02:06:22,731 INFO] | epoch   1 | train_loss  4.87 | val_ppl 124.26746 | time  14.0s
[2018-08-14 02:06:36,678 INFO] | epoch   2 | train_loss  4.73 | val_ppl 117.67876 | time  13.9s
[2018-08-14 02:06:50,563 INFO] | epoch   3 | train_loss  4.68 | val_ppl 114.20064 | time  13.9s
[2018-08-14 02:07:04,496 INFO] | epoch   4 | train_loss  4.65 | val_ppl 112.10386 | time  13.9s
[2018-08-14 02:07:18,357 INFO] | epoch   5 | train_loss  4.63 | val_ppl 110.65113 | time  13.9s
[2018-08-14 02:07:32,403 INFO] | epoch   6 | train_loss  4.61 | val_ppl 109.63534 | time  14.0s
[2018-08-14 02:07:46,259 INFO] | epoch   7 | train_loss  4.60 | val_ppl 108.87460 | time  13.9s
[2018-08-14 02:08:00,294 INFO] | epoch   8 | train_loss  4.58 | val_ppl 108.31211 | time  14.0s
[2018-08-14 02:08:00,963 INFO] test_ppl: 106.19774
[2018-08-14 02:11:11,969 INFO] -------------

(update_out_emb)
[2018-08-14 02:11:11,969 INFO] Start training...
[2018-08-14 02:11:11,969 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./3bptt_2epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=190, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-14 02:11:23,125 INFO] train token: 2127402
[2018-08-14 02:11:23,125 INFO] test token: 250140
[2018-08-14 02:11:23,125 INFO] valid token: 221606
[2018-08-14 02:11:23,271 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 02:11:43,478 INFO] | epoch   1 | train_loss  4.81 | val_ppl 124.05484 | time  15.9s
[2018-08-14 02:11:59,322 INFO] | epoch   2 | train_loss  4.65 | val_ppl 115.16294 | time  15.8s
[2018-08-14 02:12:15,414 INFO] | epoch   3 | train_loss  4.58 | val_ppl 110.32851 | time  16.1s
[2018-08-14 02:12:31,272 INFO] | epoch   4 | train_loss  4.53 | val_ppl 107.24493 | time  15.9s
[2018-08-14 02:12:47,468 INFO] | epoch   5 | train_loss  4.49 | val_ppl 104.96506 | time  16.2s
[2018-08-14 02:13:03,595 INFO] | epoch   6 | train_loss  4.46 | val_ppl 103.24610 | time  16.1s
[2018-08-14 02:13:19,718 INFO] | epoch   7 | train_loss  4.43 | val_ppl 101.95085 | time  16.1s
[2018-08-14 02:13:35,734 INFO] | epoch   8 | train_loss  4.40 | val_ppl 100.97340 | time  16.0s
[2018-08-14 02:13:36,403 INFO] test_ppl: 98.82227
[2018-08-14 17:39:36,901 INFO] -------------
[2018-08-14 17:41:37,992 INFO] -------------

(mlp out emb. 200 dimension )
[2018-08-14 17:41:37,992 INFO] Start training...
[2018-08-14 17:41:37,992 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./2mlplen_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=191, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-14 17:41:48,976 INFO] train token: 2127402
[2018-08-14 17:41:48,977 INFO] test token: 250140
[2018-08-14 17:41:48,977 INFO] valid token: 221606
[2018-08-14 17:41:49,198 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 17:42:13,328 INFO] | epoch   1 | train_loss  4.77 | val_ppl 125.58400 | time  19.5s
[2018-08-14 17:42:33,169 INFO] | epoch   2 | train_loss  4.53 | val_ppl 113.92994 | time  19.8s
[2018-08-14 17:42:52,788 INFO] | epoch   3 | train_loss  4.43 | val_ppl 108.56970 | time  19.6s
[2018-08-14 17:43:12,503 INFO] | epoch   4 | train_loss  4.36 | val_ppl 105.55509 | time  19.7s
[2018-08-14 17:43:32,504 INFO] | epoch   5 | train_loss  4.30 | val_ppl 103.50520 | time  20.0s
[2018-08-14 17:43:52,332 INFO] | epoch   6 | train_loss  4.25 | val_ppl 102.10628 | time  19.8s
[2018-08-14 17:44:12,258 INFO] | epoch   7 | train_loss  4.21 | val_ppl 101.17461 | time  19.9s
[2018-08-14 17:44:32,130 INFO] | epoch   8 | train_loss  4.17 | val_ppl 100.57368 | time  19.9s
[2018-08-14 17:44:32,896 INFO] test_ppl: 98.56248
[2018-08-14 17:47:13,596 INFO] -------------

(1 mlp. result seems good)
[2018-08-14 17:47:13,596 INFO] Start training...
[2018-08-14 17:47:13,596 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./1mlplen_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=191, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-14 17:47:25,463 INFO] train token: 2127402
[2018-08-14 17:47:25,464 INFO] test token: 250140
[2018-08-14 17:47:25,464 INFO] valid token: 221606
[2018-08-14 17:47:25,705 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 17:47:46,296 INFO] | epoch   1 | train_loss  4.87 | val_ppl 129.96926 | time  16.2s
[2018-08-14 17:48:02,410 INFO] | epoch   2 | train_loss  4.67 | val_ppl 117.38232 | time  16.1s
[2018-08-14 17:48:18,387 INFO] | epoch   3 | train_loss  4.58 | val_ppl 111.38211 | time  16.0s
[2018-08-14 17:48:34,407 INFO] | epoch   4 | train_loss  4.52 | val_ppl 107.56873 | time  16.0s
[2018-08-14 17:48:50,505 INFO] | epoch   5 | train_loss  4.47 | val_ppl 105.11069 | time  16.1s
[2018-08-14 17:49:06,520 INFO] | epoch   6 | train_loss  4.43 | val_ppl 103.29662 | time  16.0s
[2018-08-14 17:49:22,607 INFO] | epoch   7 | train_loss  4.40 | val_ppl 101.94067 | time  16.1s
[2018-08-14 17:49:38,792 INFO] | epoch   8 | train_loss  4.37 | val_ppl 100.93084 | time  16.2s
[2018-08-14 17:49:39,459 INFO] test_ppl: 98.56323
[2018-08-14 17:55:23,063 INFO] -------------

(use out_emb_path to init input. at start, not good as cbow input emb. but final result same)
[2018-08-14 17:55:23,063 INFO] Start training...
[2018-08-14 17:55:23,063 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./1mlplen_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=191, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-14 17:55:34,543 INFO] train token: 2127402
[2018-08-14 17:55:34,543 INFO] test token: 250140
[2018-08-14 17:55:34,544 INFO] valid token: 221606
[2018-08-14 17:55:34,687 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 17:55:54,782 INFO] | epoch   1 | train_loss  5.07 | val_ppl 138.06361 | time  16.1s
[2018-08-14 17:56:10,959 INFO] | epoch   2 | train_loss  4.76 | val_ppl 122.75515 | time  16.2s
[2018-08-14 17:56:27,295 INFO] | epoch   3 | train_loss  4.64 | val_ppl 114.89150 | time  16.3s
[2018-08-14 17:56:43,581 INFO] | epoch   4 | train_loss  4.57 | val_ppl 109.95043 | time  16.3s
[2018-08-14 17:56:59,758 INFO] | epoch   5 | train_loss  4.51 | val_ppl 106.56374 | time  16.2s
[2018-08-14 17:57:16,101 INFO] | epoch   6 | train_loss  4.47 | val_ppl 104.05287 | time  16.3s
[2018-08-14 17:57:32,409 INFO] | epoch   7 | train_loss  4.43 | val_ppl 102.11651 | time  16.3s
[2018-08-14 17:57:48,588 INFO] | epoch   8 | train_loss  4.39 | val_ppl 100.61905 | time  16.2s
[2018-08-14 17:57:49,261 INFO] test_ppl: 98.61270
[2018-08-15 10:30:08,013 INFO] -------------
[2018-08-15 10:30:48,932 INFO] -------------
[2018-08-15 10:30:48,933 INFO] Start training...
[2018-08-15 10:30:48,933 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=6, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./2mlplen_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=11, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-15 10:31:00,581 INFO] train token: 2127402
[2018-08-15 10:31:00,582 INFO] test token: 250140
[2018-08-15 10:31:00,582 INFO] valid token: 221606
[2018-08-15 10:31:00,847 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-15 10:35:01,742 INFO] -------------


(explanation: this is comparison with torch-example result)
[2018-08-15 10:35:01,742 INFO] Start training...
[2018-08-15 10:35:01,742 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=6, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./2mlplen_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=11, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-15 10:35:12,929 INFO] train token: 2127402
[2018-08-15 10:35:12,929 INFO] test token: 250140
[2018-08-15 10:35:12,929 INFO] valid token: 221606
[2018-08-15 10:35:13,076 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-15 10:35:38,965 INFO] | epoch   1 | train_loss  4.98 | val_ppl 134.25213 | time  21.1s
[2018-08-15 10:36:00,214 INFO] | epoch   2 | train_loss  4.59 | val_ppl 116.35322 | time  21.2s
[2018-08-15 10:36:21,531 INFO] | epoch   3 | train_loss  4.48 | val_ppl 108.09905 | time  21.3s
[2018-08-15 10:36:42,912 INFO] | epoch   4 | train_loss  4.40 | val_ppl 103.00094 | time  21.4s
[2018-08-15 10:37:04,251 INFO] | epoch   5 | train_loss  4.34 | val_ppl 99.50944 | time  21.3s
[2018-08-15 10:37:25,597 INFO] | epoch   6 | train_loss  4.29 | val_ppl 96.95864 | time  21.3s
[2018-08-15 10:37:26,361 INFO] test_ppl: 93.23290
[2018-08-15 10:39:27,510 INFO] -------------

(I reduced bptt to original one to make sure the above good result is not caused by bptt. here is a
nother import point: maybe bptt longer in later training phrase is better)
[2018-08-15 10:39:27,510 INFO] Start training...
[2018-08-15 10:39:27,510 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=6, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./2mlplen_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=11, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-15 10:39:38,685 INFO] train token: 2127402
[2018-08-15 10:39:38,685 INFO] test token: 250140
[2018-08-15 10:39:38,685 INFO] valid token: 221606
[2018-08-15 10:39:38,833 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-15 10:40:10,357 INFO] | epoch   1 | train_loss  4.81 | val_ppl 120.22324 | time  26.8s
[2018-08-15 10:40:37,201 INFO] | epoch   2 | train_loss  4.51 | val_ppl 109.03083 | time  26.8s
[2018-08-15 10:41:04,054 INFO] | epoch   3 | train_loss  4.40 | val_ppl 104.09236 | time  26.9s
[2018-08-15 10:41:30,919 INFO] | epoch   4 | train_loss  4.32 | val_ppl 101.31761 | time  26.9s
[2018-08-15 10:41:57,884 INFO] | epoch   5 | train_loss  4.26 | val_ppl 99.56572 | time  27.0s
[2018-08-15 10:42:24,878 INFO] | epoch   6 | train_loss  4.21 | val_ppl 98.42463 | time  27.0s
[2018-08-15 10:42:25,820 INFO] test_ppl: 94.95294
[2018-08-15 10:46:51,125 INFO] -------------

(only 2 epochs already better than example)
[2018-08-15 10:46:51,125 INFO] Start training...
[2018-08-15 10:46:51,125 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=2, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./2mlplen_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=11, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-15 10:47:02,240 INFO] train token: 2127402
[2018-08-15 10:47:02,240 INFO] test token: 250140
[2018-08-15 10:47:02,240 INFO] valid token: 221606
[2018-08-15 10:47:02,386 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-15 10:47:33,861 INFO] | epoch   1 | train_loss  4.81 | val_ppl 120.22324 | time  26.7s
[2018-08-15 10:48:00,695 INFO] | epoch   2 | train_loss  4.51 | val_ppl 109.03083 | time  26.8s
[2018-08-15 10:48:01,712 INFO] test_ppl: 104.64654
[2018-08-15 11:04:15,178 INFO] -------------
[2018-08-15 11:04:15,178 INFO] Start training...
[2018-08-15 11:04:15,179 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=20, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./2mlplen_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=131, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-15 11:04:26,559 INFO] train token: 2127402
[2018-08-15 11:04:26,560 INFO] test token: 250140
[2018-08-15 11:04:26,560 INFO] valid token: 221606
[2018-08-15 11:04:26,707 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-15 11:04:52,961 INFO] | epoch   1 | train_loss  4.98 | val_ppl 136.07956 | time  21.1s
[2018-08-15 11:05:14,116 INFO] | epoch   2 | train_loss  4.60 | val_ppl 117.77344 | time  21.2s
[2018-08-15 11:05:35,458 INFO] | epoch   3 | train_loss  4.48 | val_ppl 109.66688 | time  21.3s
[2018-08-15 11:05:56,962 INFO] | epoch   4 | train_loss  4.40 | val_ppl 104.76385 | time  21.5s
[2018-08-15 11:06:18,310 INFO] | epoch   5 | train_loss  4.34 | val_ppl 101.30790 | time  21.3s
[2018-08-15 11:06:39,767 INFO] | epoch   6 | train_loss  4.29 | val_ppl 98.66735 | time  21.5s
[2018-08-15 11:07:01,114 INFO] | epoch   7 | train_loss  4.25 | val_ppl 96.53800 | time  21.3s
[2018-08-15 11:07:22,509 INFO] | epoch   8 | train_loss  4.21 | val_ppl 94.78180 | time  21.4s
[2018-08-15 11:07:43,873 INFO] | epoch   9 | train_loss  4.18 | val_ppl 93.30883 | time  21.4s
[2018-08-15 11:08:05,299 INFO] | epoch  10 | train_loss  4.15 | val_ppl 92.05666 | time  21.4s
[2018-08-15 11:08:26,735 INFO] | epoch  11 | train_loss  4.12 | val_ppl 90.98491 | time  21.4s
[2018-08-15 11:08:48,282 INFO] | epoch  12 | train_loss  4.09 | val_ppl 90.06722 | time  21.5s
[2018-08-15 11:09:09,768 INFO] | epoch  13 | train_loss  4.07 | val_ppl 89.28476 | time  21.5s
[2018-08-15 11:09:31,043 INFO] | epoch  14 | train_loss  4.05 | val_ppl 88.62257 | time  21.3s
[2018-08-15 11:09:51,678 INFO] | epoch  15 | train_loss  4.03 | val_ppl 88.06784 | time  20.6s
[2018-08-15 11:10:12,075 INFO] | epoch  16 | train_loss  4.00 | val_ppl 87.60946 | time  20.4s
[2018-08-15 11:10:32,352 INFO] | epoch  17 | train_loss  3.98 | val_ppl 87.23774 | time  20.3s
[2018-08-15 11:10:52,591 INFO] | epoch  18 | train_loss  3.97 | val_ppl 86.94408 | time  20.2s
[2018-08-15 11:11:12,743 INFO] | epoch  19 | train_loss  3.95 | val_ppl 86.72086 | time  20.2s
[2018-08-15 11:11:32,712 INFO] | epoch  20 | train_loss  3.93 | val_ppl 86.56128 | time  20.0s
[2018-08-15 11:11:33,545 INFO] test_ppl: 83.59881
[2018-08-15 16:21:54,251 INFO] -------------

(compare: this is training all from scratch)
[2018-08-15 16:21:54,252 INFO] Start training...
[2018-08-15 16:21:54,252 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=20, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=131, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-15 16:22:05,542 INFO] train token: 2127402
[2018-08-15 16:22:05,543 INFO] test token: 250140
[2018-08-15 16:22:05,543 INFO] valid token: 221606
[2018-08-15 16:22:05,691 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-15 16:22:31,053 INFO] | epoch   1 | train_loss  5.59 | val_ppl 230.11018 | time  18.5s
[2018-08-15 16:22:49,740 INFO] | epoch   2 | train_loss  5.09 | val_ppl 175.92646 | time  18.7s
[2018-08-15 16:23:08,577 INFO] | epoch   3 | train_loss  4.93 | val_ppl 155.14470 | time  18.8s
[2018-08-15 16:23:27,443 INFO] | epoch   4 | train_loss  4.83 | val_ppl 144.57571 | time  18.9s
[2018-08-15 16:23:46,234 INFO] | epoch   5 | train_loss  4.75 | val_ppl 137.43208 | time  18.8s
[2018-08-15 16:24:05,086 INFO] | epoch   6 | train_loss  4.69 | val_ppl 132.08146 | time  18.9s
[2018-08-15 16:24:24,075 INFO] | epoch   7 | train_loss  4.63 | val_ppl 127.57145 | time  19.0s
[2018-08-15 16:24:43,018 INFO] | epoch   8 | train_loss  4.59 | val_ppl 124.15321 | time  18.9s
[2018-08-15 16:25:01,997 INFO] | epoch   9 | train_loss  4.55 | val_ppl 121.72800 | time  19.0s
[2018-08-15 16:25:21,035 INFO] | epoch  10 | train_loss  4.51 | val_ppl 119.83254 | time  19.0s
[2018-08-15 16:25:40,169 INFO] | epoch  11 | train_loss  4.48 | val_ppl 118.21816 | time  19.1s
[2018-08-15 16:25:59,126 INFO] | epoch  12 | train_loss  4.45 | val_ppl 116.80247 | time  19.0s
[2018-08-15 16:26:18,040 INFO] | epoch  13 | train_loss  4.43 | val_ppl 115.78821 | time  18.9s
[2018-08-15 16:26:37,011 INFO] | epoch  14 | train_loss  4.40 | val_ppl 114.83463 | time  19.0s
[2018-08-15 16:26:56,025 INFO] | epoch  15 | train_loss  4.38 | val_ppl 114.06880 | time  19.0s
[2018-08-15 16:27:15,030 INFO] | epoch  16 | train_loss  4.36 | val_ppl 113.66757 | time  19.0s
[2018-08-15 16:27:33,946 INFO] | epoch  17 | train_loss  4.34 | val_ppl 113.20984 | time  18.9s
[2018-08-15 16:27:52,923 INFO] | epoch  18 | train_loss  4.32 | val_ppl 112.72291 | time  19.0s
[2018-08-15 16:28:11,815 INFO] | epoch  19 | train_loss  4.30 | val_ppl 112.57509 | time  18.9s
[2018-08-15 16:28:30,779 INFO] | epoch  20 | train_loss  4.29 | val_ppl 112.18042 | time  19.0s
[2018-08-15 16:28:31,485 INFO] test_ppl: 107.32168
[2018-08-15 16:38:36,673 INFO] -------------
[2018-08-15 16:38:36,673 INFO] Start training...
[2018-08-15 16:38:36,674 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=20, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='/home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.200d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=131, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-15 16:38:48,282 INFO] train token: 2127402
[2018-08-15 16:38:48,283 INFO] test token: 250140
[2018-08-15 16:38:48,283 INFO] valid token: 221606
[2018-08-15 16:38:48,428 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-15 16:43:49,356 INFO] -------------

input and output using cbow 200d. still bad. now i have a idea
[2018-08-15 16:43:49,356 INFO] Start training...
[2018-08-15 16:43:49,356 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=20, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='/home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.200d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=131, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-15 16:44:00,559 INFO] train token: 2127402
[2018-08-15 16:44:00,559 INFO] test token: 250140
[2018-08-15 16:44:00,559 INFO] valid token: 221606
[2018-08-15 16:44:00,704 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-15 16:44:24,077 INFO] | epoch   1 | train_loss  5.93 | val_ppl 249.74867 | time  18.6s
[2018-08-15 16:44:42,770 INFO] | epoch   2 | train_loss  5.31 | val_ppl 209.21213 | time  18.7s
[2018-08-15 16:45:01,570 INFO] | epoch   3 | train_loss  5.13 | val_ppl 181.43523 | time  18.8s
[2018-08-15 16:45:20,408 INFO] | epoch   4 | train_loss  5.02 | val_ppl 162.84359 | time  18.8s
[2018-08-15 16:45:39,320 INFO] | epoch   5 | train_loss  4.93 | val_ppl 150.38944 | time  18.9s
[2018-08-15 16:45:58,200 INFO] | epoch   6 | train_loss  4.86 | val_ppl 141.16442 | time  18.9s
[2018-08-15 16:46:17,171 INFO] | epoch   7 | train_loss  4.80 | val_ppl 134.22232 | time  19.0s
[2018-08-15 16:46:36,066 INFO] | epoch   8 | train_loss  4.75 | val_ppl 128.59292 | time  18.9s
[2018-08-15 16:46:55,051 INFO] | epoch   9 | train_loss  4.70 | val_ppl 123.87695 | time  19.0s
[2018-08-15 16:47:14,227 INFO] | epoch  10 | train_loss  4.65 | val_ppl 119.94257 | time  19.2s
[2018-08-15 16:47:33,234 INFO] | epoch  11 | train_loss  4.61 | val_ppl 116.57959 | time  19.0s
[2018-08-15 16:47:52,337 INFO] | epoch  12 | train_loss  4.57 | val_ppl 113.62566 | time  19.1s
[2018-08-15 16:48:11,248 INFO] | epoch  13 | train_loss  4.54 | val_ppl 111.13059 | time  18.9s
[2018-08-15 16:48:30,292 INFO] | epoch  14 | train_loss  4.51 | val_ppl 109.01028 | time  19.0s
[2018-08-15 16:48:49,318 INFO] | epoch  15 | train_loss  4.48 | val_ppl 107.14072 | time  19.0s
[2018-08-15 16:49:08,447 INFO] | epoch  16 | train_loss  4.45 | val_ppl 105.47412 | time  19.1s
[2018-08-15 16:49:27,712 INFO] | epoch  17 | train_loss  4.42 | val_ppl 103.98657 | time  19.3s
[2018-08-15 16:49:46,748 INFO] | epoch  18 | train_loss  4.40 | val_ppl 102.66219 | time  19.0s
[2018-08-15 16:50:05,840 INFO] | epoch  19 | train_loss  4.37 | val_ppl 101.47360 | time  19.1s
[2018-08-15 16:50:24,871 INFO] | epoch  20 | train_loss  4.35 | val_ppl 100.38955 | time  19.0s
[2018-08-15 16:50:25,579 INFO] test_ppl: 96.62703
[2018-08-17 15:58:09,339 INFO] -------------
[2018-08-17 16:05:33,164 INFO] -------------


(add learning rate decay. and tries to achieve the limit of the model)
[2018-08-17 16:05:33,164 INFO] Start training...
[2018-08-17 16:05:33,164 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=40, every_n_epoch_decay=15, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='../nnlm/2mlplen_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=231, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-17 16:05:44,956 INFO] train token: 2127402
[2018-08-17 16:05:44,957 INFO] test token: 250140
[2018-08-17 16:05:44,957 INFO] valid token: 221606
[2018-08-17 16:05:45,117 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-17 16:06:08,487 INFO] | epoch   1 | train_loss  4.94 | val_ppl 133.24670 | time  18.6s
[2018-08-17 16:06:27,327 INFO] | epoch   2 | train_loss  4.58 | val_ppl 115.62567 | time  18.8s
[2018-08-17 16:06:46,035 INFO] | epoch   3 | train_loss  4.46 | val_ppl 107.71218 | time  18.7s
[2018-08-17 16:07:04,972 INFO] | epoch   4 | train_loss  4.39 | val_ppl 102.94732 | time  18.9s
[2018-08-17 16:07:23,901 INFO] | epoch   5 | train_loss  4.33 | val_ppl 99.58792 | time  18.9s
[2018-08-17 16:07:42,808 INFO] | epoch   6 | train_loss  4.28 | val_ppl 97.14991 | time  18.9s
[2018-08-17 16:08:01,639 INFO] | epoch   7 | train_loss  4.24 | val_ppl 95.26966 | time  18.8s
[2018-08-17 16:08:20,492 INFO] | epoch   8 | train_loss  4.20 | val_ppl 93.74459 | time  18.9s
[2018-08-17 16:08:39,498 INFO] | epoch   9 | train_loss  4.17 | val_ppl 92.47227 | time  19.0s
[2018-08-17 16:08:58,584 INFO] | epoch  10 | train_loss  4.14 | val_ppl 91.39952 | time  19.1s
[2018-08-17 16:09:17,681 INFO] | epoch  11 | train_loss  4.11 | val_ppl 90.49338 | time  19.1s
[2018-08-17 16:09:36,498 INFO] | epoch  12 | train_loss  4.09 | val_ppl 89.72923 | time  18.8s
[2018-08-17 16:09:55,488 INFO] | epoch  13 | train_loss  4.07 | val_ppl 89.08651 | time  19.0s
[2018-08-17 16:10:14,445 INFO] | epoch  14 | train_loss  4.04 | val_ppl 88.54802 | time  19.0s
[2018-08-17 16:10:33,340 INFO] learning rate has been changed to 0.05
[2018-08-17 16:10:33,341 INFO] | epoch  15 | train_loss  4.02 | val_ppl 88.09980 | time  18.9s
[2018-08-17 16:10:52,383 INFO] | epoch  16 | train_loss  4.00 | val_ppl 81.10210 | time  19.0s
[2018-08-17 16:11:11,426 INFO] | epoch  17 | train_loss  3.99 | val_ppl 80.94908 | time  19.0s
[2018-08-17 16:11:30,281 INFO] | epoch  18 | train_loss  3.98 | val_ppl 80.88628 | time  18.9s
[2018-08-17 16:11:49,328 INFO] | epoch  19 | train_loss  3.98 | val_ppl 80.84831 | time  19.0s
[2018-08-17 16:12:08,309 INFO] | epoch  20 | train_loss  3.98 | val_ppl 80.82070 | time  19.0s
[2018-08-17 16:12:27,234 INFO] | epoch  21 | train_loss  3.97 | val_ppl 80.79836 | time  18.9s
[2018-08-17 16:12:46,223 INFO] | epoch  22 | train_loss  3.97 | val_ppl 80.77912 | time  19.0s
[2018-08-17 16:13:05,234 INFO] | epoch  23 | train_loss  3.97 | val_ppl 80.76189 | time  19.0s
[2018-08-17 16:13:24,262 INFO] | epoch  24 | train_loss  3.97 | val_ppl 80.74611 | time  19.0s
[2018-08-17 16:13:43,361 INFO] | epoch  25 | train_loss  3.96 | val_ppl 80.73145 | time  19.1s
[2018-08-17 16:14:02,400 INFO] | epoch  26 | train_loss  3.96 | val_ppl 80.71772 | time  19.0s
[2018-08-17 16:14:21,416 INFO] | epoch  27 | train_loss  3.96 | val_ppl 80.70480 | time  19.0s
[2018-08-17 16:14:40,325 INFO] | epoch  28 | train_loss  3.96 | val_ppl 80.69260 | time  18.9s
[2018-08-17 16:14:59,284 INFO] | epoch  29 | train_loss  3.95 | val_ppl 80.68109 | time  19.0s
[2018-08-17 16:15:18,459 INFO] learning rate has been changed to 0.005000000000000001
[2018-08-17 16:15:18,459 INFO] | epoch  30 | train_loss  3.95 | val_ppl 80.67021 | time  19.2s
[2018-08-17 16:15:37,381 INFO] | epoch  31 | train_loss  3.95 | val_ppl 79.76065 | time  18.9s
[2018-08-17 16:15:56,530 INFO] | epoch  32 | train_loss  3.95 | val_ppl 79.69372 | time  19.1s
[2018-08-17 16:16:15,570 INFO] | epoch  33 | train_loss  3.95 | val_ppl 79.66838 | time  19.0s
[2018-08-17 16:16:34,552 INFO] | epoch  34 | train_loss  3.95 | val_ppl 79.65570 | time  19.0s
[2018-08-17 16:16:53,511 INFO] | epoch  35 | train_loss  3.95 | val_ppl 79.64816 | time  19.0s
[2018-08-17 16:17:12,475 INFO] | epoch  36 | train_loss  3.95 | val_ppl 79.64305 | time  19.0s
[2018-08-17 16:17:31,550 INFO] | epoch  37 | train_loss  3.95 | val_ppl 79.63924 | time  19.1s
[2018-08-17 16:17:50,706 INFO] | epoch  38 | train_loss  3.95 | val_ppl 79.63617 | time  19.2s
[2018-08-17 16:18:09,646 INFO] | epoch  39 | train_loss  3.95 | val_ppl 79.63356 | time  18.9s
[2018-08-17 16:18:28,659 INFO] | epoch  40 | train_loss  3.95 | val_ppl 79.63125 | time  19.0s
[2018-08-17 16:18:28,660 INFO] start to save model on nnlm.model
[2018-08-17 16:18:30,009 INFO] test_ppl: 77.59396
[2018-08-17 16:27:43,713 INFO] -------------
[2018-08-17 16:41:52,692 INFO] -------------
[2018-08-17 16:45:42,428 INFO] -------------

(long epoch test. use pretrained outemb based one long epoch training)
[2018-08-17 16:45:42,429 INFO] Start training...
[2018-08-17 16:45:42,429 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=40, every_n_epoch_decay=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./35bptt_40epoch_outemb1st.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=500, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-17 16:45:53,563 INFO] train token: 2127402
[2018-08-17 16:45:53,563 INFO] test token: 250140
[2018-08-17 16:45:53,563 INFO] valid token: 221606
[2018-08-17 16:45:53,704 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-17 16:46:16,840 INFO] | epoch   1 | train_loss  4.81 | val_ppl 121.35807 | time  18.6s
[2018-08-17 16:46:35,611 INFO] | epoch   2 | train_loss  4.40 | val_ppl 104.97451 | time  18.8s
[2018-08-17 16:46:54,430 INFO] | epoch   3 | train_loss  4.29 | val_ppl 98.56207 | time  18.8s
[2018-08-17 16:47:13,273 INFO] | epoch   4 | train_loss  4.22 | val_ppl 94.98923 | time  18.8s
[2018-08-17 16:47:32,150 INFO] | epoch   5 | train_loss  4.17 | val_ppl 92.61660 | time  18.9s
[2018-08-17 16:47:50,936 INFO] | epoch   6 | train_loss  4.13 | val_ppl 90.89218 | time  18.8s
[2018-08-17 16:48:09,786 INFO] | epoch   7 | train_loss  4.09 | val_ppl 89.56602 | time  18.8s
[2018-08-17 16:48:28,834 INFO] learning rate has been changed to 0.15
[2018-08-17 16:48:28,835 INFO] | epoch   8 | train_loss  4.06 | val_ppl 88.51720 | time  19.0s
[2018-08-17 16:48:47,791 INFO] | epoch   9 | train_loss  4.03 | val_ppl 81.91565 | time  19.0s
[2018-08-17 16:49:06,774 INFO] | epoch  10 | train_loss  4.02 | val_ppl 81.71901 | time  19.0s
[2018-08-17 16:49:25,769 INFO] | epoch  11 | train_loss  4.01 | val_ppl 81.56188 | time  19.0s
[2018-08-17 16:49:44,774 INFO] | epoch  12 | train_loss  4.00 | val_ppl 81.42170 | time  19.0s
[2018-08-17 16:50:03,815 INFO] | epoch  13 | train_loss  3.99 | val_ppl 81.29376 | time  19.0s
[2018-08-17 16:50:22,832 INFO] | epoch  14 | train_loss  3.98 | val_ppl 81.17623 | time  19.0s
[2018-08-17 16:50:41,777 INFO] | epoch  15 | train_loss  3.98 | val_ppl 81.06814 | time  18.9s
[2018-08-17 16:51:00,739 INFO] learning rate has been changed to 0.045
[2018-08-17 16:51:00,739 INFO] | epoch  16 | train_loss  3.97 | val_ppl 80.96885 | time  19.0s
[2018-08-17 16:51:19,761 INFO] | epoch  17 | train_loss  3.97 | val_ppl 79.12312 | time  19.0s
[2018-08-17 16:51:38,702 INFO] | epoch  18 | train_loss  3.96 | val_ppl 79.06699 | time  18.9s
[2018-08-17 16:51:57,584 INFO] | epoch  19 | train_loss  3.96 | val_ppl 79.03215 | time  18.9s
[2018-08-17 16:52:16,461 INFO] | epoch  20 | train_loss  3.96 | val_ppl 79.00258 | time  18.9s
[2018-08-17 16:52:35,425 INFO] | epoch  21 | train_loss  3.95 | val_ppl 78.97524 | time  19.0s
[2018-08-17 16:52:54,359 INFO] | epoch  22 | train_loss  3.95 | val_ppl 78.94937 | time  18.9s
[2018-08-17 16:53:13,357 INFO] | epoch  23 | train_loss  3.95 | val_ppl 78.92454 | time  19.0s
[2018-08-17 16:53:32,303 INFO] learning rate has been changed to 0.013499999999999998
[2018-08-17 16:53:32,304 INFO] | epoch  24 | train_loss  3.95 | val_ppl 78.90067 | time  18.9s
[2018-08-17 16:53:51,235 INFO] | epoch  25 | train_loss  3.95 | val_ppl 78.13881 | time  18.9s
[2018-08-17 16:54:10,230 INFO] | epoch  26 | train_loss  3.95 | val_ppl 78.10903 | time  19.0s
[2018-08-17 16:54:29,295 INFO] | epoch  27 | train_loss  3.95 | val_ppl 78.09381 | time  19.1s
[2018-08-17 16:54:48,255 INFO] | epoch  28 | train_loss  3.95 | val_ppl 78.08252 | time  19.0s
[2018-08-17 16:55:07,324 INFO] | epoch  29 | train_loss  3.94 | val_ppl 78.07256 | time  19.1s
[2018-08-17 16:55:26,395 INFO] | epoch  30 | train_loss  3.94 | val_ppl 78.06372 | time  19.1s
[2018-08-17 16:55:45,332 INFO] | epoch  31 | train_loss  3.94 | val_ppl 78.05518 | time  18.9s
[2018-08-17 16:56:04,219 INFO] learning rate has been changed to 0.00405
[2018-08-17 16:56:04,220 INFO] | epoch  32 | train_loss  3.94 | val_ppl 78.04722 | time  18.9s
[2018-08-17 16:56:23,350 INFO] | epoch  33 | train_loss  3.94 | val_ppl 77.68514 | time  19.1s
[2018-08-17 16:56:42,291 INFO] | epoch  34 | train_loss  3.94 | val_ppl 77.66894 | time  18.9s
[2018-08-17 16:57:01,289 INFO] | epoch  35 | train_loss  3.94 | val_ppl 77.66148 | time  19.0s
[2018-08-17 16:57:20,209 INFO] | epoch  36 | train_loss  3.94 | val_ppl 77.65647 | time  18.9s
[2018-08-17 16:57:39,209 INFO] | epoch  37 | train_loss  3.94 | val_ppl 77.65245 | time  19.0s
[2018-08-17 16:57:58,054 INFO] | epoch  38 | train_loss  3.94 | val_ppl 77.64892 | time  18.8s
[2018-08-17 16:58:16,947 INFO] | epoch  39 | train_loss  3.94 | val_ppl 77.64568 | time  18.9s
[2018-08-17 16:58:35,989 INFO] learning rate has been changed to 0.0012149999999999997
[2018-08-17 16:58:35,990 INFO] | epoch  40 | train_loss  3.94 | val_ppl 77.64261 | time  19.0s
[2018-08-17 16:58:35,990 INFO] start to save model on nnlm.model
[2018-08-17 16:58:37,282 INFO] test_ppl: 75.71181
[2018-08-17 17:18:54,613 INFO] -------------
[2018-08-17 20:30:34,082 INFO] -------------


(explanation: varify whether teach bptt2 is good or not. it seems it's not necessary)
[2018-08-17 20:30:34,082 INFO] Start training...
[2018-08-17 20:30:34,082 INFO] Namespace(batch_size=100, bidirectional=False, bptt_len=2, device='cuda:0', dropout=0.0, epoch=13, every_n_epoch_decay=4, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='../nnlm/2mlplen_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=100, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-17 20:30:45,113 INFO] train token: 2127402
[2018-08-17 20:30:45,113 INFO] test token: 250140
[2018-08-17 20:30:45,113 INFO] valid token: 221606
[2018-08-17 20:30:45,255 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-17 20:31:14,504 INFO] | epoch   1 | train_loss  4.96 | val_ppl 139.16571 | time  24.5s
[2018-08-17 20:31:39,242 INFO] | epoch   2 | train_loss  4.76 | val_ppl 133.03108 | time  24.7s
[2018-08-17 20:32:04,037 INFO] | epoch   3 | train_loss  4.68 | val_ppl 130.45050 | time  24.8s
[2018-08-17 20:32:28,790 INFO] learning rate has been changed to 0.15
[2018-08-17 20:32:28,791 INFO] | epoch   4 | train_loss  4.63 | val_ppl 129.14171 | time  24.8s
[2018-08-17 20:32:53,395 INFO] | epoch   5 | train_loss  4.57 | val_ppl 125.64007 | time  24.6s
[2018-08-17 20:33:17,991 INFO] | epoch   6 | train_loss  4.55 | val_ppl 125.51234 | time  24.6s
[2018-08-17 20:33:42,900 INFO] | epoch   7 | train_loss  4.53 | val_ppl 125.46569 | time  24.9s
[2018-08-17 20:34:07,558 INFO] learning rate has been changed to 0.045
[2018-08-17 20:34:07,558 INFO] | epoch   8 | train_loss  4.52 | val_ppl 125.46514 | time  24.7s
[2018-08-17 20:34:32,327 INFO] | epoch   9 | train_loss  4.51 | val_ppl 123.49124 | time  24.8s
[2018-08-17 20:34:57,669 INFO] | epoch  10 | train_loss  4.50 | val_ppl 123.48624 | time  25.3s
[2018-08-17 20:35:22,755 INFO] | epoch  11 | train_loss  4.49 | val_ppl 123.50730 | time  25.1s
[2018-08-17 20:35:47,381 INFO] learning rate has been changed to 0.013499999999999998
[2018-08-17 20:35:47,382 INFO] | epoch  12 | train_loss  4.49 | val_ppl 123.53305 | time  24.6s
[2018-08-17 20:36:12,250 INFO] | epoch  13 | train_loss  4.49 | val_ppl 122.49116 | time  24.9s
[2018-08-17 20:36:13,140 INFO] test_ppl: 119.49927
[2018-08-17 20:39:08,940 INFO] -------------

(verify reduce learning rate frequency)
[2018-08-17 20:39:08,940 INFO] Start training...
[2018-08-17 20:39:08,940 INFO] Namespace(batch_size=100, bidirectional=False, bptt_len=2, device='cuda:0', dropout=0.0, epoch=30, every_n_epoch_decay=2, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='../nnlm/2mlplen_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=100, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-17 20:39:19,655 INFO] train token: 2127402
[2018-08-17 20:39:19,655 INFO] test token: 250140
[2018-08-17 20:39:19,655 INFO] valid token: 221606
[2018-08-17 20:39:19,797 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-17 20:39:48,708 INFO] | epoch   1 | train_loss  4.96 | val_ppl 139.16571 | time  24.2s
[2018-08-17 20:40:13,217 INFO] learning rate has been changed to 0.15
[2018-08-17 20:40:13,217 INFO] | epoch   2 | train_loss  4.76 | val_ppl 133.03108 | time  24.5s
[2018-08-17 20:40:37,603 INFO] | epoch   3 | train_loss  4.67 | val_ppl 128.56693 | time  24.4s
[2018-08-17 20:41:02,784 INFO] learning rate has been changed to 0.045
[2018-08-17 20:41:02,784 INFO] | epoch   4 | train_loss  4.65 | val_ppl 127.86226 | time  25.2s
[2018-08-17 20:41:27,433 INFO] | epoch   5 | train_loss  4.63 | val_ppl 125.71925 | time  24.6s
[2018-08-17 20:41:52,476 INFO] learning rate has been changed to 0.013499999999999998
[2018-08-17 20:41:52,477 INFO] | epoch   6 | train_loss  4.62 | val_ppl 125.52729 | time  25.0s
[2018-08-17 20:42:17,113 INFO] | epoch   7 | train_loss  4.61 | val_ppl 124.46328 | time  24.6s
[2018-08-17 20:42:41,744 INFO] learning rate has been changed to 0.00405
[2018-08-17 20:42:41,744 INFO] | epoch   8 | train_loss  4.61 | val_ppl 124.37626 | time  24.6s
[2018-08-17 20:43:06,518 INFO] | epoch   9 | train_loss  4.61 | val_ppl 124.04832 | time  24.8s
[2018-08-17 20:43:31,617 INFO] learning rate has been changed to 0.0012149999999999997
[2018-08-17 20:43:31,618 INFO] | epoch  10 | train_loss  4.61 | val_ppl 123.99628 | time  25.1s
[2018-08-17 20:43:56,286 INFO] | epoch  11 | train_loss  4.61 | val_ppl 123.96422 | time  24.7s
[2018-08-17 20:44:21,219 INFO] learning rate has been changed to 0.0003644999999999999
[2018-08-17 20:44:21,219 INFO] | epoch  12 | train_loss  4.61 | val_ppl 123.95292 | time  24.9s
[2018-08-17 20:44:46,154 INFO] | epoch  13 | train_loss  4.61 | val_ppl 123.95256 | time  24.9s
[2018-08-17 20:45:11,182 INFO] learning rate has been changed to 0.00010934999999999997
[2018-08-17 20:45:11,183 INFO] | epoch  14 | train_loss  4.61 | val_ppl 123.95866 | time  25.0s
[2018-08-17 20:48:55,528 INFO] -------------
[2018-08-17 20:48:55,528 INFO] Start training...
[2018-08-17 20:48:55,528 INFO] Namespace(batch_size=100, bidirectional=False, bptt_len=2, device='cuda:0', dropout=0.0, epoch=30, every_n_epoch_decay=2, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='../nnlm/2mlplen_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=100, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-17 20:49:07,081 INFO] train token: 2127402
[2018-08-17 20:49:07,081 INFO] test token: 250140
[2018-08-17 20:49:07,081 INFO] valid token: 221606
[2018-08-17 20:49:07,225 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-17 20:49:36,295 INFO] | epoch   1 | train_loss  4.96 | val_ppl 139.16571 | time  24.4s
[2018-08-17 20:50:00,778 INFO] learning rate has been changed to 0.25
[2018-08-17 20:50:00,779 INFO] | epoch   2 | train_loss  4.76 | val_ppl 133.03108 | time  24.5s
[2018-08-17 20:50:25,384 INFO] | epoch   3 | train_loss  4.67 | val_ppl 129.35671 | time  24.6s
[2018-08-17 20:50:50,055 INFO] learning rate has been changed to 0.125
[2018-08-17 20:50:50,056 INFO] | epoch   4 | train_loss  4.64 | val_ppl 128.42623 | time  24.7s
[2018-08-17 20:51:14,718 INFO] | epoch   5 | train_loss  4.60 | val_ppl 126.43208 | time  24.7s
[2018-08-17 20:51:39,543 INFO] learning rate has been changed to 0.0625
[2018-08-17 20:51:39,543 INFO] | epoch   6 | train_loss  4.59 | val_ppl 126.17141 | time  24.8s
[2018-08-17 20:52:04,108 INFO] | epoch   7 | train_loss  4.57 | val_ppl 124.86563 | time  24.6s
[2018-08-17 20:52:28,866 INFO] learning rate has been changed to 0.03125
[2018-08-17 20:52:28,866 INFO] | epoch   8 | train_loss  4.57 | val_ppl 124.76916 | time  24.8s
[2018-08-17 20:52:53,613 INFO] | epoch   9 | train_loss  4.56 | val_ppl 123.88228 | time  24.7s
[2018-08-17 20:53:18,483 INFO] learning rate has been changed to 0.015625
[2018-08-17 20:53:18,484 INFO] | epoch  10 | train_loss  4.55 | val_ppl 123.83465 | time  24.9s
[2018-08-17 20:53:43,434 INFO] | epoch  11 | train_loss  4.55 | val_ppl 123.23092 | time  24.9s
[2018-08-19 19:08:06,697 INFO] -------------
[2018-08-19 19:10:26,431 INFO] -------------
[2018-08-19 20:03:17,288 INFO] -------------


---------------------------------------------
-  trying to duplicate previous experiment  -
---------------------------------------------

(new lowered cbow, why so bad?)
[2018-08-19 20:03:17,288 INFO] Start training...
[2018-08-19 20:03:17,288 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=2, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 20:03:28,763 INFO] train token: 2127402
[2018-08-19 20:03:28,764 INFO] test token: 250140
[2018-08-19 20:03:28,764 INFO] valid token: 221606
[2018-08-19 20:03:28,764 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt.pt
[2018-08-19 20:03:46,170 INFO] | epoch   1 | train_loss  5.87 | val_ppl 299.07014 | time  13.3s
[2018-08-19 20:03:59,642 INFO] | epoch   2 | train_loss  5.54 | val_ppl 265.58214 | time  13.5s
[2018-08-19 20:04:13,062 INFO] | epoch   3 | train_loss  5.43 | val_ppl 246.37691 | time  13.4s
[2018-08-19 20:04:26,672 INFO] | epoch   4 | train_loss  5.34 | val_ppl 231.43115 | time  13.6s
[2018-08-19 20:04:40,253 INFO] | epoch   5 | train_loss  5.27 | val_ppl 220.21720 | time  13.6s
[2018-08-19 20:04:53,606 INFO] | epoch   6 | train_loss  5.21 | val_ppl 211.64234 | time  13.4s
[2018-08-19 20:05:07,293 INFO] | epoch   7 | train_loss  5.16 | val_ppl 204.96876 | time  13.7s
[2018-08-19 20:05:21,039 INFO] learning rate has been changed to 0.25
[2018-08-19 20:05:21,040 INFO] | epoch   8 | train_loss  5.11 | val_ppl 199.45869 | time  13.7s
[2018-08-19 20:05:21,706 INFO] test_ppl: 183.50683
[2018-08-19 20:07:45,066 INFO] -------------

(original cbow. still not good as previous. bpptlen is different. But here is a important thing.
when out emb is well pre-trained, long bptt give better ppl)
[2018-08-19 20:07:45,066 INFO] Start training...
[2018-08-19 20:07:45,067 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=2, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 20:07:56,464 INFO] train token: 2127402
[2018-08-19 20:07:56,464 INFO] test token: 250140
[2018-08-19 20:07:56,464 INFO] valid token: 221606
[2018-08-19 20:07:56,729 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt
[2018-08-19 20:07:56,734 WARNING] Skipping token 23380 with 1-dimensional vector ['100']; likely a header
[2018-08-19 20:07:57,570 INFO] Saving vectors to /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt.pt
[2018-08-19 20:08:16,556 INFO] | epoch   1 | train_loss  5.49 | val_ppl 204.08545 | time  14.5s
[2018-08-19 20:08:30,992 INFO] | epoch   2 | train_loss  5.10 | val_ppl 177.22877 | time  14.4s
[2018-08-19 20:08:45,326 INFO] | epoch   3 | train_loss  4.99 | val_ppl 162.45061 | time  14.3s
[2018-08-19 20:08:59,898 INFO] | epoch   4 | train_loss  4.90 | val_ppl 152.49020 | time  14.6s
[2018-08-19 20:09:14,379 INFO] | epoch   5 | train_loss  4.84 | val_ppl 145.09570 | time  14.5s
[2018-08-19 20:09:28,976 INFO] | epoch   6 | train_loss  4.78 | val_ppl 139.55051 | time  14.6s
[2018-08-19 20:09:43,668 INFO] | epoch   7 | train_loss  4.74 | val_ppl 135.34312 | time  14.7s
[2018-08-19 20:09:58,335 INFO] learning rate has been changed to 0.25
[2018-08-19 20:09:58,336 INFO] | epoch   8 | train_loss  4.70 | val_ppl 131.91110 | time  14.7s
[2018-08-19 20:09:58,946 INFO] test_ppl: 126.77791
[2018-08-19 20:14:13,598 INFO] -------------

(change seed as before. similary result is observed. The seed is important??. It should be the bptt
len)
[2018-08-19 20:14:13,599 INFO] Start training...
[2018-08-19 20:14:13,599 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 20:14:24,809 INFO] train token: 2127402
[2018-08-19 20:14:24,810 INFO] test token: 250140
[2018-08-19 20:14:24,810 INFO] valid token: 221606
[2018-08-19 20:14:24,811 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt.pt
[2018-08-19 20:14:51,621 INFO] | epoch   1 | train_loss  5.27 | val_ppl 165.09230 | time  22.7s
[2018-08-19 20:15:13,696 INFO] | epoch   2 | train_loss  4.96 | val_ppl 145.60978 | time  22.1s
[2018-08-19 20:15:36,008 INFO] | epoch   3 | train_loss  4.84 | val_ppl 136.41983 | time  22.3s
[2018-08-19 20:15:58,010 INFO] | epoch   4 | train_loss  4.76 | val_ppl 131.02124 | time  22.0s
[2018-08-19 20:16:20,492 INFO] | epoch   5 | train_loss  4.69 | val_ppl 127.32532 | time  22.5s
[2018-08-19 20:16:42,468 INFO] | epoch   6 | train_loss  4.64 | val_ppl 124.66468 | time  22.0s
[2018-08-19 20:17:04,832 INFO] | epoch   7 | train_loss  4.59 | val_ppl 122.66109 | time  22.4s
[2018-08-19 20:17:27,202 INFO] learning rate has been changed to 0.25
[2018-08-19 20:17:27,202 INFO] | epoch   8 | train_loss  4.55 | val_ppl 121.25213 | time  22.4s
[2018-08-19 20:17:28,069 INFO] test_ppl: 117.35846
[2018-08-19 20:21:03,169 INFO] -------------

(same seed. lowerd cbow. strange!!!)
[2018-08-19 20:21:03,169 INFO] Start training...
[2018-08-19 20:21:03,169 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 20:21:14,402 INFO] train token: 2127402
[2018-08-19 20:21:14,402 INFO] test token: 250140
[2018-08-19 20:21:14,402 INFO] valid token: 221606
[2018-08-19 20:21:14,403 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt.pt
[2018-08-19 20:21:39,941 INFO] | epoch   1 | train_loss  5.69 | val_ppl 253.20658 | time  21.5s
[2018-08-19 20:22:00,807 INFO] | epoch   2 | train_loss  5.39 | val_ppl 223.62686 | time  20.9s
[2018-08-19 20:22:22,591 INFO] | epoch   3 | train_loss  5.25 | val_ppl 209.25784 | time  21.8s
[2018-08-19 20:22:42,844 INFO] | epoch   4 | train_loss  5.14 | val_ppl 200.87544 | time  20.3s
[2018-08-19 20:23:03,673 INFO] | epoch   5 | train_loss  5.06 | val_ppl 195.63026 | time  20.8s
[2018-08-19 20:23:24,583 INFO] | epoch   6 | train_loss  4.99 | val_ppl 192.43315 | time  20.9s
[2018-08-19 20:23:45,991 INFO] | epoch   7 | train_loss  4.93 | val_ppl 190.48292 | time  21.4s
[2018-08-19 20:24:06,663 INFO] learning rate has been changed to 0.25
[2018-08-19 20:24:06,663 INFO] | epoch   8 | train_loss  4.87 | val_ppl 189.47014 | time  20.7s
[2018-08-19 20:24:07,476 INFO] test_ppl: 175.81078
[2018-08-19 20:29:11,795 INFO] -------------


(not because the learning rate)
[2018-08-19 20:29:11,795 INFO] Start training...
[2018-08-19 20:29:11,795 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt', log_file='log', lr=0.25, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 20:29:23,167 INFO] train token: 2127402
[2018-08-19 20:29:23,167 INFO] test token: 250140
[2018-08-19 20:29:23,167 INFO] valid token: 221606
[2018-08-19 20:29:23,168 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt.pt
[2018-08-19 20:29:48,202 INFO] | epoch   1 | train_loss  5.70 | val_ppl 255.48203 | time  20.9s
[2018-08-19 20:30:09,421 INFO] | epoch   2 | train_loss  5.46 | val_ppl 227.84849 | time  21.2s
[2018-08-19 20:31:40,476 INFO] -------------


[2018-08-19 20:31:40,476 INFO] Start training...
[2018-08-19 20:31:40,477 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=2, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 20:31:51,756 INFO] train token: 2127402
[2018-08-19 20:31:51,756 INFO] test token: 250140
[2018-08-19 20:31:51,757 INFO] valid token: 221606
[2018-08-19 20:31:51,758 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt.pt
[2018-08-19 20:32:17,956 INFO] | epoch   1 | train_loss  5.26 | val_ppl 164.25272 | time  22.0s
[2018-08-19 20:40:52,142 INFO] -------------

as expected, long bptt is good for init model
[2018-08-19 20:40:52,142 INFO] Start training...
[2018-08-19 20:40:52,142 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 20:41:03,673 INFO] train token: 2127402
[2018-08-19 20:41:03,673 INFO] test token: 250140
[2018-08-19 20:41:03,673 INFO] valid token: 221606
[2018-08-19 20:41:03,674 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt.pt
[2018-08-19 20:41:22,082 INFO] | epoch   1 | train_loss  5.57 | val_ppl 214.51320 | time  14.3s
[2018-08-19 20:41:36,265 INFO] | epoch   2 | train_loss  5.13 | val_ppl 181.98464 | time  14.2s
[2018-08-19 20:41:50,743 INFO] | epoch   3 | train_loss  5.00 | val_ppl 162.94709 | time  14.5s
[2018-08-19 20:42:05,147 INFO] | epoch   4 | train_loss  4.92 | val_ppl 150.74864 | time  14.4s
[2018-08-19 20:42:19,376 INFO] | epoch   5 | train_loss  4.85 | val_ppl 142.81045 | time  14.2s
[2018-08-19 20:42:34,055 INFO] | epoch   6 | train_loss  4.80 | val_ppl 137.34703 | time  14.7s
[2018-08-19 20:42:48,811 INFO] | epoch   7 | train_loss  4.75 | val_ppl 133.16450 | time  14.8s
[2018-08-19 20:43:03,259 INFO] learning rate has been changed to 0.25
[2018-08-19 20:43:03,260 INFO] | epoch   8 | train_loss  4.71 | val_ppl 129.74701 | time  14.4s
[2018-08-19 20:43:03,860 INFO] test_ppl: 125.02505
[2018-08-19 20:51:35,587 INFO] -------------


it's not big vocab which contains lots of never-meet words that give better ppl.
[2018-08-19 20:51:35,587 INFO] Start training...
[2018-08-19 20:51:35,587 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 20:51:46,908 INFO] train token: 2127402
[2018-08-19 20:51:46,908 INFO] test token: 250140
[2018-08-19 20:51:46,908 INFO] valid token: 221606
[2018-08-19 20:51:46,952 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt
[2018-08-19 20:51:47,788 INFO] Saving vectors to /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt.pt
[2018-08-19 20:52:15,346 INFO] | epoch   1 | train_loss  5.69 | val_ppl 253.35450 | time  23.0s
[2018-08-19 20:52:38,051 INFO] | epoch   2 | train_loss  5.39 | val_ppl 222.76986 | time  22.7s
[2018-08-19 20:53:00,491 INFO] | epoch   3 | train_loss  5.25 | val_ppl 209.24298 | time  22.4s
[2018-08-19 20:55:40,606 INFO] -------------
[2018-08-19 20:55:40,607 INFO] Start training...

this one. I set lower=False for field. But it turns out it will affect the quality as well
[2018-08-19 20:55:40,607 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 20:55:50,324 INFO] train token: 2127402
[2018-08-19 20:55:50,324 INFO] test token: 250140
[2018-08-19 20:55:50,324 INFO] valid token: 221606
[2018-08-19 20:55:50,324 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt.pt
[2018-08-19 20:56:08,929 INFO] | epoch   1 | train_loss  6.01 | val_ppl 326.61733 | time  14.4s
[2018-08-19 20:56:23,538 INFO] | epoch   2 | train_loss  5.61 | val_ppl 284.21094 | time  14.6s
[2018-08-19 20:56:38,283 INFO] | epoch   3 | train_loss  5.48 | val_ppl 257.42236 | time  14.7s
[2018-08-19 20:56:52,759 INFO] | epoch   4 | train_loss  5.39 | val_ppl 240.78045 | time  14.5s
[2018-08-19 20:57:07,263 INFO] | epoch   5 | train_loss  5.31 | val_ppl 229.33775 | time  14.5s
[2018-08-19 20:57:21,789 INFO] | epoch   6 | train_loss  5.25 | val_ppl 220.61904 | time  14.5s
[2018-08-19 20:57:36,477 INFO] | epoch   7 | train_loss  5.20 | val_ppl 213.54886 | time  14.7s
[2018-08-19 21:03:19,618 INFO] -------------

reset bptt to 10. but it still bad compared to lower=True
[2018-08-19 21:03:19,619 INFO] Start training...
[2018-08-19 21:03:19,619 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 21:03:29,600 INFO] train token: 2127402
[2018-08-19 21:03:29,600 INFO] test token: 250140
[2018-08-19 21:03:29,601 INFO] valid token: 221606
[2018-08-19 21:03:29,602 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt.pt
[2018-08-19 21:03:56,466 INFO] | epoch   1 | train_loss  5.74 | val_ppl 260.70944 | time  22.6s
[2018-08-19 21:04:18,916 INFO] | epoch   2 | train_loss  5.42 | val_ppl 229.32540 | time  22.4s
[2018-08-19 21:04:41,703 INFO] | epoch   3 | train_loss  5.27 | val_ppl 214.34622 | time  22.8s
[2018-08-19 21:05:03,719 INFO] | epoch   4 | train_loss  5.16 | val_ppl 206.09255 | time  22.0s
[2018-08-19 22:01:44,465 INFO] -------------
[2018-08-19 22:01:44,466 INFO] Start training...
[2018-08-19 22:01:44,466 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=874, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 22:01:55,791 INFO] train token: 2127402
[2018-08-19 22:01:55,791 INFO] test token: 250140
[2018-08-19 22:01:55,791 INFO] valid token: 221606
[2018-08-19 22:01:55,792 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt.pt
[2018-08-19 22:04:14,168 INFO] -------------

big training start
[2018-08-19 22:04:14,168 INFO] Start training...
[2018-08-19 22:04:14,169 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=874, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 22:04:25,463 INFO] train token: 2127402
[2018-08-19 22:04:25,464 INFO] test token: 250140
[2018-08-19 22:04:25,464 INFO] valid token: 221606
[2018-08-19 22:04:25,464 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt.pt
[2018-08-19 22:05:15,572 INFO] | epoch   1 | train_loss  4.94 | val_ppl 126.76808 | time  42.8s
[2018-08-19 22:05:58,882 INFO] | epoch   2 | train_loss  4.52 | val_ppl 111.97383 | time  43.3s
[2018-08-19 22:06:42,495 INFO] | epoch   3 | train_loss  4.40 | val_ppl 104.21964 | time  43.6s
[2018-08-19 22:07:26,160 INFO] | epoch   4 | train_loss  4.30 | val_ppl 99.54663 | time  43.7s
[2018-08-19 22:08:00,279 INFO] -------------
[2018-08-19 22:08:37,578 INFO] -------------
[2018-08-19 22:08:37,578 INFO] Start training...
[2018-08-19 22:08:37,578 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=80, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1074, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 22:08:49,040 INFO] train token: 2127402
[2018-08-19 22:08:49,041 INFO] test token: 250140
[2018-08-19 22:08:49,041 INFO] valid token: 221606
[2018-08-19 22:08:49,041 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt.pt
[2018-08-19 22:09:39,608 INFO] | epoch   1 | train_loss  4.89 | val_ppl 125.36983 | time  43.0s
[2018-08-19 22:10:23,100 INFO] | epoch   2 | train_loss  4.50 | val_ppl 111.11028 | time  43.5s
[2018-08-19 22:11:06,864 INFO] | epoch   3 | train_loss  4.38 | val_ppl 103.89130 | time  43.8s
[2018-08-19 22:11:50,598 INFO] | epoch   4 | train_loss  4.29 | val_ppl 99.38949 | time  43.7s
[2018-08-19 22:12:34,482 INFO] | epoch   5 | train_loss  4.21 | val_ppl 96.28414 | time  43.9s
[2018-08-19 22:13:18,330 INFO] | epoch   6 | train_loss  4.14 | val_ppl 94.04755 | time  43.8s
[2018-08-19 22:14:02,170 INFO] | epoch   7 | train_loss  4.08 | val_ppl 92.49147 | time  43.8s
[2018-08-19 22:14:46,087 INFO] learning rate has been changed to 0.25
[2018-08-19 22:14:46,088 INFO] | epoch   8 | train_loss  4.02 | val_ppl 91.47728 | time  43.9s
[2018-08-19 22:15:29,921 INFO] | epoch   9 | train_loss  3.94 | val_ppl 84.48646 | time  43.8s
[2018-08-19 22:16:13,837 INFO] | epoch  10 | train_loss  3.91 | val_ppl 84.51386 | time  43.9s
[2018-08-19 22:16:57,666 INFO] | epoch  11 | train_loss  3.88 | val_ppl 84.63713 | time  43.8s
[2018-08-19 22:17:41,483 INFO] | epoch  12 | train_loss  3.85 | val_ppl 84.84605 | time  43.8s
[2018-08-19 22:18:25,300 INFO] | epoch  13 | train_loss  3.82 | val_ppl 85.13900 | time  43.8s
[2018-08-19 22:19:09,147 INFO] | epoch  14 | train_loss  3.79 | val_ppl 85.51532 | time  43.8s
[2018-08-19 22:19:52,951 INFO] | epoch  15 | train_loss  3.76 | val_ppl 85.97497 | time  43.8s
[2018-08-19 22:20:36,821 INFO] learning rate has been changed to 0.125
[2018-08-19 22:20:36,822 INFO] | epoch  16 | train_loss  3.73 | val_ppl 86.51911 | time  43.9s
[2018-08-19 22:21:20,693 INFO] | epoch  17 | train_loss  3.70 | val_ppl 84.21341 | time  43.9s
[2018-08-19 22:22:04,518 INFO] | epoch  18 | train_loss  3.68 | val_ppl 84.57015 | time  43.8s
[2018-08-19 22:22:48,396 INFO] | epoch  19 | train_loss  3.66 | val_ppl 84.95681 | time  43.9s
[2018-08-19 22:23:32,347 INFO] | epoch  20 | train_loss  3.65 | val_ppl 85.36659 | time  43.9s
[2018-08-19 22:24:16,311 INFO] | epoch  21 | train_loss  3.63 | val_ppl 85.80026 | time  44.0s
[2018-08-19 22:25:00,260 INFO] | epoch  22 | train_loss  3.62 | val_ppl 86.25896 | time  43.9s
[2018-08-19 22:25:44,091 INFO] | epoch  23 | train_loss  3.60 | val_ppl 86.74371 | time  43.8s
[2018-08-19 22:26:28,044 INFO] learning rate has been changed to 0.0625
[2018-08-19 22:26:28,045 INFO] | epoch  24 | train_loss  3.59 | val_ppl 87.25539 | time  44.0s
[2018-08-19 22:27:11,867 INFO] | epoch  25 | train_loss  3.57 | val_ppl 86.12905 | time  43.8s
[2018-08-19 22:27:55,738 INFO] | epoch  26 | train_loss  3.56 | val_ppl 86.39265 | time  43.9s
[2018-08-19 22:28:39,539 INFO] | epoch  27 | train_loss  3.55 | val_ppl 86.67727 | time  43.8s
[2018-08-19 22:29:23,415 INFO] | epoch  28 | train_loss  3.54 | val_ppl 86.97264 | time  43.9s
[2018-08-19 22:30:07,270 INFO] | epoch  29 | train_loss  3.54 | val_ppl 87.27744 | time  43.9s
[2018-08-19 22:30:51,084 INFO] | epoch  30 | train_loss  3.53 | val_ppl 87.59146 | time  43.8s
[2018-08-19 22:31:34,958 INFO] | epoch  31 | train_loss  3.52 | val_ppl 87.91478 | time  43.9s
[2018-08-19 22:32:18,819 INFO] learning rate has been changed to 0.03125
[2018-08-19 22:32:18,820 INFO] | epoch  32 | train_loss  3.51 | val_ppl 88.24754 | time  43.9s
[2018-08-19 22:33:02,688 INFO] | epoch  33 | train_loss  3.51 | val_ppl 87.49839 | time  43.9s
[2018-08-19 22:37:50,250 INFO] -------------
[2018-08-19 22:37:50,251 INFO] Start training...
[2018-08-19 22:37:50,251 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:1', dropout=0.0, epoch=80, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1074, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 22:38:01,542 INFO] train token: 2127402
[2018-08-19 22:38:01,543 INFO] test token: 250140
[2018-08-19 22:38:01,543 INFO] valid token: 221606
[2018-08-19 22:38:01,543 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt.pt
[2018-08-19 22:38:56,956 INFO] | epoch   1 | train_loss  4.89 | val_ppl 125.36983 | time  44.1s
[2018-08-19 22:39:41,644 INFO] | epoch   2 | train_loss  4.50 | val_ppl 111.11028 | time  44.7s
[2018-08-19 22:40:27,238 INFO] | epoch   3 | train_loss  4.38 | val_ppl 103.89130 | time  45.6s
[2018-08-19 22:41:13,215 INFO] | epoch   4 | train_loss  4.29 | val_ppl 99.38949 | time  46.0s
[2018-08-19 22:41:59,386 INFO] | epoch   5 | train_loss  4.21 | val_ppl 96.28414 | time  46.2s
[2018-08-19 22:42:45,849 INFO] | epoch   6 | train_loss  4.14 | val_ppl 94.04755 | time  46.5s
[2018-08-19 22:43:32,402 INFO] | epoch   7 | train_loss  4.08 | val_ppl 92.49147 | time  46.6s
[2018-08-19 22:44:18,881 INFO] learning rate has been changed to 0.15
[2018-08-19 22:44:18,882 INFO] | epoch   8 | train_loss  4.02 | val_ppl 91.47728 | time  46.5s
[2018-08-19 22:45:05,631 INFO] | epoch   9 | train_loss  3.94 | val_ppl 82.34174 | time  46.7s
[2018-08-19 22:45:52,087 INFO] | epoch  10 | train_loss  3.91 | val_ppl 82.30018 | time  46.5s
[2018-08-19 22:46:38,819 INFO] | epoch  11 | train_loss  3.89 | val_ppl 82.33132 | time  46.7s
[2018-08-19 22:47:25,473 INFO] | epoch  12 | train_loss  3.87 | val_ppl 82.40259 | time  46.7s
[2018-08-19 22:48:12,059 INFO] | epoch  13 | train_loss  3.85 | val_ppl 82.50898 | time  46.6s
[2018-08-19 22:48:58,779 INFO] | epoch  14 | train_loss  3.84 | val_ppl 82.64904 | time  46.7s
[2018-08-19 22:49:45,424 INFO] | epoch  15 | train_loss  3.82 | val_ppl 82.82216 | time  46.6s
[2018-08-19 22:50:32,046 INFO] learning rate has been changed to 0.045
[2018-08-19 22:50:32,047 INFO] | epoch  16 | train_loss  3.80 | val_ppl 83.02801 | time  46.6s
[2018-08-19 22:51:18,598 INFO] | epoch  17 | train_loss  3.78 | val_ppl 80.78233 | time  46.6s
[2018-08-19 22:52:05,163 INFO] | epoch  18 | train_loss  3.77 | val_ppl 80.81645 | time  46.6s
[2018-08-19 22:52:51,762 INFO] | epoch  19 | train_loss  3.76 | val_ppl 80.88673 | time  46.6s
[2018-08-19 22:57:38,195 INFO] -------------

better than above on learning rate decay
[2018-08-19 22:57:38,195 INFO] Start training...
[2018-08-19 22:57:38,196 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=80, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1074, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 22:57:49,404 INFO] train token: 2127402
[2018-08-19 22:57:49,404 INFO] test token: 250140
[2018-08-19 22:57:49,404 INFO] valid token: 221606
[2018-08-19 22:57:49,405 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt.pt
[2018-08-19 22:58:44,376 INFO] | epoch   1 | train_loss  4.89 | val_ppl 125.36983 | time  43.9s
[2018-08-19 22:59:28,949 INFO] | epoch   2 | train_loss  4.50 | val_ppl 111.11028 | time  44.6s
[2018-08-19 23:00:14,145 INFO] | epoch   3 | train_loss  4.38 | val_ppl 103.89130 | time  45.2s
[2018-08-19 23:00:59,869 INFO] | epoch   4 | train_loss  4.29 | val_ppl 99.38949 | time  45.7s
[2018-08-19 23:01:45,735 INFO] | epoch   5 | train_loss  4.21 | val_ppl 96.28414 | time  45.9s
[2018-08-19 23:02:31,708 INFO] | epoch   6 | train_loss  4.14 | val_ppl 94.04755 | time  46.0s
[2018-08-19 23:03:18,076 INFO] | epoch   7 | train_loss  4.08 | val_ppl 92.49147 | time  46.4s
[2018-08-19 23:04:04,277 INFO] | epoch   8 | train_loss  4.02 | val_ppl 91.47728 | time  46.2s
[2018-08-19 23:04:50,665 INFO] learning rate has been changed to 0.013499999999999998
[2018-08-19 23:04:50,666 INFO] | epoch   9 | train_loss  3.96 | val_ppl 90.94896 | time  46.4s
[2018-08-19 23:05:37,183 INFO] | epoch  10 | train_loss  3.92 | val_ppl 79.86755 | time  46.5s
[2018-08-19 23:06:23,508 INFO] | epoch  11 | train_loss  3.89 | val_ppl 79.25296 | time  46.3s
[2018-08-19 23:07:10,117 INFO] learning rate has been changed to 0.00405
[2018-08-19 23:07:10,117 INFO] | epoch  12 | train_loss  3.88 | val_ppl 79.00183 | time  46.6s
[2018-08-19 23:07:56,572 INFO] | epoch  13 | train_loss  3.88 | val_ppl 78.63571 | time  46.5s
[2018-08-19 23:08:42,970 INFO] | epoch  14 | train_loss  3.88 | val_ppl 78.57319 | time  46.4s
[2018-08-19 23:09:29,340 INFO] learning rate has been changed to 0.0012149999999999997
[2018-08-19 23:09:29,340 INFO] | epoch  15 | train_loss  3.88 | val_ppl 78.53011 | time  46.4s
[2018-08-19 23:10:15,876 INFO] | epoch  16 | train_loss  3.88 | val_ppl 78.44988 | time  46.5s
[2018-08-19 23:11:02,358 INFO] | epoch  17 | train_loss  3.87 | val_ppl 78.42776 | time  46.5s
[2018-08-19 23:11:48,688 INFO] learning rate has been changed to 0.0003644999999999999
[2018-08-19 23:11:48,689 INFO] | epoch  18 | train_loss  3.87 | val_ppl 78.41371 | time  46.3s
[2018-08-19 23:12:35,164 INFO] | epoch  19 | train_loss  3.87 | val_ppl 78.40797 | time  46.5s
[2018-08-19 23:13:21,521 INFO] | epoch  20 | train_loss  3.87 | val_ppl 78.40193 | time  46.4s
[2018-08-19 23:14:07,928 INFO] learning rate has been changed to 0.00010934999999999997
[2018-08-19 23:14:07,928 INFO] | epoch  21 | train_loss  3.87 | val_ppl 78.39683 | time  46.4s
[2018-08-19 23:14:54,330 INFO] | epoch  22 | train_loss  3.87 | val_ppl 78.39579 | time  46.4s
[2018-08-19 23:15:40,773 INFO] | epoch  23 | train_loss  3.87 | val_ppl 78.39470 | time  46.4s
[2018-08-19 23:16:27,159 INFO] learning rate has been changed to 3.280499999999999e-05
[2018-08-19 23:16:27,160 INFO] | epoch  24 | train_loss  3.87 | val_ppl 78.39359 | time  46.4s
[2018-08-19 23:19:10,001 INFO] -------------

should be better than above. when using big input emb same as out.
but here the learning rate is 0.3
[2018-08-19 23:19:10,001 INFO] Start training...
[2018-08-19 23:19:10,001 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=80, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1074, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 23:19:21,200 INFO] train token: 2127402
[2018-08-19 23:19:21,200 INFO] test token: 250140
[2018-08-19 23:19:21,200 INFO] valid token: 221606
[2018-08-19 23:19:21,306 INFO] Loading vectors from /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt
[2018-08-19 23:19:21,309 WARNING] Skipping token 23381 with 1-dimensional vector ['650']; likely a header
[2018-08-19 23:19:25,825 INFO] Saving vectors to /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt.pt
[2018-08-19 23:20:27,981 INFO] | epoch   1 | train_loss  5.28 | val_ppl 143.42573 | time  49.4s
[2018-08-19 23:21:18,166 INFO] | epoch   2 | train_loss  4.64 | val_ppl 118.12046 | time  50.2s
[2018-08-19 23:22:09,183 INFO] | epoch   3 | train_loss  4.48 | val_ppl 106.46697 | time  51.0s
[2018-08-19 23:23:00,595 INFO] | epoch   4 | train_loss  4.36 | val_ppl 99.60619 | time  51.4s
[2018-08-19 23:23:52,025 INFO] | epoch   5 | train_loss  4.27 | val_ppl 94.94928 | time  51.4s
[2018-08-19 23:24:43,456 INFO] | epoch   6 | train_loss  4.20 | val_ppl 91.66289 | time  51.4s
[2018-08-19 23:25:35,078 INFO] | epoch   7 | train_loss  4.13 | val_ppl 89.35276 | time  51.6s
[2018-08-19 23:26:26,694 INFO] | epoch   8 | train_loss  4.07 | val_ppl 87.71917 | time  51.6s
[2018-08-19 23:27:18,352 INFO] learning rate has been changed to 0.013499999999999998
[2018-08-19 23:27:18,352 INFO] | epoch   9 | train_loss  4.01 | val_ppl 86.57244 | time  51.7s
[2018-08-19 23:28:10,111 INFO] | epoch  10 | train_loss  3.97 | val_ppl 77.05106 | time  51.8s
[2018-08-19 23:29:01,743 INFO] | epoch  11 | train_loss  3.95 | val_ppl 76.57816 | time  51.6s
[2018-08-19 23:29:53,632 INFO] learning rate has been changed to 0.00405
[2018-08-19 23:29:53,633 INFO] | epoch  12 | train_loss  3.94 | val_ppl 76.38391 | time  51.9s
[2018-08-19 23:30:45,320 INFO] | epoch  13 | train_loss  3.94 | val_ppl 75.96646 | time  51.7s
[2018-08-19 23:31:36,991 INFO] | epoch  14 | train_loss  3.94 | val_ppl 75.91234 | time  51.7s
[2018-08-19 23:32:28,771 INFO] learning rate has been changed to 0.0012149999999999997
[2018-08-19 23:32:28,772 INFO] | epoch  15 | train_loss  3.93 | val_ppl 75.87474 | time  51.8s
[2018-08-19 23:33:20,400 INFO] | epoch  16 | train_loss  3.93 | val_ppl 75.75914 | time  51.6s
[2018-08-19 23:34:12,132 INFO] | epoch  17 | train_loss  3.93 | val_ppl 75.73913 | time  51.7s
[2018-08-19 23:34:45,146 INFO] -------------
[2018-08-19 23:37:11,731 INFO] -------------
[2018-08-19 23:37:45,945 INFO] -------------
[2018-08-19 23:40:19,126 INFO] -------------
[2018-08-19 23:40:19,127 INFO] Start training...
[2018-08-19 23:40:19,127 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=104, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 23:40:30,436 INFO] train token: 2127402
[2018-08-19 23:40:30,436 INFO] test token: 250140
[2018-08-19 23:40:30,436 INFO] valid token: 221606
[2018-08-19 23:40:30,437 INFO] Loading vectors from /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt.pt
[2018-08-19 23:41:31,794 INFO] | epoch   1 | train_loss  5.11 | val_ppl 141.03557 | time  49.4s
[2018-08-19 23:42:21,768 INFO] | epoch   2 | train_loss  4.60 | val_ppl 116.08966 | time  50.0s
[2018-08-19 23:43:12,498 INFO] | epoch   3 | train_loss  4.43 | val_ppl 105.32855 | time  50.7s
[2018-08-19 23:44:03,587 INFO] | epoch   4 | train_loss  4.32 | val_ppl 99.22133 | time  51.1s
[2018-08-19 23:44:54,881 INFO] | epoch   5 | train_loss  4.24 | val_ppl 95.19602 | time  51.3s
[2018-08-19 23:45:46,191 INFO] | epoch   6 | train_loss  4.16 | val_ppl 92.32671 | time  51.3s
[2018-08-19 23:46:37,729 INFO] | epoch   7 | train_loss  4.09 | val_ppl 90.26666 | time  51.5s
[2018-08-19 23:47:29,220 INFO] | epoch   8 | train_loss  4.03 | val_ppl 88.86703 | time  51.5s
[2018-08-19 23:48:20,906 INFO] learning rate has been changed to 0.0625
[2018-08-19 23:48:20,906 INFO] | epoch   9 | train_loss  3.97 | val_ppl 87.98041 | time  51.7s
[2018-08-19 23:49:12,526 INFO] | epoch  10 | train_loss  3.90 | val_ppl 77.56884 | time  51.6s
[2018-08-19 23:50:04,303 INFO] | epoch  11 | train_loss  3.88 | val_ppl 77.46684 | time  51.8s
[2018-08-19 23:50:55,995 INFO] learning rate has been changed to 0.03125
[2018-08-19 23:50:55,995 INFO] | epoch  12 | train_loss  3.87 | val_ppl 77.45928 | time  51.7s
[2018-08-19 23:51:47,508 INFO] | epoch  13 | train_loss  3.86 | val_ppl 76.68369 | time  51.5s
[2018-08-19 23:52:39,214 INFO] | epoch  14 | train_loss  3.86 | val_ppl 76.66439 | time  51.7s
[2018-08-19 23:53:30,984 INFO] learning rate has been changed to 0.015625
[2018-08-19 23:53:30,985 INFO] | epoch  15 | train_loss  3.85 | val_ppl 76.66612 | time  51.8s
[2018-08-19 23:54:22,853 INFO] | epoch  16 | train_loss  3.85 | val_ppl 76.20287 | time  51.9s
[2018-08-19 23:55:14,483 INFO] | epoch  17 | train_loss  3.85 | val_ppl 76.18755 | time  51.6s
[2018-08-19 23:56:06,106 INFO] learning rate has been changed to 0.0078125
[2018-08-19 23:56:06,106 INFO] | epoch  18 | train_loss  3.84 | val_ppl 76.18489 | time  51.6s
[2018-08-19 23:56:57,867 INFO] | epoch  19 | train_loss  3.84 | val_ppl 75.86600 | time  51.8s
[2018-08-19 23:57:49,266 INFO] | epoch  20 | train_loss  3.84 | val_ppl 75.85384 | time  51.4s
[2018-08-19 23:58:40,993 INFO] learning rate has been changed to 0.00390625
[2018-08-19 23:58:40,994 INFO] | epoch  21 | train_loss  3.84 | val_ppl 75.84966 | time  51.7s
[2018-08-19 23:59:32,799 INFO] | epoch  22 | train_loss  3.84 | val_ppl 75.64248 | time  51.8s
[2018-08-20 00:00:24,453 INFO] | epoch  23 | train_loss  3.84 | val_ppl 75.63432 | time  51.7s
[2018-08-20 00:01:16,072 INFO] learning rate has been changed to 0.001953125
[2018-08-20 00:01:16,073 INFO] | epoch  24 | train_loss  3.84 | val_ppl 75.63078 | time  51.6s
[2018-08-20 00:02:07,798 INFO] | epoch  25 | train_loss  3.84 | val_ppl 75.53255 | time  51.7s
[2018-08-20 00:02:59,420 INFO] | epoch  26 | train_loss  3.84 | val_ppl 75.52727 | time  51.6s
[2018-08-20 00:03:50,992 INFO] learning rate has been changed to 0.0009765625
[2018-08-20 00:03:50,992 INFO] | epoch  27 | train_loss  3.84 | val_ppl 75.52466 | time  51.6s
[2018-08-20 00:04:42,899 INFO] | epoch  28 | train_loss  3.84 | val_ppl 75.49070 | time  51.9s
[2018-08-20 00:05:34,728 INFO] | epoch  29 | train_loss  3.84 | val_ppl 75.48625 | time  51.8s
[2018-08-20 00:06:26,510 INFO] learning rate has been changed to 0.00048828125
[2018-08-20 00:06:26,510 INFO] | epoch  30 | train_loss  3.84 | val_ppl 75.48443 | time  51.8s
[2018-08-20 00:07:18,263 INFO] | epoch  31 | train_loss  3.84 | val_ppl 75.47864 | time  51.8s
[2018-08-20 00:08:09,882 INFO] | epoch  32 | train_loss  3.84 | val_ppl 75.47580 | time  51.6s
[2018-08-20 00:09:01,674 INFO] learning rate has been changed to 0.000244140625
[2018-08-20 00:09:01,675 INFO] | epoch  33 | train_loss  3.84 | val_ppl 75.47443 | time  51.8s
[2018-08-20 00:09:53,295 INFO] | epoch  34 | train_loss  3.84 | val_ppl 75.47477 | time  51.6s
[2018-08-20 00:10:45,030 INFO] | epoch  35 | train_loss  3.84 | val_ppl 75.47418 | time  51.7s
[2018-08-20 00:11:36,605 INFO] learning rate has been changed to 0.0001220703125
[2018-08-20 00:11:36,606 INFO] | epoch  36 | train_loss  3.84 | val_ppl 75.47361 | time  51.6s
[2018-08-20 00:12:28,261 INFO] | epoch  37 | train_loss  3.84 | val_ppl 75.47402 | time  51.7s
[2018-08-20 00:13:19,924 INFO] | epoch  38 | train_loss  3.84 | val_ppl 75.47413 | time  51.7s
[2018-08-20 00:14:11,430 INFO] learning rate has been changed to 6.103515625e-05
[2018-08-20 00:14:11,431 INFO] | epoch  39 | train_loss  3.84 | val_ppl 75.47411 | time  51.5s
[2018-08-20 00:15:02,982 INFO] | epoch  40 | train_loss  3.84 | val_ppl 75.47435 | time  51.6s
[2018-08-20 00:15:02,982 INFO] start to save model on nnlm.model
[2018-08-20 00:15:06,210 INFO] test_ppl: 73.48962
[2018-08-20 00:17:52,588 INFO] -------------

ited
[2018-08-20 00:17:52,588 INFO] Start training...
[2018-08-20 00:17:52,589 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=104, tied=True, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 00:18:03,860 INFO] train token: 2127402
[2018-08-20 00:18:03,861 INFO] test token: 250140
[2018-08-20 00:18:03,861 INFO] valid token: 221606
[2018-08-20 00:18:03,861 INFO] Loading vectors from /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt.pt
[2018-08-20 00:19:03,497 INFO] | epoch   1 | train_loss  5.19 | val_ppl 143.71671 | time  47.6s
[2018-08-20 00:19:51,792 INFO] | epoch   2 | train_loss  4.61 | val_ppl 118.02012 | time  48.3s
[2018-08-20 00:20:41,310 INFO] | epoch   3 | train_loss  4.45 | val_ppl 106.73913 | time  49.5s
[2018-08-20 00:21:31,045 INFO] | epoch   4 | train_loss  4.34 | val_ppl 100.34599 | time  49.7s
[2018-08-20 00:22:20,740 INFO] | epoch   5 | train_loss  4.25 | val_ppl 96.11057 | time  49.7s
[2018-08-20 00:23:10,525 INFO] | epoch   6 | train_loss  4.17 | val_ppl 93.03707 | time  49.8s
[2018-08-20 00:24:00,457 INFO] | epoch   7 | train_loss  4.11 | val_ppl 90.70156 | time  49.9s
[2018-08-20 00:24:50,313 INFO] | epoch   8 | train_loss  4.04 | val_ppl 88.94185 | time  49.9s
[2018-08-20 00:25:40,378 INFO] learning rate has been changed to 0.0625
[2018-08-20 00:25:40,379 INFO] | epoch   9 | train_loss  3.99 | val_ppl 87.65711 | time  50.1s
[2018-08-20 00:26:30,309 INFO] | epoch  10 | train_loss  3.92 | val_ppl 76.37582 | time  49.9s
[2018-08-20 00:27:20,209 INFO] | epoch  11 | train_loss  3.90 | val_ppl 76.26111 | time  49.9s
[2018-08-20 00:28:10,290 INFO] learning rate has been changed to 0.03125
[2018-08-20 00:28:10,291 INFO] | epoch  12 | train_loss  3.89 | val_ppl 76.24006 | time  50.1s
[2018-08-20 00:29:00,284 INFO] | epoch  13 | train_loss  3.88 | val_ppl 75.50026 | time  50.0s
[2018-08-20 00:29:50,304 INFO] | epoch  14 | train_loss  3.87 | val_ppl 75.47829 | time  50.0s
[2018-08-20 00:30:40,341 INFO] learning rate has been changed to 0.015625
[2018-08-20 00:30:40,341 INFO] | epoch  15 | train_loss  3.87 | val_ppl 75.47506 | time  50.0s
[2018-08-20 00:31:30,395 INFO] | epoch  16 | train_loss  3.86 | val_ppl 75.02646 | time  50.1s
[2018-08-20 00:32:20,422 INFO] | epoch  17 | train_loss  3.86 | val_ppl 75.00990 | time  50.0s
[2018-08-20 00:33:10,354 INFO] learning rate has been changed to 0.0078125
[2018-08-20 00:33:10,355 INFO] | epoch  18 | train_loss  3.86 | val_ppl 75.00564 | time  49.9s
[2018-08-20 00:34:00,257 INFO] | epoch  19 | train_loss  3.86 | val_ppl 74.72778 | time  49.9s
[2018-08-20 00:34:50,184 INFO] | epoch  20 | train_loss  3.85 | val_ppl 74.71557 | time  49.9s
[2018-08-20 00:35:40,107 INFO] learning rate has been changed to 0.00390625
[2018-08-20 00:35:40,108 INFO] | epoch  21 | train_loss  3.85 | val_ppl 74.71097 | time  49.9s
[2018-08-20 00:36:29,946 INFO] | epoch  22 | train_loss  3.85 | val_ppl 74.55623 | time  49.8s
[2018-08-20 00:37:20,004 INFO] | epoch  23 | train_loss  3.85 | val_ppl 74.54862 | time  50.1s
[2018-08-20 00:38:09,923 INFO] learning rate has been changed to 0.001953125
[2018-08-20 00:38:09,923 INFO] | epoch  24 | train_loss  3.85 | val_ppl 74.54524 | time  49.9s
[2018-08-20 00:38:59,965 INFO] | epoch  25 | train_loss  3.85 | val_ppl 74.46924 | time  50.0s
[2018-08-20 00:39:50,049 INFO] | epoch  26 | train_loss  3.85 | val_ppl 74.46431 | time  50.1s
[2018-08-20 00:40:40,107 INFO] learning rate has been changed to 0.0009765625
[2018-08-20 00:40:40,108 INFO] | epoch  27 | train_loss  3.85 | val_ppl 74.46199 | time  50.1s
[2018-08-20 00:41:30,003 INFO] | epoch  28 | train_loss  3.85 | val_ppl 74.42661 | time  49.9s
[2018-08-20 00:42:19,974 INFO] | epoch  29 | train_loss  3.85 | val_ppl 74.42235 | time  50.0s
[2018-08-20 00:43:09,856 INFO] learning rate has been changed to 0.00048828125
[2018-08-20 00:43:09,856 INFO] | epoch  30 | train_loss  3.85 | val_ppl 74.42062 | time  49.9s
[2018-08-20 00:43:59,907 INFO] | epoch  31 | train_loss  3.85 | val_ppl 74.40933 | time  50.1s
[2018-08-20 00:44:49,912 INFO] | epoch  32 | train_loss  3.85 | val_ppl 74.40591 | time  50.0s
[2018-08-20 00:45:39,863 INFO] learning rate has been changed to 0.000244140625
[2018-08-20 00:45:39,863 INFO] | epoch  33 | train_loss  3.85 | val_ppl 74.40447 | time  50.0s
[2018-08-20 00:46:29,827 INFO] | epoch  34 | train_loss  3.85 | val_ppl 74.40230 | time  50.0s
[2018-08-20 00:47:19,742 INFO] | epoch  35 | train_loss  3.85 | val_ppl 74.40085 | time  49.9s
[2018-08-20 00:48:09,636 INFO] learning rate has been changed to 0.0001220703125
[2018-08-20 00:48:09,637 INFO] | epoch  36 | train_loss  3.85 | val_ppl 74.39997 | time  49.9s
[2018-08-20 00:48:59,474 INFO] | epoch  37 | train_loss  3.85 | val_ppl 74.39964 | time  49.8s
[2018-08-20 00:49:49,584 INFO] | epoch  38 | train_loss  3.85 | val_ppl 74.39929 | time  50.1s
[2018-08-20 00:50:39,488 INFO] learning rate has been changed to 6.103515625e-05
[2018-08-20 00:50:39,489 INFO] | epoch  39 | train_loss  3.85 | val_ppl 74.39900 | time  49.9s
[2018-08-20 00:51:29,386 INFO] | epoch  40 | train_loss  3.85 | val_ppl 74.39900 | time  49.9s
[2018-08-20 00:51:29,387 INFO] start to save model on nnlm.model
[2018-08-20 00:51:31,858 INFO] test_ppl: 72.65853
[2018-08-20 09:37:48,871 INFO] -------------

add clip
[2018-08-20 09:37:48,871 INFO] Start training...
[2018-08-20 09:37:48,871 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, clip=0.25, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=104, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 09:37:59,989 INFO] train token: 2127402
[2018-08-20 09:37:59,990 INFO] test token: 250140
[2018-08-20 09:37:59,990 INFO] valid token: 221606
[2018-08-20 09:37:59,991 INFO] Loading vectors from /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt.pt
[2018-08-20 09:39:05,229 INFO] | epoch   1 | train_loss  5.29 | val_ppl 155.09909 | time  53.5s
[2018-08-20 09:39:59,616 INFO] | epoch   2 | train_loss  4.89 | val_ppl 130.15426 | time  54.4s
[2018-08-20 09:40:54,312 INFO] | epoch   3 | train_loss  4.74 | val_ppl 118.44237 | time  54.7s
[2018-08-20 09:41:49,189 INFO] | epoch   4 | train_loss  4.64 | val_ppl 111.30812 | time  54.9s
[2018-08-20 09:42:44,564 INFO] | epoch   5 | train_loss  4.56 | val_ppl 106.43658 | time  55.4s
[2018-08-20 09:43:39,921 INFO] | epoch   6 | train_loss  4.50 | val_ppl 102.73136 | time  55.4s
[2018-08-20 09:44:35,436 INFO] | epoch   7 | train_loss  4.45 | val_ppl 99.73833 | time  55.5s
[2018-08-20 09:45:31,164 INFO] | epoch   8 | train_loss  4.41 | val_ppl 97.31888 | time  55.7s
[2018-08-20 09:46:26,995 INFO] learning rate has been changed to 0.0625
[2018-08-20 09:46:26,995 INFO] | epoch   9 | train_loss  4.37 | val_ppl 95.33711 | time  55.8s
[2018-08-20 09:47:22,560 INFO] | epoch  10 | train_loss  4.33 | val_ppl 90.15667 | time  55.6s
[2018-08-20 09:48:18,436 INFO] | epoch  11 | train_loss  4.32 | val_ppl 89.84031 | time  55.9s
[2018-08-20 09:49:14,103 INFO] learning rate has been changed to 0.03125
[2018-08-20 09:49:14,104 INFO] | epoch  12 | train_loss  4.32 | val_ppl 89.60571 | time  55.7s
[2018-08-20 09:50:09,635 INFO] | epoch  13 | train_loss  4.31 | val_ppl 89.08217 | time  55.5s
[2018-08-20 09:51:05,408 INFO] | epoch  14 | train_loss  4.31 | val_ppl 88.96735 | time  55.8s
[2018-08-20 09:52:01,298 INFO] learning rate has been changed to 0.015625
[2018-08-20 09:52:01,299 INFO] | epoch  15 | train_loss  4.31 | val_ppl 88.86334 | time  55.9s
[2018-08-20 09:52:56,948 INFO] | epoch  16 | train_loss  4.30 | val_ppl 88.61481 | time  55.6s
[2018-08-20 09:57:58,182 INFO] -------------


clip afer 14 epochs, but still no difference
[2018-08-20 09:57:58,182 INFO] Start training...
[2018-08-20 09:57:58,182 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, clip=0.25, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=104, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 09:58:09,554 INFO] train token: 2127402
[2018-08-20 09:58:09,554 INFO] test token: 250140
[2018-08-20 09:58:09,554 INFO] valid token: 221606
[2018-08-20 09:58:09,555 INFO] Loading vectors from /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt.pt
[2018-08-20 09:59:10,066 INFO] | epoch   1 | train_loss  5.11 | val_ppl 141.03557 | time  49.2s
[2018-08-20 09:59:59,896 INFO] | epoch   2 | train_loss  4.60 | val_ppl 116.08966 | time  49.8s
[2018-08-20 10:00:50,134 INFO] | epoch   3 | train_loss  4.43 | val_ppl 105.32855 | time  50.2s
[2018-08-20 10:01:40,850 INFO] | epoch   4 | train_loss  4.32 | val_ppl 99.22133 | time  50.7s
[2018-08-20 10:02:31,886 INFO] | epoch   5 | train_loss  4.24 | val_ppl 95.19602 | time  51.0s
[2018-08-20 10:03:23,123 INFO] | epoch   6 | train_loss  4.16 | val_ppl 92.32671 | time  51.2s
[2018-08-20 10:04:14,480 INFO] | epoch   7 | train_loss  4.09 | val_ppl 90.26666 | time  51.4s
[2018-08-20 10:05:05,974 INFO] | epoch   8 | train_loss  4.03 | val_ppl 88.86703 | time  51.5s
[2018-08-20 10:05:57,526 INFO] learning rate has been changed to 0.0625
[2018-08-20 10:05:57,527 INFO] | epoch   9 | train_loss  3.97 | val_ppl 87.98041 | time  51.6s
[2018-08-20 10:06:48,953 INFO] | epoch  10 | train_loss  3.90 | val_ppl 77.56884 | time  51.4s
[2018-08-20 10:07:40,477 INFO] | epoch  11 | train_loss  3.88 | val_ppl 77.46684 | time  51.5s
[2018-08-20 10:08:32,140 INFO] learning rate has been changed to 0.03125
[2018-08-20 10:08:32,141 INFO] | epoch  12 | train_loss  3.87 | val_ppl 77.45928 | time  51.7s
[2018-08-20 10:09:23,649 INFO] | epoch  13 | train_loss  3.86 | val_ppl 76.68369 | time  51.5s
[2018-08-20 10:10:19,521 INFO] | epoch  14 | train_loss  3.86 | val_ppl 75.96549 | time  55.9s
[2018-08-20 10:11:16,002 INFO] learning rate has been changed to 0.015625
[2018-08-20 10:11:16,002 INFO] | epoch  15 | train_loss  3.86 | val_ppl 75.92267 | time  56.5s
[2018-08-20 10:12:11,898 INFO] | epoch  16 | train_loss  3.86 | val_ppl 75.68378 | time  55.9s
[2018-08-20 10:13:07,654 INFO] | epoch  17 | train_loss  3.86 | val_ppl 75.66667 | time  55.8s
[2018-08-20 10:14:03,303 INFO] learning rate has been changed to 0.0078125
[2018-08-20 10:14:03,303 INFO] | epoch  18 | train_loss  3.85 | val_ppl 75.65696 | time  55.6s
[2018-08-20 10:35:16,071 INFO] -------------
[2018-08-20 10:35:16,072 INFO] Start training...

new lr decay stratege. decay when poor val loss appears. there is no difference in final performance
[2018-08-20 10:35:16,072 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=104, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 10:35:27,702 INFO] train token: 2127402
[2018-08-20 10:35:27,702 INFO] test token: 250140
[2018-08-20 10:35:27,702 INFO] valid token: 221606
[2018-08-20 10:35:27,703 INFO] Loading vectors from /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt.pt
[2018-08-20 10:36:28,121 INFO] | epoch   1 | train_loss  5.11 | val_ppl 141.03557 | time  48.9s
[2018-08-20 10:37:17,735 INFO] | epoch   2 | train_loss  4.60 | val_ppl 116.08966 | time  49.6s
[2018-08-20 10:38:07,700 INFO] | epoch   3 | train_loss  4.43 | val_ppl 105.32855 | time  50.0s
[2018-08-20 10:38:57,920 INFO] | epoch   4 | train_loss  4.32 | val_ppl 99.22133 | time  50.2s
[2018-08-20 10:39:48,416 INFO] | epoch   5 | train_loss  4.24 | val_ppl 95.19602 | time  50.5s
[2018-08-20 10:40:39,039 INFO] | epoch   6 | train_loss  4.16 | val_ppl 92.32671 | time  50.6s
[2018-08-20 10:41:29,961 INFO] | epoch   7 | train_loss  4.09 | val_ppl 90.26666 | time  50.9s
[2018-08-20 10:42:21,141 INFO] | epoch   8 | train_loss  4.03 | val_ppl 88.86703 | time  51.2s
[2018-08-20 10:43:12,250 INFO] | epoch   9 | train_loss  3.97 | val_ppl 87.98041 | time  51.1s
[2018-08-20 10:44:03,624 INFO] | epoch  10 | train_loss  3.92 | val_ppl 87.51270 | time  51.4s
[2018-08-20 10:44:54,856 INFO] | epoch  11 | train_loss  3.86 | val_ppl 87.41345 | time  51.2s
[2018-08-20 10:45:46,378 INFO] | epoch  12 | train_loss  3.81 | val_ppl 87.64859 | time  51.5s
[2018-08-20 10:45:46,379 INFO] learning rate has been changed to 0.03125
[2018-08-20 10:46:37,672 INFO] | epoch  13 | train_loss  3.76 | val_ppl 77.19238 | time  51.3s
[2018-08-20 10:47:29,089 INFO] | epoch  14 | train_loss  3.73 | val_ppl 76.98822 | time  51.4s
[2018-08-20 10:48:20,448 INFO] | epoch  15 | train_loss  3.72 | val_ppl 76.97483 | time  51.4s
[2018-08-20 10:49:11,886 INFO] | epoch  16 | train_loss  3.71 | val_ppl 77.01342 | time  51.4s
[2018-08-20 10:49:11,887 INFO] learning rate has been changed to 0.015625
[2018-08-20 10:50:03,322 INFO] | epoch  17 | train_loss  3.71 | val_ppl 76.50021 | time  51.4s
[2018-08-20 10:50:54,667 INFO] | epoch  18 | train_loss  3.71 | val_ppl 76.50132 | time  51.3s
[2018-08-20 10:50:54,667 INFO] learning rate has been changed to 0.0078125
[2018-08-20 10:51:46,458 INFO] | epoch  19 | train_loss  3.71 | val_ppl 76.13509 | time  51.8s
[2018-08-20 10:52:37,867 INFO] | epoch  20 | train_loss  3.71 | val_ppl 76.12704 | time  51.4s
[2018-08-20 10:53:29,231 INFO] | epoch  21 | train_loss  3.71 | val_ppl 76.13105 | time  51.4s
[2018-08-20 10:53:29,232 INFO] learning rate has been changed to 0.00390625
[2018-08-20 10:54:20,745 INFO] | epoch  22 | train_loss  3.71 | val_ppl 75.90484 | time  51.5s
[2018-08-20 10:55:12,061 INFO] | epoch  23 | train_loss  3.70 | val_ppl 75.89861 | time  51.3s
[2018-08-20 10:56:03,575 INFO] | epoch  24 | train_loss  3.70 | val_ppl 75.89892 | time  51.5s
[2018-08-20 10:56:03,575 INFO] learning rate has been changed to 0.001953125
[2018-08-20 10:56:54,962 INFO] | epoch  25 | train_loss  3.70 | val_ppl 75.79593 | time  51.4s
[2018-08-20 10:57:46,360 INFO] | epoch  26 | train_loss  3.70 | val_ppl 75.79117 | time  51.4s
[2018-08-20 10:58:37,495 INFO] | epoch  27 | train_loss  3.70 | val_ppl 75.79019 | time  51.1s
[2018-08-20 10:59:28,939 INFO] | epoch  28 | train_loss  3.70 | val_ppl 75.79057 | time  51.4s
[2018-08-20 10:59:28,940 INFO] learning rate has been changed to 0.0009765625
[2018-08-20 11:00:20,260 INFO] | epoch  29 | train_loss  3.70 | val_ppl 75.75747 | time  51.3s
[2018-08-20 11:01:11,751 INFO] | epoch  30 | train_loss  3.70 | val_ppl 75.75322 | time  51.5s
[2018-08-20 11:02:03,201 INFO] | epoch  31 | train_loss  3.70 | val_ppl 75.75229 | time  51.4s
[2018-08-20 11:02:54,527 INFO] | epoch  32 | train_loss  3.70 | val_ppl 75.75215 | time  51.3s
[2018-08-20 11:03:45,985 INFO] | epoch  33 | train_loss  3.70 | val_ppl 75.75237 | time  51.5s
[2018-08-20 11:03:45,985 INFO] learning rate has been changed to 0.000244140625
[2018-08-20 11:04:37,544 INFO] | epoch  34 | train_loss  3.70 | val_ppl 75.75019 | time  51.6s
[2018-08-20 11:05:28,924 INFO] | epoch  35 | train_loss  3.70 | val_ppl 75.74824 | time  51.4s
[2018-08-20 11:06:20,311 INFO] | epoch  36 | train_loss  3.70 | val_ppl 75.74678 | time  51.4s
[2018-08-20 11:07:11,719 INFO] | epoch  37 | train_loss  3.70 | val_ppl 75.74583 | time  51.4s
[2018-08-20 11:08:03,229 INFO] | epoch  38 | train_loss  3.70 | val_ppl 75.74525 | time  51.5s
[2018-08-20 11:08:54,574 INFO] | epoch  39 | train_loss  3.70 | val_ppl 75.74493 | time  51.3s
[2018-08-20 11:09:45,951 INFO] | epoch  40 | train_loss  3.70 | val_ppl 75.74478 | time  51.4s
[2018-08-20 11:09:45,951 INFO] start to save model on nnlm.model
[2018-08-20 11:09:49,087 INFO] test_ppl: 73.82636
[2018-08-20 11:22:59,950 INFO] -------------
[2018-08-20 11:22:59,950 INFO] Start training...
[2018-08-20 11:22:59,950 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=20, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=25, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1000, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 11:23:11,130 INFO] train token: 2127402
[2018-08-20 11:23:11,130 INFO] test token: 250140
[2018-08-20 11:23:11,130 INFO] valid token: 221606
[2018-08-20 11:23:11,131 INFO] Loading vectors from /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt.pt
[2018-08-20 11:24:19,269 INFO] | epoch   1 | train_loss  4.96 | val_ppl 120.45483 | time  56.7s
[2018-08-20 11:25:16,928 INFO] | epoch   2 | train_loss  4.52 | val_ppl 105.53733 | time  57.7s
[2018-08-20 11:26:14,950 INFO] | epoch   3 | train_loss  4.36 | val_ppl 98.79761 | time  58.0s
[2018-08-20 11:27:13,586 INFO] | epoch   4 | train_loss  4.25 | val_ppl 95.09573 | time  58.6s
[2018-08-20 11:28:12,430 INFO] | epoch   5 | train_loss  4.16 | val_ppl 92.92944 | time  58.8s
[2018-08-20 11:29:11,554 INFO] | epoch   6 | train_loss  4.07 | val_ppl 91.77284 | time  59.1s
[2018-08-20 11:30:10,987 INFO] | epoch   7 | train_loss  4.00 | val_ppl 91.41444 | time  59.4s
[2018-08-20 11:31:10,357 INFO] | epoch   8 | train_loss  3.92 | val_ppl 91.79557 | time  59.4s
[2018-08-20 11:31:10,357 INFO] learning rate has been changed to 0.125
[2018-08-20 11:32:09,870 INFO] | epoch   9 | train_loss  3.81 | val_ppl 85.35872 | time  59.5s
[2018-08-20 11:33:09,576 INFO] | epoch  10 | train_loss  3.78 | val_ppl 85.72805 | time  59.7s
[2018-08-20 11:33:09,577 INFO] learning rate has been changed to 0.0625
[2018-08-20 11:34:09,262 INFO] | epoch  11 | train_loss  3.76 | val_ppl 84.20292 | time  59.7s
[2018-08-20 11:35:08,879 INFO] | epoch  12 | train_loss  3.74 | val_ppl 84.41526 | time  59.6s
[2018-08-20 11:35:08,880 INFO] learning rate has been changed to 0.03125
[2018-08-20 11:36:08,520 INFO] | epoch  13 | train_loss  3.73 | val_ppl 83.35108 | time  59.6s
[2018-08-20 11:37:08,076 INFO] | epoch  14 | train_loss  3.73 | val_ppl 83.44127 | time  59.6s
[2018-08-20 11:37:08,076 INFO] learning rate has been changed to 0.03125
[2018-08-20 11:38:07,819 INFO] | epoch  15 | train_loss  3.72 | val_ppl 83.56623 | time  59.7s
[2018-08-20 11:38:07,819 INFO] learning rate has been changed to 0.015625
[2018-08-20 11:39:07,521 INFO] | epoch  16 | train_loss  3.72 | val_ppl 82.81920 | time  59.7s
[2018-08-20 11:40:07,226 INFO] | epoch  17 | train_loss  3.71 | val_ppl 82.84713 | time  59.7s
[2018-08-20 11:40:07,226 INFO] learning rate has been changed to 0.015625
[2018-08-20 11:41:06,875 INFO] | epoch  18 | train_loss  3.71 | val_ppl 82.90011 | time  59.6s
[2018-08-20 11:41:06,875 INFO] learning rate has been changed to 0.0078125
[2018-08-20 11:42:06,547 INFO] | epoch  19 | train_loss  3.71 | val_ppl 82.33012 | time  59.7s
[2018-08-20 11:43:06,304 INFO] | epoch  20 | train_loss  3.71 | val_ppl 82.33148 | time  59.8s
[2018-08-20 11:43:06,305 INFO] learning rate has been changed to 0.0078125
[2018-08-20 11:44:05,994 INFO] | epoch  21 | train_loss  3.71 | val_ppl 82.34959 | time  59.7s
[2018-08-20 11:44:05,994 INFO] learning rate has been changed to 0.00390625
[2018-08-20 11:45:05,697 INFO] | epoch  22 | train_loss  3.71 | val_ppl 81.96810 | time  59.7s
[2018-08-20 11:46:05,556 INFO] | epoch  23 | train_loss  3.71 | val_ppl 81.96126 | time  59.9s
[2018-08-20 11:47:05,280 INFO] | epoch  24 | train_loss  3.70 | val_ppl 81.96662 | time  59.7s
[2018-08-20 11:47:05,281 INFO] learning rate has been changed to 0.001953125
[2018-08-20 11:48:04,956 INFO] | epoch  25 | train_loss  3.71 | val_ppl 81.78937 | time  59.7s
[2018-08-20 11:48:06,853 INFO] test_ppl: 79.69801
[2018-08-20 11:51:15,959 INFO] -------------
[2018-08-20 11:51:15,959 INFO] Start training...
[2018-08-20 11:51:15,959 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=45, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=25, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1050, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 11:51:27,720 INFO] train token: 2127402
[2018-08-20 11:51:27,720 INFO] test token: 250140
[2018-08-20 11:51:27,720 INFO] valid token: 221606
[2018-08-20 11:51:27,721 INFO] Loading vectors from /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt.pt
[2018-08-20 11:52:27,545 INFO] | epoch   1 | train_loss  5.38 | val_ppl 131.42977 | time  47.9s
[2018-08-20 11:53:16,252 INFO] | epoch   2 | train_loss  4.68 | val_ppl 109.95667 | time  48.7s
[2018-08-20 11:54:05,542 INFO] | epoch   3 | train_loss  4.51 | val_ppl 100.06157 | time  49.3s
[2018-08-20 11:54:55,188 INFO] | epoch   4 | train_loss  4.40 | val_ppl 94.37306 | time  49.6s
[2018-08-20 11:55:44,927 INFO] | epoch   5 | train_loss  4.31 | val_ppl 90.56957 | time  49.7s
[2018-08-20 11:56:34,821 INFO] | epoch   6 | train_loss  4.24 | val_ppl 87.87388 | time  49.9s
[2018-08-20 11:57:24,756 INFO] | epoch   7 | train_loss  4.18 | val_ppl 85.87049 | time  49.9s
[2018-08-20 11:58:14,880 INFO] | epoch   8 | train_loss  4.12 | val_ppl 84.34226 | time  50.1s
[2018-08-20 11:59:04,953 INFO] | epoch   9 | train_loss  4.07 | val_ppl 83.16898 | time  50.1s
[2018-08-20 11:59:55,090 INFO] | epoch  10 | train_loss  4.02 | val_ppl 82.29134 | time  50.1s
[2018-08-20 12:00:45,110 INFO] | epoch  11 | train_loss  3.97 | val_ppl 81.68497 | time  50.0s
[2018-08-20 12:01:35,257 INFO] | epoch  12 | train_loss  3.92 | val_ppl 81.32560 | time  50.1s
[2018-08-20 12:02:25,298 INFO] | epoch  13 | train_loss  3.88 | val_ppl 81.19867 | time  50.0s
[2018-08-20 12:03:15,520 INFO] | epoch  14 | train_loss  3.83 | val_ppl 81.28646 | time  50.2s
[2018-08-20 12:03:15,521 INFO] learning rate has been changed to 0.03125
[2018-08-20 12:04:05,781 INFO] | epoch  15 | train_loss  3.79 | val_ppl 75.32389 | time  50.3s
[2018-08-20 12:04:55,980 INFO] | epoch  16 | train_loss  3.77 | val_ppl 75.12798 | time  50.2s
[2018-08-20 12:05:46,303 INFO] | epoch  17 | train_loss  3.76 | val_ppl 75.08756 | time  50.3s
[2018-08-20 12:06:36,426 INFO] | epoch  18 | train_loss  3.75 | val_ppl 75.09157 | time  50.1s
[2018-08-20 12:06:36,427 INFO] learning rate has been changed to 0.0078125
[2018-08-20 12:07:26,644 INFO] | epoch  19 | train_loss  3.75 | val_ppl 74.31194 | time  50.2s
[2018-08-20 12:08:16,813 INFO] | epoch  20 | train_loss  3.75 | val_ppl 74.27011 | time  50.2s
[2018-08-20 12:09:06,996 INFO] | epoch  21 | train_loss  3.75 | val_ppl 74.25763 | time  50.2s
[2018-08-20 12:09:57,273 INFO] | epoch  22 | train_loss  3.75 | val_ppl 74.25345 | time  50.3s
[2018-08-20 12:10:47,418 INFO] | epoch  23 | train_loss  3.75 | val_ppl 74.25296 | time  50.1s
[2018-08-20 12:11:37,637 INFO] | epoch  24 | train_loss  3.75 | val_ppl 74.25461 | time  50.2s
[2018-08-20 12:11:37,638 INFO] learning rate has been changed to 0.001953125
[2018-08-20 12:12:27,901 INFO] | epoch  25 | train_loss  3.75 | val_ppl 73.98699 | time  50.3s
[2018-08-20 12:12:29,593 INFO] test_ppl: 71.97410
[2018-08-20 12:15:29,700 INFO] -------------
[2018-08-20 12:15:29,701 INFO] Start training...
[2018-08-20 12:15:29,701 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=65, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=25, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1050, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 12:15:41,257 INFO] train token: 2127402
[2018-08-20 12:15:41,258 INFO] test token: 250140
[2018-08-20 12:15:41,258 INFO] valid token: 221606
[2018-08-20 12:15:41,259 INFO] Loading vectors from /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt.pt
[2018-08-20 12:16:40,710 INFO] | epoch   1 | train_loss  5.59 | val_ppl 165.49105 | time  47.4s
[2018-08-20 12:17:28,595 INFO] | epoch   2 | train_loss  4.76 | val_ppl 116.03688 | time  47.9s
[2018-08-20 12:18:17,191 INFO] | epoch   3 | train_loss  4.59 | val_ppl 104.62808 | time  48.6s
[2018-08-20 12:19:06,004 INFO] | epoch   4 | train_loss  4.48 | val_ppl 97.47969 | time  48.8s
[2018-08-20 12:19:54,776 INFO] | epoch   5 | train_loss  4.39 | val_ppl 92.66835 | time  48.8s
[2018-08-20 12:20:43,803 INFO] | epoch   6 | train_loss  4.32 | val_ppl 89.28869 | time  49.0s
[2018-08-20 12:21:32,798 INFO] | epoch   7 | train_loss  4.26 | val_ppl 86.76176 | time  49.0s
[2018-08-20 12:22:21,646 INFO] | epoch   8 | train_loss  4.20 | val_ppl 84.77375 | time  48.8s
[2018-08-20 12:23:10,988 INFO] | epoch   9 | train_loss  4.15 | val_ppl 83.16034 | time  49.3s
[2018-08-20 12:24:00,146 INFO] | epoch  10 | train_loss  4.11 | val_ppl 81.83822 | time  49.2s
[2018-08-20 12:24:49,417 INFO] | epoch  11 | train_loss  4.06 | val_ppl 80.77599 | time  49.3s
[2018-08-20 12:25:38,555 INFO] | epoch  12 | train_loss  4.02 | val_ppl 79.93262 | time  49.1s
[2018-08-20 12:26:27,752 INFO] | epoch  13 | train_loss  3.98 | val_ppl 79.27874 | time  49.2s
[2018-08-20 12:27:17,075 INFO] | epoch  14 | train_loss  3.95 | val_ppl 78.79569 | time  49.3s
[2018-08-20 12:28:06,168 INFO] | epoch  15 | train_loss  3.91 | val_ppl 78.45853 | time  49.1s
[2018-08-20 12:28:55,328 INFO] | epoch  16 | train_loss  3.87 | val_ppl 78.26867 | time  49.2s
[2018-08-20 12:29:44,450 INFO] | epoch  17 | train_loss  3.84 | val_ppl 78.21735 | time  49.1s
[2018-08-20 12:30:33,653 INFO] | epoch  18 | train_loss  3.80 | val_ppl 78.28757 | time  49.2s
[2018-08-20 12:30:33,654 INFO] learning rate has been changed to 0.0078125
[2018-08-20 12:31:22,792 INFO] | epoch  19 | train_loss  3.79 | val_ppl 73.18062 | time  49.1s
[2018-08-20 12:32:11,693 INFO] | epoch  20 | train_loss  3.77 | val_ppl 72.69085 | time  48.9s
[2018-08-20 12:33:00,729 INFO] | epoch  21 | train_loss  3.76 | val_ppl 72.45983 | time  49.0s
[2018-08-20 12:33:49,756 INFO] | epoch  22 | train_loss  3.76 | val_ppl 72.32642 | time  49.0s
[2018-08-20 12:34:38,660 INFO] | epoch  23 | train_loss  3.75 | val_ppl 72.24142 | time  48.9s
[2018-08-20 12:35:27,608 INFO] | epoch  24 | train_loss  3.75 | val_ppl 72.18408 | time  48.9s
[2018-08-20 12:36:16,593 INFO] | epoch  25 | train_loss  3.75 | val_ppl 72.14403 | time  49.0s
[2018-08-20 12:36:18,219 INFO] test_ppl: 70.28066
[2018-08-20 13:16:39,864 INFO] -------------

2 layers. it seems i should use only 1 layer
[2018-08-20 13:16:39,864 INFO] Start training...
[2018-08-20 13:16:39,864 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=2, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=104, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 13:16:51,210 INFO] train token: 2127402
[2018-08-20 13:16:51,210 INFO] test token: 250140
[2018-08-20 13:16:51,210 INFO] valid token: 221606
[2018-08-20 13:16:51,211 INFO] Loading vectors from /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt.pt
[2018-08-20 13:18:00,816 INFO] | epoch   1 | train_loss  5.93 | val_ppl 215.04088 | time  57.6s
[2018-08-20 13:18:59,196 INFO] | epoch   2 | train_loss  5.06 | val_ppl 166.01496 | time  58.4s
[2018-08-20 13:19:57,873 INFO] | epoch   3 | train_loss  4.85 | val_ppl 138.66288 | time  58.7s
[2018-08-20 13:20:56,994 INFO] | epoch   4 | train_loss  4.70 | val_ppl 124.66834 | time  59.1s
[2018-08-20 13:21:56,454 INFO] | epoch   5 | train_loss  4.60 | val_ppl 114.95868 | time  59.5s
[2018-08-20 13:22:56,221 INFO] | epoch   6 | train_loss  4.51 | val_ppl 107.84480 | time  59.8s
[2018-08-20 13:23:56,246 INFO] | epoch   7 | train_loss  4.43 | val_ppl 102.66827 | time  60.0s
[2018-08-20 13:24:56,469 INFO] | epoch   8 | train_loss  4.36 | val_ppl 98.71378 | time  60.2s
[2018-08-20 13:25:56,644 INFO] | epoch   9 | train_loss  4.30 | val_ppl 95.86997 | time  60.2s
[2018-08-20 13:26:57,012 INFO] | epoch  10 | train_loss  4.25 | val_ppl 93.72840 | time  60.4s
[2018-08-20 13:27:57,354 INFO] | epoch  11 | train_loss  4.20 | val_ppl 91.83409 | time  60.3s
[2018-08-20 13:28:57,898 INFO] | epoch  12 | train_loss  4.15 | val_ppl 90.20184 | time  60.5s
[2018-08-20 13:29:58,426 INFO] | epoch  13 | train_loss  4.10 | val_ppl 88.92336 | time  60.5s
[2018-08-20 13:30:59,203 INFO] | epoch  14 | train_loss  4.06 | val_ppl 87.95239 | time  60.8s
[2018-08-20 13:31:59,795 INFO] | epoch  15 | train_loss  4.01 | val_ppl 87.38172 | time  60.6s
[2018-08-20 13:33:00,420 INFO] | epoch  16 | train_loss  3.97 | val_ppl 87.11732 | time  60.6s
[2018-08-20 13:34:01,204 INFO] | epoch  17 | train_loss  3.93 | val_ppl 87.13007 | time  60.8s
[2018-08-20 13:34:01,205 INFO] learning rate has been changed to 0.015625
[2018-08-20 13:35:01,747 INFO] | epoch  18 | train_loss  3.91 | val_ppl 78.06620 | time  60.5s
[2018-08-20 13:36:02,460 INFO] | epoch  19 | train_loss  3.89 | val_ppl 77.62813 | time  60.7s
[2018-08-20 13:37:03,088 INFO] | epoch  20 | train_loss  3.88 | val_ppl 77.45063 | time  60.6s
[2018-08-20 13:38:03,705 INFO] | epoch  21 | train_loss  3.87 | val_ppl 77.35681 | time  60.6s
[2018-08-20 13:39:04,342 INFO] | epoch  22 | train_loss  3.87 | val_ppl 77.30142 | time  60.6s
[2018-08-20 13:40:05,040 INFO] | epoch  23 | train_loss  3.87 | val_ppl 77.26706 | time  60.7s
[2018-08-20 13:41:05,718 INFO] | epoch  24 | train_loss  3.86 | val_ppl 77.24552 | time  60.7s
[2018-08-20 13:42:06,292 INFO] | epoch  25 | train_loss  3.86 | val_ppl 77.23238 | time  60.6s
[2018-08-20 13:43:07,137 INFO] | epoch  26 | train_loss  3.86 | val_ppl 77.22515 | time  60.8s
[2018-08-20 13:44:07,780 INFO] | epoch  27 | train_loss  3.85 | val_ppl 77.22228 | time  60.6s
[2018-08-20 13:45:08,402 INFO] | epoch  28 | train_loss  3.85 | val_ppl 77.22275 | time  60.6s
[2018-08-20 13:45:08,403 INFO] learning rate has been changed to 0.0009765625
[2018-08-20 13:46:09,169 INFO] | epoch  29 | train_loss  3.86 | val_ppl 76.80234 | time  60.8s
[2018-08-20 13:47:09,918 INFO] | epoch  30 | train_loss  3.86 | val_ppl 76.71240 | time  60.7s
[2018-08-20 13:48:10,782 INFO] | epoch  31 | train_loss  3.86 | val_ppl 76.66737 | time  60.9s
[2018-08-20 13:49:11,597 INFO] | epoch  32 | train_loss  3.85 | val_ppl 76.64074 | time  60.8s
[2018-08-20 13:50:12,442 INFO] | epoch  33 | train_loss  3.85 | val_ppl 76.62345 | time  60.8s
[2018-08-20 13:51:13,375 INFO] | epoch  34 | train_loss  3.85 | val_ppl 76.61148 | time  60.9s
[2018-08-20 13:52:14,105 INFO] | epoch  35 | train_loss  3.85 | val_ppl 76.60280 | time  60.7s
[2018-08-20 13:53:14,911 INFO] | epoch  36 | train_loss  3.85 | val_ppl 76.59626 | time  60.8s
[2018-08-20 13:54:15,713 INFO] | epoch  37 | train_loss  3.85 | val_ppl 76.59120 | time  60.8s
[2018-08-20 13:55:16,445 INFO] | epoch  38 | train_loss  3.85 | val_ppl 76.58718 | time  60.7s
[2018-08-20 13:56:17,279 INFO] | epoch  39 | train_loss  3.85 | val_ppl 76.58393 | time  60.8s
[2018-08-20 13:57:18,141 INFO] | epoch  40 | train_loss  3.85 | val_ppl 76.58124 | time  60.9s
[2018-08-20 13:57:18,142 INFO] start to save model on nnlm.model
[2018-08-20 13:57:21,644 INFO] test_ppl: 74.59234
[2018-08-20 13:59:54,226 INFO] -------------
[2018-08-20 13:59:54,226 INFO] Start training...
[2018-08-20 13:59:54,226 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=100, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=205, tied=True, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 14:00:05,317 INFO] train token: 2127402
[2018-08-20 14:00:05,317 INFO] test token: 250140
[2018-08-20 14:00:05,317 INFO] valid token: 221606
[2018-08-20 14:00:05,318 INFO] Loading vectors from /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt.pt
[2018-08-20 14:00:58,545 INFO] | epoch   1 | train_loss   nan | val_ppl      nan | time  41.2s
[2018-08-20 14:00:58,546 INFO] learning rate has been changed to 0.5
[2018-08-20 14:01:39,660 INFO] | epoch   2 | train_loss   nan | val_ppl      nan | time  41.1s
[2018-08-20 14:01:39,660 INFO] learning rate has been changed to 0.5
[2018-08-20 14:02:45,458 INFO] -------------
[2018-08-20 14:02:45,459 INFO] Start training...
[2018-08-20 14:02:45,459 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=205, tied=True, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 14:02:56,755 INFO] train token: 2127402
[2018-08-20 14:02:56,755 INFO] test token: 250140
[2018-08-20 14:02:56,756 INFO] valid token: 221606
[2018-08-20 14:02:56,756 INFO] Loading vectors from /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt.pt
[2018-08-20 14:03:52,933 INFO] | epoch   1 | train_loss  5.62 | val_ppl 143.06949 | time  44.0s
[2018-08-20 14:04:37,497 INFO] | epoch   2 | train_loss  4.80 | val_ppl 117.40320 | time  44.6s
[2018-08-20 14:05:22,586 INFO] | epoch   3 | train_loss  4.63 | val_ppl 105.30826 | time  45.1s
[2018-08-20 14:06:08,120 INFO] | epoch   4 | train_loss  4.51 | val_ppl 98.53912 | time  45.5s
[2018-08-20 14:06:53,665 INFO] | epoch   5 | train_loss  4.43 | val_ppl 93.62653 | time  45.5s
[2018-08-20 14:07:39,408 INFO] | epoch   6 | train_loss  4.36 | val_ppl 89.81784 | time  45.7s
[2018-08-20 14:08:25,122 INFO] | epoch   7 | train_loss  4.30 | val_ppl 86.89260 | time  45.7s
[2018-08-20 14:09:10,875 INFO] | epoch   8 | train_loss  4.24 | val_ppl 84.58103 | time  45.8s
[2018-08-20 14:09:56,622 INFO] | epoch   9 | train_loss  4.20 | val_ppl 82.70147 | time  45.7s
[2018-08-20 14:10:42,483 INFO] | epoch  10 | train_loss  4.15 | val_ppl 81.14021 | time  45.9s
[2018-08-20 14:11:28,222 INFO] | epoch  11 | train_loss  4.11 | val_ppl 79.83402 | time  45.7s
[2018-08-20 14:12:14,149 INFO] | epoch  12 | train_loss  4.07 | val_ppl 78.74503 | time  45.9s
[2018-08-20 14:13:00,074 INFO] | epoch  13 | train_loss  4.04 | val_ppl 77.84325 | time  45.9s
[2018-08-20 14:13:46,113 INFO] | epoch  14 | train_loss  4.00 | val_ppl 77.10370 | time  46.0s
[2018-08-20 14:14:31,989 INFO] | epoch  15 | train_loss  3.97 | val_ppl 76.50848 | time  45.9s
[2018-08-20 14:15:17,988 INFO] | epoch  16 | train_loss  3.93 | val_ppl 76.04555 | time  46.0s
[2018-08-20 14:16:03,929 INFO] | epoch  17 | train_loss  3.90 | val_ppl 75.70366 | time  45.9s
[2018-08-20 14:16:49,931 INFO] | epoch  18 | train_loss  3.87 | val_ppl 75.47211 | time  46.0s
[2018-08-20 14:17:35,805 INFO] | epoch  19 | train_loss  3.84 | val_ppl 75.34335 | time  45.9s
[2018-08-20 14:18:21,808 INFO] | epoch  20 | train_loss  3.81 | val_ppl 75.30749 | time  46.0s
[2018-08-20 14:19:07,916 INFO] | epoch  21 | train_loss  3.78 | val_ppl 75.36192 | time  46.1s
[2018-08-20 14:19:07,917 INFO] learning rate has been changed to 0.00390625
[2018-08-20 14:19:53,884 INFO] | epoch  22 | train_loss  3.77 | val_ppl 71.51084 | time  46.0s
[2018-08-20 14:20:40,130 INFO] | epoch  23 | train_loss  3.76 | val_ppl 71.02854 | time  46.2s
[2018-08-20 14:21:26,231 INFO] | epoch  24 | train_loss  3.75 | val_ppl 70.78498 | time  46.1s
[2018-08-20 14:22:12,507 INFO] | epoch  25 | train_loss  3.74 | val_ppl 70.63598 | time  46.3s
[2018-08-20 14:22:58,617 INFO] | epoch  26 | train_loss  3.74 | val_ppl 70.53541 | time  46.1s
[2018-08-20 14:23:44,867 INFO] | epoch  27 | train_loss  3.74 | val_ppl 70.46317 | time  46.2s
[2018-08-20 14:24:31,198 INFO] | epoch  28 | train_loss  3.74 | val_ppl 70.40901 | time  46.3s
[2018-08-20 14:25:17,723 INFO] | epoch  29 | train_loss  3.74 | val_ppl 70.36713 | time  46.5s
[2018-08-20 14:26:04,029 INFO] | epoch  30 | train_loss  3.74 | val_ppl 70.33399 | time  46.3s
[2018-08-20 14:26:50,482 INFO] | epoch  31 | train_loss  3.73 | val_ppl 70.30730 | time  46.5s
[2018-08-20 14:27:37,033 INFO] | epoch  32 | train_loss  3.73 | val_ppl 70.28553 | time  46.5s
[2018-08-20 14:28:23,619 INFO] | epoch  33 | train_loss  3.73 | val_ppl 70.26760 | time  46.6s
[2018-08-20 14:29:10,243 INFO] | epoch  34 | train_loss  3.73 | val_ppl 70.25269 | time  46.6s
[2018-08-20 14:29:56,702 INFO] | epoch  35 | train_loss  3.73 | val_ppl 70.24022 | time  46.5s
[2018-08-20 14:30:43,304 INFO] | epoch  36 | train_loss  3.73 | val_ppl 70.22976 | time  46.6s
[2018-08-20 14:31:29,811 INFO] | epoch  37 | train_loss  3.73 | val_ppl 70.22097 | time  46.5s
[2018-08-20 14:32:16,258 INFO] | epoch  38 | train_loss  3.73 | val_ppl 70.21357 | time  46.4s
[2018-08-20 14:33:02,773 INFO] | epoch  39 | train_loss  3.73 | val_ppl 70.20735 | time  46.5s
[2018-08-20 14:33:49,416 INFO] | epoch  40 | train_loss  3.73 | val_ppl 70.20214 | time  46.6s
[2018-08-20 14:33:49,417 INFO] start to save model on nnlm.model
[2018-08-20 14:33:52,034 INFO] test_ppl: 68.47562
[2018-08-20 15:04:18,963 INFO] -------------
[2018-08-20 15:04:18,963 INFO] Start training...
[2018-08-20 15:04:18,963 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='./80bptt_40epoch_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./80bptt_40epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1205, tied=True, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 15:04:30,695 INFO] train token: 2127402
[2018-08-20 15:04:30,696 INFO] test token: 250140
[2018-08-20 15:04:30,696 INFO] valid token: 221606
[2018-08-20 15:04:30,805 INFO] Loading vectors from 80bptt_40epoch_outemb.txt
[2018-08-20 15:04:30,808 WARNING] Skipping token 23381 with 1-dimensional vector ['650']; likely a header
[2018-08-20 15:04:35,389 INFO] Saving vectors to ./80bptt_40epoch_outemb.txt.pt
[2018-08-20 15:05:30,941 INFO] | epoch   1 | train_loss  5.18 | val_ppl 113.08257 | time  43.5s
[2018-08-20 15:06:15,326 INFO] | epoch   2 | train_loss  4.44 | val_ppl 93.21598 | time  44.4s
[2018-08-20 15:06:59,867 INFO] | epoch   3 | train_loss  4.26 | val_ppl 85.28243 | time  44.5s
[2018-08-20 15:07:44,693 INFO] | epoch   4 | train_loss  4.15 | val_ppl 81.51149 | time  44.8s
[2018-08-20 15:08:29,772 INFO] | epoch   5 | train_loss  4.08 | val_ppl 79.12604 | time  45.1s
[2018-08-20 15:09:15,155 INFO] | epoch   6 | train_loss  4.02 | val_ppl 77.52597 | time  45.4s
[2018-08-20 15:10:00,829 INFO] | epoch   7 | train_loss  3.97 | val_ppl 76.41304 | time  45.7s
[2018-08-20 15:10:46,447 INFO] | epoch   8 | train_loss  3.93 | val_ppl 75.59597 | time  45.6s
[2018-08-20 15:11:32,098 INFO] | epoch   9 | train_loss  3.89 | val_ppl 74.96525 | time  45.7s
[2018-08-20 15:12:18,037 INFO] | epoch  10 | train_loss  3.86 | val_ppl 74.46990 | time  45.9s
[2018-08-20 15:13:03,852 INFO] | epoch  11 | train_loss  3.82 | val_ppl 74.07900 | time  45.8s
[2018-08-20 15:13:49,784 INFO] | epoch  12 | train_loss  3.79 | val_ppl 73.78254 | time  45.9s
[2018-08-20 15:14:35,705 INFO] | epoch  13 | train_loss  3.76 | val_ppl 73.57270 | time  45.9s
[2018-08-20 15:15:21,506 INFO] | epoch  14 | train_loss  3.74 | val_ppl 73.44712 | time  45.8s
[2018-08-20 15:16:07,404 INFO] | epoch  15 | train_loss  3.71 | val_ppl 73.41404 | time  45.9s
[2018-08-20 15:16:53,227 INFO] | epoch  16 | train_loss  3.68 | val_ppl 73.47974 | time  45.8s
[2018-08-20 15:16:53,227 INFO] learning rate has been changed to 0.015625
[2018-08-20 15:17:39,077 INFO] | epoch  17 | train_loss  3.66 | val_ppl 68.85428 | time  45.8s
[2018-08-20 15:18:24,951 INFO] | epoch  18 | train_loss  3.64 | val_ppl 68.59650 | time  45.9s
[2018-08-20 15:19:10,954 INFO] | epoch  19 | train_loss  3.64 | val_ppl 68.50983 | time  46.0s
[2018-08-20 15:19:57,003 INFO] | epoch  20 | train_loss  3.63 | val_ppl 68.47276 | time  46.0s
[2018-08-20 15:20:42,986 INFO] | epoch  21 | train_loss  3.63 | val_ppl 68.45689 | time  46.0s
[2018-08-20 15:21:28,920 INFO] | epoch  22 | train_loss  3.63 | val_ppl 68.45205 | time  45.9s
[2018-08-20 15:22:15,016 INFO] | epoch  23 | train_loss  3.63 | val_ppl 68.45366 | time  46.1s
[2018-08-20 15:22:15,017 INFO] learning rate has been changed to 0.00390625
[2018-08-20 15:23:01,178 INFO] | epoch  24 | train_loss  3.63 | val_ppl 68.18115 | time  46.2s
[2018-08-20 15:23:47,303 INFO] | epoch  25 | train_loss  3.63 | val_ppl 68.16443 | time  46.1s
[2018-08-20 15:24:33,348 INFO] | epoch  26 | train_loss  3.63 | val_ppl 68.15840 | time  46.0s
[2018-08-20 15:25:19,510 INFO] | epoch  27 | train_loss  3.63 | val_ppl 68.15575 | time  46.2s
[2018-08-20 15:26:05,975 INFO] | epoch  28 | train_loss  3.63 | val_ppl 68.15466 | time  46.5s
[2018-08-20 15:26:52,244 INFO] | epoch  29 | train_loss  3.63 | val_ppl 68.15443 | time  46.3s
[2018-08-20 15:27:38,531 INFO] | epoch  30 | train_loss  3.63 | val_ppl 68.15476 | time  46.3s
[2018-08-20 15:27:38,532 INFO] learning rate has been changed to 0.00048828125
[2018-08-20 15:28:24,934 INFO] | epoch  31 | train_loss  3.63 | val_ppl 68.12223 | time  46.4s
[2018-08-20 15:29:11,335 INFO] | epoch  32 | train_loss  3.63 | val_ppl 68.11358 | time  46.4s
[2018-08-20 15:29:57,800 INFO] | epoch  33 | train_loss  3.63 | val_ppl 68.10960 | time  46.5s
[2018-08-20 15:30:44,200 INFO] | epoch  34 | train_loss  3.63 | val_ppl 68.10739 | time  46.4s
[2018-08-20 15:31:30,525 INFO] | epoch  35 | train_loss  3.63 | val_ppl 68.10602 | time  46.3s
[2018-08-20 15:32:17,026 INFO] | epoch  36 | train_loss  3.63 | val_ppl 68.10512 | time  46.5s
[2018-08-20 15:33:03,664 INFO] | epoch  37 | train_loss  3.63 | val_ppl 68.10452 | time  46.6s
[2018-08-20 15:33:50,379 INFO] | epoch  38 | train_loss  3.63 | val_ppl 68.10410 | time  46.7s
[2018-08-20 15:34:37,175 INFO] | epoch  39 | train_loss  3.63 | val_ppl 68.10381 | time  46.8s
[2018-08-20 15:35:24,072 INFO] | epoch  40 | train_loss  3.63 | val_ppl 68.10361 | time  46.7s
[2018-08-20 15:35:24,073 INFO] start to save model on nnlm.model
[2018-08-20 15:35:26,760 INFO] test_ppl: 66.61851
[2018-08-20 15:41:25,107 INFO] -------------
[2018-08-20 15:41:25,108 INFO] Start training...
[2018-08-20 15:41:25,108 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='./80bptt_40epoch_outemb2ed.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./80bptt_40epoch_outemb2ed.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=125, tied=True, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 15:41:35,942 INFO] train token: 2127402
[2018-08-20 15:41:35,942 INFO] test token: 250140
[2018-08-20 15:41:35,942 INFO] valid token: 221606
[2018-08-20 15:41:37,460 INFO] Loading vectors from 80bptt_40epoch_outemb2ed.txt
[2018-08-20 15:41:37,464 WARNING] Skipping token 23381 with 1-dimensional vector ['650']; likely a header
[2018-08-20 15:41:42,030 INFO] Saving vectors to ./80bptt_40epoch_outemb2ed.txt.pt
[2018-08-20 15:42:39,007 INFO] | epoch   1 | train_loss  4.98 | val_ppl 105.27533 | time  43.8s
[2018-08-20 15:43:23,407 INFO] | epoch   2 | train_loss  4.30 | val_ppl 88.28194 | time  44.4s
[2018-08-20 15:44:08,009 INFO] | epoch   3 | train_loss  4.11 | val_ppl 80.99695 | time  44.6s
[2018-08-20 15:44:53,115 INFO] | epoch   4 | train_loss  4.00 | val_ppl 77.93251 | time  45.1s
[2018-08-20 15:45:38,326 INFO] | epoch   5 | train_loss  3.92 | val_ppl 76.24291 | time  45.2s
[2018-08-20 15:46:23,770 INFO] | epoch   6 | train_loss  3.86 | val_ppl 75.16906 | time  45.4s
[2018-08-20 15:47:09,594 INFO] | epoch   7 | train_loss  3.82 | val_ppl 74.45319 | time  45.8s
[2018-08-20 15:47:55,110 INFO] | epoch   8 | train_loss  3.78 | val_ppl 73.94379 | time  45.5s
[2018-08-20 15:48:40,827 INFO] | epoch   9 | train_loss  3.74 | val_ppl 73.59727 | time  45.7s
[2018-08-20 15:49:26,745 INFO] | epoch  10 | train_loss  3.71 | val_ppl 73.39771 | time  45.9s
[2018-08-20 15:50:12,605 INFO] | epoch  11 | train_loss  3.68 | val_ppl 73.31659 | time  45.9s
[2018-08-20 15:50:58,336 INFO] | epoch  12 | train_loss  3.65 | val_ppl 73.32038 | time  45.7s
[2018-08-20 15:50:58,336 INFO] learning rate has been changed to 0.03125
[2018-08-20 15:51:44,263 INFO] | epoch  13 | train_loss  3.63 | val_ppl 68.27783 | time  45.9s
[2018-08-20 15:52:30,076 INFO] | epoch  14 | train_loss  3.61 | val_ppl 68.14108 | time  45.8s
[2018-08-20 15:53:16,030 INFO] | epoch  15 | train_loss  3.61 | val_ppl 68.11502 | time  46.0s
[2018-08-20 15:54:01,910 INFO] | epoch  16 | train_loss  3.60 | val_ppl 68.11615 | time  45.9s
[2018-08-20 15:54:01,911 INFO] learning rate has been changed to 0.015625
[2018-08-20 15:54:47,999 INFO] | epoch  17 | train_loss  3.60 | val_ppl 67.81565 | time  46.1s
[2018-08-20 15:55:33,871 INFO] | epoch  18 | train_loss  3.60 | val_ppl 67.80364 | time  45.9s
[2018-08-20 15:56:19,859 INFO] | epoch  19 | train_loss  3.60 | val_ppl 67.80416 | time  46.0s
[2018-08-20 15:56:19,860 INFO] learning rate has been changed to 0.0078125
[2018-08-20 15:57:05,895 INFO] | epoch  20 | train_loss  3.60 | val_ppl 67.63813 | time  46.0s
[2018-08-20 15:57:51,952 INFO] | epoch  21 | train_loss  3.60 | val_ppl 67.62952 | time  46.1s
[2018-08-20 15:58:38,018 INFO] | epoch  22 | train_loss  3.60 | val_ppl 67.62755 | time  46.1s
[2018-08-20 15:59:23,985 INFO] | epoch  23 | train_loss  3.60 | val_ppl 67.62786 | time  46.0s
[2018-08-20 15:59:23,986 INFO] learning rate has been changed to 0.00390625
[2018-08-20 16:00:10,209 INFO] | epoch  24 | train_loss  3.60 | val_ppl 67.53975 | time  46.2s
[2018-08-20 16:00:56,395 INFO] | epoch  25 | train_loss  3.60 | val_ppl 67.53589 | time  46.2s
[2018-08-20 16:01:42,594 INFO] | epoch  26 | train_loss  3.60 | val_ppl 67.53447 | time  46.2s
[2018-08-20 16:02:28,754 INFO] | epoch  27 | train_loss  3.59 | val_ppl 67.53402 | time  46.2s
[2018-08-20 16:03:14,884 INFO] | epoch  28 | train_loss  3.59 | val_ppl 67.53411 | time  46.1s
[2018-08-20 16:03:14,885 INFO] learning rate has been changed to 0.0009765625
[2018-08-20 16:04:01,250 INFO] | epoch  29 | train_loss  3.59 | val_ppl 67.48046 | time  46.4s
[2018-08-20 16:04:47,313 INFO] | epoch  30 | train_loss  3.59 | val_ppl 67.47492 | time  46.1s
[2018-08-20 16:05:33,641 INFO] | epoch  31 | train_loss  3.59 | val_ppl 67.47316 | time  46.3s
[2018-08-20 16:06:19,917 INFO] | epoch  32 | train_loss  3.59 | val_ppl 67.47223 | time  46.3s
[2018-08-20 16:07:06,051 INFO] | epoch  33 | train_loss  3.59 | val_ppl 67.47164 | time  46.1s
[2018-08-20 16:07:52,323 INFO] | epoch  34 | train_loss  3.59 | val_ppl 67.47125 | time  46.3s
[2018-08-20 16:08:38,467 INFO] | epoch  35 | train_loss  3.59 | val_ppl 67.47098 | time  46.1s
[2018-08-20 16:09:24,718 INFO] | epoch  36 | train_loss  3.59 | val_ppl 67.47080 | time  46.3s
[2018-08-20 16:10:11,133 INFO] | epoch  37 | train_loss  3.59 | val_ppl 67.47069 | time  46.4s
[2018-08-20 16:10:57,344 INFO] | epoch  38 | train_loss  3.59 | val_ppl 67.47062 | time  46.2s
[2018-08-20 16:11:43,687 INFO] | epoch  39 | train_loss  3.59 | val_ppl 67.47060 | time  46.3s
[2018-08-20 16:12:30,063 INFO] | epoch  40 | train_loss  3.59 | val_ppl 67.47061 | time  46.4s
[2018-08-20 16:12:30,064 INFO] learning rate has been changed to 6.103515625e-05
[2018-08-20 16:12:30,064 INFO] start to save model on nnlm.model
[2018-08-20 16:12:32,526 INFO] test_ppl: 65.95860
[2018-08-20 16:16:50,772 INFO] -------------
[2018-08-20 16:16:50,773 INFO] Start training...
[2018-08-20 16:16:50,773 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='./80bptt_40epoch_outemb3th.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./80bptt_40epoch_outemb3th.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=125, tied=True, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 16:17:02,170 INFO] train token: 2127402
[2018-08-20 16:17:02,171 INFO] test token: 250140
[2018-08-20 16:17:02,171 INFO] valid token: 221606
[2018-08-20 16:17:03,458 INFO] Loading vectors from 80bptt_40epoch_outemb3th.txt
[2018-08-20 16:17:03,462 WARNING] Skipping token 23381 with 1-dimensional vector ['650']; likely a header
[2018-08-20 16:17:08,183 INFO] Saving vectors to ./80bptt_40epoch_outemb3th.txt.pt
[2018-08-20 16:18:04,432 INFO] | epoch   1 | train_loss  5.03 | val_ppl 102.10232 | time  43.8s
[2018-08-20 16:18:48,873 INFO] | epoch   2 | train_loss  4.25 | val_ppl 85.56427 | time  44.4s
[2018-08-20 16:19:33,564 INFO] | epoch   3 | train_loss  4.04 | val_ppl 79.23915 | time  44.7s
[2018-08-20 16:20:18,839 INFO] | epoch   4 | train_loss  3.92 | val_ppl 76.35675 | time  45.3s
[2018-08-20 16:21:04,149 INFO] | epoch   5 | train_loss  3.84 | val_ppl 74.96352 | time  45.3s
[2018-08-20 16:21:49,729 INFO] | epoch   6 | train_loss  3.79 | val_ppl 74.11392 | time  45.6s
[2018-08-20 16:22:35,449 INFO] | epoch   7 | train_loss  3.74 | val_ppl 73.57435 | time  45.7s
[2018-08-20 16:23:21,193 INFO] | epoch   8 | train_loss  3.70 | val_ppl 73.28997 | time  45.7s
[2018-08-20 16:24:06,871 INFO] | epoch   9 | train_loss  3.67 | val_ppl 73.17143 | time  45.7s
[2018-08-20 16:24:52,782 INFO] | epoch  10 | train_loss  3.64 | val_ppl 73.13727 | time  45.9s
[2018-08-20 16:25:39,029 INFO] | epoch  11 | train_loss  3.61 | val_ppl 73.18302 | time  46.2s
[2018-08-20 16:25:39,030 INFO] learning rate has been changed to 0.0625
[2018-08-20 16:26:25,361 INFO] | epoch  12 | train_loss  3.58 | val_ppl 68.95899 | time  46.3s
[2018-08-20 16:27:11,808 INFO] | epoch  13 | train_loss  3.56 | val_ppl 68.91639 | time  46.4s
[2018-08-20 16:27:58,224 INFO] | epoch  14 | train_loss  3.56 | val_ppl 68.94122 | time  46.4s
[2018-08-20 16:27:58,225 INFO] learning rate has been changed to 0.03125
[2018-08-20 16:28:44,699 INFO] | epoch  15 | train_loss  3.56 | val_ppl 68.41463 | time  46.5s
[2018-08-20 16:29:31,095 INFO] | epoch  16 | train_loss  3.55 | val_ppl 68.41253 | time  46.4s
[2018-08-20 16:30:17,533 INFO] | epoch  17 | train_loss  3.55 | val_ppl 68.42448 | time  46.4s
[2018-08-20 16:30:17,534 INFO] learning rate has been changed to 0.015625
[2018-08-20 16:31:03,953 INFO] | epoch  18 | train_loss  3.55 | val_ppl 68.08111 | time  46.4s
[2018-08-20 16:31:50,203 INFO] | epoch  19 | train_loss  3.55 | val_ppl 68.07208 | time  46.2s
[2018-08-20 16:32:36,736 INFO] | epoch  20 | train_loss  3.55 | val_ppl 68.07355 | time  46.5s
[2018-08-20 16:32:36,737 INFO] learning rate has been changed to 0.0078125
[2018-08-20 16:33:23,237 INFO] | epoch  21 | train_loss  3.55 | val_ppl 67.86498 | time  46.5s
[2018-08-20 16:34:09,611 INFO] | epoch  22 | train_loss  3.55 | val_ppl 67.85690 | time  46.4s
[2018-08-20 16:34:55,940 INFO] | epoch  23 | train_loss  3.55 | val_ppl 67.85545 | time  46.3s
[2018-08-20 16:35:42,344 INFO] | epoch  24 | train_loss  3.55 | val_ppl 67.85606 | time  46.4s
[2018-08-20 16:35:42,345 INFO] learning rate has been changed to 0.001953125
[2018-08-20 16:36:28,813 INFO] | epoch  25 | train_loss  3.55 | val_ppl 67.69524 | time  46.5s
[2018-08-20 16:37:15,034 INFO] | epoch  26 | train_loss  3.55 | val_ppl 67.68265 | time  46.2s
[2018-08-20 16:38:01,361 INFO] | epoch  27 | train_loss  3.55 | val_ppl 67.67824 | time  46.3s
[2018-08-20 16:38:47,697 INFO] | epoch  28 | train_loss  3.55 | val_ppl 67.67609 | time  46.3s
[2018-08-20 16:39:34,017 INFO] | epoch  29 | train_loss  3.55 | val_ppl 67.67484 | time  46.3s
[2018-08-20 16:40:20,448 INFO] | epoch  30 | train_loss  3.55 | val_ppl 67.67406 | time  46.4s
[2018-08-20 16:41:06,874 INFO] | epoch  31 | train_loss  3.55 | val_ppl 67.67356 | time  46.4s
[2018-08-20 16:41:53,158 INFO] | epoch  32 | train_loss  3.55 | val_ppl 67.67325 | time  46.3s
[2018-08-20 16:42:39,474 INFO] | epoch  33 | train_loss  3.54 | val_ppl 67.67308 | time  46.3s
[2018-08-20 16:43:26,006 INFO] | epoch  34 | train_loss  3.54 | val_ppl 67.67302 | time  46.5s
[2018-08-20 16:44:12,377 INFO] | epoch  35 | train_loss  3.54 | val_ppl 67.67304 | time  46.4s
[2018-08-20 16:44:12,378 INFO] learning rate has been changed to 0.000244140625
[2018-08-20 16:44:58,965 INFO] | epoch  36 | train_loss  3.54 | val_ppl 67.66358 | time  46.6s
[2018-08-20 16:45:45,347 INFO] | epoch  37 | train_loss  3.54 | val_ppl 67.65910 | time  46.4s
[2018-08-20 16:46:31,960 INFO] | epoch  38 | train_loss  3.54 | val_ppl 67.65641 | time  46.6s
[2018-08-20 16:47:18,499 INFO] | epoch  39 | train_loss  3.54 | val_ppl 67.65459 | time  46.5s
[2018-08-20 16:48:05,044 INFO] | epoch  40 | train_loss  3.54 | val_ppl 67.65326 | time  46.5s
[2018-08-20 16:48:05,045 INFO] start to save model on nnlm.model
[2018-08-20 16:48:07,825 INFO] test_ppl: 66.29112
[2018-08-20 16:58:51,373 INFO] -------------
[2018-08-20 16:58:51,374 INFO] Start training...
[2018-08-20 16:58:51,374 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='./80bptt_40epoch_outemb3th.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./80bptt_40epoch_outemb3th.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1215, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-20 16:59:02,635 INFO] train token: 2127402
[2018-08-20 16:59:02,635 INFO] test token: 250140
[2018-08-20 16:59:02,635 INFO] valid token: 221606
[2018-08-20 16:59:02,635 INFO] Loading vectors from ./80bptt_40epoch_outemb3th.txt.pt
[2018-08-20 16:59:58,555 INFO] | epoch   1 | train_loss  4.81 | val_ppl 101.25213 | time  43.6s
[2018-08-20 17:00:42,931 INFO] | epoch   2 | train_loss  4.19 | val_ppl 84.82137 | time  44.4s
[2018-08-20 17:01:27,434 INFO] | epoch   3 | train_loss  4.00 | val_ppl 78.35311 | time  44.5s
[2018-08-20 17:02:12,145 INFO] | epoch   4 | train_loss  3.89 | val_ppl 75.96403 | time  44.7s
[2018-08-20 17:02:57,093 INFO] | epoch   5 | train_loss  3.82 | val_ppl 74.61279 | time  44.9s
[2018-08-20 17:03:42,369 INFO] | epoch   6 | train_loss  3.76 | val_ppl 73.76939 | time  45.3s
[2018-08-20 17:04:28,110 INFO] | epoch   7 | train_loss  3.72 | val_ppl 73.21514 | time  45.7s
[2018-08-20 17:05:13,682 INFO] | epoch   8 | train_loss  3.68 | val_ppl 72.87730 | time  45.6s
[2018-08-20 17:05:59,350 INFO] | epoch   9 | train_loss  3.65 | val_ppl 72.70236 | time  45.7s
[2018-08-20 17:06:45,158 INFO] | epoch  10 | train_loss  3.62 | val_ppl 72.65380 | time  45.8s
[2018-08-20 17:07:30,943 INFO] | epoch  11 | train_loss  3.59 | val_ppl 72.71319 | time  45.8s
[2018-08-20 17:07:30,944 INFO] learning rate has been changed to 0.0625
[2018-08-20 17:08:16,726 INFO] | epoch  12 | train_loss  3.56 | val_ppl 68.64287 | time  45.8s
[2018-08-20 17:09:02,558 INFO] | epoch  13 | train_loss  3.54 | val_ppl 68.62171 | time  45.8s
[2018-08-20 17:09:48,548 INFO] | epoch  14 | train_loss  3.54 | val_ppl 68.65971 | time  46.0s
[2018-08-20 17:09:48,549 INFO] learning rate has been changed to 0.03125
[2018-08-20 17:10:34,492 INFO] | epoch  15 | train_loss  3.54 | val_ppl 68.18017 | time  45.9s
[2018-08-20 17:11:20,391 INFO] | epoch  16 | train_loss  3.53 | val_ppl 68.18500 | time  45.9s
[2018-08-20 17:11:20,392 INFO] learning rate has been changed to 0.015625
[2018-08-20 17:12:06,473 INFO] | epoch  17 | train_loss  3.53 | val_ppl 67.89107 | time  46.1s
[2018-08-20 17:12:52,436 INFO] | epoch  18 | train_loss  3.53 | val_ppl 67.88381 | time  46.0s
[2018-08-20 17:13:38,425 INFO] | epoch  19 | train_loss  3.53 | val_ppl 67.88710 | time  46.0s
[2018-08-20 17:13:38,426 INFO] learning rate has been changed to 0.0078125
[2018-08-20 17:14:24,538 INFO] | epoch  20 | train_loss  3.53 | val_ppl 67.72157 | time  46.1s
[2018-08-20 17:15:10,488 INFO] | epoch  21 | train_loss  3.53 | val_ppl 67.71473 | time  45.9s
[2018-08-20 17:15:56,443 INFO] | epoch  22 | train_loss  3.53 | val_ppl 67.71434 | time  46.0s
[2018-08-20 17:16:42,658 INFO] | epoch  23 | train_loss  3.53 | val_ppl 67.71593 | time  46.2s
[2018-08-20 17:16:42,659 INFO] learning rate has been changed to 0.00390625
[2018-08-20 17:17:28,942 INFO] | epoch  24 | train_loss  3.53 | val_ppl 67.62936 | time  46.3s
[2018-08-20 17:18:15,043 INFO] | epoch  25 | train_loss  3.53 | val_ppl 67.62635 | time  46.1s
[2018-08-20 17:19:01,083 INFO] | epoch  26 | train_loss  3.53 | val_ppl 67.62577 | time  46.0s
[2018-08-20 17:19:47,395 INFO] | epoch  27 | train_loss  3.53 | val_ppl 67.62605 | time  46.3s
[2018-08-20 17:19:47,396 INFO] learning rate has been changed to 0.0009765625
[2018-08-20 17:20:33,485 INFO] | epoch  28 | train_loss  3.53 | val_ppl 67.56975 | time  46.1s
[2018-08-20 17:21:19,639 INFO] | epoch  29 | train_loss  3.53 | val_ppl 67.56418 | time  46.2s
[2018-08-20 17:22:05,708 INFO] | epoch  30 | train_loss  3.53 | val_ppl 67.56276 | time  46.1s
[2018-08-20 17:22:52,202 INFO] | epoch  31 | train_loss  3.53 | val_ppl 67.56225 | time  46.5s
[2018-08-20 17:23:38,333 INFO] | epoch  32 | train_loss  3.53 | val_ppl 67.56206 | time  46.1s
[2018-08-20 17:24:24,630 INFO] | epoch  33 | train_loss  3.53 | val_ppl 67.56200 | time  46.3s
[2018-08-20 17:25:10,845 INFO] | epoch  34 | train_loss  3.53 | val_ppl 67.56203 | time  46.2s
[2018-08-20 17:25:10,846 INFO] learning rate has been changed to 0.000244140625
[2018-08-20 17:25:57,330 INFO] | epoch  35 | train_loss  3.53 | val_ppl 67.56146 | time  46.5s
[2018-08-20 17:26:43,634 INFO] | epoch  36 | train_loss  3.53 | val_ppl 67.56137 | time  46.3s
[2018-08-20 17:27:29,923 INFO] | epoch  37 | train_loss  3.53 | val_ppl 67.56132 | time  46.3s
[2018-08-20 17:28:16,155 INFO] | epoch  38 | train_loss  3.53 | val_ppl 67.56128 | time  46.2s
[2018-08-20 17:29:02,297 INFO] | epoch  39 | train_loss  3.53 | val_ppl 67.56129 | time  46.1s
[2018-08-20 17:29:02,298 INFO] learning rate has been changed to 6.103515625e-05
[2018-08-20 17:29:48,589 INFO] | epoch  40 | train_loss  3.53 | val_ppl 67.56170 | time  46.3s
[2018-08-20 17:29:48,590 INFO] learning rate has been changed to 6.103515625e-05
[2018-08-20 17:29:48,590 INFO] start to save model on nnlm.model
[2018-08-20 17:29:51,206 INFO] test_ppl: 66.19761
[2018-08-20 20:16:32,133 INFO] -------------
[2018-08-20 20:16:32,133 INFO] Start training...
[2018-08-20 20:16:32,133 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/1mlplen_8epoch_850d.outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/1mlplen_8epoch_850d.outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=125, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-20 20:16:44,005 INFO] train token: 2127402
[2018-08-20 20:16:44,005 INFO] test token: 250140
[2018-08-20 20:16:44,005 INFO] valid token: 221606
[2018-08-20 20:16:47,172 INFO] Loading vectors from /home/lr/yukun/common_corpus/1mlplen_8epoch_850d.outemb.txt
[2018-08-20 20:16:47,684 WARNING] Skipping token 23381 with 1-dimensional vector ['850']; likely a header
[2018-08-20 20:16:53,817 INFO] Saving vectors to /home/lr/yukun/common_corpus/1mlplen_8epoch_850d.outemb.txt.pt
[2018-08-20 20:18:05,131 INFO] | epoch   1 | train_loss  5.88 | val_ppl 190.68417 | time  55.8s
[2018-08-20 20:19:01,152 INFO] | epoch   2 | train_loss  4.90 | val_ppl 126.32410 | time  56.0s
[2018-08-20 20:19:58,620 INFO] | epoch   3 | train_loss  4.72 | val_ppl 112.26508 | time  57.5s
[2018-08-20 20:20:56,544 INFO] | epoch   4 | train_loss  4.61 | val_ppl 103.79554 | time  57.9s
[2018-08-20 20:21:54,845 INFO] | epoch   5 | train_loss  4.51 | val_ppl 97.79462 | time  58.3s
[2018-08-20 20:22:54,161 INFO] | epoch   6 | train_loss  4.44 | val_ppl 93.34692 | time  59.2s
[2018-08-20 20:23:52,893 INFO] | epoch   7 | train_loss  4.37 | val_ppl 89.90953 | time  58.7s
[2018-08-20 20:24:52,270 INFO] | epoch   8 | train_loss  4.31 | val_ppl 87.19525 | time  59.4s
[2018-08-20 20:25:51,484 INFO] | epoch   9 | train_loss  4.26 | val_ppl 84.99280 | time  59.2s
[2018-08-20 20:26:50,270 INFO] | epoch  10 | train_loss  4.21 | val_ppl 83.13882 | time  58.8s
[2018-08-20 20:27:49,453 INFO] | epoch  11 | train_loss  4.16 | val_ppl 81.53011 | time  59.2s
[2018-08-20 20:28:48,310 INFO] | epoch  12 | train_loss  4.12 | val_ppl 80.15046 | time  58.9s
[2018-08-20 20:29:47,596 INFO] | epoch  13 | train_loss  4.08 | val_ppl 79.00673 | time  59.3s
[2018-08-20 20:30:46,480 INFO] | epoch  14 | train_loss  4.04 | val_ppl 78.08167 | time  58.9s
[2018-08-20 20:31:45,255 INFO] | epoch  15 | train_loss  4.00 | val_ppl 77.34690 | time  58.8s
[2018-08-20 20:32:43,994 INFO] | epoch  16 | train_loss  3.96 | val_ppl 76.78017 | time  58.7s
[2018-08-20 20:33:42,688 INFO] | epoch  17 | train_loss  3.92 | val_ppl 76.37064 | time  58.7s
[2018-08-20 20:34:41,639 INFO] | epoch  18 | train_loss  3.89 | val_ppl 76.11440 | time  58.9s
[2018-08-20 20:35:40,339 INFO] | epoch  19 | train_loss  3.85 | val_ppl 76.01639 | time  58.7s
[2018-08-20 20:36:39,556 INFO] | epoch  20 | train_loss  3.81 | val_ppl 76.08385 | time  59.2s
[2018-08-20 20:36:39,556 INFO] learning rate has been changed to 0.0078125
[2018-08-20 20:37:38,239 INFO] | epoch  21 | train_loss  3.79 | val_ppl 71.49515 | time  58.7s
[2018-08-20 20:38:37,080 INFO] | epoch  22 | train_loss  3.77 | val_ppl 71.06354 | time  58.8s
[2018-08-20 20:39:35,714 INFO] | epoch  23 | train_loss  3.76 | val_ppl 70.87251 | time  58.6s
[2018-08-20 20:40:34,307 INFO] | epoch  24 | train_loss  3.76 | val_ppl 70.76832 | time  58.6s
[2018-08-20 20:41:33,018 INFO] | epoch  25 | train_loss  3.75 | val_ppl 70.70536 | time  58.7s
[2018-08-20 20:42:31,724 INFO] | epoch  26 | train_loss  3.75 | val_ppl 70.66509 | time  58.7s
[2018-08-20 20:43:30,610 INFO] | epoch  27 | train_loss  3.75 | val_ppl 70.63854 | time  58.9s
[2018-08-20 20:44:29,505 INFO] | epoch  28 | train_loss  3.75 | val_ppl 70.62089 | time  58.9s
[2018-08-20 20:45:28,391 INFO] | epoch  29 | train_loss  3.75 | val_ppl 70.60931 | time  58.9s
[2018-08-20 20:46:27,267 INFO] | epoch  30 | train_loss  3.75 | val_ppl 70.60205 | time  58.8s
[2018-08-20 20:47:25,934 INFO] | epoch  31 | train_loss  3.74 | val_ppl 70.59793 | time  58.7s
[2018-08-20 20:48:25,132 INFO] | epoch  32 | train_loss  3.74 | val_ppl 70.59619 | time  59.2s
[2018-08-20 20:49:24,205 INFO] | epoch  33 | train_loss  3.74 | val_ppl 70.59625 | time  59.1s
[2018-08-20 20:49:24,205 INFO] learning rate has been changed to 0.000244140625
[2018-08-20 20:50:22,814 INFO] | epoch  34 | train_loss  3.74 | val_ppl 70.50608 | time  58.6s
[2018-08-20 20:51:22,387 INFO] | epoch  35 | train_loss  3.74 | val_ppl 70.47132 | time  59.6s
[2018-08-20 20:52:21,493 INFO] | epoch  36 | train_loss  3.74 | val_ppl 70.45288 | time  59.1s
[2018-08-20 20:53:20,273 INFO] | epoch  37 | train_loss  3.74 | val_ppl 70.44117 | time  58.8s
[2018-08-20 20:54:19,196 INFO] | epoch  38 | train_loss  3.74 | val_ppl 70.43303 | time  58.9s
[2018-08-20 20:55:18,282 INFO] | epoch  39 | train_loss  3.74 | val_ppl 70.42708 | time  59.0s
[2018-08-20 20:56:17,680 INFO] | epoch  40 | train_loss  3.74 | val_ppl 70.42260 | time  59.2s
[2018-08-20 20:56:17,681 INFO] start to save model on nnlm.model
[2018-08-20 20:56:21,640 INFO] test_ppl: 68.73485
[2018-08-20 21:02:01,987 INFO] -------------
[2018-08-20 21:02:01,987 INFO] Start training...
[2018-08-20 21:02:01,987 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='./80bptt_40epoch_850d.1st.outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./80bptt_40epoch_850d.1st.outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=125, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-20 21:02:13,474 INFO] train token: 2127402
[2018-08-20 21:02:13,475 INFO] test token: 250140
[2018-08-20 21:02:13,475 INFO] valid token: 221606
[2018-08-20 21:02:14,760 INFO] Loading vectors from 80bptt_40epoch_850d.1st.outemb.txt
[2018-08-20 21:02:14,767 WARNING] Skipping token 23381 with 1-dimensional vector ['850']; likely a header
[2018-08-20 21:02:20,621 INFO] Saving vectors to ./80bptt_40epoch_850d.1st.outemb.txt.pt
[2018-08-20 21:03:30,905 INFO] | epoch   1 | train_loss  5.30 | val_ppl 116.66195 | time  55.8s
[2018-08-20 21:04:27,305 INFO] | epoch   2 | train_loss  4.47 | val_ppl 94.26703 | time  56.4s
[2018-08-20 21:05:24,936 INFO] | epoch   3 | train_loss  4.28 | val_ppl 86.11082 | time  57.6s
[2018-08-20 21:06:23,251 INFO] | epoch   4 | train_loss  4.17 | val_ppl 81.34071 | time  58.3s
[2018-08-20 21:07:22,203 INFO] | epoch   5 | train_loss  4.09 | val_ppl 78.59621 | time  58.8s
[2018-08-20 21:08:21,526 INFO] | epoch   6 | train_loss  4.03 | val_ppl 76.85938 | time  59.3s
[2018-08-20 21:09:20,541 INFO] | epoch   7 | train_loss  3.98 | val_ppl 75.66025 | time  59.0s
[2018-08-20 21:10:19,904 INFO] | epoch   8 | train_loss  3.94 | val_ppl 74.79874 | time  59.4s
[2018-08-20 21:11:18,682 INFO] | epoch   9 | train_loss  3.89 | val_ppl 74.17413 | time  58.8s
[2018-08-20 21:12:17,842 INFO] | epoch  10 | train_loss  3.86 | val_ppl 73.74231 | time  59.2s
[2018-08-20 21:13:16,338 INFO] | epoch  11 | train_loss  3.82 | val_ppl 73.47398 | time  58.5s
[2018-08-20 21:14:14,838 INFO] | epoch  12 | train_loss  3.78 | val_ppl 73.34168 | time  58.5s
[2018-08-20 21:15:13,587 INFO] | epoch  13 | train_loss  3.75 | val_ppl 73.32537 | time  58.7s
[2018-08-20 21:16:12,242 INFO] | epoch  14 | train_loss  3.71 | val_ppl 73.42595 | time  58.7s
[2018-08-20 21:16:12,243 INFO] learning rate has been changed to 0.03125
[2018-08-20 21:17:10,777 INFO] | epoch  15 | train_loss  3.68 | val_ppl 68.43583 | time  58.5s
[2018-08-20 21:18:09,160 INFO] | epoch  16 | train_loss  3.66 | val_ppl 68.32693 | time  58.4s
[2018-08-20 21:19:07,918 INFO] | epoch  17 | train_loss  3.65 | val_ppl 68.32069 | time  58.8s
[2018-08-20 21:20:06,578 INFO] | epoch  18 | train_loss  3.65 | val_ppl 68.33961 | time  58.7s
[2018-08-20 21:20:06,579 INFO] learning rate has been changed to 0.0078125
[2018-08-20 21:21:05,302 INFO] | epoch  19 | train_loss  3.65 | val_ppl 67.81343 | time  58.7s
[2018-08-20 21:22:04,431 INFO] | epoch  20 | train_loss  3.65 | val_ppl 67.78466 | time  59.1s
[2018-08-20 21:23:03,533 INFO] | epoch  21 | train_loss  3.65 | val_ppl 67.77619 | time  59.1s
[2018-08-20 21:24:02,569 INFO] | epoch  22 | train_loss  3.64 | val_ppl 67.77441 | time  59.0s
[2018-08-20 21:25:01,514 INFO] | epoch  23 | train_loss  3.64 | val_ppl 67.77581 | time  58.9s
[2018-08-20 21:25:01,595 INFO] learning rate has been changed to 0.00390625
[2018-08-20 21:26:00,385 INFO] | epoch  24 | train_loss  3.64 | val_ppl 67.67216 | time  58.8s
[2018-08-20 21:26:59,647 INFO] | epoch  25 | train_loss  3.64 | val_ppl 67.66732 | time  59.3s
[2018-08-20 21:27:58,523 INFO] | epoch  26 | train_loss  3.64 | val_ppl 67.66623 | time  58.9s
[2018-08-20 21:28:57,746 INFO] | epoch  27 | train_loss  3.64 | val_ppl 67.66652 | time  59.2s
[2018-08-20 21:28:57,746 INFO] learning rate has been changed to 0.0009765625
[2018-08-20 21:29:56,600 INFO] | epoch  28 | train_loss  3.64 | val_ppl 67.61140 | time  58.9s
[2018-08-20 21:30:55,561 INFO] | epoch  29 | train_loss  3.64 | val_ppl 67.60575 | time  59.0s
[2018-08-20 21:31:54,515 INFO] | epoch  30 | train_loss  3.64 | val_ppl 67.60342 | time  59.0s
[2018-08-20 21:32:53,334 INFO] | epoch  31 | train_loss  3.64 | val_ppl 67.60205 | time  58.8s
[2018-08-20 21:33:52,294 INFO] | epoch  32 | train_loss  3.64 | val_ppl 67.60119 | time  59.0s
[2018-08-20 21:34:51,056 INFO] | epoch  33 | train_loss  3.64 | val_ppl 67.60064 | time  58.8s
[2018-08-20 21:35:50,297 INFO] | epoch  34 | train_loss  3.64 | val_ppl 67.60029 | time  59.2s
[2018-08-20 21:36:49,252 INFO] | epoch  35 | train_loss  3.64 | val_ppl 67.60010 | time  59.0s
[2018-08-20 21:37:48,087 INFO] | epoch  36 | train_loss  3.64 | val_ppl 67.60001 | time  58.8s
[2018-08-20 21:38:46,989 INFO] | epoch  37 | train_loss  3.64 | val_ppl 67.60001 | time  58.9s
[2018-08-20 21:38:46,989 INFO] learning rate has been changed to 0.0001220703125
[2018-08-20 21:39:45,956 INFO] | epoch  38 | train_loss  3.64 | val_ppl 67.59936 | time  59.0s
[2018-08-20 21:40:44,937 INFO] | epoch  39 | train_loss  3.64 | val_ppl 67.59916 | time  59.0s
[2018-08-20 21:41:43,781 INFO] | epoch  40 | train_loss  3.64 | val_ppl 67.59915 | time  58.8s
[2018-08-20 21:41:43,781 INFO] start to save model on nnlm.model
[2018-08-20 21:41:46,999 INFO] test_ppl: 66.28892
[2018-08-20 21:50:39,738 INFO] -------------
[2018-08-20 21:50:39,738 INFO] Start training...
[2018-08-20 21:50:39,738 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='./80bptt_40epoch_850d.2st.outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./80bptt_40epoch_850d.2st.outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=15, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-20 21:50:50,986 INFO] train token: 2127402
[2018-08-20 21:50:50,987 INFO] test token: 250140
[2018-08-20 21:50:50,987 INFO] valid token: 221606
[2018-08-20 21:50:52,270 INFO] Loading vectors from 80bptt_40epoch_850d.2st.outemb.txt
[2018-08-20 21:50:52,275 WARNING] Skipping token 23381 with 1-dimensional vector ['850']; likely a header
[2018-08-20 21:50:58,269 INFO] Saving vectors to ./80bptt_40epoch_850d.2st.outemb.txt.pt
[2018-08-20 21:52:08,452 INFO] | epoch   1 | train_loss 28.55 | val_ppl 408446238.32923 | time  55.8s
[2018-08-20 21:53:04,290 INFO] | epoch   2 | train_loss 20.68 | val_ppl 255777681.29091 | time  55.8s
[2018-08-20 21:54:00,630 INFO] | epoch   3 | train_loss 18.81 | val_ppl 375359910177.63739 | time  56.3s
[2018-08-20 21:54:00,631 INFO] learning rate has been changed to 0.25
[2018-08-20 21:54:57,186 INFO] | epoch   4 | train_loss 10.87 | val_ppl 21671.30705 | time  56.6s
[2018-08-20 21:55:54,056 INFO] | epoch   5 | train_loss 10.65 | val_ppl 26596.12157 | time  56.9s
[2018-08-20 21:55:54,057 INFO] learning rate has been changed to 0.25
[2018-08-20 21:56:51,249 INFO] | epoch   6 | train_loss 10.53 | val_ppl 13427.86453 | time  57.2s
[2018-08-20 21:57:48,416 INFO] | epoch   7 | train_loss 10.33 | val_ppl 13514.98229 | time  57.2s
[2018-08-20 21:57:48,416 INFO] learning rate has been changed to 0.125
[2018-08-20 21:58:45,488 INFO] | epoch   8 | train_loss  7.83 | val_ppl 4049.40762 | time  57.1s
[2018-08-20 21:59:42,285 INFO] | epoch   9 | train_loss  7.79 | val_ppl 4753.58337 | time  56.8s
[2018-08-20 21:59:42,285 INFO] learning rate has been changed to 0.0625
[2018-08-20 22:00:38,957 INFO] | epoch  10 | train_loss  7.05 | val_ppl 1434.91585 | time  56.7s
[2018-08-20 22:07:24,515 INFO] -------------
[2018-08-20 22:07:24,515 INFO] Start training...
[2018-08-20 22:07:24,515 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='./80bptt_40epoch_850d.2st.outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./80bptt_40epoch_850d.2st.outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=125, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-20 22:07:36,083 INFO] train token: 2127402
[2018-08-20 22:07:36,083 INFO] test token: 250140
[2018-08-20 22:07:36,084 INFO] valid token: 221606
[2018-08-20 22:07:36,084 INFO] Loading vectors from ./80bptt_40epoch_850d.2st.outemb.txt.pt
[2018-08-20 22:08:45,773 INFO] | epoch   1 | train_loss  5.60 | val_ppl 116.00444 | time  55.8s
[2018-08-20 22:09:41,928 INFO] | epoch   2 | train_loss  4.45 | val_ppl 93.74372 | time  56.2s
[2018-08-20 22:10:39,235 INFO] | epoch   3 | train_loss  4.22 | val_ppl 84.18973 | time  57.3s
[2018-08-20 22:11:37,241 INFO] | epoch   4 | train_loss  4.10 | val_ppl 80.46532 | time  58.0s
[2018-08-20 22:12:35,364 INFO] | epoch   5 | train_loss  4.01 | val_ppl 77.25910 | time  58.1s
[2018-08-20 22:13:33,780 INFO] | epoch   6 | train_loss  3.94 | val_ppl 75.45863 | time  58.4s
[2018-08-20 22:14:32,187 INFO] | epoch   7 | train_loss  3.89 | val_ppl 74.30015 | time  58.4s
[2018-08-20 22:15:30,779 INFO] | epoch   8 | train_loss  3.84 | val_ppl 73.23836 | time  58.6s
[2018-08-20 22:16:29,368 INFO] | epoch   9 | train_loss  3.80 | val_ppl 72.54908 | time  58.6s
[2018-08-20 22:17:28,033 INFO] | epoch  10 | train_loss  3.76 | val_ppl 72.21705 | time  58.7s
[2018-08-20 22:18:26,834 INFO] | epoch  11 | train_loss  3.73 | val_ppl 72.02290 | time  58.8s
[2018-08-20 22:19:25,577 INFO] | epoch  12 | train_loss  3.69 | val_ppl 71.93137 | time  58.7s
[2018-08-20 22:20:24,330 INFO] | epoch  13 | train_loss  3.66 | val_ppl 71.98888 | time  58.8s
[2018-08-20 22:20:24,330 INFO] learning rate has been changed to 0.03125
[2018-08-20 22:21:23,420 INFO] | epoch  14 | train_loss  3.63 | val_ppl 67.59586 | time  59.1s
[2018-08-20 22:22:22,199 INFO] | epoch  15 | train_loss  3.61 | val_ppl 67.45261 | time  58.8s
[2018-08-20 22:23:21,125 INFO] | epoch  16 | train_loss  3.60 | val_ppl 67.42262 | time  58.9s
[2018-08-20 22:24:19,902 INFO] | epoch  17 | train_loss  3.60 | val_ppl 67.42537 | time  58.8s
[2018-08-20 22:24:19,903 INFO] learning rate has been changed to 0.015625
[2018-08-20 22:25:18,606 INFO] | epoch  18 | train_loss  3.60 | val_ppl 67.12470 | time  58.7s
[2018-08-20 22:26:16,941 INFO] | epoch  19 | train_loss  3.60 | val_ppl 67.11289 | time  58.3s
[2018-08-20 22:27:15,886 INFO] | epoch  20 | train_loss  3.60 | val_ppl 67.11593 | time  58.9s
[2018-08-20 22:27:15,887 INFO] learning rate has been changed to 0.0078125
[2018-08-20 22:28:14,416 INFO] | epoch  21 | train_loss  3.60 | val_ppl 66.93428 | time  58.5s
[2018-08-20 22:29:12,905 INFO] | epoch  22 | train_loss  3.59 | val_ppl 66.92441 | time  58.5s
[2018-08-20 22:30:11,352 INFO] | epoch  23 | train_loss  3.59 | val_ppl 66.92340 | time  58.4s
[2018-08-20 22:31:09,953 INFO] | epoch  24 | train_loss  3.59 | val_ppl 66.92525 | time  58.6s
[2018-08-20 22:31:09,953 INFO] learning rate has been changed to 0.001953125
[2018-08-20 22:32:08,553 INFO] | epoch  25 | train_loss  3.59 | val_ppl 66.77978 | time  58.6s
[2018-08-20 22:33:06,869 INFO] | epoch  26 | train_loss  3.59 | val_ppl 66.76449 | time  58.3s
[2018-08-20 22:34:05,736 INFO] | epoch  27 | train_loss  3.59 | val_ppl 66.75880 | time  58.9s
[2018-08-20 22:35:04,436 INFO] | epoch  28 | train_loss  3.59 | val_ppl 66.75608 | time  58.7s
[2018-08-20 22:36:03,086 INFO] | epoch  29 | train_loss  3.59 | val_ppl 66.75463 | time  58.6s
[2018-08-20 22:37:01,556 INFO] | epoch  30 | train_loss  3.59 | val_ppl 66.75387 | time  58.5s
[2018-08-20 22:38:00,426 INFO] | epoch  31 | train_loss  3.59 | val_ppl 66.75354 | time  58.9s
[2018-08-20 22:38:58,928 INFO] | epoch  32 | train_loss  3.59 | val_ppl 66.75349 | time  58.5s
[2018-08-20 22:39:57,484 INFO] | epoch  33 | train_loss  3.59 | val_ppl 66.75365 | time  58.6s
[2018-08-20 22:39:57,485 INFO] learning rate has been changed to 0.000244140625
[2018-08-20 22:40:56,319 INFO] | epoch  34 | train_loss  3.59 | val_ppl 66.74201 | time  58.8s
[2018-08-20 22:41:54,956 INFO] | epoch  35 | train_loss  3.59 | val_ppl 66.73585 | time  58.6s
[2018-08-20 22:42:53,556 INFO] | epoch  36 | train_loss  3.59 | val_ppl 66.73175 | time  58.6s
[2018-08-20 22:43:52,122 INFO] | epoch  37 | train_loss  3.59 | val_ppl 66.72875 | time  58.6s
[2018-08-20 22:44:50,787 INFO] | epoch  38 | train_loss  3.59 | val_ppl 66.72644 | time  58.7s
[2018-08-20 22:45:49,599 INFO] | epoch  39 | train_loss  3.59 | val_ppl 66.72464 | time  58.7s
[2018-08-20 22:46:48,060 INFO] | epoch  40 | train_loss  3.59 | val_ppl 66.72320 | time  58.5s
[2018-08-20 22:46:48,139 INFO] start to save model on nnlm.model
[2018-08-20 22:46:51,382 INFO] test_ppl: 65.54082

