[2018-07-11 11:57:23,593 INFO] Start training...
[2018-07-11 11:57:23,593 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=4, every_n_epoch_save=4, input_embeddings_trainable=True, log_file='log', lr=1.0, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, vector_type='glove.6B.100d')
[2018-07-11 11:57:36,856 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-11 11:58:35,398 INFO] | epoch   1 | train_loss  5.36 | val_ppl   162.03 | time  53.9s
[2018-07-11 11:59:29,589 INFO] | epoch   2 | train_loss  4.91 | val_ppl   141.38 | time  54.2s
[2018-07-11 12:00:23,862 INFO] | epoch   3 | train_loss  4.76 | val_ppl   135.60 | time  54.3s
[2018-07-11 12:01:17,954 INFO] | epoch   4 | train_loss  4.67 | val_ppl   132.10 | time  54.1s
[2018-07-11 12:01:17,954 INFO] start to save model on nnlm.model
[2018-07-11 12:01:20,663 INFO] test_ppl: 121.5
[2018-07-11 12:01:52,326 INFO] Start training...
[2018-07-11 12:01:52,326 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=4, every_n_epoch_save=4, input_embeddings_trainable=True, log_file='log', lr=1.0, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, vector_type='glove.6B.100d')
[2018-07-11 12:02:04,668 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-11 12:03:03,107 INFO] | epoch   1 | train_loss  5.36 | val_ppl   162.03 | time  54.1s
[2018-07-11 12:03:57,274 INFO] | epoch   2 | train_loss  4.91 | val_ppl   141.38 | time  54.2s
[2018-07-11 12:04:51,551 INFO] | epoch   3 | train_loss  4.76 | val_ppl   135.60 | time  54.3s
[2018-07-11 12:05:45,834 INFO] | epoch   4 | train_loss  4.67 | val_ppl   132.10 | time  54.3s
[2018-07-11 12:05:45,835 INFO] start to save model on nnlm.model
[2018-07-11 12:05:48,531 INFO] test_ppl: 121.5
[2018-07-11 12:13:51,900 INFO] Start training...
[2018-07-11 12:13:51,901 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=4, every_n_epoch_save=4, input_embeddings_trainable=True, log_file='log', lr=1.0, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=True, vector_type='glove.6B.100d')
[2018-07-11 12:14:03,920 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-11 12:14:30,772 INFO] Start training...
[2018-07-11 12:14:30,773 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=4, every_n_epoch_save=4, input_embeddings_trainable=True, log_file='log', lr=1.0, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=True, vector_type='glove.6B.100d')
[2018-07-11 12:14:44,150 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-11 12:15:15,018 INFO] Start training...
[2018-07-11 12:15:15,018 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=4, every_n_epoch_save=4, input_embeddings_trainable=True, log_file='log', lr=1.0, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=True, vector_type='glove.6B.100d')
[2018-07-11 12:15:28,133 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-11 12:16:25,528 INFO] | epoch   1 | train_loss  5.97 | val_ppl   227.08 | time  52.2s
[2018-07-11 12:17:17,273 INFO] | epoch   2 | train_loss  5.30 | val_ppl   198.76 | time  51.7s
[2018-07-11 12:18:08,877 INFO] | epoch   3 | train_loss  5.18 | val_ppl   185.42 | time  51.6s
[2018-07-11 12:19:00,652 INFO] | epoch   4 | train_loss  5.10 | val_ppl   175.43 | time  51.8s
[2018-07-11 12:19:00,652 INFO] start to save model on nnlm.model
[2018-07-11 12:19:03,120 INFO] test_ppl: 161.4
[2018-07-28 22:55:08,800 INFO] Start training...
[2018-07-28 22:55:08,800 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=4, input_embeddings_trainable=1, log_file='log', lr=0.5, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-07-28 22:55:24,865 INFO] train token: 2127402
[2018-07-28 22:55:24,866 INFO] test token: 250140
[2018-07-28 22:55:24,866 INFO] valid token: 221606
[2018-07-28 22:55:25,372 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-28 22:56:28,014 INFO] | epoch   1 | train_loss  5.48 | val_ppl   174.45 | time  58.2s
[2018-07-28 22:57:26,507 INFO] | epoch   2 | train_loss  5.03 | val_ppl   148.51 | time  58.5s
[2018-07-28 22:58:25,131 INFO] | epoch   3 | train_loss  4.89 | val_ppl   137.81 | time  58.6s
[2018-07-28 22:59:23,791 INFO] | epoch   4 | train_loss  4.80 | val_ppl   132.02 | time  58.7s
[2018-07-28 22:59:23,791 INFO] start to save model on nnlm.model
[2018-07-28 23:00:23,383 INFO] | epoch   5 | train_loss  4.73 | val_ppl   128.47 | time  58.9s
[2018-07-28 23:01:22,137 INFO] | epoch   6 | train_loss  4.68 | val_ppl   126.19 | time  58.8s
[2018-07-28 23:02:20,923 INFO] | epoch   7 | train_loss  4.63 | val_ppl   124.58 | time  58.8s
[2018-07-28 23:03:19,775 INFO] | epoch   8 | train_loss  4.59 | val_ppl   123.33 | time  58.9s
[2018-07-28 23:03:19,775 INFO] start to save model on nnlm.model
[2018-07-28 23:05:54,299 INFO] test_ppl: 113.9

(explanation: during testing, I changed the trained emb both input and output to the raw
pre-trained word emb. And get 2554 ppl on test data)
[2018-07-31 14:09:14,392 INFO] Start training...
[2018-07-31 14:09:14,392 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, input_embeddings_trainable=1, log_file='log', lr=0.5, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-07-31 14:09:25,980 INFO] train token: 2127402
[2018-07-31 14:09:25,980 INFO] test token: 250140
[2018-07-31 14:09:25,980 INFO] valid token: 221606
[2018-07-31 14:09:26,425 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-31 14:10:37,426 INFO] | epoch   1 | train_loss  5.62 | val_ppl   202.87 | time  67.0s
[2018-07-31 14:11:45,479 INFO] | epoch   2 | train_loss  5.26 | val_ppl   182.92 | time  68.1s
[2018-07-31 14:12:53,601 INFO] | epoch   3 | train_loss  5.17 | val_ppl   173.45 | time  68.1s
[2018-07-31 14:14:02,259 INFO] | epoch   4 | train_loss  5.11 | val_ppl   167.48 | time  68.7s
[2018-07-31 14:15:10,687 INFO] | epoch   5 | train_loss  5.07 | val_ppl   163.20 | time  68.4s
[2018-07-31 14:16:19,743 INFO] | epoch   6 | train_loss  5.03 | val_ppl   159.85 | time  69.1s
[2018-07-31 14:17:27,937 INFO] | epoch   7 | train_loss  5.00 | val_ppl   157.40 | time  68.2s
[2018-07-31 14:18:36,343 INFO] | epoch   8 | train_loss  4.97 | val_ppl   155.19 | time  68.4s
[2018-07-31 14:18:38,957 INFO] test_ppl: 2554.4

(explanation: during testing, I only changed the output train emb to the input and raw pre-trained)
[2018-07-31 14:30:17,872 INFO] Start training...
[2018-07-31 14:30:17,872 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, input_embeddings_trainable=1, log_file='log', lr=0.5, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-07-31 14:30:29,691 INFO] train token: 2127402
[2018-07-31 14:30:29,692 INFO] test token: 250140
[2018-07-31 14:30:29,692 INFO] valid token: 221606
[2018-07-31 14:30:30,120 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-31 14:31:41,477 INFO] | epoch   1 | train_loss  5.62 | val_ppl   202.87 | time  67.3s
[2018-07-31 14:32:49,501 INFO] | epoch   2 | train_loss  5.26 | val_ppl   182.92 | time  68.0s
[2018-07-31 14:33:57,168 INFO] | epoch   3 | train_loss  5.17 | val_ppl   173.45 | time  67.7s
[2018-07-31 14:35:05,325 INFO] | epoch   4 | train_loss  5.11 | val_ppl   167.48 | time  68.2s
[2018-07-31 14:36:13,854 INFO] | epoch   5 | train_loss  5.07 | val_ppl   163.20 | time  68.5s
[2018-07-31 14:37:22,128 INFO] | epoch   6 | train_loss  5.03 | val_ppl   159.85 | time  68.3s
[2018-07-31 14:38:30,394 INFO] | epoch   7 | train_loss  5.00 | val_ppl   157.40 | time  68.3s
[2018-07-31 14:39:38,630 INFO] | epoch   8 | train_loss  4.97 | val_ppl   155.19 | time  68.2s
[2018-07-31 14:39:41,242 INFO] out emb from pre-trained emb, test_ppl: 1557.8
[2018-07-31 14:39:43,849 INFO] out emb from input trained emb, test_ppl: 1864.3

(explanation: both input and output emb are randomly inited. but latter poor similarity on input
emb is observed, but good performance on output emb)
[2018-07-31 14:54:30,371 INFO] Start training...
[2018-07-31 14:54:30,371 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, input_embeddings_trainable=1, log_file='log', lr=0.5, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-07-31 14:54:42,263 INFO] train token: 2127402
[2018-07-31 14:54:42,263 INFO] test token: 250140
[2018-07-31 14:54:42,263 INFO] valid token: 221606
[2018-07-31 14:54:42,697 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-31 14:55:53,816 INFO] | epoch   1 | train_loss  5.73 | val_ppl   217.15 | time  67.2s
[2018-07-31 14:57:01,955 INFO] | epoch   2 | train_loss  5.30 | val_ppl   191.46 | time  68.1s
[2018-07-31 14:58:09,843 INFO] | epoch   3 | train_loss  5.16 | val_ppl   179.09 | time  67.9s
[2018-07-31 14:59:18,046 INFO] | epoch   4 | train_loss  5.07 | val_ppl   172.12 | time  68.2s
[2018-07-31 15:00:26,312 INFO] | epoch   5 | train_loss  5.01 | val_ppl   167.67 | time  68.3s
[2018-07-31 15:01:34,973 INFO] | epoch   6 | train_loss  4.95 | val_ppl   164.24 | time  68.7s
[2018-07-31 15:02:43,250 INFO] | epoch   7 | train_loss  4.91 | val_ppl   161.55 | time  68.3s
[2018-07-31 15:03:51,422 INFO] | epoch   8 | train_loss  4.87 | val_ppl   159.90 | time  68.2s
[2018-07-31 15:03:54,032 INFO] test_ppl: 146.8
[2018-07-31 15:28:57,698 INFO] Start training...

(explanation: change random seed to observe above xianxiang)
[2018-07-31 15:28:57,698 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, input_embeddings_trainable=1, log_file='log', lr=0.5, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=2, tied=False, vector_type='glove.6B.100d')
[2018-07-31 15:29:09,650 INFO] train token: 2127402
[2018-07-31 15:29:09,650 INFO] test token: 250140
[2018-07-31 15:29:09,650 INFO] valid token: 221606
[2018-07-31 15:29:10,092 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-31 15:30:21,567 INFO] | epoch   1 | train_loss  5.72 | val_ppl   211.07 | time  67.5s
[2018-07-31 15:31:29,211 INFO] | epoch   2 | train_loss  5.30 | val_ppl   188.27 | time  67.6s
[2018-07-31 15:32:37,209 INFO] | epoch   3 | train_loss  5.16 | val_ppl   177.49 | time  68.0s
[2018-07-31 15:33:44,926 INFO] | epoch   4 | train_loss  5.07 | val_ppl   171.14 | time  67.7s
[2018-07-31 15:34:53,238 INFO] | epoch   5 | train_loss  5.01 | val_ppl   166.88 | time  68.3s
[2018-07-31 15:36:01,612 INFO] | epoch   6 | train_loss  4.96 | val_ppl   163.86 | time  68.4s
[2018-07-31 15:37:09,962 INFO] | epoch   7 | train_loss  4.91 | val_ppl   161.72 | time  68.4s
[2018-07-31 15:38:18,200 INFO] | epoch   8 | train_loss  4.87 | val_ppl   160.12 | time  68.2s
[2018-07-31 15:38:20,809 INFO] test_ppl: 147.1

(explanation: tied, randomly inited)
[2018-07-31 16:04:23,671 INFO] Start training...
[2018-07-31 16:04:23,672 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, input_embeddings_trainable=1, log_file='log', lr=0.5, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=True, vector_type='glove.6B.100d')
[2018-07-31 16:04:35,709 INFO] train token: 2127402
[2018-07-31 16:04:35,709 INFO] test token: 250140
[2018-07-31 16:04:35,710 INFO] valid token: 221606
[2018-07-31 16:04:36,135 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-31 16:05:44,870 INFO] | epoch   1 | train_loss  6.71 | val_ppl   513.26 | time  64.8s
[2018-07-31 16:06:49,821 INFO] | epoch   2 | train_loss  6.21 | val_ppl   405.96 | time  65.0s
[2018-07-31 16:07:55,041 INFO] | epoch   3 | train_loss  6.04 | val_ppl   357.50 | time  65.2s
[2018-07-31 16:08:59,693 INFO] | epoch   4 | train_loss  5.93 | val_ppl   328.33 | time  64.7s
[2018-07-31 16:10:05,344 INFO] | epoch   5 | train_loss  5.85 | val_ppl   308.08 | time  65.7s
[2018-07-31 16:11:10,503 INFO] | epoch   6 | train_loss  5.79 | val_ppl   292.92 | time  65.2s
[2018-07-31 16:12:16,001 INFO] | epoch   7 | train_loss  5.74 | val_ppl   281.16 | time  65.5s
[2018-07-31 16:13:21,448 INFO] | epoch   8 | train_loss  5.70 | val_ppl   271.68 | time  65.4s
[2018-07-31 16:13:24,054 INFO] test_ppl: 250.3


(explanation: input will be updated. output is fixed using pre-trained emb)
[2018-07-31 19:49:39,046 INFO] Start training...
[2018-07-31 19:49:39,046 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, input_embeddings_trainable=1, log_file='log', lr=0.5, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-07-31 19:49:50,588 INFO] train token: 2127402
[2018-07-31 19:49:50,589 INFO] test token: 250140
[2018-07-31 19:49:50,589 INFO] valid token: 221606
[2018-07-31 19:49:51,008 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-31 19:51:03,078 INFO] | epoch   1 | train_loss  5.62 | val_ppl   202.87 | time  68.1s
[2018-07-31 19:52:11,188 INFO] | epoch   2 | train_loss  5.26 | val_ppl   182.92 | time  68.1s
[2018-07-31 19:53:19,355 INFO] | epoch   3 | train_loss  5.17 | val_ppl   173.45 | time  68.2s
[2018-07-31 19:54:28,062 INFO] | epoch   4 | train_loss  5.11 | val_ppl   167.48 | time  68.7s
[2018-07-31 19:55:36,061 INFO] | epoch   5 | train_loss  5.07 | val_ppl   163.20 | time  68.0s
[2018-07-31 19:56:45,114 INFO] | epoch   6 | train_loss  5.03 | val_ppl   159.85 | time  69.1s
[2018-07-31 19:57:53,615 INFO] | epoch   7 | train_loss  5.00 | val_ppl   157.40 | time  68.5s
[2018-07-31 19:59:01,928 INFO] | epoch   8 | train_loss  4.97 | val_ppl   155.19 | time  68.3s
[2018-07-31 19:59:04,521 INFO] test_ppl: 143.7

(explanation: I disabled both input and output embeddings from pre-trained. it still works)
[2018-07-31 21:58:56,589 INFO] Start training...
[2018-07-31 21:58:56,589 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=True, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-07-31 21:59:08,303 INFO] train token: 2127402
[2018-07-31 21:59:08,303 INFO] test token: 250140
[2018-07-31 21:59:08,303 INFO] valid token: 221606
[2018-07-31 21:59:08,747 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-31 22:00:20,066 INFO] | epoch   1 | train_loss  5.62 | val_ppl   202.87 | time  67.3s
[2018-07-31 22:01:27,876 INFO] | epoch   2 | train_loss  5.26 | val_ppl   182.92 | time  67.8s
[2018-07-31 22:02:36,551 INFO] | epoch   3 | train_loss  5.17 | val_ppl   173.45 | time  68.7s
[2018-07-31 22:03:45,416 INFO] | epoch   4 | train_loss  5.11 | val_ppl   167.48 | time  68.9s
[2018-07-31 22:04:53,778 INFO] | epoch   5 | train_loss  5.07 | val_ppl   163.20 | time  68.4s
[2018-07-31 22:06:02,175 INFO] | epoch   6 | train_loss  5.03 | val_ppl   159.85 | time  68.4s
[2018-07-31 22:07:10,262 INFO] | epoch   7 | train_loss  5.00 | val_ppl   157.40 | time  68.1s
[2018-07-31 22:08:18,607 INFO] | epoch   8 | train_loss  4.97 | val_ppl   155.19 | time  68.3s
[2018-07-31 22:08:21,205 INFO] test_ppl: 143.7

(explanation: I disabled output update, enable input, but result is same. strange mark here)
[2018-07-31 22:16:48,673 INFO] Start training...
[2018-07-31 22:16:48,673 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-07-31 22:17:00,997 INFO] train token: 2127402
[2018-07-31 22:17:00,997 INFO] test token: 250140
[2018-07-31 22:17:00,997 INFO] valid token: 221606
[2018-07-31 22:17:01,473 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-31 22:17:05,825 INFO] embeddings input emb requries_grad:True
[2018-07-31 22:18:12,708 INFO] | epoch   1 | train_loss  5.62 | val_ppl   202.87 | time  66.9s
[2018-07-31 22:19:20,513 INFO] | epoch   2 | train_loss  5.26 | val_ppl   182.92 | time  67.8s
[2018-07-31 22:20:28,542 INFO] | epoch   3 | train_loss  5.17 | val_ppl   173.45 | time  68.0s
[2018-07-31 22:21:36,978 INFO] | epoch   4 | train_loss  5.11 | val_ppl   167.48 | time  68.4s
[2018-07-31 22:22:44,891 INFO] | epoch   5 | train_loss  5.07 | val_ppl   163.20 | time  67.9s
[2018-07-31 22:23:53,138 INFO] | epoch   6 | train_loss  5.03 | val_ppl   159.85 | time  68.2s
[2018-07-31 22:25:01,365 INFO] | epoch   7 | train_loss  5.00 | val_ppl   157.40 | time  68.2s
[2018-07-31 22:26:10,235 INFO] | epoch   8 | train_loss  4.97 | val_ppl   155.19 | time  68.9s
[2018-07-31 22:26:12,711 INFO] test_ppl: 143.7
[2018-08-03 16:20:08,523 INFO] Start training...

(explanation: using trained cbow on same training data. the output emb is fixed, input is updating.
al most obtain the best result)
[2018-08-03 16:20:08,523 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:1', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-03 16:20:19,495 INFO] train token: 2127402
[2018-08-03 16:20:19,495 INFO] test token: 250140
[2018-08-03 16:20:19,495 INFO] valid token: 221606
[2018-08-03 16:20:19,683 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt
[2018-08-03 16:20:19,687 WARNING] Skipping token 23380 with 1-dimensional vector ['100']; likely a header
[2018-08-03 16:20:20,509 INFO] Saving vectors to /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-03 16:20:28,049 INFO] embeddings input emb requries_grad:True
[2018-08-03 16:20:52,152 INFO] | epoch   1 | train_loss  5.28 | val_ppl   164.29 | time  24.1s
[2018-08-03 16:21:16,072 INFO] | epoch   2 | train_loss  4.96 | val_ppl   145.30 | time  23.9s
[2018-08-03 16:21:40,427 INFO] | epoch   3 | train_loss  4.84 | val_ppl   136.03 | time  24.4s
[2018-08-03 16:22:04,642 INFO] | epoch   4 | train_loss  4.75 | val_ppl   130.40 | time  24.2s
[2018-08-03 16:22:28,586 INFO] | epoch   5 | train_loss  4.68 | val_ppl   126.64 | time  23.9s
[2018-08-03 16:22:53,095 INFO] | epoch   6 | train_loss  4.62 | val_ppl   124.04 | time  24.5s
[2018-08-03 16:23:17,185 INFO] | epoch   7 | train_loss  4.58 | val_ppl   122.21 | time  24.1s
[2018-08-03 16:23:41,889 INFO] | epoch   8 | train_loss  4.53 | val_ppl   120.94 | time  24.7s
[2018-08-03 16:23:42,887 INFO] test_ppl: 116.5
[2018-08-04 16:38:43,055 INFO] -------------
explanation: val_ppl and test_ppl are -consine. wiki2 trained cbow to fix out emb and update in emb
[2018-08-04 16:38:43,056 INFO] Start training...
[2018-08-04 16:38:43,056 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-04 16:38:54,264 INFO] train token: 2127402
[2018-08-04 16:38:54,264 INFO] test token: 250140
[2018-08-04 16:38:54,265 INFO] valid token: 221606
[2018-08-04 16:38:54,482 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-04 16:39:22,428 INFO] | epoch   1 | train_loss  5.28 | val_ppl    -0.21 | time  23.7s
[2018-08-04 16:39:45,128 INFO] | epoch   2 | train_loss  4.96 | val_ppl    -0.22 | time  22.7s
[2018-08-04 16:40:08,614 INFO] | epoch   3 | train_loss  4.84 | val_ppl    -0.23 | time  23.5s
[2018-08-04 16:40:32,137 INFO] | epoch   4 | train_loss  4.75 | val_ppl    -0.23 | time  23.5s
[2018-08-04 16:40:55,733 INFO] | epoch   5 | train_loss  4.68 | val_ppl    -0.23 | time  23.6s
[2018-08-04 16:41:19,158 INFO] | epoch   6 | train_loss  4.62 | val_ppl    -0.23 | time  23.4s
[2018-08-04 16:41:42,629 INFO] | epoch   7 | train_loss  4.58 | val_ppl    -0.24 | time  23.5s
[2018-08-04 16:42:05,937 INFO] | epoch   8 | train_loss  4.53 | val_ppl    -0.24 | time  23.3s
[2018-08-04 16:42:06,589 INFO] test_ppl:  -0.2
[2018-08-04 16:49:32,227 INFO] -------------
(explanation: the same as above one. I changed the float point of cosine)
[2018-08-04 16:49:32,227 INFO] Start training...
[2018-08-04 16:49:32,227 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-04 16:49:43,473 INFO] train token: 2127402
[2018-08-04 16:49:43,473 INFO] test token: 250140
[2018-08-04 16:49:43,474 INFO] valid token: 221606
[2018-08-04 16:49:43,619 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-04 16:50:10,367 INFO] | epoch   1 | train_loss  5.28 | val_ppl -0.21334 | time  23.3s
[2018-08-04 16:50:33,777 INFO] | epoch   2 | train_loss  4.96 | val_ppl -0.22230 | time  23.4s
[2018-08-04 16:50:56,918 INFO] | epoch   3 | train_loss  4.84 | val_ppl -0.22630 | time  23.1s
[2018-08-04 16:51:20,258 INFO] | epoch   4 | train_loss  4.75 | val_ppl -0.22975 | time  23.3s
[2018-08-04 16:51:43,789 INFO] | epoch   5 | train_loss  4.68 | val_ppl -0.23230 | time  23.5s
[2018-08-04 16:52:07,929 INFO] | epoch   6 | train_loss  4.62 | val_ppl -0.23413 | time  24.1s
[2018-08-04 16:52:31,161 INFO] | epoch   7 | train_loss  4.58 | val_ppl -0.23547 | time  23.2s
[2018-08-04 16:52:54,546 INFO] | epoch   8 | train_loss  4.53 | val_ppl -0.23652 | time  23.4s
[2018-08-04 16:52:55,215 INFO] test_ppl: -0.23469


(explanation: full-softmax norm hidden output and pretrained norm out emb from the start, all is same as before
the result shows it performs a slightly bad than non-norm one. But note fixing out emb, still works)
[2018-08-11 10:11:52,834 INFO] -------------
[2018-08-11 10:11:52,834 INFO] Start training...
[2018-08-11 10:11:52,834 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 10:12:03,779 INFO] train token: 2127402
[2018-08-11 10:12:03,779 INFO] test token: 250140
[2018-08-11 10:12:03,779 INFO] valid token: 221606
[2018-08-11 10:12:03,918 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 10:12:31,943 INFO] | epoch   1 | train_loss  5.69 | val_ppl 212.15373 | time  24.6s
[2018-08-11 10:12:56,157 INFO] | epoch   2 | train_loss  5.32 | val_ppl 180.26816 | time  24.2s
[2018-08-11 10:13:21,018 INFO] | epoch   3 | train_loss  5.18 | val_ppl 164.25467 | time  24.9s
[2018-08-11 10:13:45,154 INFO] | epoch   4 | train_loss  5.10 | val_ppl 154.49554 | time  24.1s
[2018-08-11 10:14:09,838 INFO] | epoch   5 | train_loss  5.03 | val_ppl 147.72783 | time  24.7s
[2018-08-11 10:14:35,549 INFO] | epoch   6 | train_loss  4.98 | val_ppl 142.51899 | time  25.7s
[2018-08-11 10:15:00,965 INFO] | epoch   7 | train_loss  4.94 | val_ppl 138.56315 | time  25.4s
[2018-08-11 10:15:25,451 INFO] | epoch   8 | train_loss  4.91 | val_ppl 135.48768 | time  24.5s
[2018-08-11 10:15:26,474 INFO] test_ppl: 131.53229


(explanation: randomly out emb, updating. this is the PPL result)
[2018-08-11 10:40:34,481 INFO] -------------
[2018-08-11 10:40:34,481 INFO] Start training...
[2018-08-11 10:40:34,481 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 10:40:45,832 INFO] train token: 2127402
[2018-08-11 10:40:45,832 INFO] test token: 250140
[2018-08-11 10:40:45,832 INFO] valid token: 221606
[2018-08-11 10:40:45,972 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 10:41:13,416 INFO] | epoch   1 | train_loss  5.21 | val_ppl 154.21461 | time  23.9s
[2018-08-11 10:41:37,165 INFO] | epoch   2 | train_loss  4.85 | val_ppl 134.51386 | time  23.7s
[2018-08-11 10:42:01,007 INFO] | epoch   3 | train_loss  4.73 | val_ppl 124.98321 | time  23.8s
[2018-08-11 10:42:25,112 INFO] | epoch   4 | train_loss  4.64 | val_ppl 119.01536 | time  24.1s
[2018-08-11 10:42:48,558 INFO] | epoch   5 | train_loss  4.58 | val_ppl 115.04513 | time  23.4s
[2018-08-11 10:43:12,139 INFO] | epoch   6 | train_loss  4.53 | val_ppl 112.35071 | time  23.6s
[2018-08-11 10:43:35,855 INFO] | epoch   7 | train_loss  4.49 | val_ppl 110.55550 | time  23.7s
[2018-08-11 10:43:59,139 INFO] | epoch   8 | train_loss  4.45 | val_ppl 109.30011 | time  23.3s
[2018-08-11 10:44:00,116 INFO] test_ppl: 105.30712


(explanation: randomly out emb, fixed, the totally same result!. any bug? how it could be!)
[2018-08-11 10:52:13,115 INFO] -------------
[2018-08-11 10:52:13,115 INFO] Start training...
[2018-08-11 10:52:13,116 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 10:52:24,324 INFO] train token: 2127402
[2018-08-11 10:52:24,324 INFO] test token: 250140
[2018-08-11 10:52:24,324 INFO] valid token: 221606
[2018-08-11 10:52:24,464 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 10:52:51,258 INFO] | epoch   1 | train_loss  5.21 | val_ppl 154.21461 | time  23.8s
[2018-08-11 10:53:14,410 INFO] | epoch   2 | train_loss  4.85 | val_ppl 134.51386 | time  23.2s
[2018-08-11 10:53:37,993 INFO] | epoch   3 | train_loss  4.73 | val_ppl 124.98321 | time  23.6s
[2018-08-11 10:54:01,673 INFO] | epoch   4 | train_loss  4.64 | val_ppl 119.01536 | time  23.7s
[2018-08-11 10:54:25,475 INFO] | epoch   5 | train_loss  4.58 | val_ppl 115.04513 | time  23.8s
[2018-08-11 10:54:48,660 INFO] | epoch   6 | train_loss  4.53 | val_ppl 112.35071 | time  23.2s
[2018-08-11 10:55:12,417 INFO] | epoch   7 | train_loss  4.49 | val_ppl 110.55550 | time  23.8s
[2018-08-11 10:55:35,869 INFO] | epoch   8 | train_loss  4.45 | val_ppl 109.30011 | time  23.5s
[2018-08-11 10:55:36,836 INFO] test_ppl: 105.30712


----------------
-  split line  -
----------------

After I found the reason of a bug in my program. The above result have to be ignored for
non-updating setting.
------------------------------------------
-----------------------------------------


(explanation: standard. pretrained out in, updating both)
[2018-08-11 11:42:02,033 INFO] -------------
[2018-08-11 11:42:02,033 INFO] Start training...
[2018-08-11 11:42:02,033 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 11:42:13,059 INFO] train token: 2127402
[2018-08-11 11:42:13,060 INFO] test token: 250140
[2018-08-11 11:42:13,060 INFO] valid token: 221606
[2018-08-11 11:42:13,294 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 11:42:40,425 INFO] | epoch   1 | train_loss  5.28 | val_ppl 164.29145 | time  23.7s
[2018-08-11 11:43:03,660 INFO] | epoch   2 | train_loss  4.96 | val_ppl 145.29785 | time  23.2s
[2018-08-11 11:43:28,005 INFO] | epoch   3 | train_loss  4.84 | val_ppl 136.03464 | time  24.3s
[2018-08-11 11:43:51,476 INFO] | epoch   4 | train_loss  4.75 | val_ppl 130.40298 | time  23.5s
[2018-08-11 11:44:15,149 INFO] | epoch   5 | train_loss  4.68 | val_ppl 126.63874 | time  23.7s
[2018-08-11 11:44:38,460 INFO] | epoch   6 | train_loss  4.62 | val_ppl 124.03754 | time  23.3s
[2018-08-11 11:45:01,810 INFO] | epoch   7 | train_loss  4.58 | val_ppl 122.20709 | time  23.3s
[2018-08-11 11:45:25,251 INFO] | epoch   8 | train_loss  4.53 | val_ppl 120.94260 | time  23.4s
[2018-08-11 11:45:26,214 INFO] test_ppl: 116.48836
[2018-08-11 11:47:09,263 INFO] -------------
[2018-08-11 11:47:09,263 INFO] Start training...
[2018-08-11 11:47:09,263 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 11:47:20,770 INFO] train token: 2127402
[2018-08-11 11:47:20,771 INFO] test token: 250140
[2018-08-11 11:47:20,771 INFO] valid token: 221606
[2018-08-11 11:47:20,914 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt

(explanation: no bias term in softmax output)
[2018-08-11 11:53:32,440 INFO] -------------
[2018-08-11 11:53:32,440 INFO] Start training...
[2018-08-11 11:53:32,440 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 11:53:43,587 INFO] train token: 2127402
[2018-08-11 11:53:43,587 INFO] test token: 250140
[2018-08-11 11:53:43,587 INFO] valid token: 221606
[2018-08-11 11:53:43,730 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 11:54:09,951 INFO] | epoch   1 | train_loss  5.27 | val_ppl 167.26648 | time  22.9s
[2018-08-11 11:54:32,207 INFO] | epoch   2 | train_loss  4.96 | val_ppl 146.64552 | time  22.3s
[2018-08-11 11:54:54,706 INFO] | epoch   3 | train_loss  4.84 | val_ppl 137.08501 | time  22.5s
[2018-08-11 11:55:17,098 INFO] | epoch   4 | train_loss  4.75 | val_ppl 131.19981 | time  22.4s
[2018-08-11 11:55:39,398 INFO] | epoch   5 | train_loss  4.68 | val_ppl 127.14218 | time  22.3s
[2018-08-11 11:56:02,100 INFO] | epoch   6 | train_loss  4.63 | val_ppl 124.31848 | time  22.7s
[2018-08-11 11:56:24,560 INFO] | epoch   7 | train_loss  4.58 | val_ppl 122.25929 | time  22.5s
[2018-08-11 11:56:46,903 INFO] | epoch   8 | train_loss  4.53 | val_ppl 120.73668 | time  22.3s
[2018-08-11 11:56:47,783 INFO] test_ppl: 116.25565
[2018-08-11 11:58:12,622 INFO] -------------

explanation: this not updating pretrained emb
[2018-08-11 11:58:12,622 INFO] Start training...
[2018-08-11 11:58:12,622 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 11:58:23,951 INFO] train token: 2127402
[2018-08-11 11:58:23,951 INFO] test token: 250140
[2018-08-11 11:58:23,951 INFO] valid token: 221606
[2018-08-11 11:58:24,093 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 11:58:47,852 INFO] | epoch   1 | train_loss  5.69 | val_ppl 252.04634 | time  20.5s
[2018-08-11 11:59:07,940 INFO] | epoch   2 | train_loss  5.42 | val_ppl 230.61994 | time  20.1s
[2018-08-11 11:59:28,003 INFO] | epoch   3 | train_loss  5.33 | val_ppl 221.23442 | time  20.1s
[2018-08-11 11:59:48,386 INFO] | epoch   4 | train_loss  5.27 | val_ppl 215.90383 | time  20.4s
[2018-08-11 12:00:08,196 INFO] | epoch   5 | train_loss  5.23 | val_ppl 213.32098 | time  19.8s
[2018-08-11 12:00:28,499 INFO] | epoch   6 | train_loss  5.19 | val_ppl 211.77433 | time  20.3s
[2018-08-11 12:00:48,346 INFO] | epoch   7 | train_loss  5.16 | val_ppl 211.10733 | time  19.8s
[2018-08-11 12:01:08,003 INFO] | epoch   8 | train_loss  5.13 | val_ppl 210.85058 | time  19.7s
[2018-08-11 12:01:08,865 INFO] test_ppl: 202.07194
[2018-08-11 12:10:28,346 INFO] -------------

(explanation: following above setting ,updating bias)
[2018-08-11 12:10:28,346 INFO] Start training...
[2018-08-11 12:10:28,346 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 12:10:39,566 INFO] train token: 2127402
[2018-08-11 12:10:39,566 INFO] test token: 250140
[2018-08-11 12:10:39,566 INFO] valid token: 221606
[2018-08-11 12:10:39,710 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 12:11:04,395 INFO] | epoch   1 | train_loss  5.50 | val_ppl 205.60689 | time  21.4s
[2018-08-11 12:11:25,967 INFO] | epoch   2 | train_loss  5.23 | val_ppl 184.87383 | time  21.6s
[2018-08-11 12:11:47,460 INFO] | epoch   3 | train_loss  5.13 | val_ppl 176.79595 | time  21.5s
[2018-08-11 12:12:08,994 INFO] | epoch   4 | train_loss  5.07 | val_ppl 172.47004 | time  21.5s
[2018-08-11 12:12:30,035 INFO] | epoch   5 | train_loss  5.02 | val_ppl 169.36231 | time  21.0s
[2018-08-11 12:12:51,509 INFO] | epoch   6 | train_loss  4.98 | val_ppl 167.69087 | time  21.5s
[2018-08-11 12:13:12,369 INFO] | epoch   7 | train_loss  4.95 | val_ppl 166.89307 | time  20.9s
[2018-08-11 12:13:33,561 INFO] | epoch   8 | train_loss  4.92 | val_ppl 166.55194 | time  21.2s
[2018-08-11 12:13:34,523 INFO] test_ppl: 160.89592
[2018-08-11 12:23:11,616 INFO] -------------

(explanation: norm hidden, and norm fixed out emb)
[2018-08-11 12:23:11,616 INFO] Start training...
[2018-08-11 12:23:11,616 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 12:23:23,430 INFO] train token: 2127402
[2018-08-11 12:23:23,430 INFO] test token: 250140
[2018-08-11 12:23:23,431 INFO] valid token: 221606
[2018-08-11 12:23:23,664 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 12:23:48,735 INFO] | epoch   1 | train_loss  9.15 | val_ppl 9215.55642 | time  21.1s
[2018-08-11 12:24:09,707 INFO] | epoch   2 | train_loss  9.13 | val_ppl 9158.74265 | time  21.0s
[2018-08-11 12:24:30,987 INFO] | epoch   3 | train_loss  9.13 | val_ppl 9132.80471 | time  21.3s
[2018-08-11 12:24:51,834 INFO] | epoch   4 | train_loss  9.12 | val_ppl 9107.43428 | time  20.8s
[2018-08-11 12:25:13,540 INFO] | epoch   5 | train_loss  9.12 | val_ppl 9082.90436 | time  21.7s
[2018-08-11 12:25:34,020 INFO] | epoch   6 | train_loss  9.12 | val_ppl 9064.22266 | time  20.5s
[2018-08-11 12:25:54,297 INFO] | epoch   7 | train_loss  9.12 | val_ppl 9051.11456 | time  20.3s
[2018-08-11 12:26:15,181 INFO] | epoch   8 | train_loss  9.11 | val_ppl 9039.41527 | time  20.9s
[2018-08-11 12:26:16,114 INFO] test_ppl: 8990.28242

(same as above, updating normed emb. norm is only done at start)
[2018-08-11 12:27:20,148 INFO] -------------
[2018-08-11 12:27:20,148 INFO] Start training...
[2018-08-11 12:27:20,148 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 12:27:31,261 INFO] train token: 2127402
[2018-08-11 12:27:31,261 INFO] test token: 250140
[2018-08-11 12:27:31,261 INFO] valid token: 221606
[2018-08-11 12:27:31,405 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 12:27:57,805 INFO] | epoch   1 | train_loss  5.74 | val_ppl 220.63858 | time  23.0s
[2018-08-11 12:28:20,458 INFO] | epoch   2 | train_loss  5.36 | val_ppl 187.76345 | time  22.7s
[2018-08-11 12:28:43,665 INFO] | epoch   3 | train_loss  5.23 | val_ppl 171.58674 | time  23.2s
[2018-08-11 12:29:07,140 INFO] | epoch   4 | train_loss  5.15 | val_ppl 161.98186 | time  23.5s
[2018-08-11 12:29:30,515 INFO] | epoch   5 | train_loss  5.09 | val_ppl 155.08981 | time  23.4s
[2018-08-11 12:29:53,424 INFO] | epoch   6 | train_loss  5.04 | val_ppl 149.91193 | time  22.9s
[2018-08-11 12:30:16,597 INFO] | epoch   7 | train_loss  5.00 | val_ppl 145.86725 | time  23.2s
[2018-08-11 12:30:39,851 INFO] | epoch   8 | train_loss  4.97 | val_ppl 142.65083 | time  23.3s
[2018-08-11 12:30:40,802 INFO] test_ppl: 138.79193
[2018-08-11 13:00:50,147 INFO] -------------

(explanation: very standard. but norm pretrained out emb only at the start. note it's better than
non-norm)
[2018-08-11 13:00:50,148 INFO] Start training...
[2018-08-11 13:00:50,148 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 13:01:01,498 INFO] train token: 2127402
[2018-08-11 13:01:01,498 INFO] test token: 250140
[2018-08-11 13:01:01,498 INFO] valid token: 221606
[2018-08-11 13:01:01,641 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 13:01:27,496 INFO] | epoch   1 | train_loss  5.02 | val_ppl 134.90114 | time  22.5s
[2018-08-11 13:01:49,384 INFO] | epoch   2 | train_loss  4.75 | val_ppl 121.95061 | time  21.9s
[2018-08-11 13:02:11,900 INFO] | epoch   3 | train_loss  4.64 | val_ppl 116.06429 | time  22.5s
[2018-08-11 13:02:34,016 INFO] | epoch   4 | train_loss  4.57 | val_ppl 112.46828 | time  22.1s
[2018-08-11 13:02:56,513 INFO] | epoch   5 | train_loss  4.51 | val_ppl 110.15242 | time  22.5s
[2018-08-11 13:03:19,218 INFO] | epoch   6 | train_loss  4.47 | val_ppl 108.63990 | time  22.7s
[2018-08-11 13:03:41,388 INFO] | epoch   7 | train_loss  4.43 | val_ppl 107.69256 | time  22.2s
[2018-08-11 13:04:03,769 INFO] | epoch   8 | train_loss  4.39 | val_ppl 107.06490 | time  22.4s
[2018-08-11 13:04:04,630 INFO] test_ppl: 102.58162
[2018-08-11 13:12:22,848 INFO] -------------

(explanation: using the above pretrained out emb. convergence is faster but the final result keeps
same, the random seed is 0 at default)
[2018-08-11 13:12:22,848 INFO] Start training...
[2018-08-11 13:12:22,848 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 13:12:34,108 INFO] train token: 2127402
[2018-08-11 13:12:34,108 INFO] test token: 250140
[2018-08-11 13:12:34,108 INFO] valid token: 221606
[2018-08-11 13:12:34,251 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 13:13:00,180 INFO] | epoch   1 | train_loss  4.65 | val_ppl 115.26202 | time  22.0s
[2018-08-11 13:13:22,113 INFO] | epoch   2 | train_loss  4.50 | val_ppl 110.10633 | time  21.9s
[2018-08-11 13:13:44,565 INFO] | epoch   3 | train_loss  4.44 | val_ppl 107.72182 | time  22.5s
[2018-08-11 13:14:07,534 INFO] | epoch   4 | train_loss  4.39 | val_ppl 106.52273 | time  23.0s
[2018-08-11 13:14:29,769 INFO] | epoch   5 | train_loss  4.36 | val_ppl 105.91639 | time  22.2s
[2018-08-11 13:14:52,266 INFO] | epoch   6 | train_loss  4.33 | val_ppl 105.59615 | time  22.5s
[2018-08-11 13:15:14,607 INFO] | epoch   7 | train_loss  4.30 | val_ppl 105.50029 | time  22.3s
[2018-08-11 13:15:37,100 INFO] | epoch   8 | train_loss  4.27 | val_ppl 105.59313 | time  22.5s
[2018-08-11 13:15:38,098 INFO] test_ppl: 101.27162
[2018-08-11 13:17:06,753 INFO] -------------
[2018-08-11 13:17:06,753 INFO] Start training...

(explanation: using the above pretrained out emb. but keep fixed out emb. good result. preprae to
change the seed)
[2018-08-11 13:17:06,753 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 13:17:18,100 INFO] train token: 2127402
[2018-08-11 13:17:18,100 INFO] test token: 250140
[2018-08-11 13:17:18,100 INFO] valid token: 221606
[2018-08-11 13:17:18,242 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 13:17:42,749 INFO] | epoch   1 | train_loss  4.68 | val_ppl 112.72466 | time  20.4s
[2018-08-11 13:18:02,840 INFO] | epoch   2 | train_loss  4.53 | val_ppl 107.48921 | time  20.1s
[2018-08-11 13:18:23,101 INFO] | epoch   3 | train_loss  4.47 | val_ppl 105.31551 | time  20.3s
[2018-08-11 13:18:43,373 INFO] | epoch   4 | train_loss  4.44 | val_ppl 104.21897 | time  20.3s
[2018-08-11 13:19:03,549 INFO] | epoch   5 | train_loss  4.42 | val_ppl 103.66151 | time  20.2s
[2018-08-11 13:19:23,560 INFO] | epoch   6 | train_loss  4.40 | val_ppl 103.42313 | time  20.0s
[2018-08-11 13:19:44,342 INFO] | epoch   7 | train_loss  4.38 | val_ppl 103.29771 | time  20.8s
[2018-08-11 13:20:03,684 INFO] | epoch   8 | train_loss  4.37 | val_ppl 103.26707 | time  19.3s
[2018-08-11 13:20:04,560 INFO] test_ppl: 99.43876
[2018-08-11 13:21:46,779 INFO] -------------


(explanation: change seed. also keep fixed)
[2018-08-11 13:21:46,779 INFO] Start training...
[2018-08-11 13:21:46,780 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=10, tied=False, vector_type='glove.6B.100d')
[2018-08-11 13:21:57,939 INFO] train token: 2127402
[2018-08-11 13:21:57,939 INFO] test token: 250140
[2018-08-11 13:21:57,939 INFO] valid token: 221606
[2018-08-11 13:21:58,084 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 13:22:22,159 INFO] | epoch   1 | train_loss  4.69 | val_ppl 113.21638 | time  20.1s
[2018-08-11 13:22:42,222 INFO] | epoch   2 | train_loss  4.53 | val_ppl 107.68032 | time  20.1s
[2018-08-11 13:23:02,361 INFO] | epoch   3 | train_loss  4.48 | val_ppl 105.51221 | time  20.1s
[2018-08-11 13:23:22,120 INFO] | epoch   4 | train_loss  4.44 | val_ppl 104.41606 | time  19.8s
[2018-08-11 13:23:41,592 INFO] | epoch   5 | train_loss  4.42 | val_ppl 103.77690 | time  19.5s
[2018-08-11 13:24:01,753 INFO] | epoch   6 | train_loss  4.40 | val_ppl 103.42696 | time  20.2s
[2018-08-11 13:24:21,934 INFO] | epoch   7 | train_loss  4.38 | val_ppl 103.27184 | time  20.2s
[2018-08-11 13:24:41,712 INFO] | epoch   8 | train_loss  4.37 | val_ppl 103.23466 | time  19.8s
[2018-08-11 13:24:42,595 INFO] test_ppl: 99.29384

(continue to change the seed)
[2018-08-11 13:27:20,508 INFO] -------------
[2018-08-11 13:27:20,508 INFO] Start training...
[2018-08-11 13:27:20,508 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=100, tied=False, vector_type='glove.6B.100d')
[2018-08-11 13:27:31,661 INFO] train token: 2127402
[2018-08-11 13:27:31,661 INFO] test token: 250140
[2018-08-11 13:27:31,661 INFO] valid token: 221606
[2018-08-11 13:27:31,804 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 13:27:55,863 INFO] | epoch   1 | train_loss  4.69 | val_ppl 113.05575 | time  20.1s
[2018-08-11 13:28:15,902 INFO] | epoch   2 | train_loss  4.53 | val_ppl 107.66544 | time  20.0s
[2018-08-11 13:28:31,819 INFO] -------------
[2018-08-11 13:28:31,820 INFO] Start training...
[2018-08-11 13:28:31,820 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=4, tied=False, vector_type='glove.6B.100d')
[2018-08-11 13:28:43,686 INFO] train token: 2127402
[2018-08-11 13:28:43,687 INFO] test token: 250140
[2018-08-11 13:28:43,687 INFO] valid token: 221606
[2018-08-11 13:28:43,917 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 13:29:08,846 INFO] | epoch   1 | train_loss  4.69 | val_ppl 113.29452 | time  20.0s
[2018-08-11 13:29:29,050 INFO] | epoch   2 | train_loss  4.53 | val_ppl 107.81881 | time  20.2s
[2018-08-11 13:35:34,447 INFO] -------------


(explanation: norm pretrained out emb at the start. and keep fixed)
[2018-08-11 13:35:34,448 INFO] Start training...
[2018-08-11 13:35:34,448 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=3, tied=False, vector_type='glove.6B.100d')
[2018-08-11 13:35:45,395 INFO] train token: 2127402
[2018-08-11 13:35:45,395 INFO] test token: 250140
[2018-08-11 13:35:45,395 INFO] valid token: 221606
[2018-08-11 13:35:45,538 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 13:36:09,685 INFO] | epoch   1 | train_loss  5.94 | val_ppl 359.35717 | time  19.9s
[2018-08-11 13:36:29,654 INFO] | epoch   2 | train_loss  5.82 | val_ppl 340.28645 | time  20.0s
[2018-08-11 13:36:50,377 INFO] | epoch   3 | train_loss  5.77 | val_ppl 329.54376 | time  20.7s
[2018-08-11 13:37:10,706 INFO] | epoch   4 | train_loss  5.74 | val_ppl 322.69101 | time  20.3s
[2018-08-11 13:37:30,906 INFO] | epoch   5 | train_loss  5.72 | val_ppl 317.95991 | time  20.2s
[2018-08-11 13:37:50,825 INFO] | epoch   6 | train_loss  5.70 | val_ppl 314.86632 | time  19.9s
[2018-08-11 13:38:10,834 INFO] | epoch   7 | train_loss  5.69 | val_ppl 312.33242 | time  20.0s
[2018-08-11 13:38:30,577 INFO] | epoch   8 | train_loss  5.68 | val_ppl 310.29353 | time  19.7s
[2018-08-11 13:38:31,589 INFO] test_ppl: 307.08927


(explanation: loss is simple dot product. output emb is that nnlm pretrained one and fixed. out emb
normed at the start)
[2018-08-12 13:38:36,794 INFO] -------------
[2018-08-12 13:38:36,795 INFO] Start training...
[2018-08-12 13:38:36,795 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=3, tied=False, vector_type='glove.6B.100d')
[2018-08-12 13:38:48,458 INFO] train token: 2127402
[2018-08-12 13:38:48,458 INFO] test token: 250140
[2018-08-12 13:38:48,458 INFO] valid token: 221606
[2018-08-12 13:38:48,601 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-12 13:39:11,139 INFO] | epoch   1 | train_loss -3.55 | val_ppl 902.03348 | time  18.6s
[2018-08-12 13:39:28,424 INFO] | epoch   2 | train_loss -3.70 | val_ppl 866.56355 | time  17.3s
[2018-08-12 13:39:45,747 INFO] | epoch   3 | train_loss -3.76 | val_ppl 845.51901 | time  17.3s
[2018-08-12 13:40:03,768 INFO] | epoch   4 | train_loss -3.80 | val_ppl 841.61535 | time  18.0s
[2018-08-12 13:40:22,131 INFO] | epoch   5 | train_loss -3.82 | val_ppl 819.03383 | time  18.4s
[2018-08-12 13:40:40,539 INFO] | epoch   6 | train_loss -3.84 | val_ppl 818.78845 | time  18.4s
[2018-08-12 13:40:58,867 INFO] | epoch   7 | train_loss -3.85 | val_ppl 809.34811 | time  18.3s
[2018-08-12 13:41:15,157 INFO] | epoch   8 | train_loss -3.87 | val_ppl 801.43664 | time  16.3s
[2018-08-12 13:41:16,123 INFO] test_ppl: 795.94193

(explanation: not norm compared with above. it seems norm is better. But for full softmax version,
when fixing, norm is bad. for this experiment, i guess when norming, the stride for a hidden unit
will be small and more suitable if you compare when full softmax when back-prop)
[2018-08-12 13:53:27,821 INFO] -------------
[2018-08-12 13:53:27,822 INFO] Start training...
[2018-08-12 13:53:27,822 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=3, tied=False, vector_type='glove.6B.100d')
[2018-08-12 13:53:39,090 INFO] train token: 2127402
[2018-08-12 13:53:39,091 INFO] test token: 250140
[2018-08-12 13:53:39,091 INFO] valid token: 221606
[2018-08-12 13:53:39,236 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-12 13:53:59,210 INFO] | epoch   1 | train_loss -10.42 | val_ppl 4703.98806 | time  16.0s
[2018-08-12 13:54:16,775 INFO] | epoch   2 | train_loss -10.78 | val_ppl 3909.26306 | time  17.6s
[2018-08-12 13:54:34,432 INFO] | epoch   3 | train_loss -10.89 | val_ppl 3547.13782 | time  17.7s

(explanation: norm both hidden and out emb at start. the result goes bwteen the two.)
[2018-08-12 14:00:25,822 INFO] -------------
[2018-08-12 14:00:25,823 INFO] Start training...
[2018-08-12 14:00:25,823 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=3, tied=False, vector_type='glove.6B.100d')
[2018-08-12 14:00:37,250 INFO] train token: 2127402
[2018-08-12 14:00:37,250 INFO] test token: 250140
[2018-08-12 14:00:37,250 INFO] valid token: 221606
[2018-08-12 14:00:37,395 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-12 14:00:59,944 INFO] | epoch   1 | train_loss -0.36 | val_ppl 1092.42733 | time  18.4s
[2018-08-12 14:01:18,524 INFO] | epoch   2 | train_loss -0.37 | val_ppl 1024.11733 | time  18.6s
[2018-08-12 14:01:38,811 INFO] | epoch   3 | train_loss -0.37 | val_ppl 990.05335 | time  20.3s
[2018-08-12 14:01:57,473 INFO] | epoch   4 | train_loss -0.37 | val_ppl 979.25515 | time  18.7s
[2018-08-12 14:02:16,616 INFO] | epoch   5 | train_loss -0.37 | val_ppl 965.26287 | time  19.1s
[2018-08-12 14:02:35,281 INFO] | epoch   6 | train_loss -0.37 | val_ppl 955.85656 | time  18.7s
[2018-08-12 14:02:53,052 INFO] | epoch   7 | train_loss -0.38 | val_ppl 931.40796 | time  17.8s
[2018-08-12 14:03:12,398 INFO] | epoch   8 | train_loss -0.38 | val_ppl 919.60420 | time  19.3s
[2018-08-12 14:03:13,277 INFO] test_ppl: 913.41454


-------------------back to full softmax

(explanation: randomly inited out emb but updating)
[2018-08-12 15:10:43,158 INFO] Start training...
[2018-08-12 15:10:43,158 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=3, tied=False, vector_type='glove.6B.100d')
[2018-08-12 15:10:54,353 INFO] train token: 2127402
[2018-08-12 15:10:54,354 INFO] test token: 250140
[2018-08-12 15:10:54,354 INFO] valid token: 221606
[2018-08-12 15:10:54,498 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-12 15:11:20,834 INFO] | epoch   1 | train_loss  5.22 | val_ppl 152.47683 | time  23.1s
[2018-08-12 15:11:43,099 INFO] | epoch   2 | train_loss  4.86 | val_ppl 133.09695 | time  22.3s
[2018-08-12 15:13:25,405 INFO] -------------

(explanation: randomly inited out emb and fixed)
[2018-08-12 15:13:25,405 INFO] Start training...
[2018-08-12 15:13:25,406 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=3, tied=False, vector_type='glove.6B.100d')
[2018-08-12 15:13:36,460 INFO] train token: 2127402
[2018-08-12 15:13:36,461 INFO] test token: 250140
[2018-08-12 15:13:36,461 INFO] valid token: 221606
[2018-08-12 15:13:36,603 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-12 15:13:59,873 INFO] | epoch   1 | train_loss  9.09 | val_ppl 8095.25724 | time  20.0s
[2018-08-12 15:14:19,652 INFO] | epoch   2 | train_loss  9.01 | val_ppl 7807.98528 | time  19.8s
[2018-08-12 15:14:38,841 INFO] | epoch   3 | train_loss  8.98 | val_ppl 7628.68300 | time  19.2s
[2018-08-12 15:14:58,953 INFO] | epoch   4 | train_loss  8.96 | val_ppl 7494.81667 | time  20.1s
[2018-08-12 15:15:18,921 INFO] | epoch   5 | train_loss  8.95 | val_ppl 7407.63110 | time  20.0s
[2018-08-12 15:15:39,257 INFO] | epoch   6 | train_loss  8.93 | val_ppl 7335.21253 | time  20.3s
[2018-08-12 15:15:59,558 INFO] | epoch   7 | train_loss  8.92 | val_ppl 7282.63652 | time  20.3s
[2018-08-12 15:16:19,543 INFO] | epoch   8 | train_loss  8.91 | val_ppl 7235.73265 | time  20.0s
[2018-08-12 15:16:20,424 INFO] test_ppl: 7238.00396
[2018-08-13 16:24:38,947 INFO] -------------


(using cbow pretrained, and updating. we see the iteration and convergence is not as good as
self-pretrained out emb)
[2018-08-13 16:24:38,947 INFO] Start training...
[2018-08-13 16:24:38,947 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=3, tied=False, vector_type='glove.6B.100d')
[2018-08-13 16:24:50,271 INFO] train token: 2127402
[2018-08-13 16:24:50,272 INFO] test token: 250140
[2018-08-13 16:24:50,272 INFO] valid token: 221606
[2018-08-13 16:24:50,416 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-13 16:25:15,438 INFO] | epoch   1 | train_loss  5.27 | val_ppl 165.04891 | time  21.7s
[2018-08-13 16:25:37,089 INFO] | epoch   2 | train_loss  4.95 | val_ppl 144.93556 | time  21.7s
[2018-08-13 16:25:58,673 INFO] | epoch   3 | train_loss  4.83 | val_ppl 135.73802 | time  21.6s
[2018-08-13 16:26:20,276 INFO] | epoch   4 | train_loss  4.75 | val_ppl 130.26771 | time  21.6s
[2018-08-13 16:26:41,811 INFO] | epoch   5 | train_loss  4.68 | val_ppl 126.51464 | time  21.5s
[2018-08-13 16:27:03,395 INFO] | epoch   6 | train_loss  4.63 | val_ppl 123.82593 | time  21.6s
[2018-08-13 16:27:25,024 INFO] | epoch   7 | train_loss  4.58 | val_ppl 121.83505 | time  21.6s
[2018-08-13 16:27:46,537 INFO] | epoch   8 | train_loss  4.54 | val_ppl 120.44894 | time  21.5s
[2018-08-13 16:27:47,502 INFO] test_ppl: 116.50455
[2018-08-13 16:52:38,523 INFO] -------------

(see the param, batch_size and bptt_len are changed. self-pretrained out emb is fixed. bad news. it
 is my falut. bug. ignore this log)
[2018-08-13 16:52:38,523 INFO] Start training...
[2018-08-13 16:52:38,523 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=13, tied=False, vector_type='glove.6B.100d')
[2018-08-13 16:52:49,536 INFO] train token: 2127402
[2018-08-13 16:52:49,536 INFO] test token: 250140
[2018-08-13 16:52:49,536 INFO] valid token: 221606
[2018-08-13 16:52:49,679 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-13 16:53:07,622 INFO] | epoch   1 | train_loss  9.18 | val_ppl 8721.82832 | time  13.8s
[2018-08-13 16:53:21,387 INFO] | epoch   2 | train_loss  9.09 | val_ppl 8403.62200 | time  13.8s
[2018-08-13 16:53:35,386 INFO] | epoch   3 | train_loss  9.06 | val_ppl 8196.37181 | time  14.0s
[2018-08-13 16:53:49,355 INFO] | epoch   4 | train_loss  9.04 | val_ppl 8035.85206 | time  14.0s
[2018-08-13 16:55:14,810 INFO] -------------

(strange. using cbow, fixing. better. so strange)
[2018-08-13 16:55:14,810 INFO] Start training...
[2018-08-13 16:55:14,810 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=13, tied=False, vector_type='glove.6B.100d')
[2018-08-13 16:55:25,824 INFO] train token: 2127402
[2018-08-13 16:55:25,824 INFO] test token: 250140
[2018-08-13 16:55:25,824 INFO] valid token: 221606
[2018-08-13 16:55:26,046 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-13 16:55:43,578 INFO] | epoch   1 | train_loss  5.80 | val_ppl 293.62222 | time  14.1s
[2018-08-13 16:55:57,461 INFO] | epoch   2 | train_loss  5.48 | val_ppl 251.13946 | time  13.9s
[2018-08-13 16:56:11,362 INFO] | epoch   3 | train_loss  5.37 | val_ppl 232.11815 | time  13.9s
[2018-08-13 16:56:25,285 INFO] | epoch   4 | train_loss  5.30 | val_ppl 222.09285 | time  13.9s
[2018-08-13 16:56:39,367 INFO] | epoch   5 | train_loss  5.25 | val_ppl 215.73520 | time  14.1s
[2018-08-13 16:56:53,416 INFO] | epoch   6 | train_loss  5.22 | val_ppl 211.88669 | time  14.0s
[2018-08-13 16:57:07,516 INFO] | epoch   7 | train_loss  5.18 | val_ppl 209.26152 | time  14.1s
[2018-08-13 16:57:21,564 INFO] | epoch   8 | train_loss  5.16 | val_ppl 207.60089 | time  14.0s
[2018-08-13 16:57:22,227 INFO] test_ppl: 199.19498
[2018-08-13 16:59:22,997 INFO] -------------

(self-pretrained out emb. fixed. normed at start)
[2018-08-13 16:59:22,997 INFO] Start training...
[2018-08-13 16:59:22,997 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=13, tied=False, vector_type='glove.6B.100d')
[2018-08-13 16:59:34,302 INFO] train token: 2127402
[2018-08-13 16:59:34,302 INFO] test token: 250140
[2018-08-13 16:59:34,302 INFO] valid token: 221606
[2018-08-13 16:59:34,446 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-13 16:59:52,571 INFO] | epoch   1 | train_loss  5.97 | val_ppl 364.23271 | time  14.3s
[2018-08-13 17:00:06,687 INFO] | epoch   2 | train_loss  5.85 | val_ppl 346.86880 | time  14.1s
[2018-08-13 17:00:20,755 INFO] | epoch   3 | train_loss  5.81 | val_ppl 336.85057 | time  14.1s
[2018-08-13 17:00:34,858 INFO] | epoch   4 | train_loss  5.78 | val_ppl 329.78721 | time  14.1s
[2018-08-13 17:05:20,052 INFO] -------------


(this using non-normed out pretrained emb. fixed. this exp can shows even though bptt and batch is
changed. pretrained out emb is still usefull)
[2018-08-13 17:05:20,052 INFO] Start training...
[2018-08-13 17:05:20,052 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=13, tied=False, vector_type='glove.6B.100d')
[2018-08-13 17:05:31,079 INFO] train token: 2127402
[2018-08-13 17:05:31,079 INFO] test token: 250140
[2018-08-13 17:05:31,080 INFO] valid token: 221606
[2018-08-13 17:05:31,304 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-13 17:05:49,265 INFO] | epoch   1 | train_loss  4.73 | val_ppl 112.73530 | time  13.8s
[2018-08-13 17:06:03,141 INFO] | epoch   2 | train_loss  4.56 | val_ppl 105.95881 | time  13.9s
[2018-08-13 17:06:17,245 INFO] | epoch   3 | train_loss  4.51 | val_ppl 102.51871 | time  14.1s
[2018-08-13 17:06:31,180 INFO] | epoch   4 | train_loss  4.47 | val_ppl 100.56969 | time  13.9s
[2018-08-13 17:06:45,098 INFO] | epoch   5 | train_loss  4.44 | val_ppl 99.31948 | time  13.9s
[2018-08-13 17:06:58,934 INFO] | epoch   6 | train_loss  4.42 | val_ppl 98.47506 | time  13.8s
[2018-08-13 17:07:12,717 INFO] | epoch   7 | train_loss  4.40 | val_ppl 97.88738 | time  13.8s
[2018-08-13 17:07:26,792 INFO] | epoch   8 | train_loss  4.39 | val_ppl 97.47671 | time  14.1s
[2018-08-13 17:07:27,471 INFO] test_ppl: 94.64213
[2018-08-13 17:09:44,318 INFO] -------------

(explanation: randomly update out emb)
[2018-08-13 17:09:44,319 INFO] Start training...
[2018-08-13 17:09:44,319 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=13, tied=False, vector_type='glove.6B.100d')
[2018-08-13 17:09:55,422 INFO] train token: 2127402
[2018-08-13 17:09:55,422 INFO] test token: 250140
[2018-08-13 17:09:55,422 INFO] valid token: 221606
[2018-08-13 17:09:55,565 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-13 17:10:14,933 INFO] | epoch   1 | train_loss  5.37 | val_ppl 182.90919 | time  16.0s
[2018-08-13 17:10:31,049 INFO] | epoch   2 | train_loss  4.98 | val_ppl 155.57486 | time  16.1s
[2018-08-13 17:10:47,181 INFO] | epoch   3 | train_loss  4.85 | val_ppl 140.24403 | time  16.1s
[2018-08-13 17:11:03,209 INFO] | epoch   4 | train_loss  4.76 | val_ppl 130.84001 | time  16.0s
[2018-08-13 17:11:19,271 INFO] | epoch   5 | train_loss  4.70 | val_ppl 124.66550 | time  16.1s
[2018-08-13 17:11:35,406 INFO] | epoch   6 | train_loss  4.64 | val_ppl 119.58827 | time  16.1s
[2018-08-13 17:11:51,487 INFO] | epoch   7 | train_loss  4.60 | val_ppl 115.53022 | time  16.1s
[2018-08-13 17:12:07,420 INFO] | epoch   8 | train_loss  4.56 | val_ppl 112.59746 | time  15.9s
[2018-08-13 17:12:08,084 INFO] test_ppl: 110.07493
[2018-08-14 00:26:35,867 INFO] -------------

(out emb updating. almost same with non-updating)
[2018-08-14 00:26:35,867 INFO] Start training...
[2018-08-14 00:26:35,867 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=13, tied=False, vector_type='glove.6B.100d')
[2018-08-14 00:26:46,793 INFO] train token: 2127402
[2018-08-14 00:26:46,793 INFO] test token: 250140
[2018-08-14 00:26:46,793 INFO] valid token: 221606
[2018-08-14 00:26:46,953 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 00:27:06,921 INFO] | epoch   1 | train_loss  4.70 | val_ppl 114.00223 | time  16.0s
[2018-08-14 00:27:22,702 INFO] | epoch   2 | train_loss  4.53 | val_ppl 106.66522 | time  15.8s
[2018-08-14 00:27:38,743 INFO] | epoch   3 | train_loss  4.46 | val_ppl 102.97266 | time  16.0s
[2018-08-14 00:27:54,870 INFO] | epoch   4 | train_loss  4.42 | val_ppl 100.83983 | time  16.1s
[2018-08-14 00:28:10,811 INFO] | epoch   5 | train_loss  4.38 | val_ppl 99.36605 | time  15.9s
[2018-08-14 00:28:26,703 INFO] | epoch   6 | train_loss  4.36 | val_ppl 98.32752 | time  15.9s
[2018-08-14 00:28:42,841 INFO] | epoch   7 | train_loss  4.33 | val_ppl 97.56077 | time  16.1s
[2018-08-14 00:28:58,964 INFO] | epoch   8 | train_loss  4.31 | val_ppl 96.98207 | time  16.1s
[2018-08-14 00:28:59,627 INFO] test_ppl: 94.79493
[2018-08-14 00:46:50,244 INFO] -------------

(change opt. validate)
[2018-08-14 01:03:04,358 INFO] Start training...
[2018-08-14 01:03:04,358 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=13, tied=False, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-14 01:03:15,982 INFO] train token: 2127402
[2018-08-14 01:03:15,982 INFO] test token: 250140
[2018-08-14 01:03:15,982 INFO] valid token: 221606
[2018-08-14 01:03:16,204 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 01:03:34,764 INFO] | epoch   1 | train_loss  4.73 | val_ppl 112.73530 | time  14.0s
[2018-08-14 01:03:48,707 INFO] | epoch   2 | train_loss  4.56 | val_ppl 105.95881 | time  13.9s
[2018-08-14 01:04:02,874 INFO] | epoch   3 | train_loss  4.51 | val_ppl 102.51871 | time  14.2s
[2018-08-14 01:04:16,761 INFO] | epoch   4 | train_loss  4.47 | val_ppl 100.56969 | time  13.9s
[2018-08-14 01:06:47,582 INFO] -------------
[2018-08-14 01:08:03,300 INFO] -------------
[2018-08-14 01:13:50,533 INFO] -------------
[2018-08-14 01:13:50,533 INFO] Start training...
[2018-08-14 01:13:50,533 INFO] Namespace(batch_size=50, bidirectional=False, bptt_len=3, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-14 01:14:02,070 INFO] train token: 2127402
[2018-08-14 01:14:02,071 INFO] test token: 250140
[2018-08-14 01:14:02,071 INFO] valid token: 221606
[2018-08-14 01:14:02,218 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 01:14:29,242 INFO] | epoch   1 | train_loss  5.27 | val_ppl 156.47944 | time  23.6s
[2018-08-14 01:14:52,701 INFO] | epoch   2 | train_loss  4.95 | val_ppl 140.95941 | time  23.5s
[2018-08-14 01:15:16,191 INFO] | epoch   3 | train_loss  4.84 | val_ppl 134.11807 | time  23.5s
[2018-08-14 01:15:40,139 INFO] | epoch   4 | train_loss  4.77 | val_ppl 130.37092 | time  23.9s
[2018-08-14 01:16:03,617 INFO] | epoch   5 | train_loss  4.72 | val_ppl 128.05745 | time  23.5s
[2018-08-14 01:16:27,464 INFO] | epoch   6 | train_loss  4.67 | val_ppl 126.60108 | time  23.8s
[2018-08-14 01:16:51,434 INFO] | epoch   7 | train_loss  4.64 | val_ppl 125.73044 | time  24.0s
[2018-08-14 01:17:15,374 INFO] | epoch   8 | train_loss  4.60 | val_ppl 125.26940 | time  23.9s
[2018-08-14 01:17:16,320 INFO] test_ppl: 122.01947
[2018-08-14 01:27:48,938 INFO] -------------

(3bpt trained, good result)
[2018-08-14 01:27:48,938 INFO] Start training...
[2018-08-14 01:27:48,938 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./3bptt_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=13, tied=False, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-14 01:27:59,994 INFO] train token: 2127402
[2018-08-14 01:27:59,995 INFO] test token: 250140
[2018-08-14 01:27:59,995 INFO] valid token: 221606
[2018-08-14 01:28:00,215 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 01:28:18,434 INFO] | epoch   1 | train_loss  4.77 | val_ppl 118.58513 | time  14.1s
[2018-08-14 01:28:32,339 INFO] | epoch   2 | train_loss  4.62 | val_ppl 111.69263 | time  13.9s
[2018-08-14 01:28:46,220 INFO] | epoch   3 | train_loss  4.57 | val_ppl 108.31642 | time  13.9s
[2018-08-14 01:29:00,198 INFO] | epoch   4 | train_loss  4.53 | val_ppl 106.34086 | time  14.0s
[2018-08-14 01:29:14,212 INFO] | epoch   5 | train_loss  4.51 | val_ppl 104.97084 | time  14.0s
[2018-08-14 01:29:28,159 INFO] | epoch   6 | train_loss  4.49 | val_ppl 104.04239 | time  13.9s
[2018-08-14 01:29:42,201 INFO] | epoch   7 | train_loss  4.47 | val_ppl 103.41987 | time  14.0s
[2018-08-14 01:29:56,000 INFO] | epoch   8 | train_loss  4.46 | val_ppl 102.98950 | time  13.8s
[2018-08-14 01:29:56,737 INFO] test_ppl: 100.35828
[2018-08-14 01:33:07,994 INFO] -------------

(change seed validate)
[2018-08-14 01:33:07,995 INFO] Start training...
[2018-08-14 01:33:07,995 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./3bptt_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=90, tied=False, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-14 01:33:19,014 INFO] train token: 2127402
[2018-08-14 01:33:19,014 INFO] test token: 250140
[2018-08-14 01:33:19,014 INFO] valid token: 221606
[2018-08-14 01:33:19,158 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 01:33:37,219 INFO] | epoch   1 | train_loss  4.78 | val_ppl 118.63744 | time  14.1s
[2018-08-14 01:33:51,135 INFO] | epoch   2 | train_loss  4.63 | val_ppl 111.69728 | time  13.9s
[2018-08-14 01:34:05,183 INFO] | epoch   3 | train_loss  4.57 | val_ppl 108.26682 | time  14.0s
[2018-08-14 01:34:19,139 INFO] | epoch   4 | train_loss  4.54 | val_ppl 106.25249 | time  14.0s
[2018-08-14 01:34:33,313 INFO] | epoch   5 | train_loss  4.51 | val_ppl 104.86318 | time  14.2s
[2018-08-14 01:34:46,999 INFO] | epoch   6 | train_loss  4.49 | val_ppl 103.95396 | time  13.7s
[2018-08-14 01:35:00,760 INFO] | epoch   7 | train_loss  4.47 | val_ppl 103.32631 | time  13.8s
[2018-08-14 01:35:14,692 INFO] | epoch   8 | train_loss  4.46 | val_ppl 102.86615 | time  13.9s
[2018-08-14 01:35:15,348 INFO] test_ppl: 100.31762
[2018-08-14 01:38:36,077 INFO] -------------

(updating out emb)
[2018-08-14 01:38:36,077 INFO] Start training...
[2018-08-14 01:38:36,077 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./3bptt_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=90, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-14 01:38:46,739 INFO] train token: 2127402
[2018-08-14 01:38:46,739 INFO] test token: 250140
[2018-08-14 01:38:46,739 INFO] valid token: 221606
[2018-08-14 01:38:46,881 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 01:39:06,903 INFO] | epoch   1 | train_loss  4.74 | val_ppl 120.00567 | time  16.0s
[2018-08-14 01:39:22,948 INFO] | epoch   2 | train_loss  4.57 | val_ppl 111.88744 | time  16.0s
[2018-08-14 01:39:38,970 INFO] | epoch   3 | train_loss  4.51 | val_ppl 108.00286 | time  16.0s
[2018-08-14 01:39:55,005 INFO] | epoch   4 | train_loss  4.46 | val_ppl 105.65375 | time  16.0s
[2018-08-14 01:40:11,221 INFO] | epoch   5 | train_loss  4.43 | val_ppl 103.91337 | time  16.2s
[2018-08-14 01:40:27,237 INFO] | epoch   6 | train_loss  4.40 | val_ppl 102.61590 | time  16.0s
[2018-08-14 01:40:43,376 INFO] | epoch   7 | train_loss  4.37 | val_ppl 101.64003 | time  16.1s
[2018-08-14 01:40:59,414 INFO] | epoch   8 | train_loss  4.35 | val_ppl 100.88852 | time  16.0s
[2018-08-14 01:41:00,161 INFO] test_ppl: 98.33608
[2018-08-14 01:44:12,508 INFO] -------------

(for generating)
[2018-08-14 01:44:12,508 INFO] Start training...
[2018-08-14 01:44:12,508 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=2, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=11, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-14 01:44:23,573 INFO] train token: 2127402
[2018-08-14 01:44:23,574 INFO] test token: 250140
[2018-08-14 01:44:23,574 INFO] valid token: 221606
[2018-08-14 01:44:23,717 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 01:45:23,474 INFO] | epoch   1 | train_loss  5.13 | val_ppl 159.03160 | time  56.3s
[2018-08-14 01:46:18,650 INFO] | epoch   2 | train_loss  4.86 | val_ppl 148.82331 | time  55.2s
[2018-08-14 01:47:13,750 INFO] | epoch   3 | train_loss  4.76 | val_ppl 146.30748 | time  55.1s
[2018-08-14 01:48:09,485 INFO] | epoch   4 | train_loss  4.69 | val_ppl 145.77872 | time  55.7s
[2018-08-14 01:49:05,616 INFO] | epoch   5 | train_loss  4.64 | val_ppl 146.43325 | time  56.1s
[2018-08-14 01:50:01,385 INFO] | epoch   6 | train_loss  4.60 | val_ppl 147.95566 | time  55.8s
[2018-08-14 01:50:56,995 INFO] | epoch   7 | train_loss  4.56 | val_ppl 149.79260 | time  55.6s
[2018-08-14 01:51:53,227 INFO] | epoch   8 | train_loss  4.52 | val_ppl 152.01536 | time  56.2s
[2018-08-14 01:51:55,161 INFO] test_ppl: 149.65753
[2018-08-14 01:53:08,285 INFO] -------------

(2bptt pretrained)
[2018-08-14 01:53:08,285 INFO] Start training...
[2018-08-14 01:53:08,285 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./2bptt_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=190, tied=False, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-14 01:53:19,366 INFO] train token: 2127402
[2018-08-14 01:53:19,366 INFO] test token: 250140
[2018-08-14 01:53:19,366 INFO] valid token: 221606
[2018-08-14 01:53:19,511 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 01:53:37,261 INFO] | epoch   1 | train_loss  4.77 | val_ppl 126.87310 | time  13.8s
[2018-08-14 01:53:50,993 INFO] | epoch   2 | train_loss  4.61 | val_ppl 118.57411 | time  13.7s
[2018-08-14 01:54:04,890 INFO] | epoch   3 | train_loss  4.55 | val_ppl 114.36236 | time  13.9s
[2018-08-14 01:54:19,013 INFO] | epoch   4 | train_loss  4.50 | val_ppl 112.01659 | time  14.1s
[2018-08-14 01:54:33,152 INFO] | epoch   5 | train_loss  4.47 | val_ppl 110.38251 | time  14.1s
[2018-08-14 01:54:47,151 INFO] | epoch   6 | train_loss  4.44 | val_ppl 109.36511 | time  14.0s
[2018-08-14 01:55:01,183 INFO] | epoch   7 | train_loss  4.42 | val_ppl 108.61115 | time  14.0s
[2018-08-14 01:55:15,054 INFO] | epoch   8 | train_loss  4.40 | val_ppl 108.11990 | time  13.9s
[2018-08-14 01:55:15,712 INFO] test_ppl: 106.21488
[2018-08-14 02:00:59,366 INFO] -------------
[2018-08-14 02:00:59,366 INFO] Start training...
[2018-08-14 02:00:59,366 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=3, device='cuda:0', dropout=0.0, epoch=2, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=11, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-14 02:01:10,404 INFO] train token: 2127402
[2018-08-14 02:01:10,404 INFO] test token: 250140
[2018-08-14 02:01:10,404 INFO] valid token: 221606
[2018-08-14 02:01:10,548 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 02:01:54,832 INFO] | epoch   1 | train_loss  5.14 | val_ppl 154.96312 | time  40.9s
[2018-08-14 02:02:36,001 INFO] | epoch   2 | train_loss  4.84 | val_ppl 141.18390 | time  41.2s
[2018-08-14 02:02:37,586 INFO] test_ppl: 138.59411
[2018-08-14 02:05:52,816 INFO] -------------
[2018-08-14 02:05:52,816 INFO] Start training...

(2epoch pretrained. good result)
[2018-08-14 02:05:52,816 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./3bptt_2epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=190, tied=False, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-14 02:06:04,327 INFO] train token: 2127402
[2018-08-14 02:06:04,327 INFO] test token: 250140
[2018-08-14 02:06:04,328 INFO] valid token: 221606
[2018-08-14 02:06:04,473 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 02:06:22,731 INFO] | epoch   1 | train_loss  4.87 | val_ppl 124.26746 | time  14.0s
[2018-08-14 02:06:36,678 INFO] | epoch   2 | train_loss  4.73 | val_ppl 117.67876 | time  13.9s
[2018-08-14 02:06:50,563 INFO] | epoch   3 | train_loss  4.68 | val_ppl 114.20064 | time  13.9s
[2018-08-14 02:07:04,496 INFO] | epoch   4 | train_loss  4.65 | val_ppl 112.10386 | time  13.9s
[2018-08-14 02:07:18,357 INFO] | epoch   5 | train_loss  4.63 | val_ppl 110.65113 | time  13.9s
[2018-08-14 02:07:32,403 INFO] | epoch   6 | train_loss  4.61 | val_ppl 109.63534 | time  14.0s
[2018-08-14 02:07:46,259 INFO] | epoch   7 | train_loss  4.60 | val_ppl 108.87460 | time  13.9s
[2018-08-14 02:08:00,294 INFO] | epoch   8 | train_loss  4.58 | val_ppl 108.31211 | time  14.0s
[2018-08-14 02:08:00,963 INFO] test_ppl: 106.19774
[2018-08-14 02:11:11,969 INFO] -------------

(update_out_emb)
[2018-08-14 02:11:11,969 INFO] Start training...
[2018-08-14 02:11:11,969 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./3bptt_2epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=190, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-14 02:11:23,125 INFO] train token: 2127402
[2018-08-14 02:11:23,125 INFO] test token: 250140
[2018-08-14 02:11:23,125 INFO] valid token: 221606
[2018-08-14 02:11:23,271 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 02:11:43,478 INFO] | epoch   1 | train_loss  4.81 | val_ppl 124.05484 | time  15.9s
[2018-08-14 02:11:59,322 INFO] | epoch   2 | train_loss  4.65 | val_ppl 115.16294 | time  15.8s
[2018-08-14 02:12:15,414 INFO] | epoch   3 | train_loss  4.58 | val_ppl 110.32851 | time  16.1s
[2018-08-14 02:12:31,272 INFO] | epoch   4 | train_loss  4.53 | val_ppl 107.24493 | time  15.9s
[2018-08-14 02:12:47,468 INFO] | epoch   5 | train_loss  4.49 | val_ppl 104.96506 | time  16.2s
[2018-08-14 02:13:03,595 INFO] | epoch   6 | train_loss  4.46 | val_ppl 103.24610 | time  16.1s
[2018-08-14 02:13:19,718 INFO] | epoch   7 | train_loss  4.43 | val_ppl 101.95085 | time  16.1s
[2018-08-14 02:13:35,734 INFO] | epoch   8 | train_loss  4.40 | val_ppl 100.97340 | time  16.0s
[2018-08-14 02:13:36,403 INFO] test_ppl: 98.82227
[2018-08-14 17:39:36,901 INFO] -------------
[2018-08-14 17:41:37,992 INFO] -------------

(mlp out emb. 200 dimension )
[2018-08-14 17:41:37,992 INFO] Start training...
[2018-08-14 17:41:37,992 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./2mlplen_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=191, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-14 17:41:48,976 INFO] train token: 2127402
[2018-08-14 17:41:48,977 INFO] test token: 250140
[2018-08-14 17:41:48,977 INFO] valid token: 221606
[2018-08-14 17:41:49,198 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 17:42:13,328 INFO] | epoch   1 | train_loss  4.77 | val_ppl 125.58400 | time  19.5s
[2018-08-14 17:42:33,169 INFO] | epoch   2 | train_loss  4.53 | val_ppl 113.92994 | time  19.8s
[2018-08-14 17:42:52,788 INFO] | epoch   3 | train_loss  4.43 | val_ppl 108.56970 | time  19.6s
[2018-08-14 17:43:12,503 INFO] | epoch   4 | train_loss  4.36 | val_ppl 105.55509 | time  19.7s
[2018-08-14 17:43:32,504 INFO] | epoch   5 | train_loss  4.30 | val_ppl 103.50520 | time  20.0s
[2018-08-14 17:43:52,332 INFO] | epoch   6 | train_loss  4.25 | val_ppl 102.10628 | time  19.8s
[2018-08-14 17:44:12,258 INFO] | epoch   7 | train_loss  4.21 | val_ppl 101.17461 | time  19.9s
[2018-08-14 17:44:32,130 INFO] | epoch   8 | train_loss  4.17 | val_ppl 100.57368 | time  19.9s
[2018-08-14 17:44:32,896 INFO] test_ppl: 98.56248
[2018-08-14 17:47:13,596 INFO] -------------

(1 mlp. result seems good)
[2018-08-14 17:47:13,596 INFO] Start training...
[2018-08-14 17:47:13,596 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./1mlplen_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=191, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-14 17:47:25,463 INFO] train token: 2127402
[2018-08-14 17:47:25,464 INFO] test token: 250140
[2018-08-14 17:47:25,464 INFO] valid token: 221606
[2018-08-14 17:47:25,705 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 17:47:46,296 INFO] | epoch   1 | train_loss  4.87 | val_ppl 129.96926 | time  16.2s
[2018-08-14 17:48:02,410 INFO] | epoch   2 | train_loss  4.67 | val_ppl 117.38232 | time  16.1s
[2018-08-14 17:48:18,387 INFO] | epoch   3 | train_loss  4.58 | val_ppl 111.38211 | time  16.0s
[2018-08-14 17:48:34,407 INFO] | epoch   4 | train_loss  4.52 | val_ppl 107.56873 | time  16.0s
[2018-08-14 17:48:50,505 INFO] | epoch   5 | train_loss  4.47 | val_ppl 105.11069 | time  16.1s
[2018-08-14 17:49:06,520 INFO] | epoch   6 | train_loss  4.43 | val_ppl 103.29662 | time  16.0s
[2018-08-14 17:49:22,607 INFO] | epoch   7 | train_loss  4.40 | val_ppl 101.94067 | time  16.1s
[2018-08-14 17:49:38,792 INFO] | epoch   8 | train_loss  4.37 | val_ppl 100.93084 | time  16.2s
[2018-08-14 17:49:39,459 INFO] test_ppl: 98.56323
[2018-08-14 17:55:23,063 INFO] -------------

(use out_emb_path to init input. at start, not good as cbow input emb. but final result same)
[2018-08-14 17:55:23,063 INFO] Start training...
[2018-08-14 17:55:23,063 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./1mlplen_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=191, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-14 17:55:34,543 INFO] train token: 2127402
[2018-08-14 17:55:34,543 INFO] test token: 250140
[2018-08-14 17:55:34,544 INFO] valid token: 221606
[2018-08-14 17:55:34,687 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 17:55:54,782 INFO] | epoch   1 | train_loss  5.07 | val_ppl 138.06361 | time  16.1s
[2018-08-14 17:56:10,959 INFO] | epoch   2 | train_loss  4.76 | val_ppl 122.75515 | time  16.2s
[2018-08-14 17:56:27,295 INFO] | epoch   3 | train_loss  4.64 | val_ppl 114.89150 | time  16.3s
[2018-08-14 17:56:43,581 INFO] | epoch   4 | train_loss  4.57 | val_ppl 109.95043 | time  16.3s
[2018-08-14 17:56:59,758 INFO] | epoch   5 | train_loss  4.51 | val_ppl 106.56374 | time  16.2s
[2018-08-14 17:57:16,101 INFO] | epoch   6 | train_loss  4.47 | val_ppl 104.05287 | time  16.3s
[2018-08-14 17:57:32,409 INFO] | epoch   7 | train_loss  4.43 | val_ppl 102.11651 | time  16.3s
[2018-08-14 17:57:48,588 INFO] | epoch   8 | train_loss  4.39 | val_ppl 100.61905 | time  16.2s
[2018-08-14 17:57:49,261 INFO] test_ppl: 98.61270
[2018-08-15 10:30:08,013 INFO] -------------
[2018-08-15 10:30:48,932 INFO] -------------
[2018-08-15 10:30:48,933 INFO] Start training...
[2018-08-15 10:30:48,933 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=6, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./2mlplen_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=11, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-15 10:31:00,581 INFO] train token: 2127402
[2018-08-15 10:31:00,582 INFO] test token: 250140
[2018-08-15 10:31:00,582 INFO] valid token: 221606
[2018-08-15 10:31:00,847 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-15 10:35:01,742 INFO] -------------


(explanation: this is comparison with torch-example result)
[2018-08-15 10:35:01,742 INFO] Start training...
[2018-08-15 10:35:01,742 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=6, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./2mlplen_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=11, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-15 10:35:12,929 INFO] train token: 2127402
[2018-08-15 10:35:12,929 INFO] test token: 250140
[2018-08-15 10:35:12,929 INFO] valid token: 221606
[2018-08-15 10:35:13,076 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-15 10:35:38,965 INFO] | epoch   1 | train_loss  4.98 | val_ppl 134.25213 | time  21.1s
[2018-08-15 10:36:00,214 INFO] | epoch   2 | train_loss  4.59 | val_ppl 116.35322 | time  21.2s
[2018-08-15 10:36:21,531 INFO] | epoch   3 | train_loss  4.48 | val_ppl 108.09905 | time  21.3s
[2018-08-15 10:36:42,912 INFO] | epoch   4 | train_loss  4.40 | val_ppl 103.00094 | time  21.4s
[2018-08-15 10:37:04,251 INFO] | epoch   5 | train_loss  4.34 | val_ppl 99.50944 | time  21.3s
[2018-08-15 10:37:25,597 INFO] | epoch   6 | train_loss  4.29 | val_ppl 96.95864 | time  21.3s
[2018-08-15 10:37:26,361 INFO] test_ppl: 93.23290
[2018-08-15 10:39:27,510 INFO] -------------

(I reduced bptt to original one to make sure the above good result is not caused by bptt. here is a
nother import point: maybe bptt longer in later training phrase is better)
[2018-08-15 10:39:27,510 INFO] Start training...
[2018-08-15 10:39:27,510 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=6, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./2mlplen_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=11, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-15 10:39:38,685 INFO] train token: 2127402
[2018-08-15 10:39:38,685 INFO] test token: 250140
[2018-08-15 10:39:38,685 INFO] valid token: 221606
[2018-08-15 10:39:38,833 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-15 10:40:10,357 INFO] | epoch   1 | train_loss  4.81 | val_ppl 120.22324 | time  26.8s
[2018-08-15 10:40:37,201 INFO] | epoch   2 | train_loss  4.51 | val_ppl 109.03083 | time  26.8s
[2018-08-15 10:41:04,054 INFO] | epoch   3 | train_loss  4.40 | val_ppl 104.09236 | time  26.9s
[2018-08-15 10:41:30,919 INFO] | epoch   4 | train_loss  4.32 | val_ppl 101.31761 | time  26.9s
[2018-08-15 10:41:57,884 INFO] | epoch   5 | train_loss  4.26 | val_ppl 99.56572 | time  27.0s
[2018-08-15 10:42:24,878 INFO] | epoch   6 | train_loss  4.21 | val_ppl 98.42463 | time  27.0s
[2018-08-15 10:42:25,820 INFO] test_ppl: 94.95294
[2018-08-15 10:46:51,125 INFO] -------------

(only 2 epochs already better than example)
[2018-08-15 10:46:51,125 INFO] Start training...
[2018-08-15 10:46:51,125 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=2, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./2mlplen_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=11, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-15 10:47:02,240 INFO] train token: 2127402
[2018-08-15 10:47:02,240 INFO] test token: 250140
[2018-08-15 10:47:02,240 INFO] valid token: 221606
[2018-08-15 10:47:02,386 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-15 10:47:33,861 INFO] | epoch   1 | train_loss  4.81 | val_ppl 120.22324 | time  26.7s
[2018-08-15 10:48:00,695 INFO] | epoch   2 | train_loss  4.51 | val_ppl 109.03083 | time  26.8s
[2018-08-15 10:48:01,712 INFO] test_ppl: 104.64654
[2018-08-15 11:04:15,178 INFO] -------------
[2018-08-15 11:04:15,178 INFO] Start training...
[2018-08-15 11:04:15,179 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=20, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./2mlplen_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=131, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-15 11:04:26,559 INFO] train token: 2127402
[2018-08-15 11:04:26,560 INFO] test token: 250140
[2018-08-15 11:04:26,560 INFO] valid token: 221606
[2018-08-15 11:04:26,707 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-15 11:04:52,961 INFO] | epoch   1 | train_loss  4.98 | val_ppl 136.07956 | time  21.1s
[2018-08-15 11:05:14,116 INFO] | epoch   2 | train_loss  4.60 | val_ppl 117.77344 | time  21.2s
[2018-08-15 11:05:35,458 INFO] | epoch   3 | train_loss  4.48 | val_ppl 109.66688 | time  21.3s
[2018-08-15 11:05:56,962 INFO] | epoch   4 | train_loss  4.40 | val_ppl 104.76385 | time  21.5s
[2018-08-15 11:06:18,310 INFO] | epoch   5 | train_loss  4.34 | val_ppl 101.30790 | time  21.3s
[2018-08-15 11:06:39,767 INFO] | epoch   6 | train_loss  4.29 | val_ppl 98.66735 | time  21.5s
[2018-08-15 11:07:01,114 INFO] | epoch   7 | train_loss  4.25 | val_ppl 96.53800 | time  21.3s
[2018-08-15 11:07:22,509 INFO] | epoch   8 | train_loss  4.21 | val_ppl 94.78180 | time  21.4s
[2018-08-15 11:07:43,873 INFO] | epoch   9 | train_loss  4.18 | val_ppl 93.30883 | time  21.4s
[2018-08-15 11:08:05,299 INFO] | epoch  10 | train_loss  4.15 | val_ppl 92.05666 | time  21.4s
[2018-08-15 11:08:26,735 INFO] | epoch  11 | train_loss  4.12 | val_ppl 90.98491 | time  21.4s
[2018-08-15 11:08:48,282 INFO] | epoch  12 | train_loss  4.09 | val_ppl 90.06722 | time  21.5s
[2018-08-15 11:09:09,768 INFO] | epoch  13 | train_loss  4.07 | val_ppl 89.28476 | time  21.5s
[2018-08-15 11:09:31,043 INFO] | epoch  14 | train_loss  4.05 | val_ppl 88.62257 | time  21.3s
[2018-08-15 11:09:51,678 INFO] | epoch  15 | train_loss  4.03 | val_ppl 88.06784 | time  20.6s
[2018-08-15 11:10:12,075 INFO] | epoch  16 | train_loss  4.00 | val_ppl 87.60946 | time  20.4s
[2018-08-15 11:10:32,352 INFO] | epoch  17 | train_loss  3.98 | val_ppl 87.23774 | time  20.3s
[2018-08-15 11:10:52,591 INFO] | epoch  18 | train_loss  3.97 | val_ppl 86.94408 | time  20.2s
[2018-08-15 11:11:12,743 INFO] | epoch  19 | train_loss  3.95 | val_ppl 86.72086 | time  20.2s
[2018-08-15 11:11:32,712 INFO] | epoch  20 | train_loss  3.93 | val_ppl 86.56128 | time  20.0s
[2018-08-15 11:11:33,545 INFO] test_ppl: 83.59881
[2018-08-15 16:21:54,251 INFO] -------------

(compare: this is training all from scratch)
[2018-08-15 16:21:54,252 INFO] Start training...
[2018-08-15 16:21:54,252 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=20, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=131, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-15 16:22:05,542 INFO] train token: 2127402
[2018-08-15 16:22:05,543 INFO] test token: 250140
[2018-08-15 16:22:05,543 INFO] valid token: 221606
[2018-08-15 16:22:05,691 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-15 16:22:31,053 INFO] | epoch   1 | train_loss  5.59 | val_ppl 230.11018 | time  18.5s
[2018-08-15 16:22:49,740 INFO] | epoch   2 | train_loss  5.09 | val_ppl 175.92646 | time  18.7s
[2018-08-15 16:23:08,577 INFO] | epoch   3 | train_loss  4.93 | val_ppl 155.14470 | time  18.8s
[2018-08-15 16:23:27,443 INFO] | epoch   4 | train_loss  4.83 | val_ppl 144.57571 | time  18.9s
[2018-08-15 16:23:46,234 INFO] | epoch   5 | train_loss  4.75 | val_ppl 137.43208 | time  18.8s
[2018-08-15 16:24:05,086 INFO] | epoch   6 | train_loss  4.69 | val_ppl 132.08146 | time  18.9s
[2018-08-15 16:24:24,075 INFO] | epoch   7 | train_loss  4.63 | val_ppl 127.57145 | time  19.0s
[2018-08-15 16:24:43,018 INFO] | epoch   8 | train_loss  4.59 | val_ppl 124.15321 | time  18.9s
[2018-08-15 16:25:01,997 INFO] | epoch   9 | train_loss  4.55 | val_ppl 121.72800 | time  19.0s
[2018-08-15 16:25:21,035 INFO] | epoch  10 | train_loss  4.51 | val_ppl 119.83254 | time  19.0s
[2018-08-15 16:25:40,169 INFO] | epoch  11 | train_loss  4.48 | val_ppl 118.21816 | time  19.1s
[2018-08-15 16:25:59,126 INFO] | epoch  12 | train_loss  4.45 | val_ppl 116.80247 | time  19.0s
[2018-08-15 16:26:18,040 INFO] | epoch  13 | train_loss  4.43 | val_ppl 115.78821 | time  18.9s
[2018-08-15 16:26:37,011 INFO] | epoch  14 | train_loss  4.40 | val_ppl 114.83463 | time  19.0s
[2018-08-15 16:26:56,025 INFO] | epoch  15 | train_loss  4.38 | val_ppl 114.06880 | time  19.0s
[2018-08-15 16:27:15,030 INFO] | epoch  16 | train_loss  4.36 | val_ppl 113.66757 | time  19.0s
[2018-08-15 16:27:33,946 INFO] | epoch  17 | train_loss  4.34 | val_ppl 113.20984 | time  18.9s
[2018-08-15 16:27:52,923 INFO] | epoch  18 | train_loss  4.32 | val_ppl 112.72291 | time  19.0s
[2018-08-15 16:28:11,815 INFO] | epoch  19 | train_loss  4.30 | val_ppl 112.57509 | time  18.9s
[2018-08-15 16:28:30,779 INFO] | epoch  20 | train_loss  4.29 | val_ppl 112.18042 | time  19.0s
[2018-08-15 16:28:31,485 INFO] test_ppl: 107.32168
[2018-08-15 16:38:36,673 INFO] -------------
[2018-08-15 16:38:36,673 INFO] Start training...
[2018-08-15 16:38:36,674 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=20, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='/home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.200d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=131, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-15 16:38:48,282 INFO] train token: 2127402
[2018-08-15 16:38:48,283 INFO] test token: 250140
[2018-08-15 16:38:48,283 INFO] valid token: 221606
[2018-08-15 16:38:48,428 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-15 16:43:49,356 INFO] -------------

input and output using cbow 200d. still bad. now i have a idea
[2018-08-15 16:43:49,356 INFO] Start training...
[2018-08-15 16:43:49,356 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=20, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='/home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.200d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=131, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-15 16:44:00,559 INFO] train token: 2127402
[2018-08-15 16:44:00,559 INFO] test token: 250140
[2018-08-15 16:44:00,559 INFO] valid token: 221606
[2018-08-15 16:44:00,704 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-15 16:44:24,077 INFO] | epoch   1 | train_loss  5.93 | val_ppl 249.74867 | time  18.6s
[2018-08-15 16:44:42,770 INFO] | epoch   2 | train_loss  5.31 | val_ppl 209.21213 | time  18.7s
[2018-08-15 16:45:01,570 INFO] | epoch   3 | train_loss  5.13 | val_ppl 181.43523 | time  18.8s
[2018-08-15 16:45:20,408 INFO] | epoch   4 | train_loss  5.02 | val_ppl 162.84359 | time  18.8s
[2018-08-15 16:45:39,320 INFO] | epoch   5 | train_loss  4.93 | val_ppl 150.38944 | time  18.9s
[2018-08-15 16:45:58,200 INFO] | epoch   6 | train_loss  4.86 | val_ppl 141.16442 | time  18.9s
[2018-08-15 16:46:17,171 INFO] | epoch   7 | train_loss  4.80 | val_ppl 134.22232 | time  19.0s
[2018-08-15 16:46:36,066 INFO] | epoch   8 | train_loss  4.75 | val_ppl 128.59292 | time  18.9s
[2018-08-15 16:46:55,051 INFO] | epoch   9 | train_loss  4.70 | val_ppl 123.87695 | time  19.0s
[2018-08-15 16:47:14,227 INFO] | epoch  10 | train_loss  4.65 | val_ppl 119.94257 | time  19.2s
[2018-08-15 16:47:33,234 INFO] | epoch  11 | train_loss  4.61 | val_ppl 116.57959 | time  19.0s
[2018-08-15 16:47:52,337 INFO] | epoch  12 | train_loss  4.57 | val_ppl 113.62566 | time  19.1s
[2018-08-15 16:48:11,248 INFO] | epoch  13 | train_loss  4.54 | val_ppl 111.13059 | time  18.9s
[2018-08-15 16:48:30,292 INFO] | epoch  14 | train_loss  4.51 | val_ppl 109.01028 | time  19.0s
[2018-08-15 16:48:49,318 INFO] | epoch  15 | train_loss  4.48 | val_ppl 107.14072 | time  19.0s
[2018-08-15 16:49:08,447 INFO] | epoch  16 | train_loss  4.45 | val_ppl 105.47412 | time  19.1s
[2018-08-15 16:49:27,712 INFO] | epoch  17 | train_loss  4.42 | val_ppl 103.98657 | time  19.3s
[2018-08-15 16:49:46,748 INFO] | epoch  18 | train_loss  4.40 | val_ppl 102.66219 | time  19.0s
[2018-08-15 16:50:05,840 INFO] | epoch  19 | train_loss  4.37 | val_ppl 101.47360 | time  19.1s
[2018-08-15 16:50:24,871 INFO] | epoch  20 | train_loss  4.35 | val_ppl 100.38955 | time  19.0s
[2018-08-15 16:50:25,579 INFO] test_ppl: 96.62703
[2018-08-17 15:58:09,339 INFO] -------------
[2018-08-17 16:05:33,164 INFO] -------------


(add learning rate decay. and tries to achieve the limit of the model)
[2018-08-17 16:05:33,164 INFO] Start training...
[2018-08-17 16:05:33,164 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=40, every_n_epoch_decay=15, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='../nnlm/2mlplen_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=231, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-17 16:05:44,956 INFO] train token: 2127402
[2018-08-17 16:05:44,957 INFO] test token: 250140
[2018-08-17 16:05:44,957 INFO] valid token: 221606
[2018-08-17 16:05:45,117 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-17 16:06:08,487 INFO] | epoch   1 | train_loss  4.94 | val_ppl 133.24670 | time  18.6s
[2018-08-17 16:06:27,327 INFO] | epoch   2 | train_loss  4.58 | val_ppl 115.62567 | time  18.8s
[2018-08-17 16:06:46,035 INFO] | epoch   3 | train_loss  4.46 | val_ppl 107.71218 | time  18.7s
[2018-08-17 16:07:04,972 INFO] | epoch   4 | train_loss  4.39 | val_ppl 102.94732 | time  18.9s
[2018-08-17 16:07:23,901 INFO] | epoch   5 | train_loss  4.33 | val_ppl 99.58792 | time  18.9s
[2018-08-17 16:07:42,808 INFO] | epoch   6 | train_loss  4.28 | val_ppl 97.14991 | time  18.9s
[2018-08-17 16:08:01,639 INFO] | epoch   7 | train_loss  4.24 | val_ppl 95.26966 | time  18.8s
[2018-08-17 16:08:20,492 INFO] | epoch   8 | train_loss  4.20 | val_ppl 93.74459 | time  18.9s
[2018-08-17 16:08:39,498 INFO] | epoch   9 | train_loss  4.17 | val_ppl 92.47227 | time  19.0s
[2018-08-17 16:08:58,584 INFO] | epoch  10 | train_loss  4.14 | val_ppl 91.39952 | time  19.1s
[2018-08-17 16:09:17,681 INFO] | epoch  11 | train_loss  4.11 | val_ppl 90.49338 | time  19.1s
[2018-08-17 16:09:36,498 INFO] | epoch  12 | train_loss  4.09 | val_ppl 89.72923 | time  18.8s
[2018-08-17 16:09:55,488 INFO] | epoch  13 | train_loss  4.07 | val_ppl 89.08651 | time  19.0s
[2018-08-17 16:10:14,445 INFO] | epoch  14 | train_loss  4.04 | val_ppl 88.54802 | time  19.0s
[2018-08-17 16:10:33,340 INFO] learning rate has been changed to 0.05
[2018-08-17 16:10:33,341 INFO] | epoch  15 | train_loss  4.02 | val_ppl 88.09980 | time  18.9s
[2018-08-17 16:10:52,383 INFO] | epoch  16 | train_loss  4.00 | val_ppl 81.10210 | time  19.0s
[2018-08-17 16:11:11,426 INFO] | epoch  17 | train_loss  3.99 | val_ppl 80.94908 | time  19.0s
[2018-08-17 16:11:30,281 INFO] | epoch  18 | train_loss  3.98 | val_ppl 80.88628 | time  18.9s
[2018-08-17 16:11:49,328 INFO] | epoch  19 | train_loss  3.98 | val_ppl 80.84831 | time  19.0s
[2018-08-17 16:12:08,309 INFO] | epoch  20 | train_loss  3.98 | val_ppl 80.82070 | time  19.0s
[2018-08-17 16:12:27,234 INFO] | epoch  21 | train_loss  3.97 | val_ppl 80.79836 | time  18.9s
[2018-08-17 16:12:46,223 INFO] | epoch  22 | train_loss  3.97 | val_ppl 80.77912 | time  19.0s
[2018-08-17 16:13:05,234 INFO] | epoch  23 | train_loss  3.97 | val_ppl 80.76189 | time  19.0s
[2018-08-17 16:13:24,262 INFO] | epoch  24 | train_loss  3.97 | val_ppl 80.74611 | time  19.0s
[2018-08-17 16:13:43,361 INFO] | epoch  25 | train_loss  3.96 | val_ppl 80.73145 | time  19.1s
[2018-08-17 16:14:02,400 INFO] | epoch  26 | train_loss  3.96 | val_ppl 80.71772 | time  19.0s
[2018-08-17 16:14:21,416 INFO] | epoch  27 | train_loss  3.96 | val_ppl 80.70480 | time  19.0s
[2018-08-17 16:14:40,325 INFO] | epoch  28 | train_loss  3.96 | val_ppl 80.69260 | time  18.9s
[2018-08-17 16:14:59,284 INFO] | epoch  29 | train_loss  3.95 | val_ppl 80.68109 | time  19.0s
[2018-08-17 16:15:18,459 INFO] learning rate has been changed to 0.005000000000000001
[2018-08-17 16:15:18,459 INFO] | epoch  30 | train_loss  3.95 | val_ppl 80.67021 | time  19.2s
[2018-08-17 16:15:37,381 INFO] | epoch  31 | train_loss  3.95 | val_ppl 79.76065 | time  18.9s
[2018-08-17 16:15:56,530 INFO] | epoch  32 | train_loss  3.95 | val_ppl 79.69372 | time  19.1s
[2018-08-17 16:16:15,570 INFO] | epoch  33 | train_loss  3.95 | val_ppl 79.66838 | time  19.0s
[2018-08-17 16:16:34,552 INFO] | epoch  34 | train_loss  3.95 | val_ppl 79.65570 | time  19.0s
[2018-08-17 16:16:53,511 INFO] | epoch  35 | train_loss  3.95 | val_ppl 79.64816 | time  19.0s
[2018-08-17 16:17:12,475 INFO] | epoch  36 | train_loss  3.95 | val_ppl 79.64305 | time  19.0s
[2018-08-17 16:17:31,550 INFO] | epoch  37 | train_loss  3.95 | val_ppl 79.63924 | time  19.1s
[2018-08-17 16:17:50,706 INFO] | epoch  38 | train_loss  3.95 | val_ppl 79.63617 | time  19.2s
[2018-08-17 16:18:09,646 INFO] | epoch  39 | train_loss  3.95 | val_ppl 79.63356 | time  18.9s
[2018-08-17 16:18:28,659 INFO] | epoch  40 | train_loss  3.95 | val_ppl 79.63125 | time  19.0s
[2018-08-17 16:18:28,660 INFO] start to save model on nnlm.model
[2018-08-17 16:18:30,009 INFO] test_ppl: 77.59396
[2018-08-17 16:27:43,713 INFO] -------------
[2018-08-17 16:41:52,692 INFO] -------------
[2018-08-17 16:45:42,428 INFO] -------------

(long epoch test. use pretrained outemb based one long epoch training)
[2018-08-17 16:45:42,429 INFO] Start training...
[2018-08-17 16:45:42,429 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=40, every_n_epoch_decay=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./35bptt_40epoch_outemb1st.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=500, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-17 16:45:53,563 INFO] train token: 2127402
[2018-08-17 16:45:53,563 INFO] test token: 250140
[2018-08-17 16:45:53,563 INFO] valid token: 221606
[2018-08-17 16:45:53,704 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-17 16:46:16,840 INFO] | epoch   1 | train_loss  4.81 | val_ppl 121.35807 | time  18.6s
[2018-08-17 16:46:35,611 INFO] | epoch   2 | train_loss  4.40 | val_ppl 104.97451 | time  18.8s
[2018-08-17 16:46:54,430 INFO] | epoch   3 | train_loss  4.29 | val_ppl 98.56207 | time  18.8s
[2018-08-17 16:47:13,273 INFO] | epoch   4 | train_loss  4.22 | val_ppl 94.98923 | time  18.8s
[2018-08-17 16:47:32,150 INFO] | epoch   5 | train_loss  4.17 | val_ppl 92.61660 | time  18.9s
[2018-08-17 16:47:50,936 INFO] | epoch   6 | train_loss  4.13 | val_ppl 90.89218 | time  18.8s
[2018-08-17 16:48:09,786 INFO] | epoch   7 | train_loss  4.09 | val_ppl 89.56602 | time  18.8s
[2018-08-17 16:48:28,834 INFO] learning rate has been changed to 0.15
[2018-08-17 16:48:28,835 INFO] | epoch   8 | train_loss  4.06 | val_ppl 88.51720 | time  19.0s
[2018-08-17 16:48:47,791 INFO] | epoch   9 | train_loss  4.03 | val_ppl 81.91565 | time  19.0s
[2018-08-17 16:49:06,774 INFO] | epoch  10 | train_loss  4.02 | val_ppl 81.71901 | time  19.0s
[2018-08-17 16:49:25,769 INFO] | epoch  11 | train_loss  4.01 | val_ppl 81.56188 | time  19.0s
[2018-08-17 16:49:44,774 INFO] | epoch  12 | train_loss  4.00 | val_ppl 81.42170 | time  19.0s
[2018-08-17 16:50:03,815 INFO] | epoch  13 | train_loss  3.99 | val_ppl 81.29376 | time  19.0s
[2018-08-17 16:50:22,832 INFO] | epoch  14 | train_loss  3.98 | val_ppl 81.17623 | time  19.0s
[2018-08-17 16:50:41,777 INFO] | epoch  15 | train_loss  3.98 | val_ppl 81.06814 | time  18.9s
[2018-08-17 16:51:00,739 INFO] learning rate has been changed to 0.045
[2018-08-17 16:51:00,739 INFO] | epoch  16 | train_loss  3.97 | val_ppl 80.96885 | time  19.0s
[2018-08-17 16:51:19,761 INFO] | epoch  17 | train_loss  3.97 | val_ppl 79.12312 | time  19.0s
[2018-08-17 16:51:38,702 INFO] | epoch  18 | train_loss  3.96 | val_ppl 79.06699 | time  18.9s
[2018-08-17 16:51:57,584 INFO] | epoch  19 | train_loss  3.96 | val_ppl 79.03215 | time  18.9s
[2018-08-17 16:52:16,461 INFO] | epoch  20 | train_loss  3.96 | val_ppl 79.00258 | time  18.9s
[2018-08-17 16:52:35,425 INFO] | epoch  21 | train_loss  3.95 | val_ppl 78.97524 | time  19.0s
[2018-08-17 16:52:54,359 INFO] | epoch  22 | train_loss  3.95 | val_ppl 78.94937 | time  18.9s
[2018-08-17 16:53:13,357 INFO] | epoch  23 | train_loss  3.95 | val_ppl 78.92454 | time  19.0s
[2018-08-17 16:53:32,303 INFO] learning rate has been changed to 0.013499999999999998
[2018-08-17 16:53:32,304 INFO] | epoch  24 | train_loss  3.95 | val_ppl 78.90067 | time  18.9s
[2018-08-17 16:53:51,235 INFO] | epoch  25 | train_loss  3.95 | val_ppl 78.13881 | time  18.9s
[2018-08-17 16:54:10,230 INFO] | epoch  26 | train_loss  3.95 | val_ppl 78.10903 | time  19.0s
[2018-08-17 16:54:29,295 INFO] | epoch  27 | train_loss  3.95 | val_ppl 78.09381 | time  19.1s
[2018-08-17 16:54:48,255 INFO] | epoch  28 | train_loss  3.95 | val_ppl 78.08252 | time  19.0s
[2018-08-17 16:55:07,324 INFO] | epoch  29 | train_loss  3.94 | val_ppl 78.07256 | time  19.1s
[2018-08-17 16:55:26,395 INFO] | epoch  30 | train_loss  3.94 | val_ppl 78.06372 | time  19.1s
[2018-08-17 16:55:45,332 INFO] | epoch  31 | train_loss  3.94 | val_ppl 78.05518 | time  18.9s
[2018-08-17 16:56:04,219 INFO] learning rate has been changed to 0.00405
[2018-08-17 16:56:04,220 INFO] | epoch  32 | train_loss  3.94 | val_ppl 78.04722 | time  18.9s
[2018-08-17 16:56:23,350 INFO] | epoch  33 | train_loss  3.94 | val_ppl 77.68514 | time  19.1s
[2018-08-17 16:56:42,291 INFO] | epoch  34 | train_loss  3.94 | val_ppl 77.66894 | time  18.9s
[2018-08-17 16:57:01,289 INFO] | epoch  35 | train_loss  3.94 | val_ppl 77.66148 | time  19.0s
[2018-08-17 16:57:20,209 INFO] | epoch  36 | train_loss  3.94 | val_ppl 77.65647 | time  18.9s
[2018-08-17 16:57:39,209 INFO] | epoch  37 | train_loss  3.94 | val_ppl 77.65245 | time  19.0s
[2018-08-17 16:57:58,054 INFO] | epoch  38 | train_loss  3.94 | val_ppl 77.64892 | time  18.8s
[2018-08-17 16:58:16,947 INFO] | epoch  39 | train_loss  3.94 | val_ppl 77.64568 | time  18.9s
[2018-08-17 16:58:35,989 INFO] learning rate has been changed to 0.0012149999999999997
[2018-08-17 16:58:35,990 INFO] | epoch  40 | train_loss  3.94 | val_ppl 77.64261 | time  19.0s
[2018-08-17 16:58:35,990 INFO] start to save model on nnlm.model
[2018-08-17 16:58:37,282 INFO] test_ppl: 75.71181
[2018-08-17 17:18:54,613 INFO] -------------
[2018-08-17 20:30:34,082 INFO] -------------


(explanation: varify whether teach bptt2 is good or not. it seems it's not necessary)
[2018-08-17 20:30:34,082 INFO] Start training...
[2018-08-17 20:30:34,082 INFO] Namespace(batch_size=100, bidirectional=False, bptt_len=2, device='cuda:0', dropout=0.0, epoch=13, every_n_epoch_decay=4, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='../nnlm/2mlplen_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=100, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-17 20:30:45,113 INFO] train token: 2127402
[2018-08-17 20:30:45,113 INFO] test token: 250140
[2018-08-17 20:30:45,113 INFO] valid token: 221606
[2018-08-17 20:30:45,255 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-17 20:31:14,504 INFO] | epoch   1 | train_loss  4.96 | val_ppl 139.16571 | time  24.5s
[2018-08-17 20:31:39,242 INFO] | epoch   2 | train_loss  4.76 | val_ppl 133.03108 | time  24.7s
[2018-08-17 20:32:04,037 INFO] | epoch   3 | train_loss  4.68 | val_ppl 130.45050 | time  24.8s
[2018-08-17 20:32:28,790 INFO] learning rate has been changed to 0.15
[2018-08-17 20:32:28,791 INFO] | epoch   4 | train_loss  4.63 | val_ppl 129.14171 | time  24.8s
[2018-08-17 20:32:53,395 INFO] | epoch   5 | train_loss  4.57 | val_ppl 125.64007 | time  24.6s
[2018-08-17 20:33:17,991 INFO] | epoch   6 | train_loss  4.55 | val_ppl 125.51234 | time  24.6s
[2018-08-17 20:33:42,900 INFO] | epoch   7 | train_loss  4.53 | val_ppl 125.46569 | time  24.9s
[2018-08-17 20:34:07,558 INFO] learning rate has been changed to 0.045
[2018-08-17 20:34:07,558 INFO] | epoch   8 | train_loss  4.52 | val_ppl 125.46514 | time  24.7s
[2018-08-17 20:34:32,327 INFO] | epoch   9 | train_loss  4.51 | val_ppl 123.49124 | time  24.8s
[2018-08-17 20:34:57,669 INFO] | epoch  10 | train_loss  4.50 | val_ppl 123.48624 | time  25.3s
[2018-08-17 20:35:22,755 INFO] | epoch  11 | train_loss  4.49 | val_ppl 123.50730 | time  25.1s
[2018-08-17 20:35:47,381 INFO] learning rate has been changed to 0.013499999999999998
[2018-08-17 20:35:47,382 INFO] | epoch  12 | train_loss  4.49 | val_ppl 123.53305 | time  24.6s
[2018-08-17 20:36:12,250 INFO] | epoch  13 | train_loss  4.49 | val_ppl 122.49116 | time  24.9s
[2018-08-17 20:36:13,140 INFO] test_ppl: 119.49927
[2018-08-17 20:39:08,940 INFO] -------------

(verify reduce learning rate frequency)
[2018-08-17 20:39:08,940 INFO] Start training...
[2018-08-17 20:39:08,940 INFO] Namespace(batch_size=100, bidirectional=False, bptt_len=2, device='cuda:0', dropout=0.0, epoch=30, every_n_epoch_decay=2, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='../nnlm/2mlplen_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=100, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-17 20:39:19,655 INFO] train token: 2127402
[2018-08-17 20:39:19,655 INFO] test token: 250140
[2018-08-17 20:39:19,655 INFO] valid token: 221606
[2018-08-17 20:39:19,797 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-17 20:39:48,708 INFO] | epoch   1 | train_loss  4.96 | val_ppl 139.16571 | time  24.2s
[2018-08-17 20:40:13,217 INFO] learning rate has been changed to 0.15
[2018-08-17 20:40:13,217 INFO] | epoch   2 | train_loss  4.76 | val_ppl 133.03108 | time  24.5s
[2018-08-17 20:40:37,603 INFO] | epoch   3 | train_loss  4.67 | val_ppl 128.56693 | time  24.4s
[2018-08-17 20:41:02,784 INFO] learning rate has been changed to 0.045
[2018-08-17 20:41:02,784 INFO] | epoch   4 | train_loss  4.65 | val_ppl 127.86226 | time  25.2s
[2018-08-17 20:41:27,433 INFO] | epoch   5 | train_loss  4.63 | val_ppl 125.71925 | time  24.6s
[2018-08-17 20:41:52,476 INFO] learning rate has been changed to 0.013499999999999998
[2018-08-17 20:41:52,477 INFO] | epoch   6 | train_loss  4.62 | val_ppl 125.52729 | time  25.0s
[2018-08-17 20:42:17,113 INFO] | epoch   7 | train_loss  4.61 | val_ppl 124.46328 | time  24.6s
[2018-08-17 20:42:41,744 INFO] learning rate has been changed to 0.00405
[2018-08-17 20:42:41,744 INFO] | epoch   8 | train_loss  4.61 | val_ppl 124.37626 | time  24.6s
[2018-08-17 20:43:06,518 INFO] | epoch   9 | train_loss  4.61 | val_ppl 124.04832 | time  24.8s
[2018-08-17 20:43:31,617 INFO] learning rate has been changed to 0.0012149999999999997
[2018-08-17 20:43:31,618 INFO] | epoch  10 | train_loss  4.61 | val_ppl 123.99628 | time  25.1s
[2018-08-17 20:43:56,286 INFO] | epoch  11 | train_loss  4.61 | val_ppl 123.96422 | time  24.7s
[2018-08-17 20:44:21,219 INFO] learning rate has been changed to 0.0003644999999999999
[2018-08-17 20:44:21,219 INFO] | epoch  12 | train_loss  4.61 | val_ppl 123.95292 | time  24.9s
[2018-08-17 20:44:46,154 INFO] | epoch  13 | train_loss  4.61 | val_ppl 123.95256 | time  24.9s
[2018-08-17 20:45:11,182 INFO] learning rate has been changed to 0.00010934999999999997
[2018-08-17 20:45:11,183 INFO] | epoch  14 | train_loss  4.61 | val_ppl 123.95866 | time  25.0s
[2018-08-17 20:48:55,528 INFO] -------------
[2018-08-17 20:48:55,528 INFO] Start training...
[2018-08-17 20:48:55,528 INFO] Namespace(batch_size=100, bidirectional=False, bptt_len=2, device='cuda:0', dropout=0.0, epoch=30, every_n_epoch_decay=2, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='../nnlm/2mlplen_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=100, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-17 20:49:07,081 INFO] train token: 2127402
[2018-08-17 20:49:07,081 INFO] test token: 250140
[2018-08-17 20:49:07,081 INFO] valid token: 221606
[2018-08-17 20:49:07,225 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-17 20:49:36,295 INFO] | epoch   1 | train_loss  4.96 | val_ppl 139.16571 | time  24.4s
[2018-08-17 20:50:00,778 INFO] learning rate has been changed to 0.25
[2018-08-17 20:50:00,779 INFO] | epoch   2 | train_loss  4.76 | val_ppl 133.03108 | time  24.5s
[2018-08-17 20:50:25,384 INFO] | epoch   3 | train_loss  4.67 | val_ppl 129.35671 | time  24.6s
[2018-08-17 20:50:50,055 INFO] learning rate has been changed to 0.125
[2018-08-17 20:50:50,056 INFO] | epoch   4 | train_loss  4.64 | val_ppl 128.42623 | time  24.7s
[2018-08-17 20:51:14,718 INFO] | epoch   5 | train_loss  4.60 | val_ppl 126.43208 | time  24.7s
[2018-08-17 20:51:39,543 INFO] learning rate has been changed to 0.0625
[2018-08-17 20:51:39,543 INFO] | epoch   6 | train_loss  4.59 | val_ppl 126.17141 | time  24.8s
[2018-08-17 20:52:04,108 INFO] | epoch   7 | train_loss  4.57 | val_ppl 124.86563 | time  24.6s
[2018-08-17 20:52:28,866 INFO] learning rate has been changed to 0.03125
[2018-08-17 20:52:28,866 INFO] | epoch   8 | train_loss  4.57 | val_ppl 124.76916 | time  24.8s
[2018-08-17 20:52:53,613 INFO] | epoch   9 | train_loss  4.56 | val_ppl 123.88228 | time  24.7s
[2018-08-17 20:53:18,483 INFO] learning rate has been changed to 0.015625
[2018-08-17 20:53:18,484 INFO] | epoch  10 | train_loss  4.55 | val_ppl 123.83465 | time  24.9s
[2018-08-17 20:53:43,434 INFO] | epoch  11 | train_loss  4.55 | val_ppl 123.23092 | time  24.9s
[2018-08-19 19:08:06,697 INFO] -------------
[2018-08-19 19:10:26,431 INFO] -------------
[2018-08-19 20:03:17,288 INFO] -------------


---------------------------------------------
-  trying to duplicate previous experiment  -
---------------------------------------------

(new lowered cbow, why so bad?)
[2018-08-19 20:03:17,288 INFO] Start training...
[2018-08-19 20:03:17,288 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=2, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 20:03:28,763 INFO] train token: 2127402
[2018-08-19 20:03:28,764 INFO] test token: 250140
[2018-08-19 20:03:28,764 INFO] valid token: 221606
[2018-08-19 20:03:28,764 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt.pt
[2018-08-19 20:03:46,170 INFO] | epoch   1 | train_loss  5.87 | val_ppl 299.07014 | time  13.3s
[2018-08-19 20:03:59,642 INFO] | epoch   2 | train_loss  5.54 | val_ppl 265.58214 | time  13.5s
[2018-08-19 20:04:13,062 INFO] | epoch   3 | train_loss  5.43 | val_ppl 246.37691 | time  13.4s
[2018-08-19 20:04:26,672 INFO] | epoch   4 | train_loss  5.34 | val_ppl 231.43115 | time  13.6s
[2018-08-19 20:04:40,253 INFO] | epoch   5 | train_loss  5.27 | val_ppl 220.21720 | time  13.6s
[2018-08-19 20:04:53,606 INFO] | epoch   6 | train_loss  5.21 | val_ppl 211.64234 | time  13.4s
[2018-08-19 20:05:07,293 INFO] | epoch   7 | train_loss  5.16 | val_ppl 204.96876 | time  13.7s
[2018-08-19 20:05:21,039 INFO] learning rate has been changed to 0.25
[2018-08-19 20:05:21,040 INFO] | epoch   8 | train_loss  5.11 | val_ppl 199.45869 | time  13.7s
[2018-08-19 20:05:21,706 INFO] test_ppl: 183.50683
[2018-08-19 20:07:45,066 INFO] -------------

(original cbow. still not good as previous. bpptlen is different. But here is a important thing.
when out emb is well pre-trained, long bptt give better ppl)
[2018-08-19 20:07:45,066 INFO] Start training...
[2018-08-19 20:07:45,067 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=2, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 20:07:56,464 INFO] train token: 2127402
[2018-08-19 20:07:56,464 INFO] test token: 250140
[2018-08-19 20:07:56,464 INFO] valid token: 221606
[2018-08-19 20:07:56,729 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt
[2018-08-19 20:07:56,734 WARNING] Skipping token 23380 with 1-dimensional vector ['100']; likely a header
[2018-08-19 20:07:57,570 INFO] Saving vectors to /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt.pt
[2018-08-19 20:08:16,556 INFO] | epoch   1 | train_loss  5.49 | val_ppl 204.08545 | time  14.5s
[2018-08-19 20:08:30,992 INFO] | epoch   2 | train_loss  5.10 | val_ppl 177.22877 | time  14.4s
[2018-08-19 20:08:45,326 INFO] | epoch   3 | train_loss  4.99 | val_ppl 162.45061 | time  14.3s
[2018-08-19 20:08:59,898 INFO] | epoch   4 | train_loss  4.90 | val_ppl 152.49020 | time  14.6s
[2018-08-19 20:09:14,379 INFO] | epoch   5 | train_loss  4.84 | val_ppl 145.09570 | time  14.5s
[2018-08-19 20:09:28,976 INFO] | epoch   6 | train_loss  4.78 | val_ppl 139.55051 | time  14.6s
[2018-08-19 20:09:43,668 INFO] | epoch   7 | train_loss  4.74 | val_ppl 135.34312 | time  14.7s
[2018-08-19 20:09:58,335 INFO] learning rate has been changed to 0.25
[2018-08-19 20:09:58,336 INFO] | epoch   8 | train_loss  4.70 | val_ppl 131.91110 | time  14.7s
[2018-08-19 20:09:58,946 INFO] test_ppl: 126.77791
[2018-08-19 20:14:13,598 INFO] -------------

(change seed as before. similary result is observed. The seed is important??. It should be the bptt
len)
[2018-08-19 20:14:13,599 INFO] Start training...
[2018-08-19 20:14:13,599 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 20:14:24,809 INFO] train token: 2127402
[2018-08-19 20:14:24,810 INFO] test token: 250140
[2018-08-19 20:14:24,810 INFO] valid token: 221606
[2018-08-19 20:14:24,811 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt.pt
[2018-08-19 20:14:51,621 INFO] | epoch   1 | train_loss  5.27 | val_ppl 165.09230 | time  22.7s
[2018-08-19 20:15:13,696 INFO] | epoch   2 | train_loss  4.96 | val_ppl 145.60978 | time  22.1s
[2018-08-19 20:15:36,008 INFO] | epoch   3 | train_loss  4.84 | val_ppl 136.41983 | time  22.3s
[2018-08-19 20:15:58,010 INFO] | epoch   4 | train_loss  4.76 | val_ppl 131.02124 | time  22.0s
[2018-08-19 20:16:20,492 INFO] | epoch   5 | train_loss  4.69 | val_ppl 127.32532 | time  22.5s
[2018-08-19 20:16:42,468 INFO] | epoch   6 | train_loss  4.64 | val_ppl 124.66468 | time  22.0s
[2018-08-19 20:17:04,832 INFO] | epoch   7 | train_loss  4.59 | val_ppl 122.66109 | time  22.4s
[2018-08-19 20:17:27,202 INFO] learning rate has been changed to 0.25
[2018-08-19 20:17:27,202 INFO] | epoch   8 | train_loss  4.55 | val_ppl 121.25213 | time  22.4s
[2018-08-19 20:17:28,069 INFO] test_ppl: 117.35846
[2018-08-19 20:21:03,169 INFO] -------------

(same seed. lowerd cbow. strange!!!)
[2018-08-19 20:21:03,169 INFO] Start training...
[2018-08-19 20:21:03,169 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 20:21:14,402 INFO] train token: 2127402
[2018-08-19 20:21:14,402 INFO] test token: 250140
[2018-08-19 20:21:14,402 INFO] valid token: 221606
[2018-08-19 20:21:14,403 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt.pt
[2018-08-19 20:21:39,941 INFO] | epoch   1 | train_loss  5.69 | val_ppl 253.20658 | time  21.5s
[2018-08-19 20:22:00,807 INFO] | epoch   2 | train_loss  5.39 | val_ppl 223.62686 | time  20.9s
[2018-08-19 20:22:22,591 INFO] | epoch   3 | train_loss  5.25 | val_ppl 209.25784 | time  21.8s
[2018-08-19 20:22:42,844 INFO] | epoch   4 | train_loss  5.14 | val_ppl 200.87544 | time  20.3s
[2018-08-19 20:23:03,673 INFO] | epoch   5 | train_loss  5.06 | val_ppl 195.63026 | time  20.8s
[2018-08-19 20:23:24,583 INFO] | epoch   6 | train_loss  4.99 | val_ppl 192.43315 | time  20.9s
[2018-08-19 20:23:45,991 INFO] | epoch   7 | train_loss  4.93 | val_ppl 190.48292 | time  21.4s
[2018-08-19 20:24:06,663 INFO] learning rate has been changed to 0.25
[2018-08-19 20:24:06,663 INFO] | epoch   8 | train_loss  4.87 | val_ppl 189.47014 | time  20.7s
[2018-08-19 20:24:07,476 INFO] test_ppl: 175.81078
[2018-08-19 20:29:11,795 INFO] -------------


(not because the learning rate)
[2018-08-19 20:29:11,795 INFO] Start training...
[2018-08-19 20:29:11,795 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt', log_file='log', lr=0.25, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 20:29:23,167 INFO] train token: 2127402
[2018-08-19 20:29:23,167 INFO] test token: 250140
[2018-08-19 20:29:23,167 INFO] valid token: 221606
[2018-08-19 20:29:23,168 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt.pt
[2018-08-19 20:29:48,202 INFO] | epoch   1 | train_loss  5.70 | val_ppl 255.48203 | time  20.9s
[2018-08-19 20:30:09,421 INFO] | epoch   2 | train_loss  5.46 | val_ppl 227.84849 | time  21.2s
[2018-08-19 20:31:40,476 INFO] -------------


[2018-08-19 20:31:40,476 INFO] Start training...
[2018-08-19 20:31:40,477 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=2, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 20:31:51,756 INFO] train token: 2127402
[2018-08-19 20:31:51,756 INFO] test token: 250140
[2018-08-19 20:31:51,757 INFO] valid token: 221606
[2018-08-19 20:31:51,758 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt.pt
[2018-08-19 20:32:17,956 INFO] | epoch   1 | train_loss  5.26 | val_ppl 164.25272 | time  22.0s
[2018-08-19 20:40:52,142 INFO] -------------

as expected, long bptt is good for init model
[2018-08-19 20:40:52,142 INFO] Start training...
[2018-08-19 20:40:52,142 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 20:41:03,673 INFO] train token: 2127402
[2018-08-19 20:41:03,673 INFO] test token: 250140
[2018-08-19 20:41:03,673 INFO] valid token: 221606
[2018-08-19 20:41:03,674 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt.pt
[2018-08-19 20:41:22,082 INFO] | epoch   1 | train_loss  5.57 | val_ppl 214.51320 | time  14.3s
[2018-08-19 20:41:36,265 INFO] | epoch   2 | train_loss  5.13 | val_ppl 181.98464 | time  14.2s
[2018-08-19 20:41:50,743 INFO] | epoch   3 | train_loss  5.00 | val_ppl 162.94709 | time  14.5s
[2018-08-19 20:42:05,147 INFO] | epoch   4 | train_loss  4.92 | val_ppl 150.74864 | time  14.4s
[2018-08-19 20:42:19,376 INFO] | epoch   5 | train_loss  4.85 | val_ppl 142.81045 | time  14.2s
[2018-08-19 20:42:34,055 INFO] | epoch   6 | train_loss  4.80 | val_ppl 137.34703 | time  14.7s
[2018-08-19 20:42:48,811 INFO] | epoch   7 | train_loss  4.75 | val_ppl 133.16450 | time  14.8s
[2018-08-19 20:43:03,259 INFO] learning rate has been changed to 0.25
[2018-08-19 20:43:03,260 INFO] | epoch   8 | train_loss  4.71 | val_ppl 129.74701 | time  14.4s
[2018-08-19 20:43:03,860 INFO] test_ppl: 125.02505
[2018-08-19 20:51:35,587 INFO] -------------


it's not big vocab which contains lots of never-meet words that give better ppl.
[2018-08-19 20:51:35,587 INFO] Start training...
[2018-08-19 20:51:35,587 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 20:51:46,908 INFO] train token: 2127402
[2018-08-19 20:51:46,908 INFO] test token: 250140
[2018-08-19 20:51:46,908 INFO] valid token: 221606
[2018-08-19 20:51:46,952 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt
[2018-08-19 20:51:47,788 INFO] Saving vectors to /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt.pt
[2018-08-19 20:52:15,346 INFO] | epoch   1 | train_loss  5.69 | val_ppl 253.35450 | time  23.0s
[2018-08-19 20:52:38,051 INFO] | epoch   2 | train_loss  5.39 | val_ppl 222.76986 | time  22.7s
[2018-08-19 20:53:00,491 INFO] | epoch   3 | train_loss  5.25 | val_ppl 209.24298 | time  22.4s
[2018-08-19 20:55:40,606 INFO] -------------
[2018-08-19 20:55:40,607 INFO] Start training...

this one. I set lower=False for field. But it turns out it will affect the quality as well
[2018-08-19 20:55:40,607 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 20:55:50,324 INFO] train token: 2127402
[2018-08-19 20:55:50,324 INFO] test token: 250140
[2018-08-19 20:55:50,324 INFO] valid token: 221606
[2018-08-19 20:55:50,324 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt.pt
[2018-08-19 20:56:08,929 INFO] | epoch   1 | train_loss  6.01 | val_ppl 326.61733 | time  14.4s
[2018-08-19 20:56:23,538 INFO] | epoch   2 | train_loss  5.61 | val_ppl 284.21094 | time  14.6s
[2018-08-19 20:56:38,283 INFO] | epoch   3 | train_loss  5.48 | val_ppl 257.42236 | time  14.7s
[2018-08-19 20:56:52,759 INFO] | epoch   4 | train_loss  5.39 | val_ppl 240.78045 | time  14.5s
[2018-08-19 20:57:07,263 INFO] | epoch   5 | train_loss  5.31 | val_ppl 229.33775 | time  14.5s
[2018-08-19 20:57:21,789 INFO] | epoch   6 | train_loss  5.25 | val_ppl 220.61904 | time  14.5s
[2018-08-19 20:57:36,477 INFO] | epoch   7 | train_loss  5.20 | val_ppl 213.54886 | time  14.7s
[2018-08-19 21:03:19,618 INFO] -------------

reset bptt to 10. but it still bad compared to lower=True
[2018-08-19 21:03:19,619 INFO] Start training...
[2018-08-19 21:03:19,619 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 21:03:29,600 INFO] train token: 2127402
[2018-08-19 21:03:29,600 INFO] test token: 250140
[2018-08-19 21:03:29,601 INFO] valid token: 221606
[2018-08-19 21:03:29,602 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt.pt
[2018-08-19 21:03:56,466 INFO] | epoch   1 | train_loss  5.74 | val_ppl 260.70944 | time  22.6s
[2018-08-19 21:04:18,916 INFO] | epoch   2 | train_loss  5.42 | val_ppl 229.32540 | time  22.4s
[2018-08-19 21:04:41,703 INFO] | epoch   3 | train_loss  5.27 | val_ppl 214.34622 | time  22.8s
[2018-08-19 21:05:03,719 INFO] | epoch   4 | train_loss  5.16 | val_ppl 206.09255 | time  22.0s
[2018-08-19 22:01:44,465 INFO] -------------
[2018-08-19 22:01:44,466 INFO] Start training...
[2018-08-19 22:01:44,466 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=874, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 22:01:55,791 INFO] train token: 2127402
[2018-08-19 22:01:55,791 INFO] test token: 250140
[2018-08-19 22:01:55,791 INFO] valid token: 221606
[2018-08-19 22:01:55,792 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt.pt
[2018-08-19 22:04:14,168 INFO] -------------

big training start
[2018-08-19 22:04:14,168 INFO] Start training...
[2018-08-19 22:04:14,169 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=874, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 22:04:25,463 INFO] train token: 2127402
[2018-08-19 22:04:25,464 INFO] test token: 250140
[2018-08-19 22:04:25,464 INFO] valid token: 221606
[2018-08-19 22:04:25,464 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt.pt
[2018-08-19 22:05:15,572 INFO] | epoch   1 | train_loss  4.94 | val_ppl 126.76808 | time  42.8s
[2018-08-19 22:05:58,882 INFO] | epoch   2 | train_loss  4.52 | val_ppl 111.97383 | time  43.3s
[2018-08-19 22:06:42,495 INFO] | epoch   3 | train_loss  4.40 | val_ppl 104.21964 | time  43.6s
[2018-08-19 22:07:26,160 INFO] | epoch   4 | train_loss  4.30 | val_ppl 99.54663 | time  43.7s
[2018-08-19 22:08:00,279 INFO] -------------
[2018-08-19 22:08:37,578 INFO] -------------
[2018-08-19 22:08:37,578 INFO] Start training...
[2018-08-19 22:08:37,578 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:0', dropout=0.0, epoch=80, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1074, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 22:08:49,040 INFO] train token: 2127402
[2018-08-19 22:08:49,041 INFO] test token: 250140
[2018-08-19 22:08:49,041 INFO] valid token: 221606
[2018-08-19 22:08:49,041 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt.pt
[2018-08-19 22:09:39,608 INFO] | epoch   1 | train_loss  4.89 | val_ppl 125.36983 | time  43.0s
[2018-08-19 22:10:23,100 INFO] | epoch   2 | train_loss  4.50 | val_ppl 111.11028 | time  43.5s
[2018-08-19 22:11:06,864 INFO] | epoch   3 | train_loss  4.38 | val_ppl 103.89130 | time  43.8s
[2018-08-19 22:11:50,598 INFO] | epoch   4 | train_loss  4.29 | val_ppl 99.38949 | time  43.7s
[2018-08-19 22:12:34,482 INFO] | epoch   5 | train_loss  4.21 | val_ppl 96.28414 | time  43.9s
[2018-08-19 22:13:18,330 INFO] | epoch   6 | train_loss  4.14 | val_ppl 94.04755 | time  43.8s
[2018-08-19 22:14:02,170 INFO] | epoch   7 | train_loss  4.08 | val_ppl 92.49147 | time  43.8s
[2018-08-19 22:14:46,087 INFO] learning rate has been changed to 0.25
[2018-08-19 22:14:46,088 INFO] | epoch   8 | train_loss  4.02 | val_ppl 91.47728 | time  43.9s
[2018-08-19 22:15:29,921 INFO] | epoch   9 | train_loss  3.94 | val_ppl 84.48646 | time  43.8s
[2018-08-19 22:16:13,837 INFO] | epoch  10 | train_loss  3.91 | val_ppl 84.51386 | time  43.9s
[2018-08-19 22:16:57,666 INFO] | epoch  11 | train_loss  3.88 | val_ppl 84.63713 | time  43.8s
[2018-08-19 22:17:41,483 INFO] | epoch  12 | train_loss  3.85 | val_ppl 84.84605 | time  43.8s
[2018-08-19 22:18:25,300 INFO] | epoch  13 | train_loss  3.82 | val_ppl 85.13900 | time  43.8s
[2018-08-19 22:19:09,147 INFO] | epoch  14 | train_loss  3.79 | val_ppl 85.51532 | time  43.8s
[2018-08-19 22:19:52,951 INFO] | epoch  15 | train_loss  3.76 | val_ppl 85.97497 | time  43.8s
[2018-08-19 22:20:36,821 INFO] learning rate has been changed to 0.125
[2018-08-19 22:20:36,822 INFO] | epoch  16 | train_loss  3.73 | val_ppl 86.51911 | time  43.9s
[2018-08-19 22:21:20,693 INFO] | epoch  17 | train_loss  3.70 | val_ppl 84.21341 | time  43.9s
[2018-08-19 22:22:04,518 INFO] | epoch  18 | train_loss  3.68 | val_ppl 84.57015 | time  43.8s
[2018-08-19 22:22:48,396 INFO] | epoch  19 | train_loss  3.66 | val_ppl 84.95681 | time  43.9s
[2018-08-19 22:23:32,347 INFO] | epoch  20 | train_loss  3.65 | val_ppl 85.36659 | time  43.9s
[2018-08-19 22:24:16,311 INFO] | epoch  21 | train_loss  3.63 | val_ppl 85.80026 | time  44.0s
[2018-08-19 22:25:00,260 INFO] | epoch  22 | train_loss  3.62 | val_ppl 86.25896 | time  43.9s
[2018-08-19 22:25:44,091 INFO] | epoch  23 | train_loss  3.60 | val_ppl 86.74371 | time  43.8s
[2018-08-19 22:26:28,044 INFO] learning rate has been changed to 0.0625
[2018-08-19 22:26:28,045 INFO] | epoch  24 | train_loss  3.59 | val_ppl 87.25539 | time  44.0s
[2018-08-19 22:27:11,867 INFO] | epoch  25 | train_loss  3.57 | val_ppl 86.12905 | time  43.8s
[2018-08-19 22:27:55,738 INFO] | epoch  26 | train_loss  3.56 | val_ppl 86.39265 | time  43.9s
[2018-08-19 22:28:39,539 INFO] | epoch  27 | train_loss  3.55 | val_ppl 86.67727 | time  43.8s
[2018-08-19 22:29:23,415 INFO] | epoch  28 | train_loss  3.54 | val_ppl 86.97264 | time  43.9s
[2018-08-19 22:30:07,270 INFO] | epoch  29 | train_loss  3.54 | val_ppl 87.27744 | time  43.9s
[2018-08-19 22:30:51,084 INFO] | epoch  30 | train_loss  3.53 | val_ppl 87.59146 | time  43.8s
[2018-08-19 22:31:34,958 INFO] | epoch  31 | train_loss  3.52 | val_ppl 87.91478 | time  43.9s
[2018-08-19 22:32:18,819 INFO] learning rate has been changed to 0.03125
[2018-08-19 22:32:18,820 INFO] | epoch  32 | train_loss  3.51 | val_ppl 88.24754 | time  43.9s
[2018-08-19 22:33:02,688 INFO] | epoch  33 | train_loss  3.51 | val_ppl 87.49839 | time  43.9s
[2018-08-19 22:37:50,250 INFO] -------------
[2018-08-19 22:37:50,251 INFO] Start training...
[2018-08-19 22:37:50,251 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, device='cuda:1', dropout=0.0, epoch=80, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1074, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 22:38:01,542 INFO] train token: 2127402
[2018-08-19 22:38:01,543 INFO] test token: 250140
[2018-08-19 22:38:01,543 INFO] valid token: 221606
[2018-08-19 22:38:01,543 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt.pt
[2018-08-19 22:38:56,956 INFO] | epoch   1 | train_loss  4.89 | val_ppl 125.36983 | time  44.1s
[2018-08-19 22:39:41,644 INFO] | epoch   2 | train_loss  4.50 | val_ppl 111.11028 | time  44.7s
[2018-08-19 22:40:27,238 INFO] | epoch   3 | train_loss  4.38 | val_ppl 103.89130 | time  45.6s
[2018-08-19 22:41:13,215 INFO] | epoch   4 | train_loss  4.29 | val_ppl 99.38949 | time  46.0s
[2018-08-19 22:41:59,386 INFO] | epoch   5 | train_loss  4.21 | val_ppl 96.28414 | time  46.2s
[2018-08-19 22:42:45,849 INFO] | epoch   6 | train_loss  4.14 | val_ppl 94.04755 | time  46.5s
[2018-08-19 22:43:32,402 INFO] | epoch   7 | train_loss  4.08 | val_ppl 92.49147 | time  46.6s
[2018-08-19 22:44:18,881 INFO] learning rate has been changed to 0.15
[2018-08-19 22:44:18,882 INFO] | epoch   8 | train_loss  4.02 | val_ppl 91.47728 | time  46.5s
[2018-08-19 22:45:05,631 INFO] | epoch   9 | train_loss  3.94 | val_ppl 82.34174 | time  46.7s
[2018-08-19 22:45:52,087 INFO] | epoch  10 | train_loss  3.91 | val_ppl 82.30018 | time  46.5s
[2018-08-19 22:46:38,819 INFO] | epoch  11 | train_loss  3.89 | val_ppl 82.33132 | time  46.7s
[2018-08-19 22:47:25,473 INFO] | epoch  12 | train_loss  3.87 | val_ppl 82.40259 | time  46.7s
[2018-08-19 22:48:12,059 INFO] | epoch  13 | train_loss  3.85 | val_ppl 82.50898 | time  46.6s
[2018-08-19 22:48:58,779 INFO] | epoch  14 | train_loss  3.84 | val_ppl 82.64904 | time  46.7s
[2018-08-19 22:49:45,424 INFO] | epoch  15 | train_loss  3.82 | val_ppl 82.82216 | time  46.6s
[2018-08-19 22:50:32,046 INFO] learning rate has been changed to 0.045
[2018-08-19 22:50:32,047 INFO] | epoch  16 | train_loss  3.80 | val_ppl 83.02801 | time  46.6s
[2018-08-19 22:51:18,598 INFO] | epoch  17 | train_loss  3.78 | val_ppl 80.78233 | time  46.6s
[2018-08-19 22:52:05,163 INFO] | epoch  18 | train_loss  3.77 | val_ppl 80.81645 | time  46.6s
[2018-08-19 22:52:51,762 INFO] | epoch  19 | train_loss  3.76 | val_ppl 80.88673 | time  46.6s
[2018-08-19 22:57:38,195 INFO] -------------

better than above on learning rate decay
[2018-08-19 22:57:38,195 INFO] Start training...
[2018-08-19 22:57:38,196 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=80, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1074, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 22:57:49,404 INFO] train token: 2127402
[2018-08-19 22:57:49,404 INFO] test token: 250140
[2018-08-19 22:57:49,404 INFO] valid token: 221606
[2018-08-19 22:57:49,405 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt.pt
[2018-08-19 22:58:44,376 INFO] | epoch   1 | train_loss  4.89 | val_ppl 125.36983 | time  43.9s
[2018-08-19 22:59:28,949 INFO] | epoch   2 | train_loss  4.50 | val_ppl 111.11028 | time  44.6s
[2018-08-19 23:00:14,145 INFO] | epoch   3 | train_loss  4.38 | val_ppl 103.89130 | time  45.2s
[2018-08-19 23:00:59,869 INFO] | epoch   4 | train_loss  4.29 | val_ppl 99.38949 | time  45.7s
[2018-08-19 23:01:45,735 INFO] | epoch   5 | train_loss  4.21 | val_ppl 96.28414 | time  45.9s
[2018-08-19 23:02:31,708 INFO] | epoch   6 | train_loss  4.14 | val_ppl 94.04755 | time  46.0s
[2018-08-19 23:03:18,076 INFO] | epoch   7 | train_loss  4.08 | val_ppl 92.49147 | time  46.4s
[2018-08-19 23:04:04,277 INFO] | epoch   8 | train_loss  4.02 | val_ppl 91.47728 | time  46.2s
[2018-08-19 23:04:50,665 INFO] learning rate has been changed to 0.013499999999999998
[2018-08-19 23:04:50,666 INFO] | epoch   9 | train_loss  3.96 | val_ppl 90.94896 | time  46.4s
[2018-08-19 23:05:37,183 INFO] | epoch  10 | train_loss  3.92 | val_ppl 79.86755 | time  46.5s
[2018-08-19 23:06:23,508 INFO] | epoch  11 | train_loss  3.89 | val_ppl 79.25296 | time  46.3s
[2018-08-19 23:07:10,117 INFO] learning rate has been changed to 0.00405
[2018-08-19 23:07:10,117 INFO] | epoch  12 | train_loss  3.88 | val_ppl 79.00183 | time  46.6s
[2018-08-19 23:07:56,572 INFO] | epoch  13 | train_loss  3.88 | val_ppl 78.63571 | time  46.5s
[2018-08-19 23:08:42,970 INFO] | epoch  14 | train_loss  3.88 | val_ppl 78.57319 | time  46.4s
[2018-08-19 23:09:29,340 INFO] learning rate has been changed to 0.0012149999999999997
[2018-08-19 23:09:29,340 INFO] | epoch  15 | train_loss  3.88 | val_ppl 78.53011 | time  46.4s
[2018-08-19 23:10:15,876 INFO] | epoch  16 | train_loss  3.88 | val_ppl 78.44988 | time  46.5s
[2018-08-19 23:11:02,358 INFO] | epoch  17 | train_loss  3.87 | val_ppl 78.42776 | time  46.5s
[2018-08-19 23:11:48,688 INFO] learning rate has been changed to 0.0003644999999999999
[2018-08-19 23:11:48,689 INFO] | epoch  18 | train_loss  3.87 | val_ppl 78.41371 | time  46.3s
[2018-08-19 23:12:35,164 INFO] | epoch  19 | train_loss  3.87 | val_ppl 78.40797 | time  46.5s
[2018-08-19 23:13:21,521 INFO] | epoch  20 | train_loss  3.87 | val_ppl 78.40193 | time  46.4s
[2018-08-19 23:14:07,928 INFO] learning rate has been changed to 0.00010934999999999997
[2018-08-19 23:14:07,928 INFO] | epoch  21 | train_loss  3.87 | val_ppl 78.39683 | time  46.4s
[2018-08-19 23:14:54,330 INFO] | epoch  22 | train_loss  3.87 | val_ppl 78.39579 | time  46.4s
[2018-08-19 23:15:40,773 INFO] | epoch  23 | train_loss  3.87 | val_ppl 78.39470 | time  46.4s
[2018-08-19 23:16:27,159 INFO] learning rate has been changed to 3.280499999999999e-05
[2018-08-19 23:16:27,160 INFO] | epoch  24 | train_loss  3.87 | val_ppl 78.39359 | time  46.4s
[2018-08-19 23:19:10,001 INFO] -------------

should be better than above. when using big input emb same as out.
but here the learning rate is 0.3
[2018-08-19 23:19:10,001 INFO] Start training...
[2018-08-19 23:19:10,001 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=80, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1074, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 23:19:21,200 INFO] train token: 2127402
[2018-08-19 23:19:21,200 INFO] test token: 250140
[2018-08-19 23:19:21,200 INFO] valid token: 221606
[2018-08-19 23:19:21,306 INFO] Loading vectors from /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt
[2018-08-19 23:19:21,309 WARNING] Skipping token 23381 with 1-dimensional vector ['650']; likely a header
[2018-08-19 23:19:25,825 INFO] Saving vectors to /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt.pt
[2018-08-19 23:20:27,981 INFO] | epoch   1 | train_loss  5.28 | val_ppl 143.42573 | time  49.4s
[2018-08-19 23:21:18,166 INFO] | epoch   2 | train_loss  4.64 | val_ppl 118.12046 | time  50.2s
[2018-08-19 23:22:09,183 INFO] | epoch   3 | train_loss  4.48 | val_ppl 106.46697 | time  51.0s
[2018-08-19 23:23:00,595 INFO] | epoch   4 | train_loss  4.36 | val_ppl 99.60619 | time  51.4s
[2018-08-19 23:23:52,025 INFO] | epoch   5 | train_loss  4.27 | val_ppl 94.94928 | time  51.4s
[2018-08-19 23:24:43,456 INFO] | epoch   6 | train_loss  4.20 | val_ppl 91.66289 | time  51.4s
[2018-08-19 23:25:35,078 INFO] | epoch   7 | train_loss  4.13 | val_ppl 89.35276 | time  51.6s
[2018-08-19 23:26:26,694 INFO] | epoch   8 | train_loss  4.07 | val_ppl 87.71917 | time  51.6s
[2018-08-19 23:27:18,352 INFO] learning rate has been changed to 0.013499999999999998
[2018-08-19 23:27:18,352 INFO] | epoch   9 | train_loss  4.01 | val_ppl 86.57244 | time  51.7s
[2018-08-19 23:28:10,111 INFO] | epoch  10 | train_loss  3.97 | val_ppl 77.05106 | time  51.8s
[2018-08-19 23:29:01,743 INFO] | epoch  11 | train_loss  3.95 | val_ppl 76.57816 | time  51.6s
[2018-08-19 23:29:53,632 INFO] learning rate has been changed to 0.00405
[2018-08-19 23:29:53,633 INFO] | epoch  12 | train_loss  3.94 | val_ppl 76.38391 | time  51.9s
[2018-08-19 23:30:45,320 INFO] | epoch  13 | train_loss  3.94 | val_ppl 75.96646 | time  51.7s
[2018-08-19 23:31:36,991 INFO] | epoch  14 | train_loss  3.94 | val_ppl 75.91234 | time  51.7s
[2018-08-19 23:32:28,771 INFO] learning rate has been changed to 0.0012149999999999997
[2018-08-19 23:32:28,772 INFO] | epoch  15 | train_loss  3.93 | val_ppl 75.87474 | time  51.8s
[2018-08-19 23:33:20,400 INFO] | epoch  16 | train_loss  3.93 | val_ppl 75.75914 | time  51.6s
[2018-08-19 23:34:12,132 INFO] | epoch  17 | train_loss  3.93 | val_ppl 75.73913 | time  51.7s
[2018-08-19 23:34:45,146 INFO] -------------
[2018-08-19 23:37:11,731 INFO] -------------
[2018-08-19 23:37:45,945 INFO] -------------
[2018-08-19 23:40:19,126 INFO] -------------
[2018-08-19 23:40:19,127 INFO] Start training...
[2018-08-19 23:40:19,127 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=104, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-19 23:40:30,436 INFO] train token: 2127402
[2018-08-19 23:40:30,436 INFO] test token: 250140
[2018-08-19 23:40:30,436 INFO] valid token: 221606
[2018-08-19 23:40:30,437 INFO] Loading vectors from /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt.pt
[2018-08-19 23:41:31,794 INFO] | epoch   1 | train_loss  5.11 | val_ppl 141.03557 | time  49.4s
[2018-08-19 23:42:21,768 INFO] | epoch   2 | train_loss  4.60 | val_ppl 116.08966 | time  50.0s
[2018-08-19 23:43:12,498 INFO] | epoch   3 | train_loss  4.43 | val_ppl 105.32855 | time  50.7s
[2018-08-19 23:44:03,587 INFO] | epoch   4 | train_loss  4.32 | val_ppl 99.22133 | time  51.1s
[2018-08-19 23:44:54,881 INFO] | epoch   5 | train_loss  4.24 | val_ppl 95.19602 | time  51.3s
[2018-08-19 23:45:46,191 INFO] | epoch   6 | train_loss  4.16 | val_ppl 92.32671 | time  51.3s
[2018-08-19 23:46:37,729 INFO] | epoch   7 | train_loss  4.09 | val_ppl 90.26666 | time  51.5s
[2018-08-19 23:47:29,220 INFO] | epoch   8 | train_loss  4.03 | val_ppl 88.86703 | time  51.5s
[2018-08-19 23:48:20,906 INFO] learning rate has been changed to 0.0625
[2018-08-19 23:48:20,906 INFO] | epoch   9 | train_loss  3.97 | val_ppl 87.98041 | time  51.7s
[2018-08-19 23:49:12,526 INFO] | epoch  10 | train_loss  3.90 | val_ppl 77.56884 | time  51.6s
[2018-08-19 23:50:04,303 INFO] | epoch  11 | train_loss  3.88 | val_ppl 77.46684 | time  51.8s
[2018-08-19 23:50:55,995 INFO] learning rate has been changed to 0.03125
[2018-08-19 23:50:55,995 INFO] | epoch  12 | train_loss  3.87 | val_ppl 77.45928 | time  51.7s
[2018-08-19 23:51:47,508 INFO] | epoch  13 | train_loss  3.86 | val_ppl 76.68369 | time  51.5s
[2018-08-19 23:52:39,214 INFO] | epoch  14 | train_loss  3.86 | val_ppl 76.66439 | time  51.7s
[2018-08-19 23:53:30,984 INFO] learning rate has been changed to 0.015625
[2018-08-19 23:53:30,985 INFO] | epoch  15 | train_loss  3.85 | val_ppl 76.66612 | time  51.8s
[2018-08-19 23:54:22,853 INFO] | epoch  16 | train_loss  3.85 | val_ppl 76.20287 | time  51.9s
[2018-08-19 23:55:14,483 INFO] | epoch  17 | train_loss  3.85 | val_ppl 76.18755 | time  51.6s
[2018-08-19 23:56:06,106 INFO] learning rate has been changed to 0.0078125
[2018-08-19 23:56:06,106 INFO] | epoch  18 | train_loss  3.84 | val_ppl 76.18489 | time  51.6s
[2018-08-19 23:56:57,867 INFO] | epoch  19 | train_loss  3.84 | val_ppl 75.86600 | time  51.8s
[2018-08-19 23:57:49,266 INFO] | epoch  20 | train_loss  3.84 | val_ppl 75.85384 | time  51.4s
[2018-08-19 23:58:40,993 INFO] learning rate has been changed to 0.00390625
[2018-08-19 23:58:40,994 INFO] | epoch  21 | train_loss  3.84 | val_ppl 75.84966 | time  51.7s
[2018-08-19 23:59:32,799 INFO] | epoch  22 | train_loss  3.84 | val_ppl 75.64248 | time  51.8s
[2018-08-20 00:00:24,453 INFO] | epoch  23 | train_loss  3.84 | val_ppl 75.63432 | time  51.7s
[2018-08-20 00:01:16,072 INFO] learning rate has been changed to 0.001953125
[2018-08-20 00:01:16,073 INFO] | epoch  24 | train_loss  3.84 | val_ppl 75.63078 | time  51.6s
[2018-08-20 00:02:07,798 INFO] | epoch  25 | train_loss  3.84 | val_ppl 75.53255 | time  51.7s
[2018-08-20 00:02:59,420 INFO] | epoch  26 | train_loss  3.84 | val_ppl 75.52727 | time  51.6s
[2018-08-20 00:03:50,992 INFO] learning rate has been changed to 0.0009765625
[2018-08-20 00:03:50,992 INFO] | epoch  27 | train_loss  3.84 | val_ppl 75.52466 | time  51.6s
[2018-08-20 00:04:42,899 INFO] | epoch  28 | train_loss  3.84 | val_ppl 75.49070 | time  51.9s
[2018-08-20 00:05:34,728 INFO] | epoch  29 | train_loss  3.84 | val_ppl 75.48625 | time  51.8s
[2018-08-20 00:06:26,510 INFO] learning rate has been changed to 0.00048828125
[2018-08-20 00:06:26,510 INFO] | epoch  30 | train_loss  3.84 | val_ppl 75.48443 | time  51.8s
[2018-08-20 00:07:18,263 INFO] | epoch  31 | train_loss  3.84 | val_ppl 75.47864 | time  51.8s
[2018-08-20 00:08:09,882 INFO] | epoch  32 | train_loss  3.84 | val_ppl 75.47580 | time  51.6s
[2018-08-20 00:09:01,674 INFO] learning rate has been changed to 0.000244140625
[2018-08-20 00:09:01,675 INFO] | epoch  33 | train_loss  3.84 | val_ppl 75.47443 | time  51.8s
[2018-08-20 00:09:53,295 INFO] | epoch  34 | train_loss  3.84 | val_ppl 75.47477 | time  51.6s
[2018-08-20 00:10:45,030 INFO] | epoch  35 | train_loss  3.84 | val_ppl 75.47418 | time  51.7s
[2018-08-20 00:11:36,605 INFO] learning rate has been changed to 0.0001220703125
[2018-08-20 00:11:36,606 INFO] | epoch  36 | train_loss  3.84 | val_ppl 75.47361 | time  51.6s
[2018-08-20 00:12:28,261 INFO] | epoch  37 | train_loss  3.84 | val_ppl 75.47402 | time  51.7s
[2018-08-20 00:13:19,924 INFO] | epoch  38 | train_loss  3.84 | val_ppl 75.47413 | time  51.7s
[2018-08-20 00:14:11,430 INFO] learning rate has been changed to 6.103515625e-05
[2018-08-20 00:14:11,431 INFO] | epoch  39 | train_loss  3.84 | val_ppl 75.47411 | time  51.5s
[2018-08-20 00:15:02,982 INFO] | epoch  40 | train_loss  3.84 | val_ppl 75.47435 | time  51.6s
[2018-08-20 00:15:02,982 INFO] start to save model on nnlm.model
[2018-08-20 00:15:06,210 INFO] test_ppl: 73.48962
[2018-08-20 00:17:52,588 INFO] -------------

ited
[2018-08-20 00:17:52,588 INFO] Start training...
[2018-08-20 00:17:52,589 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=104, tied=True, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 00:18:03,860 INFO] train token: 2127402
[2018-08-20 00:18:03,861 INFO] test token: 250140
[2018-08-20 00:18:03,861 INFO] valid token: 221606
[2018-08-20 00:18:03,861 INFO] Loading vectors from /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt.pt
[2018-08-20 00:19:03,497 INFO] | epoch   1 | train_loss  5.19 | val_ppl 143.71671 | time  47.6s
[2018-08-20 00:19:51,792 INFO] | epoch   2 | train_loss  4.61 | val_ppl 118.02012 | time  48.3s
[2018-08-20 00:20:41,310 INFO] | epoch   3 | train_loss  4.45 | val_ppl 106.73913 | time  49.5s
[2018-08-20 00:21:31,045 INFO] | epoch   4 | train_loss  4.34 | val_ppl 100.34599 | time  49.7s
[2018-08-20 00:22:20,740 INFO] | epoch   5 | train_loss  4.25 | val_ppl 96.11057 | time  49.7s
[2018-08-20 00:23:10,525 INFO] | epoch   6 | train_loss  4.17 | val_ppl 93.03707 | time  49.8s
[2018-08-20 00:24:00,457 INFO] | epoch   7 | train_loss  4.11 | val_ppl 90.70156 | time  49.9s
[2018-08-20 00:24:50,313 INFO] | epoch   8 | train_loss  4.04 | val_ppl 88.94185 | time  49.9s
[2018-08-20 00:25:40,378 INFO] learning rate has been changed to 0.0625
[2018-08-20 00:25:40,379 INFO] | epoch   9 | train_loss  3.99 | val_ppl 87.65711 | time  50.1s
[2018-08-20 00:26:30,309 INFO] | epoch  10 | train_loss  3.92 | val_ppl 76.37582 | time  49.9s
[2018-08-20 00:27:20,209 INFO] | epoch  11 | train_loss  3.90 | val_ppl 76.26111 | time  49.9s
[2018-08-20 00:28:10,290 INFO] learning rate has been changed to 0.03125
[2018-08-20 00:28:10,291 INFO] | epoch  12 | train_loss  3.89 | val_ppl 76.24006 | time  50.1s
[2018-08-20 00:29:00,284 INFO] | epoch  13 | train_loss  3.88 | val_ppl 75.50026 | time  50.0s
[2018-08-20 00:29:50,304 INFO] | epoch  14 | train_loss  3.87 | val_ppl 75.47829 | time  50.0s
[2018-08-20 00:30:40,341 INFO] learning rate has been changed to 0.015625
[2018-08-20 00:30:40,341 INFO] | epoch  15 | train_loss  3.87 | val_ppl 75.47506 | time  50.0s
[2018-08-20 00:31:30,395 INFO] | epoch  16 | train_loss  3.86 | val_ppl 75.02646 | time  50.1s
[2018-08-20 00:32:20,422 INFO] | epoch  17 | train_loss  3.86 | val_ppl 75.00990 | time  50.0s
[2018-08-20 00:33:10,354 INFO] learning rate has been changed to 0.0078125
[2018-08-20 00:33:10,355 INFO] | epoch  18 | train_loss  3.86 | val_ppl 75.00564 | time  49.9s
[2018-08-20 00:34:00,257 INFO] | epoch  19 | train_loss  3.86 | val_ppl 74.72778 | time  49.9s
[2018-08-20 00:34:50,184 INFO] | epoch  20 | train_loss  3.85 | val_ppl 74.71557 | time  49.9s
[2018-08-20 00:35:40,107 INFO] learning rate has been changed to 0.00390625
[2018-08-20 00:35:40,108 INFO] | epoch  21 | train_loss  3.85 | val_ppl 74.71097 | time  49.9s
[2018-08-20 00:36:29,946 INFO] | epoch  22 | train_loss  3.85 | val_ppl 74.55623 | time  49.8s
[2018-08-20 00:37:20,004 INFO] | epoch  23 | train_loss  3.85 | val_ppl 74.54862 | time  50.1s
[2018-08-20 00:38:09,923 INFO] learning rate has been changed to 0.001953125
[2018-08-20 00:38:09,923 INFO] | epoch  24 | train_loss  3.85 | val_ppl 74.54524 | time  49.9s
[2018-08-20 00:38:59,965 INFO] | epoch  25 | train_loss  3.85 | val_ppl 74.46924 | time  50.0s
[2018-08-20 00:39:50,049 INFO] | epoch  26 | train_loss  3.85 | val_ppl 74.46431 | time  50.1s
[2018-08-20 00:40:40,107 INFO] learning rate has been changed to 0.0009765625
[2018-08-20 00:40:40,108 INFO] | epoch  27 | train_loss  3.85 | val_ppl 74.46199 | time  50.1s
[2018-08-20 00:41:30,003 INFO] | epoch  28 | train_loss  3.85 | val_ppl 74.42661 | time  49.9s
[2018-08-20 00:42:19,974 INFO] | epoch  29 | train_loss  3.85 | val_ppl 74.42235 | time  50.0s
[2018-08-20 00:43:09,856 INFO] learning rate has been changed to 0.00048828125
[2018-08-20 00:43:09,856 INFO] | epoch  30 | train_loss  3.85 | val_ppl 74.42062 | time  49.9s
[2018-08-20 00:43:59,907 INFO] | epoch  31 | train_loss  3.85 | val_ppl 74.40933 | time  50.1s
[2018-08-20 00:44:49,912 INFO] | epoch  32 | train_loss  3.85 | val_ppl 74.40591 | time  50.0s
[2018-08-20 00:45:39,863 INFO] learning rate has been changed to 0.000244140625
[2018-08-20 00:45:39,863 INFO] | epoch  33 | train_loss  3.85 | val_ppl 74.40447 | time  50.0s
[2018-08-20 00:46:29,827 INFO] | epoch  34 | train_loss  3.85 | val_ppl 74.40230 | time  50.0s
[2018-08-20 00:47:19,742 INFO] | epoch  35 | train_loss  3.85 | val_ppl 74.40085 | time  49.9s
[2018-08-20 00:48:09,636 INFO] learning rate has been changed to 0.0001220703125
[2018-08-20 00:48:09,637 INFO] | epoch  36 | train_loss  3.85 | val_ppl 74.39997 | time  49.9s
[2018-08-20 00:48:59,474 INFO] | epoch  37 | train_loss  3.85 | val_ppl 74.39964 | time  49.8s
[2018-08-20 00:49:49,584 INFO] | epoch  38 | train_loss  3.85 | val_ppl 74.39929 | time  50.1s
[2018-08-20 00:50:39,488 INFO] learning rate has been changed to 6.103515625e-05
[2018-08-20 00:50:39,489 INFO] | epoch  39 | train_loss  3.85 | val_ppl 74.39900 | time  49.9s
[2018-08-20 00:51:29,386 INFO] | epoch  40 | train_loss  3.85 | val_ppl 74.39900 | time  49.9s
[2018-08-20 00:51:29,387 INFO] start to save model on nnlm.model
[2018-08-20 00:51:31,858 INFO] test_ppl: 72.65853
[2018-08-20 09:37:48,871 INFO] -------------

add clip
[2018-08-20 09:37:48,871 INFO] Start training...
[2018-08-20 09:37:48,871 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, clip=0.25, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=104, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 09:37:59,989 INFO] train token: 2127402
[2018-08-20 09:37:59,990 INFO] test token: 250140
[2018-08-20 09:37:59,990 INFO] valid token: 221606
[2018-08-20 09:37:59,991 INFO] Loading vectors from /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt.pt
[2018-08-20 09:39:05,229 INFO] | epoch   1 | train_loss  5.29 | val_ppl 155.09909 | time  53.5s
[2018-08-20 09:39:59,616 INFO] | epoch   2 | train_loss  4.89 | val_ppl 130.15426 | time  54.4s
[2018-08-20 09:40:54,312 INFO] | epoch   3 | train_loss  4.74 | val_ppl 118.44237 | time  54.7s
[2018-08-20 09:41:49,189 INFO] | epoch   4 | train_loss  4.64 | val_ppl 111.30812 | time  54.9s
[2018-08-20 09:42:44,564 INFO] | epoch   5 | train_loss  4.56 | val_ppl 106.43658 | time  55.4s
[2018-08-20 09:43:39,921 INFO] | epoch   6 | train_loss  4.50 | val_ppl 102.73136 | time  55.4s
[2018-08-20 09:44:35,436 INFO] | epoch   7 | train_loss  4.45 | val_ppl 99.73833 | time  55.5s
[2018-08-20 09:45:31,164 INFO] | epoch   8 | train_loss  4.41 | val_ppl 97.31888 | time  55.7s
[2018-08-20 09:46:26,995 INFO] learning rate has been changed to 0.0625
[2018-08-20 09:46:26,995 INFO] | epoch   9 | train_loss  4.37 | val_ppl 95.33711 | time  55.8s
[2018-08-20 09:47:22,560 INFO] | epoch  10 | train_loss  4.33 | val_ppl 90.15667 | time  55.6s
[2018-08-20 09:48:18,436 INFO] | epoch  11 | train_loss  4.32 | val_ppl 89.84031 | time  55.9s
[2018-08-20 09:49:14,103 INFO] learning rate has been changed to 0.03125
[2018-08-20 09:49:14,104 INFO] | epoch  12 | train_loss  4.32 | val_ppl 89.60571 | time  55.7s
[2018-08-20 09:50:09,635 INFO] | epoch  13 | train_loss  4.31 | val_ppl 89.08217 | time  55.5s
[2018-08-20 09:51:05,408 INFO] | epoch  14 | train_loss  4.31 | val_ppl 88.96735 | time  55.8s
[2018-08-20 09:52:01,298 INFO] learning rate has been changed to 0.015625
[2018-08-20 09:52:01,299 INFO] | epoch  15 | train_loss  4.31 | val_ppl 88.86334 | time  55.9s
[2018-08-20 09:52:56,948 INFO] | epoch  16 | train_loss  4.30 | val_ppl 88.61481 | time  55.6s
[2018-08-20 09:57:58,182 INFO] -------------


clip afer 14 epochs, but still no difference
[2018-08-20 09:57:58,182 INFO] Start training...
[2018-08-20 09:57:58,182 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, clip=0.25, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=104, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 09:58:09,554 INFO] train token: 2127402
[2018-08-20 09:58:09,554 INFO] test token: 250140
[2018-08-20 09:58:09,554 INFO] valid token: 221606
[2018-08-20 09:58:09,555 INFO] Loading vectors from /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt.pt
[2018-08-20 09:59:10,066 INFO] | epoch   1 | train_loss  5.11 | val_ppl 141.03557 | time  49.2s
[2018-08-20 09:59:59,896 INFO] | epoch   2 | train_loss  4.60 | val_ppl 116.08966 | time  49.8s
[2018-08-20 10:00:50,134 INFO] | epoch   3 | train_loss  4.43 | val_ppl 105.32855 | time  50.2s
[2018-08-20 10:01:40,850 INFO] | epoch   4 | train_loss  4.32 | val_ppl 99.22133 | time  50.7s
[2018-08-20 10:02:31,886 INFO] | epoch   5 | train_loss  4.24 | val_ppl 95.19602 | time  51.0s
[2018-08-20 10:03:23,123 INFO] | epoch   6 | train_loss  4.16 | val_ppl 92.32671 | time  51.2s
[2018-08-20 10:04:14,480 INFO] | epoch   7 | train_loss  4.09 | val_ppl 90.26666 | time  51.4s
[2018-08-20 10:05:05,974 INFO] | epoch   8 | train_loss  4.03 | val_ppl 88.86703 | time  51.5s
[2018-08-20 10:05:57,526 INFO] learning rate has been changed to 0.0625
[2018-08-20 10:05:57,527 INFO] | epoch   9 | train_loss  3.97 | val_ppl 87.98041 | time  51.6s
[2018-08-20 10:06:48,953 INFO] | epoch  10 | train_loss  3.90 | val_ppl 77.56884 | time  51.4s
[2018-08-20 10:07:40,477 INFO] | epoch  11 | train_loss  3.88 | val_ppl 77.46684 | time  51.5s
[2018-08-20 10:08:32,140 INFO] learning rate has been changed to 0.03125
[2018-08-20 10:08:32,141 INFO] | epoch  12 | train_loss  3.87 | val_ppl 77.45928 | time  51.7s
[2018-08-20 10:09:23,649 INFO] | epoch  13 | train_loss  3.86 | val_ppl 76.68369 | time  51.5s
[2018-08-20 10:10:19,521 INFO] | epoch  14 | train_loss  3.86 | val_ppl 75.96549 | time  55.9s
[2018-08-20 10:11:16,002 INFO] learning rate has been changed to 0.015625
[2018-08-20 10:11:16,002 INFO] | epoch  15 | train_loss  3.86 | val_ppl 75.92267 | time  56.5s
[2018-08-20 10:12:11,898 INFO] | epoch  16 | train_loss  3.86 | val_ppl 75.68378 | time  55.9s
[2018-08-20 10:13:07,654 INFO] | epoch  17 | train_loss  3.86 | val_ppl 75.66667 | time  55.8s
[2018-08-20 10:14:03,303 INFO] learning rate has been changed to 0.0078125
[2018-08-20 10:14:03,303 INFO] | epoch  18 | train_loss  3.85 | val_ppl 75.65696 | time  55.6s
[2018-08-20 10:35:16,071 INFO] -------------
[2018-08-20 10:35:16,072 INFO] Start training...

new lr decay stratege. decay when poor val loss appears. there is no difference in final performance
[2018-08-20 10:35:16,072 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=104, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 10:35:27,702 INFO] train token: 2127402
[2018-08-20 10:35:27,702 INFO] test token: 250140
[2018-08-20 10:35:27,702 INFO] valid token: 221606
[2018-08-20 10:35:27,703 INFO] Loading vectors from /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt.pt
[2018-08-20 10:36:28,121 INFO] | epoch   1 | train_loss  5.11 | val_ppl 141.03557 | time  48.9s
[2018-08-20 10:37:17,735 INFO] | epoch   2 | train_loss  4.60 | val_ppl 116.08966 | time  49.6s
[2018-08-20 10:38:07,700 INFO] | epoch   3 | train_loss  4.43 | val_ppl 105.32855 | time  50.0s
[2018-08-20 10:38:57,920 INFO] | epoch   4 | train_loss  4.32 | val_ppl 99.22133 | time  50.2s
[2018-08-20 10:39:48,416 INFO] | epoch   5 | train_loss  4.24 | val_ppl 95.19602 | time  50.5s
[2018-08-20 10:40:39,039 INFO] | epoch   6 | train_loss  4.16 | val_ppl 92.32671 | time  50.6s
[2018-08-20 10:41:29,961 INFO] | epoch   7 | train_loss  4.09 | val_ppl 90.26666 | time  50.9s
[2018-08-20 10:42:21,141 INFO] | epoch   8 | train_loss  4.03 | val_ppl 88.86703 | time  51.2s
[2018-08-20 10:43:12,250 INFO] | epoch   9 | train_loss  3.97 | val_ppl 87.98041 | time  51.1s
[2018-08-20 10:44:03,624 INFO] | epoch  10 | train_loss  3.92 | val_ppl 87.51270 | time  51.4s
[2018-08-20 10:44:54,856 INFO] | epoch  11 | train_loss  3.86 | val_ppl 87.41345 | time  51.2s
[2018-08-20 10:45:46,378 INFO] | epoch  12 | train_loss  3.81 | val_ppl 87.64859 | time  51.5s
[2018-08-20 10:45:46,379 INFO] learning rate has been changed to 0.03125
[2018-08-20 10:46:37,672 INFO] | epoch  13 | train_loss  3.76 | val_ppl 77.19238 | time  51.3s
[2018-08-20 10:47:29,089 INFO] | epoch  14 | train_loss  3.73 | val_ppl 76.98822 | time  51.4s
[2018-08-20 10:48:20,448 INFO] | epoch  15 | train_loss  3.72 | val_ppl 76.97483 | time  51.4s
[2018-08-20 10:49:11,886 INFO] | epoch  16 | train_loss  3.71 | val_ppl 77.01342 | time  51.4s
[2018-08-20 10:49:11,887 INFO] learning rate has been changed to 0.015625
[2018-08-20 10:50:03,322 INFO] | epoch  17 | train_loss  3.71 | val_ppl 76.50021 | time  51.4s
[2018-08-20 10:50:54,667 INFO] | epoch  18 | train_loss  3.71 | val_ppl 76.50132 | time  51.3s
[2018-08-20 10:50:54,667 INFO] learning rate has been changed to 0.0078125
[2018-08-20 10:51:46,458 INFO] | epoch  19 | train_loss  3.71 | val_ppl 76.13509 | time  51.8s
[2018-08-20 10:52:37,867 INFO] | epoch  20 | train_loss  3.71 | val_ppl 76.12704 | time  51.4s
[2018-08-20 10:53:29,231 INFO] | epoch  21 | train_loss  3.71 | val_ppl 76.13105 | time  51.4s
[2018-08-20 10:53:29,232 INFO] learning rate has been changed to 0.00390625
[2018-08-20 10:54:20,745 INFO] | epoch  22 | train_loss  3.71 | val_ppl 75.90484 | time  51.5s
[2018-08-20 10:55:12,061 INFO] | epoch  23 | train_loss  3.70 | val_ppl 75.89861 | time  51.3s
[2018-08-20 10:56:03,575 INFO] | epoch  24 | train_loss  3.70 | val_ppl 75.89892 | time  51.5s
[2018-08-20 10:56:03,575 INFO] learning rate has been changed to 0.001953125
[2018-08-20 10:56:54,962 INFO] | epoch  25 | train_loss  3.70 | val_ppl 75.79593 | time  51.4s
[2018-08-20 10:57:46,360 INFO] | epoch  26 | train_loss  3.70 | val_ppl 75.79117 | time  51.4s
[2018-08-20 10:58:37,495 INFO] | epoch  27 | train_loss  3.70 | val_ppl 75.79019 | time  51.1s
[2018-08-20 10:59:28,939 INFO] | epoch  28 | train_loss  3.70 | val_ppl 75.79057 | time  51.4s
[2018-08-20 10:59:28,940 INFO] learning rate has been changed to 0.0009765625
[2018-08-20 11:00:20,260 INFO] | epoch  29 | train_loss  3.70 | val_ppl 75.75747 | time  51.3s
[2018-08-20 11:01:11,751 INFO] | epoch  30 | train_loss  3.70 | val_ppl 75.75322 | time  51.5s
[2018-08-20 11:02:03,201 INFO] | epoch  31 | train_loss  3.70 | val_ppl 75.75229 | time  51.4s
[2018-08-20 11:02:54,527 INFO] | epoch  32 | train_loss  3.70 | val_ppl 75.75215 | time  51.3s
[2018-08-20 11:03:45,985 INFO] | epoch  33 | train_loss  3.70 | val_ppl 75.75237 | time  51.5s
[2018-08-20 11:03:45,985 INFO] learning rate has been changed to 0.000244140625
[2018-08-20 11:04:37,544 INFO] | epoch  34 | train_loss  3.70 | val_ppl 75.75019 | time  51.6s
[2018-08-20 11:05:28,924 INFO] | epoch  35 | train_loss  3.70 | val_ppl 75.74824 | time  51.4s
[2018-08-20 11:06:20,311 INFO] | epoch  36 | train_loss  3.70 | val_ppl 75.74678 | time  51.4s
[2018-08-20 11:07:11,719 INFO] | epoch  37 | train_loss  3.70 | val_ppl 75.74583 | time  51.4s
[2018-08-20 11:08:03,229 INFO] | epoch  38 | train_loss  3.70 | val_ppl 75.74525 | time  51.5s
[2018-08-20 11:08:54,574 INFO] | epoch  39 | train_loss  3.70 | val_ppl 75.74493 | time  51.3s
[2018-08-20 11:09:45,951 INFO] | epoch  40 | train_loss  3.70 | val_ppl 75.74478 | time  51.4s
[2018-08-20 11:09:45,951 INFO] start to save model on nnlm.model
[2018-08-20 11:09:49,087 INFO] test_ppl: 73.82636
[2018-08-20 11:22:59,950 INFO] -------------
[2018-08-20 11:22:59,950 INFO] Start training...
[2018-08-20 11:22:59,950 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=20, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=25, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1000, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 11:23:11,130 INFO] train token: 2127402
[2018-08-20 11:23:11,130 INFO] test token: 250140
[2018-08-20 11:23:11,130 INFO] valid token: 221606
[2018-08-20 11:23:11,131 INFO] Loading vectors from /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt.pt
[2018-08-20 11:24:19,269 INFO] | epoch   1 | train_loss  4.96 | val_ppl 120.45483 | time  56.7s
[2018-08-20 11:25:16,928 INFO] | epoch   2 | train_loss  4.52 | val_ppl 105.53733 | time  57.7s
[2018-08-20 11:26:14,950 INFO] | epoch   3 | train_loss  4.36 | val_ppl 98.79761 | time  58.0s
[2018-08-20 11:27:13,586 INFO] | epoch   4 | train_loss  4.25 | val_ppl 95.09573 | time  58.6s
[2018-08-20 11:28:12,430 INFO] | epoch   5 | train_loss  4.16 | val_ppl 92.92944 | time  58.8s
[2018-08-20 11:29:11,554 INFO] | epoch   6 | train_loss  4.07 | val_ppl 91.77284 | time  59.1s
[2018-08-20 11:30:10,987 INFO] | epoch   7 | train_loss  4.00 | val_ppl 91.41444 | time  59.4s
[2018-08-20 11:31:10,357 INFO] | epoch   8 | train_loss  3.92 | val_ppl 91.79557 | time  59.4s
[2018-08-20 11:31:10,357 INFO] learning rate has been changed to 0.125
[2018-08-20 11:32:09,870 INFO] | epoch   9 | train_loss  3.81 | val_ppl 85.35872 | time  59.5s
[2018-08-20 11:33:09,576 INFO] | epoch  10 | train_loss  3.78 | val_ppl 85.72805 | time  59.7s
[2018-08-20 11:33:09,577 INFO] learning rate has been changed to 0.0625
[2018-08-20 11:34:09,262 INFO] | epoch  11 | train_loss  3.76 | val_ppl 84.20292 | time  59.7s
[2018-08-20 11:35:08,879 INFO] | epoch  12 | train_loss  3.74 | val_ppl 84.41526 | time  59.6s
[2018-08-20 11:35:08,880 INFO] learning rate has been changed to 0.03125
[2018-08-20 11:36:08,520 INFO] | epoch  13 | train_loss  3.73 | val_ppl 83.35108 | time  59.6s
[2018-08-20 11:37:08,076 INFO] | epoch  14 | train_loss  3.73 | val_ppl 83.44127 | time  59.6s
[2018-08-20 11:37:08,076 INFO] learning rate has been changed to 0.03125
[2018-08-20 11:38:07,819 INFO] | epoch  15 | train_loss  3.72 | val_ppl 83.56623 | time  59.7s
[2018-08-20 11:38:07,819 INFO] learning rate has been changed to 0.015625
[2018-08-20 11:39:07,521 INFO] | epoch  16 | train_loss  3.72 | val_ppl 82.81920 | time  59.7s
[2018-08-20 11:40:07,226 INFO] | epoch  17 | train_loss  3.71 | val_ppl 82.84713 | time  59.7s
[2018-08-20 11:40:07,226 INFO] learning rate has been changed to 0.015625
[2018-08-20 11:41:06,875 INFO] | epoch  18 | train_loss  3.71 | val_ppl 82.90011 | time  59.6s
[2018-08-20 11:41:06,875 INFO] learning rate has been changed to 0.0078125
[2018-08-20 11:42:06,547 INFO] | epoch  19 | train_loss  3.71 | val_ppl 82.33012 | time  59.7s
[2018-08-20 11:43:06,304 INFO] | epoch  20 | train_loss  3.71 | val_ppl 82.33148 | time  59.8s
[2018-08-20 11:43:06,305 INFO] learning rate has been changed to 0.0078125
[2018-08-20 11:44:05,994 INFO] | epoch  21 | train_loss  3.71 | val_ppl 82.34959 | time  59.7s
[2018-08-20 11:44:05,994 INFO] learning rate has been changed to 0.00390625
[2018-08-20 11:45:05,697 INFO] | epoch  22 | train_loss  3.71 | val_ppl 81.96810 | time  59.7s
[2018-08-20 11:46:05,556 INFO] | epoch  23 | train_loss  3.71 | val_ppl 81.96126 | time  59.9s
[2018-08-20 11:47:05,280 INFO] | epoch  24 | train_loss  3.70 | val_ppl 81.96662 | time  59.7s
[2018-08-20 11:47:05,281 INFO] learning rate has been changed to 0.001953125
[2018-08-20 11:48:04,956 INFO] | epoch  25 | train_loss  3.71 | val_ppl 81.78937 | time  59.7s
[2018-08-20 11:48:06,853 INFO] test_ppl: 79.69801
[2018-08-20 11:51:15,959 INFO] -------------
[2018-08-20 11:51:15,959 INFO] Start training...
[2018-08-20 11:51:15,959 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=45, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=25, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1050, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 11:51:27,720 INFO] train token: 2127402
[2018-08-20 11:51:27,720 INFO] test token: 250140
[2018-08-20 11:51:27,720 INFO] valid token: 221606
[2018-08-20 11:51:27,721 INFO] Loading vectors from /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt.pt
[2018-08-20 11:52:27,545 INFO] | epoch   1 | train_loss  5.38 | val_ppl 131.42977 | time  47.9s
[2018-08-20 11:53:16,252 INFO] | epoch   2 | train_loss  4.68 | val_ppl 109.95667 | time  48.7s
[2018-08-20 11:54:05,542 INFO] | epoch   3 | train_loss  4.51 | val_ppl 100.06157 | time  49.3s
[2018-08-20 11:54:55,188 INFO] | epoch   4 | train_loss  4.40 | val_ppl 94.37306 | time  49.6s
[2018-08-20 11:55:44,927 INFO] | epoch   5 | train_loss  4.31 | val_ppl 90.56957 | time  49.7s
[2018-08-20 11:56:34,821 INFO] | epoch   6 | train_loss  4.24 | val_ppl 87.87388 | time  49.9s
[2018-08-20 11:57:24,756 INFO] | epoch   7 | train_loss  4.18 | val_ppl 85.87049 | time  49.9s
[2018-08-20 11:58:14,880 INFO] | epoch   8 | train_loss  4.12 | val_ppl 84.34226 | time  50.1s
[2018-08-20 11:59:04,953 INFO] | epoch   9 | train_loss  4.07 | val_ppl 83.16898 | time  50.1s
[2018-08-20 11:59:55,090 INFO] | epoch  10 | train_loss  4.02 | val_ppl 82.29134 | time  50.1s
[2018-08-20 12:00:45,110 INFO] | epoch  11 | train_loss  3.97 | val_ppl 81.68497 | time  50.0s
[2018-08-20 12:01:35,257 INFO] | epoch  12 | train_loss  3.92 | val_ppl 81.32560 | time  50.1s
[2018-08-20 12:02:25,298 INFO] | epoch  13 | train_loss  3.88 | val_ppl 81.19867 | time  50.0s
[2018-08-20 12:03:15,520 INFO] | epoch  14 | train_loss  3.83 | val_ppl 81.28646 | time  50.2s
[2018-08-20 12:03:15,521 INFO] learning rate has been changed to 0.03125
[2018-08-20 12:04:05,781 INFO] | epoch  15 | train_loss  3.79 | val_ppl 75.32389 | time  50.3s
[2018-08-20 12:04:55,980 INFO] | epoch  16 | train_loss  3.77 | val_ppl 75.12798 | time  50.2s
[2018-08-20 12:05:46,303 INFO] | epoch  17 | train_loss  3.76 | val_ppl 75.08756 | time  50.3s
[2018-08-20 12:06:36,426 INFO] | epoch  18 | train_loss  3.75 | val_ppl 75.09157 | time  50.1s
[2018-08-20 12:06:36,427 INFO] learning rate has been changed to 0.0078125
[2018-08-20 12:07:26,644 INFO] | epoch  19 | train_loss  3.75 | val_ppl 74.31194 | time  50.2s
[2018-08-20 12:08:16,813 INFO] | epoch  20 | train_loss  3.75 | val_ppl 74.27011 | time  50.2s
[2018-08-20 12:09:06,996 INFO] | epoch  21 | train_loss  3.75 | val_ppl 74.25763 | time  50.2s
[2018-08-20 12:09:57,273 INFO] | epoch  22 | train_loss  3.75 | val_ppl 74.25345 | time  50.3s
[2018-08-20 12:10:47,418 INFO] | epoch  23 | train_loss  3.75 | val_ppl 74.25296 | time  50.1s
[2018-08-20 12:11:37,637 INFO] | epoch  24 | train_loss  3.75 | val_ppl 74.25461 | time  50.2s
[2018-08-20 12:11:37,638 INFO] learning rate has been changed to 0.001953125
[2018-08-20 12:12:27,901 INFO] | epoch  25 | train_loss  3.75 | val_ppl 73.98699 | time  50.3s
[2018-08-20 12:12:29,593 INFO] test_ppl: 71.97410
[2018-08-20 12:15:29,700 INFO] -------------
[2018-08-20 12:15:29,701 INFO] Start training...
[2018-08-20 12:15:29,701 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=65, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=25, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1050, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 12:15:41,257 INFO] train token: 2127402
[2018-08-20 12:15:41,258 INFO] test token: 250140
[2018-08-20 12:15:41,258 INFO] valid token: 221606
[2018-08-20 12:15:41,259 INFO] Loading vectors from /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt.pt
[2018-08-20 12:16:40,710 INFO] | epoch   1 | train_loss  5.59 | val_ppl 165.49105 | time  47.4s
[2018-08-20 12:17:28,595 INFO] | epoch   2 | train_loss  4.76 | val_ppl 116.03688 | time  47.9s
[2018-08-20 12:18:17,191 INFO] | epoch   3 | train_loss  4.59 | val_ppl 104.62808 | time  48.6s
[2018-08-20 12:19:06,004 INFO] | epoch   4 | train_loss  4.48 | val_ppl 97.47969 | time  48.8s
[2018-08-20 12:19:54,776 INFO] | epoch   5 | train_loss  4.39 | val_ppl 92.66835 | time  48.8s
[2018-08-20 12:20:43,803 INFO] | epoch   6 | train_loss  4.32 | val_ppl 89.28869 | time  49.0s
[2018-08-20 12:21:32,798 INFO] | epoch   7 | train_loss  4.26 | val_ppl 86.76176 | time  49.0s
[2018-08-20 12:22:21,646 INFO] | epoch   8 | train_loss  4.20 | val_ppl 84.77375 | time  48.8s
[2018-08-20 12:23:10,988 INFO] | epoch   9 | train_loss  4.15 | val_ppl 83.16034 | time  49.3s
[2018-08-20 12:24:00,146 INFO] | epoch  10 | train_loss  4.11 | val_ppl 81.83822 | time  49.2s
[2018-08-20 12:24:49,417 INFO] | epoch  11 | train_loss  4.06 | val_ppl 80.77599 | time  49.3s
[2018-08-20 12:25:38,555 INFO] | epoch  12 | train_loss  4.02 | val_ppl 79.93262 | time  49.1s
[2018-08-20 12:26:27,752 INFO] | epoch  13 | train_loss  3.98 | val_ppl 79.27874 | time  49.2s
[2018-08-20 12:27:17,075 INFO] | epoch  14 | train_loss  3.95 | val_ppl 78.79569 | time  49.3s
[2018-08-20 12:28:06,168 INFO] | epoch  15 | train_loss  3.91 | val_ppl 78.45853 | time  49.1s
[2018-08-20 12:28:55,328 INFO] | epoch  16 | train_loss  3.87 | val_ppl 78.26867 | time  49.2s
[2018-08-20 12:29:44,450 INFO] | epoch  17 | train_loss  3.84 | val_ppl 78.21735 | time  49.1s
[2018-08-20 12:30:33,653 INFO] | epoch  18 | train_loss  3.80 | val_ppl 78.28757 | time  49.2s
[2018-08-20 12:30:33,654 INFO] learning rate has been changed to 0.0078125
[2018-08-20 12:31:22,792 INFO] | epoch  19 | train_loss  3.79 | val_ppl 73.18062 | time  49.1s
[2018-08-20 12:32:11,693 INFO] | epoch  20 | train_loss  3.77 | val_ppl 72.69085 | time  48.9s
[2018-08-20 12:33:00,729 INFO] | epoch  21 | train_loss  3.76 | val_ppl 72.45983 | time  49.0s
[2018-08-20 12:33:49,756 INFO] | epoch  22 | train_loss  3.76 | val_ppl 72.32642 | time  49.0s
[2018-08-20 12:34:38,660 INFO] | epoch  23 | train_loss  3.75 | val_ppl 72.24142 | time  48.9s
[2018-08-20 12:35:27,608 INFO] | epoch  24 | train_loss  3.75 | val_ppl 72.18408 | time  48.9s
[2018-08-20 12:36:16,593 INFO] | epoch  25 | train_loss  3.75 | val_ppl 72.14403 | time  49.0s
[2018-08-20 12:36:18,219 INFO] test_ppl: 70.28066
[2018-08-20 13:16:39,864 INFO] -------------

2 layers. it seems i should use only 1 layer
[2018-08-20 13:16:39,864 INFO] Start training...
[2018-08-20 13:16:39,864 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=2, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=104, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 13:16:51,210 INFO] train token: 2127402
[2018-08-20 13:16:51,210 INFO] test token: 250140
[2018-08-20 13:16:51,210 INFO] valid token: 221606
[2018-08-20 13:16:51,211 INFO] Loading vectors from /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt.pt
[2018-08-20 13:18:00,816 INFO] | epoch   1 | train_loss  5.93 | val_ppl 215.04088 | time  57.6s
[2018-08-20 13:18:59,196 INFO] | epoch   2 | train_loss  5.06 | val_ppl 166.01496 | time  58.4s
[2018-08-20 13:19:57,873 INFO] | epoch   3 | train_loss  4.85 | val_ppl 138.66288 | time  58.7s
[2018-08-20 13:20:56,994 INFO] | epoch   4 | train_loss  4.70 | val_ppl 124.66834 | time  59.1s
[2018-08-20 13:21:56,454 INFO] | epoch   5 | train_loss  4.60 | val_ppl 114.95868 | time  59.5s
[2018-08-20 13:22:56,221 INFO] | epoch   6 | train_loss  4.51 | val_ppl 107.84480 | time  59.8s
[2018-08-20 13:23:56,246 INFO] | epoch   7 | train_loss  4.43 | val_ppl 102.66827 | time  60.0s
[2018-08-20 13:24:56,469 INFO] | epoch   8 | train_loss  4.36 | val_ppl 98.71378 | time  60.2s
[2018-08-20 13:25:56,644 INFO] | epoch   9 | train_loss  4.30 | val_ppl 95.86997 | time  60.2s
[2018-08-20 13:26:57,012 INFO] | epoch  10 | train_loss  4.25 | val_ppl 93.72840 | time  60.4s
[2018-08-20 13:27:57,354 INFO] | epoch  11 | train_loss  4.20 | val_ppl 91.83409 | time  60.3s
[2018-08-20 13:28:57,898 INFO] | epoch  12 | train_loss  4.15 | val_ppl 90.20184 | time  60.5s
[2018-08-20 13:29:58,426 INFO] | epoch  13 | train_loss  4.10 | val_ppl 88.92336 | time  60.5s
[2018-08-20 13:30:59,203 INFO] | epoch  14 | train_loss  4.06 | val_ppl 87.95239 | time  60.8s
[2018-08-20 13:31:59,795 INFO] | epoch  15 | train_loss  4.01 | val_ppl 87.38172 | time  60.6s
[2018-08-20 13:33:00,420 INFO] | epoch  16 | train_loss  3.97 | val_ppl 87.11732 | time  60.6s
[2018-08-20 13:34:01,204 INFO] | epoch  17 | train_loss  3.93 | val_ppl 87.13007 | time  60.8s
[2018-08-20 13:34:01,205 INFO] learning rate has been changed to 0.015625
[2018-08-20 13:35:01,747 INFO] | epoch  18 | train_loss  3.91 | val_ppl 78.06620 | time  60.5s
[2018-08-20 13:36:02,460 INFO] | epoch  19 | train_loss  3.89 | val_ppl 77.62813 | time  60.7s
[2018-08-20 13:37:03,088 INFO] | epoch  20 | train_loss  3.88 | val_ppl 77.45063 | time  60.6s
[2018-08-20 13:38:03,705 INFO] | epoch  21 | train_loss  3.87 | val_ppl 77.35681 | time  60.6s
[2018-08-20 13:39:04,342 INFO] | epoch  22 | train_loss  3.87 | val_ppl 77.30142 | time  60.6s
[2018-08-20 13:40:05,040 INFO] | epoch  23 | train_loss  3.87 | val_ppl 77.26706 | time  60.7s
[2018-08-20 13:41:05,718 INFO] | epoch  24 | train_loss  3.86 | val_ppl 77.24552 | time  60.7s
[2018-08-20 13:42:06,292 INFO] | epoch  25 | train_loss  3.86 | val_ppl 77.23238 | time  60.6s
[2018-08-20 13:43:07,137 INFO] | epoch  26 | train_loss  3.86 | val_ppl 77.22515 | time  60.8s
[2018-08-20 13:44:07,780 INFO] | epoch  27 | train_loss  3.85 | val_ppl 77.22228 | time  60.6s
[2018-08-20 13:45:08,402 INFO] | epoch  28 | train_loss  3.85 | val_ppl 77.22275 | time  60.6s
[2018-08-20 13:45:08,403 INFO] learning rate has been changed to 0.0009765625
[2018-08-20 13:46:09,169 INFO] | epoch  29 | train_loss  3.86 | val_ppl 76.80234 | time  60.8s
[2018-08-20 13:47:09,918 INFO] | epoch  30 | train_loss  3.86 | val_ppl 76.71240 | time  60.7s
[2018-08-20 13:48:10,782 INFO] | epoch  31 | train_loss  3.86 | val_ppl 76.66737 | time  60.9s
[2018-08-20 13:49:11,597 INFO] | epoch  32 | train_loss  3.85 | val_ppl 76.64074 | time  60.8s
[2018-08-20 13:50:12,442 INFO] | epoch  33 | train_loss  3.85 | val_ppl 76.62345 | time  60.8s
[2018-08-20 13:51:13,375 INFO] | epoch  34 | train_loss  3.85 | val_ppl 76.61148 | time  60.9s
[2018-08-20 13:52:14,105 INFO] | epoch  35 | train_loss  3.85 | val_ppl 76.60280 | time  60.7s
[2018-08-20 13:53:14,911 INFO] | epoch  36 | train_loss  3.85 | val_ppl 76.59626 | time  60.8s
[2018-08-20 13:54:15,713 INFO] | epoch  37 | train_loss  3.85 | val_ppl 76.59120 | time  60.8s
[2018-08-20 13:55:16,445 INFO] | epoch  38 | train_loss  3.85 | val_ppl 76.58718 | time  60.7s
[2018-08-20 13:56:17,279 INFO] | epoch  39 | train_loss  3.85 | val_ppl 76.58393 | time  60.8s
[2018-08-20 13:57:18,141 INFO] | epoch  40 | train_loss  3.85 | val_ppl 76.58124 | time  60.9s
[2018-08-20 13:57:18,142 INFO] start to save model on nnlm.model
[2018-08-20 13:57:21,644 INFO] test_ppl: 74.59234
[2018-08-20 13:59:54,226 INFO] -------------
[2018-08-20 13:59:54,226 INFO] Start training...
[2018-08-20 13:59:54,226 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=100, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=205, tied=True, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 14:00:05,317 INFO] train token: 2127402
[2018-08-20 14:00:05,317 INFO] test token: 250140
[2018-08-20 14:00:05,317 INFO] valid token: 221606
[2018-08-20 14:00:05,318 INFO] Loading vectors from /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt.pt
[2018-08-20 14:00:58,545 INFO] | epoch   1 | train_loss   nan | val_ppl      nan | time  41.2s
[2018-08-20 14:00:58,546 INFO] learning rate has been changed to 0.5
[2018-08-20 14:01:39,660 INFO] | epoch   2 | train_loss   nan | val_ppl      nan | time  41.1s
[2018-08-20 14:01:39,660 INFO] learning rate has been changed to 0.5
[2018-08-20 14:02:45,458 INFO] -------------
[2018-08-20 14:02:45,459 INFO] Start training...
[2018-08-20 14:02:45,459 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/2mlplen_8epoch_650d_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=205, tied=True, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 14:02:56,755 INFO] train token: 2127402
[2018-08-20 14:02:56,755 INFO] test token: 250140
[2018-08-20 14:02:56,756 INFO] valid token: 221606
[2018-08-20 14:02:56,756 INFO] Loading vectors from /home/lr/yukun/common_corpus/2mlplen_8epoch_650d_outemb.txt.pt
[2018-08-20 14:03:52,933 INFO] | epoch   1 | train_loss  5.62 | val_ppl 143.06949 | time  44.0s
[2018-08-20 14:04:37,497 INFO] | epoch   2 | train_loss  4.80 | val_ppl 117.40320 | time  44.6s
[2018-08-20 14:05:22,586 INFO] | epoch   3 | train_loss  4.63 | val_ppl 105.30826 | time  45.1s
[2018-08-20 14:06:08,120 INFO] | epoch   4 | train_loss  4.51 | val_ppl 98.53912 | time  45.5s
[2018-08-20 14:06:53,665 INFO] | epoch   5 | train_loss  4.43 | val_ppl 93.62653 | time  45.5s
[2018-08-20 14:07:39,408 INFO] | epoch   6 | train_loss  4.36 | val_ppl 89.81784 | time  45.7s
[2018-08-20 14:08:25,122 INFO] | epoch   7 | train_loss  4.30 | val_ppl 86.89260 | time  45.7s
[2018-08-20 14:09:10,875 INFO] | epoch   8 | train_loss  4.24 | val_ppl 84.58103 | time  45.8s
[2018-08-20 14:09:56,622 INFO] | epoch   9 | train_loss  4.20 | val_ppl 82.70147 | time  45.7s
[2018-08-20 14:10:42,483 INFO] | epoch  10 | train_loss  4.15 | val_ppl 81.14021 | time  45.9s
[2018-08-20 14:11:28,222 INFO] | epoch  11 | train_loss  4.11 | val_ppl 79.83402 | time  45.7s
[2018-08-20 14:12:14,149 INFO] | epoch  12 | train_loss  4.07 | val_ppl 78.74503 | time  45.9s
[2018-08-20 14:13:00,074 INFO] | epoch  13 | train_loss  4.04 | val_ppl 77.84325 | time  45.9s
[2018-08-20 14:13:46,113 INFO] | epoch  14 | train_loss  4.00 | val_ppl 77.10370 | time  46.0s
[2018-08-20 14:14:31,989 INFO] | epoch  15 | train_loss  3.97 | val_ppl 76.50848 | time  45.9s
[2018-08-20 14:15:17,988 INFO] | epoch  16 | train_loss  3.93 | val_ppl 76.04555 | time  46.0s
[2018-08-20 14:16:03,929 INFO] | epoch  17 | train_loss  3.90 | val_ppl 75.70366 | time  45.9s
[2018-08-20 14:16:49,931 INFO] | epoch  18 | train_loss  3.87 | val_ppl 75.47211 | time  46.0s
[2018-08-20 14:17:35,805 INFO] | epoch  19 | train_loss  3.84 | val_ppl 75.34335 | time  45.9s
[2018-08-20 14:18:21,808 INFO] | epoch  20 | train_loss  3.81 | val_ppl 75.30749 | time  46.0s
[2018-08-20 14:19:07,916 INFO] | epoch  21 | train_loss  3.78 | val_ppl 75.36192 | time  46.1s
[2018-08-20 14:19:07,917 INFO] learning rate has been changed to 0.00390625
[2018-08-20 14:19:53,884 INFO] | epoch  22 | train_loss  3.77 | val_ppl 71.51084 | time  46.0s
[2018-08-20 14:20:40,130 INFO] | epoch  23 | train_loss  3.76 | val_ppl 71.02854 | time  46.2s
[2018-08-20 14:21:26,231 INFO] | epoch  24 | train_loss  3.75 | val_ppl 70.78498 | time  46.1s
[2018-08-20 14:22:12,507 INFO] | epoch  25 | train_loss  3.74 | val_ppl 70.63598 | time  46.3s
[2018-08-20 14:22:58,617 INFO] | epoch  26 | train_loss  3.74 | val_ppl 70.53541 | time  46.1s
[2018-08-20 14:23:44,867 INFO] | epoch  27 | train_loss  3.74 | val_ppl 70.46317 | time  46.2s
[2018-08-20 14:24:31,198 INFO] | epoch  28 | train_loss  3.74 | val_ppl 70.40901 | time  46.3s
[2018-08-20 14:25:17,723 INFO] | epoch  29 | train_loss  3.74 | val_ppl 70.36713 | time  46.5s
[2018-08-20 14:26:04,029 INFO] | epoch  30 | train_loss  3.74 | val_ppl 70.33399 | time  46.3s
[2018-08-20 14:26:50,482 INFO] | epoch  31 | train_loss  3.73 | val_ppl 70.30730 | time  46.5s
[2018-08-20 14:27:37,033 INFO] | epoch  32 | train_loss  3.73 | val_ppl 70.28553 | time  46.5s
[2018-08-20 14:28:23,619 INFO] | epoch  33 | train_loss  3.73 | val_ppl 70.26760 | time  46.6s
[2018-08-20 14:29:10,243 INFO] | epoch  34 | train_loss  3.73 | val_ppl 70.25269 | time  46.6s
[2018-08-20 14:29:56,702 INFO] | epoch  35 | train_loss  3.73 | val_ppl 70.24022 | time  46.5s
[2018-08-20 14:30:43,304 INFO] | epoch  36 | train_loss  3.73 | val_ppl 70.22976 | time  46.6s
[2018-08-20 14:31:29,811 INFO] | epoch  37 | train_loss  3.73 | val_ppl 70.22097 | time  46.5s
[2018-08-20 14:32:16,258 INFO] | epoch  38 | train_loss  3.73 | val_ppl 70.21357 | time  46.4s
[2018-08-20 14:33:02,773 INFO] | epoch  39 | train_loss  3.73 | val_ppl 70.20735 | time  46.5s
[2018-08-20 14:33:49,416 INFO] | epoch  40 | train_loss  3.73 | val_ppl 70.20214 | time  46.6s
[2018-08-20 14:33:49,417 INFO] start to save model on nnlm.model
[2018-08-20 14:33:52,034 INFO] test_ppl: 68.47562
[2018-08-20 15:04:18,963 INFO] -------------
[2018-08-20 15:04:18,963 INFO] Start training...
[2018-08-20 15:04:18,963 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='./80bptt_40epoch_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./80bptt_40epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1205, tied=True, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 15:04:30,695 INFO] train token: 2127402
[2018-08-20 15:04:30,696 INFO] test token: 250140
[2018-08-20 15:04:30,696 INFO] valid token: 221606
[2018-08-20 15:04:30,805 INFO] Loading vectors from 80bptt_40epoch_outemb.txt
[2018-08-20 15:04:30,808 WARNING] Skipping token 23381 with 1-dimensional vector ['650']; likely a header
[2018-08-20 15:04:35,389 INFO] Saving vectors to ./80bptt_40epoch_outemb.txt.pt
[2018-08-20 15:05:30,941 INFO] | epoch   1 | train_loss  5.18 | val_ppl 113.08257 | time  43.5s
[2018-08-20 15:06:15,326 INFO] | epoch   2 | train_loss  4.44 | val_ppl 93.21598 | time  44.4s
[2018-08-20 15:06:59,867 INFO] | epoch   3 | train_loss  4.26 | val_ppl 85.28243 | time  44.5s
[2018-08-20 15:07:44,693 INFO] | epoch   4 | train_loss  4.15 | val_ppl 81.51149 | time  44.8s
[2018-08-20 15:08:29,772 INFO] | epoch   5 | train_loss  4.08 | val_ppl 79.12604 | time  45.1s
[2018-08-20 15:09:15,155 INFO] | epoch   6 | train_loss  4.02 | val_ppl 77.52597 | time  45.4s
[2018-08-20 15:10:00,829 INFO] | epoch   7 | train_loss  3.97 | val_ppl 76.41304 | time  45.7s
[2018-08-20 15:10:46,447 INFO] | epoch   8 | train_loss  3.93 | val_ppl 75.59597 | time  45.6s
[2018-08-20 15:11:32,098 INFO] | epoch   9 | train_loss  3.89 | val_ppl 74.96525 | time  45.7s
[2018-08-20 15:12:18,037 INFO] | epoch  10 | train_loss  3.86 | val_ppl 74.46990 | time  45.9s
[2018-08-20 15:13:03,852 INFO] | epoch  11 | train_loss  3.82 | val_ppl 74.07900 | time  45.8s
[2018-08-20 15:13:49,784 INFO] | epoch  12 | train_loss  3.79 | val_ppl 73.78254 | time  45.9s
[2018-08-20 15:14:35,705 INFO] | epoch  13 | train_loss  3.76 | val_ppl 73.57270 | time  45.9s
[2018-08-20 15:15:21,506 INFO] | epoch  14 | train_loss  3.74 | val_ppl 73.44712 | time  45.8s
[2018-08-20 15:16:07,404 INFO] | epoch  15 | train_loss  3.71 | val_ppl 73.41404 | time  45.9s
[2018-08-20 15:16:53,227 INFO] | epoch  16 | train_loss  3.68 | val_ppl 73.47974 | time  45.8s
[2018-08-20 15:16:53,227 INFO] learning rate has been changed to 0.015625
[2018-08-20 15:17:39,077 INFO] | epoch  17 | train_loss  3.66 | val_ppl 68.85428 | time  45.8s
[2018-08-20 15:18:24,951 INFO] | epoch  18 | train_loss  3.64 | val_ppl 68.59650 | time  45.9s
[2018-08-20 15:19:10,954 INFO] | epoch  19 | train_loss  3.64 | val_ppl 68.50983 | time  46.0s
[2018-08-20 15:19:57,003 INFO] | epoch  20 | train_loss  3.63 | val_ppl 68.47276 | time  46.0s
[2018-08-20 15:20:42,986 INFO] | epoch  21 | train_loss  3.63 | val_ppl 68.45689 | time  46.0s
[2018-08-20 15:21:28,920 INFO] | epoch  22 | train_loss  3.63 | val_ppl 68.45205 | time  45.9s
[2018-08-20 15:22:15,016 INFO] | epoch  23 | train_loss  3.63 | val_ppl 68.45366 | time  46.1s
[2018-08-20 15:22:15,017 INFO] learning rate has been changed to 0.00390625
[2018-08-20 15:23:01,178 INFO] | epoch  24 | train_loss  3.63 | val_ppl 68.18115 | time  46.2s
[2018-08-20 15:23:47,303 INFO] | epoch  25 | train_loss  3.63 | val_ppl 68.16443 | time  46.1s
[2018-08-20 15:24:33,348 INFO] | epoch  26 | train_loss  3.63 | val_ppl 68.15840 | time  46.0s
[2018-08-20 15:25:19,510 INFO] | epoch  27 | train_loss  3.63 | val_ppl 68.15575 | time  46.2s
[2018-08-20 15:26:05,975 INFO] | epoch  28 | train_loss  3.63 | val_ppl 68.15466 | time  46.5s
[2018-08-20 15:26:52,244 INFO] | epoch  29 | train_loss  3.63 | val_ppl 68.15443 | time  46.3s
[2018-08-20 15:27:38,531 INFO] | epoch  30 | train_loss  3.63 | val_ppl 68.15476 | time  46.3s
[2018-08-20 15:27:38,532 INFO] learning rate has been changed to 0.00048828125
[2018-08-20 15:28:24,934 INFO] | epoch  31 | train_loss  3.63 | val_ppl 68.12223 | time  46.4s
[2018-08-20 15:29:11,335 INFO] | epoch  32 | train_loss  3.63 | val_ppl 68.11358 | time  46.4s
[2018-08-20 15:29:57,800 INFO] | epoch  33 | train_loss  3.63 | val_ppl 68.10960 | time  46.5s
[2018-08-20 15:30:44,200 INFO] | epoch  34 | train_loss  3.63 | val_ppl 68.10739 | time  46.4s
[2018-08-20 15:31:30,525 INFO] | epoch  35 | train_loss  3.63 | val_ppl 68.10602 | time  46.3s
[2018-08-20 15:32:17,026 INFO] | epoch  36 | train_loss  3.63 | val_ppl 68.10512 | time  46.5s
[2018-08-20 15:33:03,664 INFO] | epoch  37 | train_loss  3.63 | val_ppl 68.10452 | time  46.6s
[2018-08-20 15:33:50,379 INFO] | epoch  38 | train_loss  3.63 | val_ppl 68.10410 | time  46.7s
[2018-08-20 15:34:37,175 INFO] | epoch  39 | train_loss  3.63 | val_ppl 68.10381 | time  46.8s
[2018-08-20 15:35:24,072 INFO] | epoch  40 | train_loss  3.63 | val_ppl 68.10361 | time  46.7s
[2018-08-20 15:35:24,073 INFO] start to save model on nnlm.model
[2018-08-20 15:35:26,760 INFO] test_ppl: 66.61851
[2018-08-20 15:41:25,107 INFO] -------------
[2018-08-20 15:41:25,108 INFO] Start training...
[2018-08-20 15:41:25,108 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='./80bptt_40epoch_outemb2ed.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./80bptt_40epoch_outemb2ed.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=125, tied=True, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 15:41:35,942 INFO] train token: 2127402
[2018-08-20 15:41:35,942 INFO] test token: 250140
[2018-08-20 15:41:35,942 INFO] valid token: 221606
[2018-08-20 15:41:37,460 INFO] Loading vectors from 80bptt_40epoch_outemb2ed.txt
[2018-08-20 15:41:37,464 WARNING] Skipping token 23381 with 1-dimensional vector ['650']; likely a header
[2018-08-20 15:41:42,030 INFO] Saving vectors to ./80bptt_40epoch_outemb2ed.txt.pt
[2018-08-20 15:42:39,007 INFO] | epoch   1 | train_loss  4.98 | val_ppl 105.27533 | time  43.8s
[2018-08-20 15:43:23,407 INFO] | epoch   2 | train_loss  4.30 | val_ppl 88.28194 | time  44.4s
[2018-08-20 15:44:08,009 INFO] | epoch   3 | train_loss  4.11 | val_ppl 80.99695 | time  44.6s
[2018-08-20 15:44:53,115 INFO] | epoch   4 | train_loss  4.00 | val_ppl 77.93251 | time  45.1s
[2018-08-20 15:45:38,326 INFO] | epoch   5 | train_loss  3.92 | val_ppl 76.24291 | time  45.2s
[2018-08-20 15:46:23,770 INFO] | epoch   6 | train_loss  3.86 | val_ppl 75.16906 | time  45.4s
[2018-08-20 15:47:09,594 INFO] | epoch   7 | train_loss  3.82 | val_ppl 74.45319 | time  45.8s
[2018-08-20 15:47:55,110 INFO] | epoch   8 | train_loss  3.78 | val_ppl 73.94379 | time  45.5s
[2018-08-20 15:48:40,827 INFO] | epoch   9 | train_loss  3.74 | val_ppl 73.59727 | time  45.7s
[2018-08-20 15:49:26,745 INFO] | epoch  10 | train_loss  3.71 | val_ppl 73.39771 | time  45.9s
[2018-08-20 15:50:12,605 INFO] | epoch  11 | train_loss  3.68 | val_ppl 73.31659 | time  45.9s
[2018-08-20 15:50:58,336 INFO] | epoch  12 | train_loss  3.65 | val_ppl 73.32038 | time  45.7s
[2018-08-20 15:50:58,336 INFO] learning rate has been changed to 0.03125
[2018-08-20 15:51:44,263 INFO] | epoch  13 | train_loss  3.63 | val_ppl 68.27783 | time  45.9s
[2018-08-20 15:52:30,076 INFO] | epoch  14 | train_loss  3.61 | val_ppl 68.14108 | time  45.8s
[2018-08-20 15:53:16,030 INFO] | epoch  15 | train_loss  3.61 | val_ppl 68.11502 | time  46.0s
[2018-08-20 15:54:01,910 INFO] | epoch  16 | train_loss  3.60 | val_ppl 68.11615 | time  45.9s
[2018-08-20 15:54:01,911 INFO] learning rate has been changed to 0.015625
[2018-08-20 15:54:47,999 INFO] | epoch  17 | train_loss  3.60 | val_ppl 67.81565 | time  46.1s
[2018-08-20 15:55:33,871 INFO] | epoch  18 | train_loss  3.60 | val_ppl 67.80364 | time  45.9s
[2018-08-20 15:56:19,859 INFO] | epoch  19 | train_loss  3.60 | val_ppl 67.80416 | time  46.0s
[2018-08-20 15:56:19,860 INFO] learning rate has been changed to 0.0078125
[2018-08-20 15:57:05,895 INFO] | epoch  20 | train_loss  3.60 | val_ppl 67.63813 | time  46.0s
[2018-08-20 15:57:51,952 INFO] | epoch  21 | train_loss  3.60 | val_ppl 67.62952 | time  46.1s
[2018-08-20 15:58:38,018 INFO] | epoch  22 | train_loss  3.60 | val_ppl 67.62755 | time  46.1s
[2018-08-20 15:59:23,985 INFO] | epoch  23 | train_loss  3.60 | val_ppl 67.62786 | time  46.0s
[2018-08-20 15:59:23,986 INFO] learning rate has been changed to 0.00390625
[2018-08-20 16:00:10,209 INFO] | epoch  24 | train_loss  3.60 | val_ppl 67.53975 | time  46.2s
[2018-08-20 16:00:56,395 INFO] | epoch  25 | train_loss  3.60 | val_ppl 67.53589 | time  46.2s
[2018-08-20 16:01:42,594 INFO] | epoch  26 | train_loss  3.60 | val_ppl 67.53447 | time  46.2s
[2018-08-20 16:02:28,754 INFO] | epoch  27 | train_loss  3.59 | val_ppl 67.53402 | time  46.2s
[2018-08-20 16:03:14,884 INFO] | epoch  28 | train_loss  3.59 | val_ppl 67.53411 | time  46.1s
[2018-08-20 16:03:14,885 INFO] learning rate has been changed to 0.0009765625
[2018-08-20 16:04:01,250 INFO] | epoch  29 | train_loss  3.59 | val_ppl 67.48046 | time  46.4s
[2018-08-20 16:04:47,313 INFO] | epoch  30 | train_loss  3.59 | val_ppl 67.47492 | time  46.1s
[2018-08-20 16:05:33,641 INFO] | epoch  31 | train_loss  3.59 | val_ppl 67.47316 | time  46.3s
[2018-08-20 16:06:19,917 INFO] | epoch  32 | train_loss  3.59 | val_ppl 67.47223 | time  46.3s
[2018-08-20 16:07:06,051 INFO] | epoch  33 | train_loss  3.59 | val_ppl 67.47164 | time  46.1s
[2018-08-20 16:07:52,323 INFO] | epoch  34 | train_loss  3.59 | val_ppl 67.47125 | time  46.3s
[2018-08-20 16:08:38,467 INFO] | epoch  35 | train_loss  3.59 | val_ppl 67.47098 | time  46.1s
[2018-08-20 16:09:24,718 INFO] | epoch  36 | train_loss  3.59 | val_ppl 67.47080 | time  46.3s
[2018-08-20 16:10:11,133 INFO] | epoch  37 | train_loss  3.59 | val_ppl 67.47069 | time  46.4s
[2018-08-20 16:10:57,344 INFO] | epoch  38 | train_loss  3.59 | val_ppl 67.47062 | time  46.2s
[2018-08-20 16:11:43,687 INFO] | epoch  39 | train_loss  3.59 | val_ppl 67.47060 | time  46.3s
[2018-08-20 16:12:30,063 INFO] | epoch  40 | train_loss  3.59 | val_ppl 67.47061 | time  46.4s
[2018-08-20 16:12:30,064 INFO] learning rate has been changed to 6.103515625e-05
[2018-08-20 16:12:30,064 INFO] start to save model on nnlm.model
[2018-08-20 16:12:32,526 INFO] test_ppl: 65.95860
[2018-08-20 16:16:50,772 INFO] -------------
[2018-08-20 16:16:50,773 INFO] Start training...
[2018-08-20 16:16:50,773 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='./80bptt_40epoch_outemb3th.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./80bptt_40epoch_outemb3th.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=125, tied=True, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-20 16:17:02,170 INFO] train token: 2127402
[2018-08-20 16:17:02,171 INFO] test token: 250140
[2018-08-20 16:17:02,171 INFO] valid token: 221606
[2018-08-20 16:17:03,458 INFO] Loading vectors from 80bptt_40epoch_outemb3th.txt
[2018-08-20 16:17:03,462 WARNING] Skipping token 23381 with 1-dimensional vector ['650']; likely a header
[2018-08-20 16:17:08,183 INFO] Saving vectors to ./80bptt_40epoch_outemb3th.txt.pt
[2018-08-20 16:18:04,432 INFO] | epoch   1 | train_loss  5.03 | val_ppl 102.10232 | time  43.8s
[2018-08-20 16:18:48,873 INFO] | epoch   2 | train_loss  4.25 | val_ppl 85.56427 | time  44.4s
[2018-08-20 16:19:33,564 INFO] | epoch   3 | train_loss  4.04 | val_ppl 79.23915 | time  44.7s
[2018-08-20 16:20:18,839 INFO] | epoch   4 | train_loss  3.92 | val_ppl 76.35675 | time  45.3s
[2018-08-20 16:21:04,149 INFO] | epoch   5 | train_loss  3.84 | val_ppl 74.96352 | time  45.3s
[2018-08-20 16:21:49,729 INFO] | epoch   6 | train_loss  3.79 | val_ppl 74.11392 | time  45.6s
[2018-08-20 16:22:35,449 INFO] | epoch   7 | train_loss  3.74 | val_ppl 73.57435 | time  45.7s
[2018-08-20 16:23:21,193 INFO] | epoch   8 | train_loss  3.70 | val_ppl 73.28997 | time  45.7s
[2018-08-20 16:24:06,871 INFO] | epoch   9 | train_loss  3.67 | val_ppl 73.17143 | time  45.7s
[2018-08-20 16:24:52,782 INFO] | epoch  10 | train_loss  3.64 | val_ppl 73.13727 | time  45.9s
[2018-08-20 16:25:39,029 INFO] | epoch  11 | train_loss  3.61 | val_ppl 73.18302 | time  46.2s
[2018-08-20 16:25:39,030 INFO] learning rate has been changed to 0.0625
[2018-08-20 16:26:25,361 INFO] | epoch  12 | train_loss  3.58 | val_ppl 68.95899 | time  46.3s
[2018-08-20 16:27:11,808 INFO] | epoch  13 | train_loss  3.56 | val_ppl 68.91639 | time  46.4s
[2018-08-20 16:27:58,224 INFO] | epoch  14 | train_loss  3.56 | val_ppl 68.94122 | time  46.4s
[2018-08-20 16:27:58,225 INFO] learning rate has been changed to 0.03125
[2018-08-20 16:28:44,699 INFO] | epoch  15 | train_loss  3.56 | val_ppl 68.41463 | time  46.5s
[2018-08-20 16:29:31,095 INFO] | epoch  16 | train_loss  3.55 | val_ppl 68.41253 | time  46.4s
[2018-08-20 16:30:17,533 INFO] | epoch  17 | train_loss  3.55 | val_ppl 68.42448 | time  46.4s
[2018-08-20 16:30:17,534 INFO] learning rate has been changed to 0.015625
[2018-08-20 16:31:03,953 INFO] | epoch  18 | train_loss  3.55 | val_ppl 68.08111 | time  46.4s
[2018-08-20 16:31:50,203 INFO] | epoch  19 | train_loss  3.55 | val_ppl 68.07208 | time  46.2s
[2018-08-20 16:32:36,736 INFO] | epoch  20 | train_loss  3.55 | val_ppl 68.07355 | time  46.5s
[2018-08-20 16:32:36,737 INFO] learning rate has been changed to 0.0078125
[2018-08-20 16:33:23,237 INFO] | epoch  21 | train_loss  3.55 | val_ppl 67.86498 | time  46.5s
[2018-08-20 16:34:09,611 INFO] | epoch  22 | train_loss  3.55 | val_ppl 67.85690 | time  46.4s
[2018-08-20 16:34:55,940 INFO] | epoch  23 | train_loss  3.55 | val_ppl 67.85545 | time  46.3s
[2018-08-20 16:35:42,344 INFO] | epoch  24 | train_loss  3.55 | val_ppl 67.85606 | time  46.4s
[2018-08-20 16:35:42,345 INFO] learning rate has been changed to 0.001953125
[2018-08-20 16:36:28,813 INFO] | epoch  25 | train_loss  3.55 | val_ppl 67.69524 | time  46.5s
[2018-08-20 16:37:15,034 INFO] | epoch  26 | train_loss  3.55 | val_ppl 67.68265 | time  46.2s
[2018-08-20 16:38:01,361 INFO] | epoch  27 | train_loss  3.55 | val_ppl 67.67824 | time  46.3s
[2018-08-20 16:38:47,697 INFO] | epoch  28 | train_loss  3.55 | val_ppl 67.67609 | time  46.3s
[2018-08-20 16:39:34,017 INFO] | epoch  29 | train_loss  3.55 | val_ppl 67.67484 | time  46.3s
[2018-08-20 16:40:20,448 INFO] | epoch  30 | train_loss  3.55 | val_ppl 67.67406 | time  46.4s
[2018-08-20 16:41:06,874 INFO] | epoch  31 | train_loss  3.55 | val_ppl 67.67356 | time  46.4s
[2018-08-20 16:41:53,158 INFO] | epoch  32 | train_loss  3.55 | val_ppl 67.67325 | time  46.3s
[2018-08-20 16:42:39,474 INFO] | epoch  33 | train_loss  3.54 | val_ppl 67.67308 | time  46.3s
[2018-08-20 16:43:26,006 INFO] | epoch  34 | train_loss  3.54 | val_ppl 67.67302 | time  46.5s
[2018-08-20 16:44:12,377 INFO] | epoch  35 | train_loss  3.54 | val_ppl 67.67304 | time  46.4s
[2018-08-20 16:44:12,378 INFO] learning rate has been changed to 0.000244140625
[2018-08-20 16:44:58,965 INFO] | epoch  36 | train_loss  3.54 | val_ppl 67.66358 | time  46.6s
[2018-08-20 16:45:45,347 INFO] | epoch  37 | train_loss  3.54 | val_ppl 67.65910 | time  46.4s
[2018-08-20 16:46:31,960 INFO] | epoch  38 | train_loss  3.54 | val_ppl 67.65641 | time  46.6s
[2018-08-20 16:47:18,499 INFO] | epoch  39 | train_loss  3.54 | val_ppl 67.65459 | time  46.5s
[2018-08-20 16:48:05,044 INFO] | epoch  40 | train_loss  3.54 | val_ppl 67.65326 | time  46.5s
[2018-08-20 16:48:05,045 INFO] start to save model on nnlm.model
[2018-08-20 16:48:07,825 INFO] test_ppl: 66.29112
[2018-08-20 16:58:51,373 INFO] -------------
[2018-08-20 16:58:51,374 INFO] Start training...
[2018-08-20 16:58:51,374 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='./80bptt_40epoch_outemb3th.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./80bptt_40epoch_outemb3th.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1215, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-20 16:59:02,635 INFO] train token: 2127402
[2018-08-20 16:59:02,635 INFO] test token: 250140
[2018-08-20 16:59:02,635 INFO] valid token: 221606
[2018-08-20 16:59:02,635 INFO] Loading vectors from ./80bptt_40epoch_outemb3th.txt.pt
[2018-08-20 16:59:58,555 INFO] | epoch   1 | train_loss  4.81 | val_ppl 101.25213 | time  43.6s
[2018-08-20 17:00:42,931 INFO] | epoch   2 | train_loss  4.19 | val_ppl 84.82137 | time  44.4s
[2018-08-20 17:01:27,434 INFO] | epoch   3 | train_loss  4.00 | val_ppl 78.35311 | time  44.5s
[2018-08-20 17:02:12,145 INFO] | epoch   4 | train_loss  3.89 | val_ppl 75.96403 | time  44.7s
[2018-08-20 17:02:57,093 INFO] | epoch   5 | train_loss  3.82 | val_ppl 74.61279 | time  44.9s
[2018-08-20 17:03:42,369 INFO] | epoch   6 | train_loss  3.76 | val_ppl 73.76939 | time  45.3s
[2018-08-20 17:04:28,110 INFO] | epoch   7 | train_loss  3.72 | val_ppl 73.21514 | time  45.7s
[2018-08-20 17:05:13,682 INFO] | epoch   8 | train_loss  3.68 | val_ppl 72.87730 | time  45.6s
[2018-08-20 17:05:59,350 INFO] | epoch   9 | train_loss  3.65 | val_ppl 72.70236 | time  45.7s
[2018-08-20 17:06:45,158 INFO] | epoch  10 | train_loss  3.62 | val_ppl 72.65380 | time  45.8s
[2018-08-20 17:07:30,943 INFO] | epoch  11 | train_loss  3.59 | val_ppl 72.71319 | time  45.8s
[2018-08-20 17:07:30,944 INFO] learning rate has been changed to 0.0625
[2018-08-20 17:08:16,726 INFO] | epoch  12 | train_loss  3.56 | val_ppl 68.64287 | time  45.8s
[2018-08-20 17:09:02,558 INFO] | epoch  13 | train_loss  3.54 | val_ppl 68.62171 | time  45.8s
[2018-08-20 17:09:48,548 INFO] | epoch  14 | train_loss  3.54 | val_ppl 68.65971 | time  46.0s
[2018-08-20 17:09:48,549 INFO] learning rate has been changed to 0.03125
[2018-08-20 17:10:34,492 INFO] | epoch  15 | train_loss  3.54 | val_ppl 68.18017 | time  45.9s
[2018-08-20 17:11:20,391 INFO] | epoch  16 | train_loss  3.53 | val_ppl 68.18500 | time  45.9s
[2018-08-20 17:11:20,392 INFO] learning rate has been changed to 0.015625
[2018-08-20 17:12:06,473 INFO] | epoch  17 | train_loss  3.53 | val_ppl 67.89107 | time  46.1s
[2018-08-20 17:12:52,436 INFO] | epoch  18 | train_loss  3.53 | val_ppl 67.88381 | time  46.0s
[2018-08-20 17:13:38,425 INFO] | epoch  19 | train_loss  3.53 | val_ppl 67.88710 | time  46.0s
[2018-08-20 17:13:38,426 INFO] learning rate has been changed to 0.0078125
[2018-08-20 17:14:24,538 INFO] | epoch  20 | train_loss  3.53 | val_ppl 67.72157 | time  46.1s
[2018-08-20 17:15:10,488 INFO] | epoch  21 | train_loss  3.53 | val_ppl 67.71473 | time  45.9s
[2018-08-20 17:15:56,443 INFO] | epoch  22 | train_loss  3.53 | val_ppl 67.71434 | time  46.0s
[2018-08-20 17:16:42,658 INFO] | epoch  23 | train_loss  3.53 | val_ppl 67.71593 | time  46.2s
[2018-08-20 17:16:42,659 INFO] learning rate has been changed to 0.00390625
[2018-08-20 17:17:28,942 INFO] | epoch  24 | train_loss  3.53 | val_ppl 67.62936 | time  46.3s
[2018-08-20 17:18:15,043 INFO] | epoch  25 | train_loss  3.53 | val_ppl 67.62635 | time  46.1s
[2018-08-20 17:19:01,083 INFO] | epoch  26 | train_loss  3.53 | val_ppl 67.62577 | time  46.0s
[2018-08-20 17:19:47,395 INFO] | epoch  27 | train_loss  3.53 | val_ppl 67.62605 | time  46.3s
[2018-08-20 17:19:47,396 INFO] learning rate has been changed to 0.0009765625
[2018-08-20 17:20:33,485 INFO] | epoch  28 | train_loss  3.53 | val_ppl 67.56975 | time  46.1s
[2018-08-20 17:21:19,639 INFO] | epoch  29 | train_loss  3.53 | val_ppl 67.56418 | time  46.2s
[2018-08-20 17:22:05,708 INFO] | epoch  30 | train_loss  3.53 | val_ppl 67.56276 | time  46.1s
[2018-08-20 17:22:52,202 INFO] | epoch  31 | train_loss  3.53 | val_ppl 67.56225 | time  46.5s
[2018-08-20 17:23:38,333 INFO] | epoch  32 | train_loss  3.53 | val_ppl 67.56206 | time  46.1s
[2018-08-20 17:24:24,630 INFO] | epoch  33 | train_loss  3.53 | val_ppl 67.56200 | time  46.3s
[2018-08-20 17:25:10,845 INFO] | epoch  34 | train_loss  3.53 | val_ppl 67.56203 | time  46.2s
[2018-08-20 17:25:10,846 INFO] learning rate has been changed to 0.000244140625
[2018-08-20 17:25:57,330 INFO] | epoch  35 | train_loss  3.53 | val_ppl 67.56146 | time  46.5s
[2018-08-20 17:26:43,634 INFO] | epoch  36 | train_loss  3.53 | val_ppl 67.56137 | time  46.3s
[2018-08-20 17:27:29,923 INFO] | epoch  37 | train_loss  3.53 | val_ppl 67.56132 | time  46.3s
[2018-08-20 17:28:16,155 INFO] | epoch  38 | train_loss  3.53 | val_ppl 67.56128 | time  46.2s
[2018-08-20 17:29:02,297 INFO] | epoch  39 | train_loss  3.53 | val_ppl 67.56129 | time  46.1s
[2018-08-20 17:29:02,298 INFO] learning rate has been changed to 6.103515625e-05
[2018-08-20 17:29:48,589 INFO] | epoch  40 | train_loss  3.53 | val_ppl 67.56170 | time  46.3s
[2018-08-20 17:29:48,590 INFO] learning rate has been changed to 6.103515625e-05
[2018-08-20 17:29:48,590 INFO] start to save model on nnlm.model
[2018-08-20 17:29:51,206 INFO] test_ppl: 66.19761
[2018-08-20 20:16:32,133 INFO] -------------
[2018-08-20 20:16:32,133 INFO] Start training...
[2018-08-20 20:16:32,133 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='~/common_corpus/1mlplen_8epoch_850d.outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/1mlplen_8epoch_850d.outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=125, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-20 20:16:44,005 INFO] train token: 2127402
[2018-08-20 20:16:44,005 INFO] test token: 250140
[2018-08-20 20:16:44,005 INFO] valid token: 221606
[2018-08-20 20:16:47,172 INFO] Loading vectors from /home/lr/yukun/common_corpus/1mlplen_8epoch_850d.outemb.txt
[2018-08-20 20:16:47,684 WARNING] Skipping token 23381 with 1-dimensional vector ['850']; likely a header
[2018-08-20 20:16:53,817 INFO] Saving vectors to /home/lr/yukun/common_corpus/1mlplen_8epoch_850d.outemb.txt.pt
[2018-08-20 20:18:05,131 INFO] | epoch   1 | train_loss  5.88 | val_ppl 190.68417 | time  55.8s
[2018-08-20 20:19:01,152 INFO] | epoch   2 | train_loss  4.90 | val_ppl 126.32410 | time  56.0s
[2018-08-20 20:19:58,620 INFO] | epoch   3 | train_loss  4.72 | val_ppl 112.26508 | time  57.5s
[2018-08-20 20:20:56,544 INFO] | epoch   4 | train_loss  4.61 | val_ppl 103.79554 | time  57.9s
[2018-08-20 20:21:54,845 INFO] | epoch   5 | train_loss  4.51 | val_ppl 97.79462 | time  58.3s
[2018-08-20 20:22:54,161 INFO] | epoch   6 | train_loss  4.44 | val_ppl 93.34692 | time  59.2s
[2018-08-20 20:23:52,893 INFO] | epoch   7 | train_loss  4.37 | val_ppl 89.90953 | time  58.7s
[2018-08-20 20:24:52,270 INFO] | epoch   8 | train_loss  4.31 | val_ppl 87.19525 | time  59.4s
[2018-08-20 20:25:51,484 INFO] | epoch   9 | train_loss  4.26 | val_ppl 84.99280 | time  59.2s
[2018-08-20 20:26:50,270 INFO] | epoch  10 | train_loss  4.21 | val_ppl 83.13882 | time  58.8s
[2018-08-20 20:27:49,453 INFO] | epoch  11 | train_loss  4.16 | val_ppl 81.53011 | time  59.2s
[2018-08-20 20:28:48,310 INFO] | epoch  12 | train_loss  4.12 | val_ppl 80.15046 | time  58.9s
[2018-08-20 20:29:47,596 INFO] | epoch  13 | train_loss  4.08 | val_ppl 79.00673 | time  59.3s
[2018-08-20 20:30:46,480 INFO] | epoch  14 | train_loss  4.04 | val_ppl 78.08167 | time  58.9s
[2018-08-20 20:31:45,255 INFO] | epoch  15 | train_loss  4.00 | val_ppl 77.34690 | time  58.8s
[2018-08-20 20:32:43,994 INFO] | epoch  16 | train_loss  3.96 | val_ppl 76.78017 | time  58.7s
[2018-08-20 20:33:42,688 INFO] | epoch  17 | train_loss  3.92 | val_ppl 76.37064 | time  58.7s
[2018-08-20 20:34:41,639 INFO] | epoch  18 | train_loss  3.89 | val_ppl 76.11440 | time  58.9s
[2018-08-20 20:35:40,339 INFO] | epoch  19 | train_loss  3.85 | val_ppl 76.01639 | time  58.7s
[2018-08-20 20:36:39,556 INFO] | epoch  20 | train_loss  3.81 | val_ppl 76.08385 | time  59.2s
[2018-08-20 20:36:39,556 INFO] learning rate has been changed to 0.0078125
[2018-08-20 20:37:38,239 INFO] | epoch  21 | train_loss  3.79 | val_ppl 71.49515 | time  58.7s
[2018-08-20 20:38:37,080 INFO] | epoch  22 | train_loss  3.77 | val_ppl 71.06354 | time  58.8s
[2018-08-20 20:39:35,714 INFO] | epoch  23 | train_loss  3.76 | val_ppl 70.87251 | time  58.6s
[2018-08-20 20:40:34,307 INFO] | epoch  24 | train_loss  3.76 | val_ppl 70.76832 | time  58.6s
[2018-08-20 20:41:33,018 INFO] | epoch  25 | train_loss  3.75 | val_ppl 70.70536 | time  58.7s
[2018-08-20 20:42:31,724 INFO] | epoch  26 | train_loss  3.75 | val_ppl 70.66509 | time  58.7s
[2018-08-20 20:43:30,610 INFO] | epoch  27 | train_loss  3.75 | val_ppl 70.63854 | time  58.9s
[2018-08-20 20:44:29,505 INFO] | epoch  28 | train_loss  3.75 | val_ppl 70.62089 | time  58.9s
[2018-08-20 20:45:28,391 INFO] | epoch  29 | train_loss  3.75 | val_ppl 70.60931 | time  58.9s
[2018-08-20 20:46:27,267 INFO] | epoch  30 | train_loss  3.75 | val_ppl 70.60205 | time  58.8s
[2018-08-20 20:47:25,934 INFO] | epoch  31 | train_loss  3.74 | val_ppl 70.59793 | time  58.7s
[2018-08-20 20:48:25,132 INFO] | epoch  32 | train_loss  3.74 | val_ppl 70.59619 | time  59.2s
[2018-08-20 20:49:24,205 INFO] | epoch  33 | train_loss  3.74 | val_ppl 70.59625 | time  59.1s
[2018-08-20 20:49:24,205 INFO] learning rate has been changed to 0.000244140625
[2018-08-20 20:50:22,814 INFO] | epoch  34 | train_loss  3.74 | val_ppl 70.50608 | time  58.6s
[2018-08-20 20:51:22,387 INFO] | epoch  35 | train_loss  3.74 | val_ppl 70.47132 | time  59.6s
[2018-08-20 20:52:21,493 INFO] | epoch  36 | train_loss  3.74 | val_ppl 70.45288 | time  59.1s
[2018-08-20 20:53:20,273 INFO] | epoch  37 | train_loss  3.74 | val_ppl 70.44117 | time  58.8s
[2018-08-20 20:54:19,196 INFO] | epoch  38 | train_loss  3.74 | val_ppl 70.43303 | time  58.9s
[2018-08-20 20:55:18,282 INFO] | epoch  39 | train_loss  3.74 | val_ppl 70.42708 | time  59.0s
[2018-08-20 20:56:17,680 INFO] | epoch  40 | train_loss  3.74 | val_ppl 70.42260 | time  59.2s
[2018-08-20 20:56:17,681 INFO] start to save model on nnlm.model
[2018-08-20 20:56:21,640 INFO] test_ppl: 68.73485
[2018-08-20 21:02:01,987 INFO] -------------
[2018-08-20 21:02:01,987 INFO] Start training...
[2018-08-20 21:02:01,987 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='./80bptt_40epoch_850d.1st.outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./80bptt_40epoch_850d.1st.outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=125, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-20 21:02:13,474 INFO] train token: 2127402
[2018-08-20 21:02:13,475 INFO] test token: 250140
[2018-08-20 21:02:13,475 INFO] valid token: 221606
[2018-08-20 21:02:14,760 INFO] Loading vectors from 80bptt_40epoch_850d.1st.outemb.txt
[2018-08-20 21:02:14,767 WARNING] Skipping token 23381 with 1-dimensional vector ['850']; likely a header
[2018-08-20 21:02:20,621 INFO] Saving vectors to ./80bptt_40epoch_850d.1st.outemb.txt.pt
[2018-08-20 21:03:30,905 INFO] | epoch   1 | train_loss  5.30 | val_ppl 116.66195 | time  55.8s
[2018-08-20 21:04:27,305 INFO] | epoch   2 | train_loss  4.47 | val_ppl 94.26703 | time  56.4s
[2018-08-20 21:05:24,936 INFO] | epoch   3 | train_loss  4.28 | val_ppl 86.11082 | time  57.6s
[2018-08-20 21:06:23,251 INFO] | epoch   4 | train_loss  4.17 | val_ppl 81.34071 | time  58.3s
[2018-08-20 21:07:22,203 INFO] | epoch   5 | train_loss  4.09 | val_ppl 78.59621 | time  58.8s
[2018-08-20 21:08:21,526 INFO] | epoch   6 | train_loss  4.03 | val_ppl 76.85938 | time  59.3s
[2018-08-20 21:09:20,541 INFO] | epoch   7 | train_loss  3.98 | val_ppl 75.66025 | time  59.0s
[2018-08-20 21:10:19,904 INFO] | epoch   8 | train_loss  3.94 | val_ppl 74.79874 | time  59.4s
[2018-08-20 21:11:18,682 INFO] | epoch   9 | train_loss  3.89 | val_ppl 74.17413 | time  58.8s
[2018-08-20 21:12:17,842 INFO] | epoch  10 | train_loss  3.86 | val_ppl 73.74231 | time  59.2s
[2018-08-20 21:13:16,338 INFO] | epoch  11 | train_loss  3.82 | val_ppl 73.47398 | time  58.5s
[2018-08-20 21:14:14,838 INFO] | epoch  12 | train_loss  3.78 | val_ppl 73.34168 | time  58.5s
[2018-08-20 21:15:13,587 INFO] | epoch  13 | train_loss  3.75 | val_ppl 73.32537 | time  58.7s
[2018-08-20 21:16:12,242 INFO] | epoch  14 | train_loss  3.71 | val_ppl 73.42595 | time  58.7s
[2018-08-20 21:16:12,243 INFO] learning rate has been changed to 0.03125
[2018-08-20 21:17:10,777 INFO] | epoch  15 | train_loss  3.68 | val_ppl 68.43583 | time  58.5s
[2018-08-20 21:18:09,160 INFO] | epoch  16 | train_loss  3.66 | val_ppl 68.32693 | time  58.4s
[2018-08-20 21:19:07,918 INFO] | epoch  17 | train_loss  3.65 | val_ppl 68.32069 | time  58.8s
[2018-08-20 21:20:06,578 INFO] | epoch  18 | train_loss  3.65 | val_ppl 68.33961 | time  58.7s
[2018-08-20 21:20:06,579 INFO] learning rate has been changed to 0.0078125
[2018-08-20 21:21:05,302 INFO] | epoch  19 | train_loss  3.65 | val_ppl 67.81343 | time  58.7s
[2018-08-20 21:22:04,431 INFO] | epoch  20 | train_loss  3.65 | val_ppl 67.78466 | time  59.1s
[2018-08-20 21:23:03,533 INFO] | epoch  21 | train_loss  3.65 | val_ppl 67.77619 | time  59.1s
[2018-08-20 21:24:02,569 INFO] | epoch  22 | train_loss  3.64 | val_ppl 67.77441 | time  59.0s
[2018-08-20 21:25:01,514 INFO] | epoch  23 | train_loss  3.64 | val_ppl 67.77581 | time  58.9s
[2018-08-20 21:25:01,595 INFO] learning rate has been changed to 0.00390625
[2018-08-20 21:26:00,385 INFO] | epoch  24 | train_loss  3.64 | val_ppl 67.67216 | time  58.8s
[2018-08-20 21:26:59,647 INFO] | epoch  25 | train_loss  3.64 | val_ppl 67.66732 | time  59.3s
[2018-08-20 21:27:58,523 INFO] | epoch  26 | train_loss  3.64 | val_ppl 67.66623 | time  58.9s
[2018-08-20 21:28:57,746 INFO] | epoch  27 | train_loss  3.64 | val_ppl 67.66652 | time  59.2s
[2018-08-20 21:28:57,746 INFO] learning rate has been changed to 0.0009765625
[2018-08-20 21:29:56,600 INFO] | epoch  28 | train_loss  3.64 | val_ppl 67.61140 | time  58.9s
[2018-08-20 21:30:55,561 INFO] | epoch  29 | train_loss  3.64 | val_ppl 67.60575 | time  59.0s
[2018-08-20 21:31:54,515 INFO] | epoch  30 | train_loss  3.64 | val_ppl 67.60342 | time  59.0s
[2018-08-20 21:32:53,334 INFO] | epoch  31 | train_loss  3.64 | val_ppl 67.60205 | time  58.8s
[2018-08-20 21:33:52,294 INFO] | epoch  32 | train_loss  3.64 | val_ppl 67.60119 | time  59.0s
[2018-08-20 21:34:51,056 INFO] | epoch  33 | train_loss  3.64 | val_ppl 67.60064 | time  58.8s
[2018-08-20 21:35:50,297 INFO] | epoch  34 | train_loss  3.64 | val_ppl 67.60029 | time  59.2s
[2018-08-20 21:36:49,252 INFO] | epoch  35 | train_loss  3.64 | val_ppl 67.60010 | time  59.0s
[2018-08-20 21:37:48,087 INFO] | epoch  36 | train_loss  3.64 | val_ppl 67.60001 | time  58.8s
[2018-08-20 21:38:46,989 INFO] | epoch  37 | train_loss  3.64 | val_ppl 67.60001 | time  58.9s
[2018-08-20 21:38:46,989 INFO] learning rate has been changed to 0.0001220703125
[2018-08-20 21:39:45,956 INFO] | epoch  38 | train_loss  3.64 | val_ppl 67.59936 | time  59.0s
[2018-08-20 21:40:44,937 INFO] | epoch  39 | train_loss  3.64 | val_ppl 67.59916 | time  59.0s
[2018-08-20 21:41:43,781 INFO] | epoch  40 | train_loss  3.64 | val_ppl 67.59915 | time  58.8s
[2018-08-20 21:41:43,781 INFO] start to save model on nnlm.model
[2018-08-20 21:41:46,999 INFO] test_ppl: 66.28892
[2018-08-20 21:50:39,738 INFO] -------------
[2018-08-20 21:50:39,738 INFO] Start training...
[2018-08-20 21:50:39,738 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='./80bptt_40epoch_850d.2st.outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./80bptt_40epoch_850d.2st.outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=15, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-20 21:50:50,986 INFO] train token: 2127402
[2018-08-20 21:50:50,987 INFO] test token: 250140
[2018-08-20 21:50:50,987 INFO] valid token: 221606
[2018-08-20 21:50:52,270 INFO] Loading vectors from 80bptt_40epoch_850d.2st.outemb.txt
[2018-08-20 21:50:52,275 WARNING] Skipping token 23381 with 1-dimensional vector ['850']; likely a header
[2018-08-20 21:50:58,269 INFO] Saving vectors to ./80bptt_40epoch_850d.2st.outemb.txt.pt
[2018-08-20 21:52:08,452 INFO] | epoch   1 | train_loss 28.55 | val_ppl 408446238.32923 | time  55.8s
[2018-08-20 21:53:04,290 INFO] | epoch   2 | train_loss 20.68 | val_ppl 255777681.29091 | time  55.8s
[2018-08-20 21:54:00,630 INFO] | epoch   3 | train_loss 18.81 | val_ppl 375359910177.63739 | time  56.3s
[2018-08-20 21:54:00,631 INFO] learning rate has been changed to 0.25
[2018-08-20 21:54:57,186 INFO] | epoch   4 | train_loss 10.87 | val_ppl 21671.30705 | time  56.6s
[2018-08-20 21:55:54,056 INFO] | epoch   5 | train_loss 10.65 | val_ppl 26596.12157 | time  56.9s
[2018-08-20 21:55:54,057 INFO] learning rate has been changed to 0.25
[2018-08-20 21:56:51,249 INFO] | epoch   6 | train_loss 10.53 | val_ppl 13427.86453 | time  57.2s
[2018-08-20 21:57:48,416 INFO] | epoch   7 | train_loss 10.33 | val_ppl 13514.98229 | time  57.2s
[2018-08-20 21:57:48,416 INFO] learning rate has been changed to 0.125
[2018-08-20 21:58:45,488 INFO] | epoch   8 | train_loss  7.83 | val_ppl 4049.40762 | time  57.1s
[2018-08-20 21:59:42,285 INFO] | epoch   9 | train_loss  7.79 | val_ppl 4753.58337 | time  56.8s
[2018-08-20 21:59:42,285 INFO] learning rate has been changed to 0.0625
[2018-08-20 22:00:38,957 INFO] | epoch  10 | train_loss  7.05 | val_ppl 1434.91585 | time  56.7s
[2018-08-20 22:07:24,515 INFO] -------------
[2018-08-20 22:07:24,515 INFO] Start training...
[2018-08-20 22:07:24,515 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay_after_n_epoch=7, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_decay=3, every_n_epoch_save=40, input_vector='./80bptt_40epoch_850d.2st.outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./80bptt_40epoch_850d.2st.outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=125, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-20 22:07:36,083 INFO] train token: 2127402
[2018-08-20 22:07:36,083 INFO] test token: 250140
[2018-08-20 22:07:36,084 INFO] valid token: 221606
[2018-08-20 22:07:36,084 INFO] Loading vectors from ./80bptt_40epoch_850d.2st.outemb.txt.pt
[2018-08-20 22:08:45,773 INFO] | epoch   1 | train_loss  5.60 | val_ppl 116.00444 | time  55.8s
[2018-08-20 22:09:41,928 INFO] | epoch   2 | train_loss  4.45 | val_ppl 93.74372 | time  56.2s
[2018-08-20 22:10:39,235 INFO] | epoch   3 | train_loss  4.22 | val_ppl 84.18973 | time  57.3s
[2018-08-20 22:11:37,241 INFO] | epoch   4 | train_loss  4.10 | val_ppl 80.46532 | time  58.0s
[2018-08-20 22:12:35,364 INFO] | epoch   5 | train_loss  4.01 | val_ppl 77.25910 | time  58.1s
[2018-08-20 22:13:33,780 INFO] | epoch   6 | train_loss  3.94 | val_ppl 75.45863 | time  58.4s
[2018-08-20 22:14:32,187 INFO] | epoch   7 | train_loss  3.89 | val_ppl 74.30015 | time  58.4s
[2018-08-20 22:15:30,779 INFO] | epoch   8 | train_loss  3.84 | val_ppl 73.23836 | time  58.6s
[2018-08-20 22:16:29,368 INFO] | epoch   9 | train_loss  3.80 | val_ppl 72.54908 | time  58.6s
[2018-08-20 22:17:28,033 INFO] | epoch  10 | train_loss  3.76 | val_ppl 72.21705 | time  58.7s
[2018-08-20 22:18:26,834 INFO] | epoch  11 | train_loss  3.73 | val_ppl 72.02290 | time  58.8s
[2018-08-20 22:19:25,577 INFO] | epoch  12 | train_loss  3.69 | val_ppl 71.93137 | time  58.7s
[2018-08-20 22:20:24,330 INFO] | epoch  13 | train_loss  3.66 | val_ppl 71.98888 | time  58.8s
[2018-08-20 22:20:24,330 INFO] learning rate has been changed to 0.03125
[2018-08-20 22:21:23,420 INFO] | epoch  14 | train_loss  3.63 | val_ppl 67.59586 | time  59.1s
[2018-08-20 22:22:22,199 INFO] | epoch  15 | train_loss  3.61 | val_ppl 67.45261 | time  58.8s
[2018-08-20 22:23:21,125 INFO] | epoch  16 | train_loss  3.60 | val_ppl 67.42262 | time  58.9s
[2018-08-20 22:24:19,902 INFO] | epoch  17 | train_loss  3.60 | val_ppl 67.42537 | time  58.8s
[2018-08-20 22:24:19,903 INFO] learning rate has been changed to 0.015625
[2018-08-20 22:25:18,606 INFO] | epoch  18 | train_loss  3.60 | val_ppl 67.12470 | time  58.7s
[2018-08-20 22:26:16,941 INFO] | epoch  19 | train_loss  3.60 | val_ppl 67.11289 | time  58.3s
[2018-08-20 22:27:15,886 INFO] | epoch  20 | train_loss  3.60 | val_ppl 67.11593 | time  58.9s
[2018-08-20 22:27:15,887 INFO] learning rate has been changed to 0.0078125
[2018-08-20 22:28:14,416 INFO] | epoch  21 | train_loss  3.60 | val_ppl 66.93428 | time  58.5s
[2018-08-20 22:29:12,905 INFO] | epoch  22 | train_loss  3.59 | val_ppl 66.92441 | time  58.5s
[2018-08-20 22:30:11,352 INFO] | epoch  23 | train_loss  3.59 | val_ppl 66.92340 | time  58.4s
[2018-08-20 22:31:09,953 INFO] | epoch  24 | train_loss  3.59 | val_ppl 66.92525 | time  58.6s
[2018-08-20 22:31:09,953 INFO] learning rate has been changed to 0.001953125
[2018-08-20 22:32:08,553 INFO] | epoch  25 | train_loss  3.59 | val_ppl 66.77978 | time  58.6s
[2018-08-20 22:33:06,869 INFO] | epoch  26 | train_loss  3.59 | val_ppl 66.76449 | time  58.3s
[2018-08-20 22:34:05,736 INFO] | epoch  27 | train_loss  3.59 | val_ppl 66.75880 | time  58.9s
[2018-08-20 22:35:04,436 INFO] | epoch  28 | train_loss  3.59 | val_ppl 66.75608 | time  58.7s
[2018-08-20 22:36:03,086 INFO] | epoch  29 | train_loss  3.59 | val_ppl 66.75463 | time  58.6s
[2018-08-20 22:37:01,556 INFO] | epoch  30 | train_loss  3.59 | val_ppl 66.75387 | time  58.5s
[2018-08-20 22:38:00,426 INFO] | epoch  31 | train_loss  3.59 | val_ppl 66.75354 | time  58.9s
[2018-08-20 22:38:58,928 INFO] | epoch  32 | train_loss  3.59 | val_ppl 66.75349 | time  58.5s
[2018-08-20 22:39:57,484 INFO] | epoch  33 | train_loss  3.59 | val_ppl 66.75365 | time  58.6s
[2018-08-20 22:39:57,485 INFO] learning rate has been changed to 0.000244140625
[2018-08-20 22:40:56,319 INFO] | epoch  34 | train_loss  3.59 | val_ppl 66.74201 | time  58.8s
[2018-08-20 22:41:54,956 INFO] | epoch  35 | train_loss  3.59 | val_ppl 66.73585 | time  58.6s
[2018-08-20 22:42:53,556 INFO] | epoch  36 | train_loss  3.59 | val_ppl 66.73175 | time  58.6s
[2018-08-20 22:43:52,122 INFO] | epoch  37 | train_loss  3.59 | val_ppl 66.72875 | time  58.6s
[2018-08-20 22:44:50,787 INFO] | epoch  38 | train_loss  3.59 | val_ppl 66.72644 | time  58.7s
[2018-08-20 22:45:49,599 INFO] | epoch  39 | train_loss  3.59 | val_ppl 66.72464 | time  58.7s
[2018-08-20 22:46:48,060 INFO] | epoch  40 | train_loss  3.59 | val_ppl 66.72320 | time  58.5s
[2018-08-20 22:46:48,139 INFO] start to save model on nnlm.model
[2018-08-20 22:46:51,382 INFO] test_ppl: 65.54082

2018-08-21 12:03:09,235 INFO] -------------
[2018-08-21 12:39:25,054 INFO] -------------


seed matters a lot? here mark
[2018-08-21 12:39:25,054 INFO] Start training...
[2018-08-21 12:39:25,055 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay=0.75, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_save=40, input_vector='~/common_corpus/1mlplen_8epoch_850d.outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/1mlplen_8epoch_850d.outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=195, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-21 12:39:36,467 INFO] train token: 2127402
[2018-08-21 12:39:36,467 INFO] test token: 250140
[2018-08-21 12:39:36,467 INFO] valid token: 221606
[2018-08-21 12:39:36,468 INFO] Loading vectors from /home/lr/yukun/common_corpus/1mlplen_8epoch_850d.outemb.txt.pt
[2018-08-21 12:40:45,787 INFO] | epoch   1 | train_loss  8.62 | val_ppl 312.32765 | time  55.9s
[2018-08-21 12:41:42,677 INFO] | epoch   2 | train_loss  5.22 | val_ppl 166.37752 | time  56.9s
[2018-08-21 12:42:40,540 INFO] | epoch   3 | train_loss  4.92 | val_ppl 127.98898 | time  57.9s
[2018-08-21 12:43:43,108 INFO] -------------
[2018-08-21 12:43:43,108 INFO] Start training...
[2018-08-21 12:43:43,108 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay=0.75, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_save=40, input_vector='~/common_corpus/1mlplen_8epoch_850d.outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/1mlplen_8epoch_850d.outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=240, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-21 12:43:54,520 INFO] train token: 2127402
[2018-08-21 12:43:54,520 INFO] test token: 250140
[2018-08-21 12:43:54,520 INFO] valid token: 221606
[2018-08-21 12:43:54,521 INFO] Loading vectors from /home/lr/yukun/common_corpus/1mlplen_8epoch_850d.outemb.txt.pt
[2018-08-21 12:45:04,246 INFO] | epoch   1 | train_loss  6.13 | val_ppl 153.99559 | time  55.9s
[2018-08-21 12:46:01,645 INFO] | epoch   2 | train_loss  4.87 | val_ppl 123.18177 | time  57.4s
[2018-08-21 12:46:59,707 INFO] | epoch   3 | train_loss  4.68 | val_ppl 106.35813 | time  58.1s
[2018-08-21 12:47:57,993 INFO] | epoch   4 | train_loss  4.55 | val_ppl 97.83997 | time  58.3s
[2018-08-21 12:48:56,216 INFO] | epoch   5 | train_loss  4.46 | val_ppl 91.78046 | time  58.2s
[2018-08-21 12:49:54,910 INFO] | epoch   6 | train_loss  4.38 | val_ppl 87.27542 | time  58.7s
[2018-08-21 12:50:53,090 INFO] | epoch   7 | train_loss  4.31 | val_ppl 83.85923 | time  58.2s
[2018-08-21 12:51:51,660 INFO] | epoch   8 | train_loss  4.24 | val_ppl 81.12285 | time  58.6s
[2018-08-21 12:52:49,928 INFO] | epoch   9 | train_loss  4.19 | val_ppl 78.85818 | time  58.3s
[2018-08-21 12:53:48,306 INFO] | epoch  10 | train_loss  4.14 | val_ppl 78.10015 | time  58.4s
[2018-08-21 12:54:46,598 INFO] | epoch  11 | train_loss  4.09 | val_ppl 76.04769 | time  58.3s
[2018-08-21 12:55:44,809 INFO] | epoch  12 | train_loss  4.04 | val_ppl 74.50179 | time  58.2s
[2018-08-21 12:56:43,311 INFO] | epoch  13 | train_loss  4.00 | val_ppl 73.22751 | time  58.5s
[2018-08-21 12:57:41,738 INFO] | epoch  14 | train_loss  3.96 | val_ppl 71.70023 | time  58.4s
[2018-08-21 12:58:40,061 INFO] | epoch  15 | train_loss  3.92 | val_ppl 70.75091 | time  58.3s
[2018-08-21 12:59:38,283 INFO] | epoch  16 | train_loss  3.88 | val_ppl 70.03679 | time  58.2s
[2018-08-21 13:00:36,671 INFO] | epoch  17 | train_loss  3.84 | val_ppl 69.49118 | time  58.4s
[2018-08-21 13:01:34,953 INFO] | epoch  18 | train_loss  3.80 | val_ppl 69.10183 | time  58.3s
[2018-08-21 13:01:34,954 INFO] learning rate has been changed to 0.375
[2018-08-21 13:02:32,917 INFO] | epoch  19 | train_loss  3.75 | val_ppl 68.01508 | time  58.0s
[2018-08-21 13:03:31,581 INFO] | epoch  20 | train_loss  3.72 | val_ppl 67.95670 | time  58.7s
[2018-08-21 13:03:31,581 INFO] learning rate has been changed to 0.28125
[2018-08-21 13:04:29,873 INFO] | epoch  21 | train_loss  3.69 | val_ppl 67.25671 | time  58.3s
[2018-08-21 13:05:28,120 INFO] | epoch  22 | train_loss  3.66 | val_ppl 67.31814 | time  58.2s
[2018-08-21 13:05:28,120 INFO] learning rate has been changed to 0.2109375
[2018-08-21 13:06:26,381 INFO] | epoch  23 | train_loss  3.64 | val_ppl 66.84461 | time  58.3s
[2018-08-21 13:06:26,381 INFO] learning rate has been changed to 0.158203125
[2018-08-21 13:07:24,724 INFO] | epoch  24 | train_loss  3.62 | val_ppl 66.47799 | time  58.3s
[2018-08-21 13:07:24,725 INFO] learning rate has been changed to 0.11865234375
[2018-08-21 13:08:23,312 INFO] | epoch  25 | train_loss  3.60 | val_ppl 66.18587 | time  58.6s
[2018-08-21 13:08:23,312 INFO] learning rate has been changed to 0.0889892578125
[2018-08-21 13:09:21,704 INFO] | epoch  26 | train_loss  3.59 | val_ppl 65.93893 | time  58.4s
[2018-08-21 13:09:21,704 INFO] learning rate has been changed to 0.066741943359375
[2018-08-21 13:10:20,283 INFO] | epoch  27 | train_loss  3.58 | val_ppl 65.72119 | time  58.6s
[2018-08-21 13:10:20,283 INFO] learning rate has been changed to 0.05005645751953125
[2018-08-21 13:11:18,707 INFO] | epoch  28 | train_loss  3.58 | val_ppl 65.53005 | time  58.4s
[2018-08-21 13:11:18,708 INFO] learning rate has been changed to 0.03754234313964844
[2018-08-21 13:12:17,266 INFO] | epoch  29 | train_loss  3.57 | val_ppl 65.36695 | time  58.6s
[2018-08-21 13:12:17,267 INFO] learning rate has been changed to 0.028156757354736328
[2018-08-21 13:13:15,704 INFO] | epoch  30 | train_loss  3.57 | val_ppl 65.23231 | time  58.4s
[2018-08-21 13:13:15,704 INFO] learning rate has been changed to 0.021117568016052246
[2018-08-21 13:14:14,156 INFO] | epoch  31 | train_loss  3.57 | val_ppl 65.12569 | time  58.5s
[2018-08-21 13:14:14,156 INFO] learning rate has been changed to 0.015838176012039185
[2018-08-21 13:15:12,612 INFO] | epoch  32 | train_loss  3.56 | val_ppl 65.04483 | time  58.5s
[2018-08-21 13:15:12,613 INFO] learning rate has been changed to 0.011878632009029388
[2018-08-21 13:16:10,995 INFO] | epoch  33 | train_loss  3.56 | val_ppl 64.98545 | time  58.4s
[2018-08-21 13:16:10,996 INFO] learning rate has been changed to 0.008908974006772041
[2018-08-21 13:17:09,746 INFO] | epoch  34 | train_loss  3.56 | val_ppl 64.94276 | time  58.7s
[2018-08-21 13:17:09,747 INFO] learning rate has been changed to 0.006681730505079031
[2018-08-21 13:18:08,486 INFO] | epoch  35 | train_loss  3.56 | val_ppl 64.91283 | time  58.7s
[2018-08-21 13:18:08,487 INFO] learning rate has been changed to 0.005011297878809273
[2018-08-21 13:19:06,946 INFO] | epoch  36 | train_loss  3.56 | val_ppl 64.89236 | time  58.5s
[2018-08-21 13:19:06,946 INFO] learning rate has been changed to 0.003758473409106955
[2018-08-21 13:20:05,353 INFO] | epoch  37 | train_loss  3.56 | val_ppl 64.87828 | time  58.4s
[2018-08-21 13:20:05,354 INFO] learning rate has been changed to 0.002818855056830216
[2018-08-21 13:21:03,789 INFO] | epoch  38 | train_loss  3.56 | val_ppl 64.86765 | time  58.4s
[2018-08-21 13:21:03,789 INFO] learning rate has been changed to 0.002114141292622662
[2018-08-21 13:22:02,425 INFO] | epoch  39 | train_loss  3.56 | val_ppl 64.85842 | time  58.6s
[2018-08-21 13:22:02,425 INFO] learning rate has been changed to 0.0015856059694669966
[2018-08-21 13:23:00,843 INFO] | epoch  40 | train_loss  3.56 | val_ppl 64.84995 | time  58.4s
[2018-08-21 13:23:00,844 INFO] learning rate has been changed to 0.0011892044771002475
[2018-08-21 13:23:00,844 INFO] start to save model on nnlm.model
[2018-08-21 13:23:04,177 INFO] test_ppl: 63.51463
[2018-08-21 14:42:32,265 INFO] -------------


(both randomly inited)
[2018-08-21 14:42:32,265 INFO] Start training...
[2018-08-21 14:42:32,265 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay=0.75, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_save=40, input_vector='~/common_corpus/1mlplen_8epoch_850d.outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/1mlplen_8epoch_850d.outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=240, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-21 14:42:43,370 INFO] train token: 2127402
[2018-08-21 14:42:43,370 INFO] test token: 250140
[2018-08-21 14:42:43,370 INFO] valid token: 221606
[2018-08-21 14:42:43,371 INFO] Loading vectors from /home/lr/yukun/common_corpus/1mlplen_8epoch_850d.outemb.txt.pt
[2018-08-21 14:43:52,535 INFO] | epoch   1 | train_loss 12.86 | val_ppl 2543.43177 | time  55.8s
[2018-08-21 14:44:48,453 INFO] | epoch   2 | train_loss  6.84 | val_ppl 1141.13518 | time  55.9s
[2018-08-21 14:45:45,183 INFO] | epoch   3 | train_loss  6.35 | val_ppl 966.83239 | time  56.7s
[2018-08-21 14:46:42,249 INFO] | epoch   4 | train_loss  6.09 | val_ppl 895.19187 | time  57.1s
[2018-08-21 14:47:39,742 INFO] | epoch   5 | train_loss  5.90 | val_ppl 817.09658 | time  57.5s
[2018-08-21 14:48:59,695 INFO] -------------
[2018-08-21 15:07:19,534 INFO] -------------
[2018-08-21 15:07:19,535 INFO] Start training...
[2018-08-21 15:07:19,535 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay=0.75, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_save=40, input_vector='~/common_corpus/1mlplen_8epoch_850d.outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/1mlplen_8epoch_850d.outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=15, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-21 15:07:30,322 INFO] train token: 2127402
[2018-08-21 15:07:30,322 INFO] test token: 250140
[2018-08-21 15:07:30,322 INFO] valid token: 221606
[2018-08-21 15:07:30,323 INFO] Loading vectors from /home/lr/yukun/common_corpus/1mlplen_8epoch_850d.outemb.txt.pt
[2018-08-21 15:08:39,655 INFO] | epoch   1 | train_loss 12.90 | val_ppl 2842.71205 | time  55.8s
[2018-08-21 15:09:35,653 INFO] | epoch   2 | train_loss  6.91 | val_ppl 1261.14680 | time  56.0s
[2018-08-21 15:10:32,291 INFO] | epoch   3 | train_loss  6.38 | val_ppl 1011.70354 | time  56.6s
[2018-08-21 15:11:29,589 INFO] | epoch   4 | train_loss  6.10 | val_ppl 916.33750 | time  57.3s
[2018-08-21 15:12:26,985 INFO] | epoch   5 | train_loss  5.91 | val_ppl 800.18154 | time  57.4s
[2018-08-21 15:13:25,021 INFO] | epoch   6 | train_loss  5.77 | val_ppl 727.06035 | time  58.0s
[2018-08-21 15:14:22,991 INFO] | epoch   7 | train_loss  5.64 | val_ppl 653.28314 | time  58.0s
[2018-08-21 15:15:21,388 INFO] | epoch   8 | train_loss  5.54 | val_ppl 601.38100 | time  58.4s
[2018-08-21 15:16:19,570 INFO] | epoch   9 | train_loss  5.45 | val_ppl 566.88534 | time  58.2s
[2018-08-21 15:17:17,989 INFO] | epoch  10 | train_loss  5.37 | val_ppl 530.70571 | time  58.4s
[2018-08-21 15:18:16,421 INFO] | epoch  11 | train_loss  5.29 | val_ppl 513.07334 | time  58.4s
[2018-08-21 15:19:14,842 INFO] | epoch  12 | train_loss  5.23 | val_ppl 472.84059 | time  58.4s
[2018-08-21 15:20:13,558 INFO] | epoch  13 | train_loss  5.16 | val_ppl 447.28063 | time  58.7s
[2018-08-21 15:21:11,995 INFO] | epoch  14 | train_loss  5.10 | val_ppl 435.93802 | time  58.4s
[2018-08-21 15:22:10,614 INFO] | epoch  15 | train_loss  5.05 | val_ppl 421.79929 | time  58.6s
[2018-08-21 15:23:09,146 INFO] | epoch  16 | train_loss  5.01 | val_ppl 413.33730 | time  58.5s
[2018-08-21 15:24:07,647 INFO] | epoch  17 | train_loss  4.97 | val_ppl 402.55912 | time  58.5s
[2018-08-21 15:25:05,952 INFO] | epoch  18 | train_loss  4.93 | val_ppl 397.80583 | time  58.3s
[2018-08-21 15:26:04,470 INFO] | epoch  19 | train_loss  4.89 | val_ppl 392.39773 | time  58.5s
[2018-08-21 15:27:03,050 INFO] | epoch  20 | train_loss  4.86 | val_ppl 391.35610 | time  58.6s
[2018-08-21 15:28:01,440 INFO] | epoch  21 | train_loss  4.83 | val_ppl 385.48137 | time  58.4s
[2018-08-21 15:28:59,903 INFO] | epoch  22 | train_loss  4.80 | val_ppl 379.34887 | time  58.5s
[2018-08-21 15:29:58,404 INFO] | epoch  23 | train_loss  4.77 | val_ppl 376.63588 | time  58.5s
[2018-08-21 15:30:56,762 INFO] | epoch  24 | train_loss  4.75 | val_ppl 377.34857 | time  58.4s
[2018-08-21 15:30:56,763 INFO] learning rate has been changed to 0.375
[2018-08-21 15:31:55,216 INFO] | epoch  25 | train_loss  4.64 | val_ppl 353.97177 | time  58.5s
[2018-08-21 15:32:53,498 INFO] | epoch  26 | train_loss  4.61 | val_ppl 354.13365 | time  58.3s
[2018-08-21 15:32:53,498 INFO] learning rate has been changed to 0.28125
[2018-08-21 15:33:52,120 INFO] | epoch  27 | train_loss  4.53 | val_ppl 334.35116 | time  58.6s
[2018-08-21 15:34:50,713 INFO] | epoch  28 | train_loss  4.52 | val_ppl 336.57926 | time  58.6s
[2018-08-21 15:34:50,714 INFO] learning rate has been changed to 0.2109375
[2018-08-21 15:35:49,501 INFO] | epoch  29 | train_loss  4.45 | val_ppl 322.56672 | time  58.8s
[2018-08-21 15:36:47,803 INFO] | epoch  30 | train_loss  4.44 | val_ppl 325.01765 | time  58.3s
[2018-08-21 15:36:47,804 INFO] learning rate has been changed to 0.158203125
[2018-08-21 15:37:46,467 INFO] | epoch  31 | train_loss  4.39 | val_ppl 315.18364 | time  58.7s
[2018-08-21 15:38:45,014 INFO] | epoch  32 | train_loss  4.38 | val_ppl 317.18651 | time  58.5s
[2018-08-21 15:38:45,015 INFO] learning rate has been changed to 0.11865234375
[2018-08-21 15:39:43,477 INFO] | epoch  33 | train_loss  4.34 | val_ppl 310.25172 | time  58.5s
[2018-08-21 15:40:42,264 INFO] | epoch  34 | train_loss  4.33 | val_ppl 312.25627 | time  58.8s
[2018-08-21 15:40:42,265 INFO] learning rate has been changed to 0.0889892578125
[2018-08-21 15:41:40,965 INFO] | epoch  35 | train_loss  4.30 | val_ppl 307.09348 | time  58.7s
[2018-08-21 15:42:39,611 INFO] | epoch  36 | train_loss  4.29 | val_ppl 308.26723 | time  58.6s
[2018-08-21 15:42:39,612 INFO] learning rate has been changed to 0.066741943359375
[2018-08-21 15:43:37,792 INFO] | epoch  37 | train_loss  4.27 | val_ppl 304.95716 | time  58.2s
[2018-08-21 15:44:36,516 INFO] | epoch  38 | train_loss  4.26 | val_ppl 305.90716 | time  58.7s
[2018-08-21 15:44:36,516 INFO] learning rate has been changed to 0.05005645751953125
[2018-08-21 15:45:34,778 INFO] | epoch  39 | train_loss  4.25 | val_ppl 303.53162 | time  58.3s
[2018-08-21 15:46:33,402 INFO] | epoch  40 | train_loss  4.24 | val_ppl 304.11338 | time  58.6s
[2018-08-21 15:46:33,403 INFO] learning rate has been changed to 0.03754234313964844
[2018-08-21 15:46:33,403 INFO] start to save model on nnlm.model
[2018-08-21 15:46:36,491 INFO] test_ppl: 296.93030
[2018-08-21 16:19:45,975 INFO] -------------
[2018-08-21 16:19:45,975 INFO] Start training...
[2018-08-21 16:19:45,975 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay=0.75, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_save=40, input_vector='~/common_corpus/1mlplen_8epoch_850d.outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/1mlplen_8epoch_850d.outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-21 16:19:57,028 INFO] train token: 2127402
[2018-08-21 16:19:57,029 INFO] test token: 250140
[2018-08-21 16:19:57,029 INFO] valid token: 221606
[2018-08-21 16:19:57,030 INFO] Loading vectors from /home/lr/yukun/common_corpus/1mlplen_8epoch_850d.outemb.txt.pt
[2018-08-21 16:21:05,873 INFO] | epoch   1 | train_loss 16.19 | val_ppl 21212.40138 | time  55.8s
[2018-08-21 16:22:05,625 INFO] | epoch   2 | train_loss  8.19 | val_ppl 3532.80028 | time  59.8s
[2018-08-21 16:23:11,716 INFO] | epoch   3 | train_loss  7.14 | val_ppl 2053.85551 | time  66.1s
[2018-08-21 16:24:08,896 INFO] | epoch   4 | train_loss  6.73 | val_ppl 1919.01050 | time  57.2s
[2018-08-21 16:25:06,436 INFO] | epoch   5 | train_loss  6.47 | val_ppl 1711.64162 | time  57.5s
[2018-08-21 16:26:04,779 INFO] | epoch   6 | train_loss  6.27 | val_ppl 1172.52068 | time  58.3s
[2018-08-21 16:27:02,845 INFO] | epoch   7 | train_loss  6.12 | val_ppl 1283.00496 | time  58.1s
[2018-08-21 16:27:02,846 INFO] learning rate has been changed to 0.375
[2018-08-21 16:28:01,402 INFO] | epoch   8 | train_loss  5.86 | val_ppl 783.94487 | time  58.6s
[2018-08-21 16:28:59,894 INFO] | epoch   9 | train_loss  5.78 | val_ppl 749.45993 | time  58.5s
[2018-08-21 16:29:58,508 INFO] | epoch  10 | train_loss  5.70 | val_ppl 720.33397 | time  58.6s
[2018-08-21 16:30:57,212 INFO] | epoch  11 | train_loss  5.63 | val_ppl 684.64643 | time  58.7s
[2018-08-21 16:31:55,724 INFO] | epoch  12 | train_loss  5.57 | val_ppl 651.16698 | time  58.5s
[2018-08-21 16:32:54,619 INFO] | epoch  13 | train_loss  5.52 | val_ppl 628.69579 | time  58.9s
[2018-08-21 16:33:53,068 INFO] | epoch  14 | train_loss  5.46 | val_ppl 594.59750 | time  58.4s
[2018-08-21 16:34:51,614 INFO] | epoch  15 | train_loss  5.42 | val_ppl 592.90156 | time  58.5s
[2018-08-21 16:35:49,859 INFO] | epoch  16 | train_loss  5.36 | val_ppl 580.18958 | time  58.2s
[2018-08-21 16:36:48,500 INFO] | epoch  17 | train_loss  5.32 | val_ppl 556.31382 | time  58.6s
[2018-08-21 16:37:49,783 INFO] | epoch  18 | train_loss  5.28 | val_ppl 533.53242 | time  61.3s
[2018-08-21 16:38:48,131 INFO] | epoch  19 | train_loss  5.24 | val_ppl 529.57963 | time  58.3s
[2018-08-21 16:39:47,071 INFO] | epoch  20 | train_loss  5.21 | val_ppl 513.24430 | time  58.9s
[2018-08-21 16:40:45,529 INFO] | epoch  21 | train_loss  5.17 | val_ppl 504.88127 | time  58.5s
[2018-08-21 16:41:43,996 INFO] | epoch  22 | train_loss  5.14 | val_ppl 495.76226 | time  58.5s
[2018-08-21 16:42:42,275 INFO] | epoch  23 | train_loss  5.11 | val_ppl 490.23183 | time  58.3s
[2018-08-21 16:43:40,808 INFO] | epoch  24 | train_loss  5.08 | val_ppl 485.65031 | time  58.5s
[2018-08-21 16:44:39,450 INFO] | epoch  25 | train_loss  5.05 | val_ppl 479.04532 | time  58.6s
[2018-08-21 16:45:37,857 INFO] | epoch  26 | train_loss  5.03 | val_ppl 476.29283 | time  58.4s
[2018-08-21 16:46:36,578 INFO] | epoch  27 | train_loss  5.00 | val_ppl 469.51624 | time  58.7s
[2018-08-21 16:47:35,058 INFO] | epoch  28 | train_loss  4.97 | val_ppl 466.43908 | time  58.5s
[2018-08-21 16:48:36,518 INFO] | epoch  29 | train_loss  4.95 | val_ppl 461.62295 | time  61.5s
[2018-08-21 16:49:35,017 INFO] | epoch  30 | train_loss  4.92 | val_ppl 457.27003 | time  58.5s
[2018-08-21 16:50:33,501 INFO] | epoch  31 | train_loss  4.90 | val_ppl 455.95244 | time  58.5s
[2018-08-21 16:51:32,020 INFO] | epoch  32 | train_loss  4.88 | val_ppl 452.08141 | time  58.5s
[2018-08-21 16:52:30,423 INFO] | epoch  33 | train_loss  4.86 | val_ppl 449.54239 | time  58.4s
[2018-08-21 16:53:29,214 INFO] | epoch  34 | train_loss  4.84 | val_ppl 447.81628 | time  58.8s
[2018-08-21 16:54:27,647 INFO] | epoch  35 | train_loss  4.82 | val_ppl 445.03757 | time  58.4s
[2018-08-21 16:55:26,227 INFO] | epoch  36 | train_loss  4.80 | val_ppl 443.46979 | time  58.6s
[2018-08-21 16:56:24,649 INFO] | epoch  37 | train_loss  4.78 | val_ppl 444.23538 | time  58.4s
[2018-08-21 16:56:24,650 INFO] learning rate has been changed to 0.28125
[2018-08-21 16:57:23,209 INFO] | epoch  38 | train_loss  4.66 | val_ppl 398.22783 | time  58.6s
[2018-08-21 16:58:21,718 INFO] | epoch  39 | train_loss  4.64 | val_ppl 400.29380 | time  58.5s
[2018-08-21 16:58:21,718 INFO] learning rate has been changed to 0.2109375
[2018-08-21 16:59:20,212 INFO] | epoch  40 | train_loss  4.56 | val_ppl 369.78106 | time  58.5s
[2018-08-21 16:59:20,213 INFO] start to save model on nnlm.model
[2018-08-21 16:59:23,285 INFO] test_ppl: 362.14361
[2018-08-22 20:50:39,299 INFO] -------------
[2018-08-22 20:50:39,299 INFO] Start training...
[2018-08-22 20:50:39,299 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay=0.75, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_save=40, input_vector='~/common_corpus/1mlplen_8epoch_10529v.850d.outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/1mlplen_8epoch_10529v.850d.outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=110, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-22 20:50:50,664 INFO] train token: 2127402
[2018-08-22 20:50:50,664 INFO] test token: 250140
[2018-08-22 20:50:50,664 INFO] valid token: 221606
[2018-08-22 20:50:51,247 INFO] Loading vectors from /home/lr/yukun/common_corpus/1mlplen_8epoch_10529v.850d.outemb.txt
[2018-08-22 20:50:51,251 WARNING] Skipping token 10528 with 1-dimensional vector ['850']; likely a header
[2018-08-22 20:50:54,059 INFO] Saving vectors to /home/lr/yukun/common_corpus/1mlplen_8epoch_10529v.850d.outemb.txt.pt
[2018-08-22 20:51:40,721 INFO] | epoch   1 | train_loss  5.43 | val_ppl 109.96954 | time  36.2s
[2018-08-22 20:52:17,374 INFO] | epoch   2 | train_loss  4.56 | val_ppl 89.26956 | time  36.7s
[2018-08-22 20:52:54,558 INFO] | epoch   3 | train_loss  4.39 | val_ppl 79.82265 | time  37.2s
[2018-08-22 20:53:31,714 INFO] | epoch   4 | train_loss  4.28 | val_ppl 73.74964 | time  37.2s
[2018-08-22 20:54:08,878 INFO] | epoch   5 | train_loss  4.19 | val_ppl 69.37019 | time  37.2s
[2018-08-22 20:54:46,248 INFO] | epoch   6 | train_loss  4.11 | val_ppl 66.05041 | time  37.4s
[2018-08-22 20:55:23,548 INFO] | epoch   7 | train_loss  4.05 | val_ppl 63.45000 | time  37.3s
[2018-08-22 20:56:01,113 INFO] | epoch   8 | train_loss  3.99 | val_ppl 61.37255 | time  37.6s
[2018-08-22 20:56:38,599 INFO] | epoch   9 | train_loss  3.94 | val_ppl 59.63209 | time  37.5s
[2018-08-22 20:57:16,415 INFO] | epoch  10 | train_loss  3.89 | val_ppl 58.17822 | time  37.8s
[2018-08-22 20:57:54,147 INFO] | epoch  11 | train_loss  3.84 | val_ppl 56.97795 | time  37.7s
[2018-08-22 20:58:31,923 INFO] | epoch  12 | train_loss  3.80 | val_ppl 55.98665 | time  37.8s
[2018-08-22 20:59:09,874 INFO] | epoch  13 | train_loss  3.76 | val_ppl 55.16792 | time  37.9s
[2018-08-22 20:59:47,868 INFO] | epoch  14 | train_loss  3.72 | val_ppl 54.49743 | time  38.0s
[2018-08-22 21:00:25,826 INFO] | epoch  15 | train_loss  3.68 | val_ppl 53.95477 | time  38.0s
[2018-08-22 21:01:03,730 INFO] | epoch  16 | train_loss  3.65 | val_ppl 53.52470 | time  37.9s
[2018-08-22 21:01:03,730 INFO] learning rate has been changed to 0.375
[2018-08-22 21:01:41,701 INFO] | epoch  17 | train_loss  3.60 | val_ppl 52.48631 | time  38.0s
[2018-08-22 21:02:19,639 INFO] | epoch  18 | train_loss  3.57 | val_ppl 52.35020 | time  37.9s
[2018-08-22 21:02:19,640 INFO] learning rate has been changed to 0.28125
[2018-08-22 21:02:57,600 INFO] | epoch  19 | train_loss  3.53 | val_ppl 51.68922 | time  38.0s
[2018-08-22 21:03:35,695 INFO] | epoch  20 | train_loss  3.51 | val_ppl 51.67147 | time  38.1s
[2018-08-22 21:03:35,695 INFO] learning rate has been changed to 0.2109375
[2018-08-22 21:04:13,775 INFO] | epoch  21 | train_loss  3.49 | val_ppl 51.19726 | time  38.1s
[2018-08-22 21:04:13,776 INFO] learning rate has been changed to 0.158203125
[2018-08-22 21:04:51,964 INFO] | epoch  22 | train_loss  3.47 | val_ppl 50.84348 | time  38.2s
[2018-08-22 21:04:51,965 INFO] learning rate has been changed to 0.11865234375
[2018-08-22 21:05:29,964 INFO] | epoch  23 | train_loss  3.45 | val_ppl 50.58218 | time  38.0s
[2018-08-22 21:05:29,965 INFO] learning rate has been changed to 0.0889892578125
[2018-08-22 21:06:07,994 INFO] | epoch  24 | train_loss  3.44 | val_ppl 50.37498 | time  38.0s
[2018-08-22 21:06:07,995 INFO] learning rate has been changed to 0.066741943359375
[2018-08-22 21:06:46,077 INFO] | epoch  25 | train_loss  3.43 | val_ppl 50.20005 | time  38.1s
[2018-08-22 21:06:46,078 INFO] learning rate has been changed to 0.05005645751953125
[2018-08-22 21:07:24,132 INFO] | epoch  26 | train_loss  3.43 | val_ppl 50.05144 | time  38.1s
[2018-08-22 21:07:24,132 INFO] learning rate has been changed to 0.03754234313964844
[2018-08-22 21:08:02,380 INFO] | epoch  27 | train_loss  3.42 | val_ppl 49.92704 | time  38.2s
[2018-08-22 21:08:02,381 INFO] learning rate has been changed to 0.028156757354736328
[2018-08-22 21:08:40,548 INFO] | epoch  28 | train_loss  3.42 | val_ppl 49.82446 | time  38.2s
[2018-08-22 21:08:40,548 INFO] learning rate has been changed to 0.021117568016052246
[2018-08-22 21:09:18,612 INFO] | epoch  29 | train_loss  3.42 | val_ppl 49.74123 | time  38.1s
[2018-08-22 21:09:18,612 INFO] learning rate has been changed to 0.015838176012039185
[2018-08-22 21:09:56,423 INFO] | epoch  30 | train_loss  3.41 | val_ppl 49.67493 | time  37.8s
[2018-08-22 21:09:56,424 INFO] learning rate has been changed to 0.011878632009029388
[2018-08-22 21:10:34,523 INFO] | epoch  31 | train_loss  3.41 | val_ppl 49.62366 | time  38.1s
[2018-08-22 21:10:34,524 INFO] learning rate has been changed to 0.008908974006772041
[2018-08-22 21:11:12,541 INFO] | epoch  32 | train_loss  3.41 | val_ppl 49.58557 | time  38.0s
[2018-08-22 21:11:12,541 INFO] learning rate has been changed to 0.006681730505079031
[2018-08-22 21:11:50,446 INFO] | epoch  33 | train_loss  3.41 | val_ppl 49.55802 | time  37.9s
[2018-08-22 21:11:50,447 INFO] learning rate has been changed to 0.005011297878809273
[2018-08-22 21:12:28,685 INFO] | epoch  34 | train_loss  3.41 | val_ppl 49.53830 | time  38.2s
[2018-08-22 21:12:28,686 INFO] learning rate has been changed to 0.003758473409106955
[2018-08-22 21:13:06,741 INFO] | epoch  35 | train_loss  3.41 | val_ppl 49.52442 | time  38.1s
[2018-08-22 21:13:06,742 INFO] learning rate has been changed to 0.002818855056830216
[2018-08-22 21:13:44,837 INFO] | epoch  36 | train_loss  3.41 | val_ppl 49.51506 | time  38.1s
[2018-08-22 21:13:44,837 INFO] learning rate has been changed to 0.002114141292622662
[2018-08-22 21:14:22,712 INFO] | epoch  37 | train_loss  3.41 | val_ppl 49.50899 | time  37.9s
[2018-08-22 21:14:22,713 INFO] learning rate has been changed to 0.0015856059694669966
[2018-08-22 21:15:00,873 INFO] | epoch  38 | train_loss  3.41 | val_ppl 49.50502 | time  38.2s
[2018-08-22 21:15:00,874 INFO] learning rate has been changed to 0.0011892044771002475
[2018-08-22 21:15:38,876 INFO] | epoch  39 | train_loss  3.41 | val_ppl 49.50228 | time  38.0s
[2018-08-22 21:15:38,877 INFO] learning rate has been changed to 0.0008919033578251856
[2018-08-22 21:16:16,888 INFO] | epoch  40 | train_loss  3.41 | val_ppl 49.50036 | time  38.0s
[2018-08-22 21:16:16,889 INFO] learning rate has been changed to 0.0006689275183688892
[2018-08-22 21:16:16,889 INFO] start to save model on nnlm.model
[2018-08-22 21:16:18,981 INFO] test_ppl: 48.86497
[2018-08-22 21:20:49,135 INFO] -------------
[2018-08-22 21:20:49,135 INFO] Start training...
[2018-08-22 21:20:49,135 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay=0.75, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_save=40, input_vector='~/common_corpus/1mlplen_8epoch_10529v.850d.outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/1mlplen_8epoch_10529v.850d.outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=110, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-22 21:21:00,004 INFO] train token: 2127402
[2018-08-22 21:21:00,005 INFO] test token: 250140
[2018-08-22 21:21:00,005 INFO] valid token: 221606
[2018-08-22 21:21:00,005 INFO] Loading vectors from /home/lr/yukun/common_corpus/1mlplen_8epoch_10529v.850d.outemb.txt.pt
[2018-08-22 21:21:46,408 INFO] | epoch   1 | train_loss 17.66 | val_ppl 1122471.44578 | time  36.5s
[2018-08-22 21:21:46,409 INFO] learning rate has been changed to 0.375
[2018-08-22 21:22:23,340 INFO] | epoch   2 | train_loss  7.72 | val_ppl 1782.33964 | time  36.9s
[2018-08-22 21:23:00,505 INFO] | epoch   3 | train_loss  6.75 | val_ppl 1133.69375 | time  37.2s
[2018-08-22 21:23:21,350 INFO] -------------
[2018-08-22 21:23:21,350 INFO] Start training...
[2018-08-22 21:23:21,350 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay=0.75, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_save=40, input_vector='~/common_corpus/1mlplen_8epoch_10529v.850d.outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/1mlplen_8epoch_10529v.850d.outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=200, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-22 21:23:32,991 INFO] train token: 2127402
[2018-08-22 21:23:32,992 INFO] test token: 250140
[2018-08-22 21:23:32,992 INFO] valid token: 221606
[2018-08-22 21:23:32,993 INFO] Loading vectors from /home/lr/yukun/common_corpus/1mlplen_8epoch_10529v.850d.outemb.txt.pt
[2018-08-22 21:24:19,522 INFO] | epoch   1 | train_loss 23.82 | val_ppl 15272855.88399 | time  37.0s
[2018-08-22 21:24:19,523 INFO] learning rate has been changed to 0.375
[2018-08-22 21:24:56,701 INFO] | epoch   2 | train_loss 12.47 | val_ppl 345547.45442 | time  37.2s
[2018-08-22 21:25:34,480 INFO] | epoch   3 | train_loss 11.00 | val_ppl 149234.86374 | time  37.8s
[2018-08-22 21:26:12,309 INFO] | epoch   4 | train_loss  9.89 | val_ppl 64532.12572 | time  37.8s
[2018-08-22 21:26:50,225 INFO] | epoch   5 | train_loss  9.37 | val_ppl 11988.96453 | time  37.9s
[2018-08-22 21:27:16,398 INFO] -------------
[2018-08-22 21:27:16,398 INFO] Start training...
[2018-08-22 21:27:16,399 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay=0.75, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_save=40, input_vector='~/common_corpus/1mlplen_8epoch_10529v.850d.outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/1mlplen_8epoch_10529v.850d.outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=2, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-22 21:27:27,943 INFO] train token: 2127402
[2018-08-22 21:27:27,944 INFO] test token: 250140
[2018-08-22 21:27:27,944 INFO] valid token: 221606
[2018-08-22 21:27:27,944 INFO] Loading vectors from /home/lr/yukun/common_corpus/1mlplen_8epoch_10529v.850d.outemb.txt.pt
[2018-08-22 21:28:14,806 INFO] | epoch   1 | train_loss 26.40 | val_ppl 565134728.14020 | time  37.0s
[2018-08-22 21:28:14,807 INFO] learning rate has been changed to 0.375
[2018-08-22 21:28:52,192 INFO] | epoch   2 | train_loss 14.55 | val_ppl 448093914.98428 | time  37.4s
[2018-08-22 21:29:30,257 INFO] | epoch   3 | train_loss 12.79 | val_ppl 1682761.42514 | time  38.1s
[2018-08-22 21:31:55,121 INFO] -------------
[2018-08-22 21:33:54,833 INFO] -------------
[2018-08-22 21:40:04,387 INFO] -------------
[2018-08-22 21:40:04,387 INFO] Start training...
[2018-08-22 21:40:04,387 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, decay=0.75, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-22 21:40:15,788 INFO] train token: 2127402
[2018-08-22 21:40:15,789 INFO] test token: 250140
[2018-08-22 21:40:15,789 INFO] valid token: 221606
[2018-08-22 21:40:15,790 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt.pt
[2018-08-22 21:41:02,489 INFO] | epoch   1 | train_loss  6.67 | val_ppl 120.38271 | time  36.5s
[2018-08-22 21:41:39,233 INFO] | epoch   2 | train_loss  4.62 | val_ppl 100.73773 | time  36.7s
[2018-08-22 21:42:16,471 INFO] | epoch   3 | train_loss  4.47 | val_ppl 88.02990 | time  37.2s
[2018-08-22 21:42:53,755 INFO] | epoch   4 | train_loss  4.38 | val_ppl 82.45454 | time  37.3s
[2018-08-22 21:43:30,941 INFO] | epoch   5 | train_loss  4.30 | val_ppl 78.31668 | time  37.2s
[2018-08-22 21:44:08,467 INFO] | epoch   6 | train_loss  4.24 | val_ppl 75.03976 | time  37.5s
[2018-08-22 21:44:46,060 INFO] | epoch   7 | train_loss  4.19 | val_ppl 72.36773 | time  37.6s
[2018-08-22 21:45:23,651 INFO] | epoch   8 | train_loss  4.14 | val_ppl 70.14923 | time  37.6s
[2018-08-22 21:46:01,346 INFO] | epoch   9 | train_loss  4.09 | val_ppl 68.29966 | time  37.7s
[2018-08-22 21:46:39,140 INFO] | epoch  10 | train_loss  4.05 | val_ppl 66.72101 | time  37.8s
[2018-08-22 21:47:17,004 INFO] | epoch  11 | train_loss  4.02 | val_ppl 65.33821 | time  37.9s
[2018-08-22 21:47:55,011 INFO] | epoch  12 | train_loss  3.98 | val_ppl 64.11534 | time  38.0s
[2018-08-22 21:48:33,083 INFO] | epoch  13 | train_loss  3.95 | val_ppl 63.03255 | time  38.1s
[2018-08-22 21:49:11,085 INFO] | epoch  14 | train_loss  3.92 | val_ppl 62.07489 | time  38.0s
[2018-08-22 21:49:49,186 INFO] | epoch  15 | train_loss  3.89 | val_ppl 61.22899 | time  38.1s
[2018-08-22 21:50:27,145 INFO] | epoch  16 | train_loss  3.86 | val_ppl 60.47496 | time  38.0s
[2018-08-22 21:51:05,180 INFO] | epoch  17 | train_loss  3.83 | val_ppl 59.81798 | time  38.0s
[2018-08-22 21:51:43,254 INFO] | epoch  18 | train_loss  3.80 | val_ppl 59.24138 | time  38.1s
[2018-08-22 21:52:21,197 INFO] | epoch  19 | train_loss  3.78 | val_ppl 58.74006 | time  37.9s
[2018-08-22 21:52:59,409 INFO] | epoch  20 | train_loss  3.75 | val_ppl 58.31200 | time  38.2s
[2018-08-22 21:52:59,410 INFO] learning rate has been changed to 0.375
[2018-08-22 21:53:37,372 INFO] | epoch  21 | train_loss  3.71 | val_ppl 57.04237 | time  38.0s
[2018-08-22 21:54:15,617 INFO] | epoch  22 | train_loss  3.69 | val_ppl 56.82690 | time  38.2s
[2018-08-22 21:54:15,618 INFO] learning rate has been changed to 0.28125
[2018-08-22 21:54:53,643 INFO] | epoch  23 | train_loss  3.67 | val_ppl 56.01399 | time  38.0s
[2018-08-22 21:55:31,694 INFO] | epoch  24 | train_loss  3.65 | val_ppl 55.89329 | time  38.1s
[2018-08-22 21:55:31,694 INFO] learning rate has been changed to 0.2109375
[2018-08-22 21:56:09,794 INFO] | epoch  25 | train_loss  3.63 | val_ppl 55.32490 | time  38.1s
[2018-08-22 21:56:47,821 INFO] | epoch  26 | train_loss  3.62 | val_ppl 55.25541 | time  38.0s
[2018-08-22 21:56:47,822 INFO] learning rate has been changed to 0.158203125
[2018-08-22 21:57:25,946 INFO] | epoch  27 | train_loss  3.61 | val_ppl 54.83735 | time  38.1s
[2018-08-22 21:57:25,947 INFO] learning rate has been changed to 0.11865234375
[2018-08-22 21:58:03,977 INFO] | epoch  28 | train_loss  3.60 | val_ppl 54.53472 | time  38.0s
[2018-08-22 21:58:03,977 INFO] learning rate has been changed to 0.0889892578125
[2018-08-22 21:58:41,971 INFO] | epoch  29 | train_loss  3.59 | val_ppl 54.31615 | time  38.0s
[2018-08-22 21:58:41,972 INFO] learning rate has been changed to 0.066741943359375
[2018-08-22 21:59:19,966 INFO] | epoch  30 | train_loss  3.58 | val_ppl 54.15461 | time  38.0s
[2018-08-22 21:59:19,967 INFO] learning rate has been changed to 0.05005645751953125
[2018-08-22 21:59:57,937 INFO] | epoch  31 | train_loss  3.58 | val_ppl 54.03337 | time  38.0s
[2018-08-22 21:59:57,937 INFO] learning rate has been changed to 0.03754234313964844
[2018-08-22 22:00:35,904 INFO] | epoch  32 | train_loss  3.58 | val_ppl 53.93889 | time  38.0s
[2018-08-22 22:00:35,970 INFO] learning rate has been changed to 0.028156757354736328
[2018-08-22 22:01:13,856 INFO] | epoch  33 | train_loss  3.57 | val_ppl 53.86514 | time  37.9s
[2018-08-22 22:01:13,856 INFO] learning rate has been changed to 0.021117568016052246
[2018-08-22 22:01:51,998 INFO] | epoch  34 | train_loss  3.57 | val_ppl 53.80879 | time  38.1s
[2018-08-22 22:01:51,999 INFO] learning rate has been changed to 0.015838176012039185
[2018-08-22 22:02:30,079 INFO] | epoch  35 | train_loss  3.57 | val_ppl 53.76725 | time  38.1s
[2018-08-22 22:02:30,080 INFO] learning rate has been changed to 0.011878632009029388
[2018-08-22 22:03:08,289 INFO] | epoch  36 | train_loss  3.57 | val_ppl 53.73798 | time  38.2s
[2018-08-22 22:03:08,290 INFO] learning rate has been changed to 0.008908974006772041
[2018-08-22 22:03:46,447 INFO] | epoch  37 | train_loss  3.57 | val_ppl 53.71807 | time  38.2s
[2018-08-22 22:03:46,448 INFO] learning rate has been changed to 0.006681730505079031
[2018-08-22 22:04:24,700 INFO] | epoch  38 | train_loss  3.57 | val_ppl 53.70441 | time  38.3s
[2018-08-22 22:04:24,700 INFO] learning rate has been changed to 0.005011297878809273
[2018-08-22 22:05:02,902 INFO] | epoch  39 | train_loss  3.57 | val_ppl 53.69448 | time  38.2s
[2018-08-22 22:05:02,903 INFO] learning rate has been changed to 0.003758473409106955
[2018-08-22 22:05:40,867 INFO] | epoch  40 | train_loss  3.57 | val_ppl 53.68681 | time  38.0s
[2018-08-22 22:05:40,868 INFO] learning rate has been changed to 0.002818855056830216
[2018-08-22 22:05:40,868 INFO] start to save model on nnlm.model
[2018-08-22 22:05:42,817 INFO] test_ppl: 52.34693
[2018-08-23 00:07:21,134 INFO] -------------
[2018-08-23 00:07:21,134 INFO] Start training...
[2018-08-23 00:07:21,134 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, data_type='wiki2', decay=0.75, device='cuda:1', dropout=0.0, epoch=40, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=200, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-23 00:07:32,352 INFO] train token: 2127402
[2018-08-23 00:07:32,352 INFO] test token: 250140
[2018-08-23 00:07:32,353 INFO] valid token: 221606
[2018-08-23 00:07:32,353 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt.pt
[2018-08-23 00:08:55,787 INFO] -------------


-------------------------
-  gradients exploding  -
-------------------------

explanation: seems gradients explode here. All the following nan may be gradients exploding
[2018-08-23 00:08:55,787 INFO] Start training...
[2018-08-23 00:08:55,787 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, data_type='wiki2', decay=0.75, device='cuda:0', dropout=0.0, epoch=40, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=200, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-23 00:09:07,521 INFO] train token: 2127402
[2018-08-23 00:09:07,522 INFO] test token: 250140
[2018-08-23 00:09:07,522 INFO] valid token: 221606
[2018-08-23 00:09:07,523 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt.pt
[2018-08-23 00:09:53,046 INFO] | epoch   1 | train_loss   nan | val_ppl      nan | time  38.3s
[2018-08-23 00:10:31,593 INFO] | epoch   2 | train_loss   nan | val_ppl      nan | time  38.5s
[2018-08-23 00:10:58,539 INFO] -------------
[2018-08-23 00:10:58,539 INFO] Start training...
[2018-08-23 00:10:58,540 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, data_type='wiki2', decay=0.75, device='cuda:0', dropout=0.0, epoch=40, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=200, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-23 00:11:09,961 INFO] train token: 2127402
[2018-08-23 00:11:09,962 INFO] test token: 250140
[2018-08-23 00:11:09,962 INFO] valid token: 221606
[2018-08-23 00:11:09,963 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt.pt
[2018-08-23 00:11:50,828 INFO] | epoch   1 | train_loss   nan | val_ppl      nan | time  34.2s
[2018-08-23 00:13:34,867 INFO] -------------
[2018-08-23 00:13:34,868 INFO] Start training...
[2018-08-23 00:13:34,868 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, data_type='wiki2', decay=0.75, device='cuda:0', dropout=0.0, epoch=40, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=201, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-23 00:13:46,377 INFO] train token: 2127402
[2018-08-23 00:13:46,377 INFO] test token: 250140
[2018-08-23 00:13:46,377 INFO] valid token: 221606
[2018-08-23 00:13:46,378 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt.pt
[2018-08-23 00:14:26,763 INFO] | epoch   1 | train_loss   nan | val_ppl      nan | time  34.1s
[2018-08-23 00:15:00,920 INFO] | epoch   2 | train_loss   nan | val_ppl      nan | time  34.2s
[2018-08-23 00:15:35,276 INFO] | epoch   3 | train_loss   nan | val_ppl      nan | time  34.4s
[2018-08-23 00:16:09,726 INFO] | epoch   4 | train_loss   nan | val_ppl      nan | time  34.4s
[2018-08-23 00:16:44,094 INFO] | epoch   5 | train_loss   nan | val_ppl      nan | time  34.4s
[2018-08-23 00:17:18,633 INFO] | epoch   6 | train_loss   nan | val_ppl      nan | time  34.5s
[2018-08-23 00:18:19,130 INFO] -------------
[2018-08-23 00:18:19,130 INFO] Start training...
[2018-08-23 00:18:19,130 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, data_type='wiki2', decay=0.75, device='cuda:0', dropout=0.0, epoch=40, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=21, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-23 00:18:30,566 INFO] train token: 2127402
[2018-08-23 00:18:30,566 INFO] test token: 250140
[2018-08-23 00:18:30,566 INFO] valid token: 221606
[2018-08-23 00:18:30,567 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt.pt
[2018-08-23 00:19:12,703 INFO] | epoch   1 | train_loss  6.56 | val_ppl 106.85491 | time  36.0s
[2018-08-23 00:19:49,030 INFO] | epoch   2 | train_loss  4.55 | val_ppl 92.23405 | time  36.3s
[2018-08-23 00:22:25,291 INFO] -------------
[2018-08-23 00:22:25,291 INFO] Start training...
[2018-08-23 00:22:25,292 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, data_type='ptb', decay=0.75, device='cuda:0', dropout=0.0, epoch=30, every_n_epoch_save=40, input_vector='~/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=200, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-23 00:22:31,428 INFO] train token: 994974
[2018-08-23 00:22:31,429 INFO] test token: 88160
[2018-08-23 00:22:31,429 INFO] valid token: 78932
[2018-08-23 00:22:31,496 INFO] Loading vectors from /home/lr/yukun/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt
[2018-08-23 00:22:31,498 WARNING] Skipping token 9859 with 1-dimensional vector ['100']; likely a header
[2018-08-23 00:22:31,857 INFO] Saving vectors to /home/lr/yukun/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt.pt
[2018-08-23 00:22:39,961 INFO] | epoch   1 | train_loss  5.75 | val_ppl 211.89155 | time   4.0s
[2018-08-23 00:22:43,876 INFO] | epoch   2 | train_loss  5.31 | val_ppl 177.88392 | time   3.9s
[2018-08-23 00:22:47,791 INFO] | epoch   3 | train_loss  5.16 | val_ppl 159.84580 | time   3.9s
[2018-08-23 00:22:51,756 INFO] | epoch   4 | train_loss  5.06 | val_ppl 148.02253 | time   4.0s
[2018-08-23 00:22:55,797 INFO] | epoch   5 | train_loss  4.98 | val_ppl 139.48625 | time   4.0s
[2018-08-23 00:22:59,816 INFO] | epoch   6 | train_loss  4.92 | val_ppl 132.93066 | time   4.0s
[2018-08-23 00:23:03,735 INFO] | epoch   7 | train_loss  4.87 | val_ppl 127.82604 | time   3.9s
[2018-08-23 00:23:07,786 INFO] | epoch   8 | train_loss  4.83 | val_ppl 123.75116 | time   4.1s
[2018-08-23 00:23:11,749 INFO] | epoch   9 | train_loss  4.79 | val_ppl 120.35090 | time   4.0s
[2018-08-23 00:23:15,689 INFO] | epoch  10 | train_loss  4.75 | val_ppl 117.41319 | time   3.9s
[2018-08-23 00:23:19,638 INFO] | epoch  11 | train_loss  4.72 | val_ppl 114.83331 | time   3.9s
[2018-08-23 00:23:23,578 INFO] | epoch  12 | train_loss  4.69 | val_ppl 112.56424 | time   3.9s
[2018-08-23 00:23:27,590 INFO] | epoch  13 | train_loss  4.67 | val_ppl 110.54499 | time   4.0s
[2018-08-23 00:23:31,576 INFO] | epoch  14 | train_loss  4.64 | val_ppl 108.73252 | time   4.0s
[2018-08-23 00:23:35,595 INFO] | epoch  15 | train_loss  4.62 | val_ppl 107.10105 | time   4.0s
[2018-08-23 00:23:39,492 INFO] | epoch  16 | train_loss  4.60 | val_ppl 105.62853 | time   3.9s
[2018-08-23 00:23:43,484 INFO] | epoch  17 | train_loss  4.58 | val_ppl 104.29365 | time   4.0s
[2018-08-23 00:23:47,582 INFO] | epoch  18 | train_loss  4.56 | val_ppl 103.07733 | time   4.1s
[2018-08-23 00:23:51,569 INFO] | epoch  19 | train_loss  4.54 | val_ppl 101.96324 | time   4.0s
[2018-08-23 00:23:55,529 INFO] | epoch  20 | train_loss  4.52 | val_ppl 100.93736 | time   4.0s
[2018-08-23 00:23:59,486 INFO] | epoch  21 | train_loss  4.51 | val_ppl 99.98771 | time   4.0s
[2018-08-23 00:24:03,444 INFO] | epoch  22 | train_loss  4.49 | val_ppl 99.10436 | time   4.0s
[2018-08-23 00:24:07,397 INFO] | epoch  23 | train_loss  4.48 | val_ppl 98.27935 | time   4.0s
[2018-08-23 00:24:11,344 INFO] | epoch  24 | train_loss  4.46 | val_ppl 97.50662 | time   3.9s
[2018-08-23 00:24:15,307 INFO] | epoch  25 | train_loss  4.45 | val_ppl 96.78145 | time   4.0s
[2018-08-23 00:24:19,269 INFO] | epoch  26 | train_loss  4.44 | val_ppl 96.09969 | time   4.0s
[2018-08-23 00:24:23,226 INFO] | epoch  27 | train_loss  4.42 | val_ppl 95.45762 | time   4.0s
[2018-08-23 00:24:27,358 INFO] | epoch  28 | train_loss  4.41 | val_ppl 94.85205 | time   4.1s
[2018-08-23 00:24:31,542 INFO] | epoch  29 | train_loss  4.40 | val_ppl 94.28028 | time   4.2s
[2018-08-23 00:24:35,513 INFO] | epoch  30 | train_loss  4.39 | val_ppl 93.74005 | time   4.0s
[2018-08-23 00:24:35,639 INFO] test_ppl: 95.38523
[2018-08-23 00:25:29,260 INFO] -------------
[2018-08-23 00:25:29,260 INFO] Start training...
[2018-08-23 00:25:29,260 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, clip=None, data_type='ptb', decay=0.75, device='cuda:0', dropout=0.0, epoch=30, every_n_epoch_save=40, input_vector='~/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=20, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-23 00:25:35,159 INFO] train token: 994974
[2018-08-23 00:25:35,159 INFO] test token: 88160
[2018-08-23 00:25:35,159 INFO] valid token: 78932
[2018-08-23 00:25:35,160 INFO] Loading vectors from /home/lr/yukun/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt.pt
[2018-08-23 00:25:44,758 INFO] | epoch   1 | train_loss  5.49 | val_ppl 179.39046 | time   5.4s
[2018-08-23 00:25:49,951 INFO] | epoch   2 | train_loss  5.08 | val_ppl 148.08357 | time   5.2s
[2018-08-23 00:25:55,251 INFO] | epoch   3 | train_loss  4.93 | val_ppl 133.52405 | time   5.3s
[2018-08-23 00:26:00,345 INFO] | epoch   4 | train_loss  4.83 | val_ppl 124.56651 | time   5.1s
[2018-08-23 00:26:05,702 INFO] | epoch   5 | train_loss  4.75 | val_ppl 118.19424 | time   5.4s
[2018-08-23 00:26:10,904 INFO] | epoch   6 | train_loss  4.69 | val_ppl 113.39243 | time   5.2s
[2018-08-23 00:26:15,953 INFO] | epoch   7 | train_loss  4.64 | val_ppl 109.58183 | time   5.0s
[2018-08-23 00:26:20,488 INFO] | epoch   8 | train_loss  4.60 | val_ppl 106.46847 | time   4.5s
[2018-08-23 00:26:25,032 INFO] | epoch   9 | train_loss  4.56 | val_ppl 103.87123 | time   4.5s
[2018-08-23 00:26:29,589 INFO] | epoch  10 | train_loss  4.52 | val_ppl 101.66639 | time   4.6s
[2018-08-23 00:26:34,141 INFO] | epoch  11 | train_loss  4.49 | val_ppl 99.78695 | time   4.6s
[2018-08-23 00:26:38,696 INFO] | epoch  12 | train_loss  4.46 | val_ppl 98.17368 | time   4.6s
[2018-08-23 00:26:43,369 INFO] | epoch  13 | train_loss  4.43 | val_ppl 96.77393 | time   4.7s
[2018-08-23 00:26:48,558 INFO] | epoch  14 | train_loss  4.41 | val_ppl 95.54875 | time   5.2s
[2018-08-23 00:26:53,682 INFO] | epoch  15 | train_loss  4.38 | val_ppl 94.47340 | time   5.1s
[2018-08-23 00:26:58,666 INFO] | epoch  16 | train_loss  4.36 | val_ppl 93.53021 | time   5.0s
[2018-08-23 00:27:03,764 INFO] | epoch  17 | train_loss  4.34 | val_ppl 92.70391 | time   5.1s
[2018-08-23 00:27:08,838 INFO] | epoch  18 | train_loss  4.32 | val_ppl 91.98044 | time   5.1s
[2018-08-23 00:27:14,014 INFO] | epoch  19 | train_loss  4.30 | val_ppl 91.34647 | time   5.2s
[2018-08-23 00:27:19,002 INFO] | epoch  20 | train_loss  4.28 | val_ppl 90.79130 | time   5.0s
[2018-08-23 00:27:23,824 INFO] | epoch  21 | train_loss  4.26 | val_ppl 90.30742 | time   4.8s
[2018-08-23 00:27:23,825 INFO] learning rate has been changed to 0.375
[2018-08-23 00:27:28,380 INFO] | epoch  22 | train_loss  4.24 | val_ppl 89.37092 | time   4.6s
[2018-08-23 00:27:32,976 INFO] | epoch  23 | train_loss  4.23 | val_ppl 89.10285 | time   4.6s
[2018-08-23 00:27:32,976 INFO] learning rate has been changed to 0.28125
[2018-08-23 00:27:38,316 INFO] | epoch  24 | train_loss  4.21 | val_ppl 88.48295 | time   5.3s
[2018-08-23 00:27:43,736 INFO] | epoch  25 | train_loss  4.20 | val_ppl 88.32288 | time   5.4s
[2018-08-23 00:27:43,736 INFO] learning rate has been changed to 0.2109375
[2018-08-23 00:27:48,625 INFO] | epoch  26 | train_loss  4.19 | val_ppl 87.88888 | time   4.9s
[2018-08-23 00:27:48,626 INFO] learning rate has been changed to 0.158203125
[2018-08-23 00:27:53,539 INFO] | epoch  27 | train_loss  4.18 | val_ppl 87.56541 | time   4.9s
[2018-08-23 00:27:53,539 INFO] learning rate has been changed to 0.11865234375
[2018-08-23 00:27:58,733 INFO] | epoch  28 | train_loss  4.17 | val_ppl 87.32628 | time   5.2s
[2018-08-23 00:27:58,733 INFO] learning rate has been changed to 0.0889892578125
[2018-08-23 00:28:04,070 INFO] | epoch  29 | train_loss  4.17 | val_ppl 87.15484 | time   5.3s
[2018-08-23 00:28:04,070 INFO] learning rate has been changed to 0.066741943359375
[2018-08-23 00:28:09,461 INFO] | epoch  30 | train_loss  4.16 | val_ppl 87.03591 | time   5.4s
[2018-08-23 00:28:09,461 INFO] learning rate has been changed to 0.05005645751953125
[2018-08-23 00:28:09,622 INFO] test_ppl: 88.95632
[2018-08-23 00:36:56,439 INFO] -------------
[2018-08-23 00:36:56,439 INFO] Start training...
[2018-08-23 00:36:56,439 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=35, clip=None, data_type='ptb', decay=0.75, device='cuda:0', dropout=0.0, epoch=30, every_n_epoch_save=40, input_vector='./35bptt_30epoch_outemb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./35bptt_30epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=20, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-23 00:37:02,484 INFO] train token: 994974
[2018-08-23 00:37:02,484 INFO] test token: 88160
[2018-08-23 00:37:02,484 INFO] valid token: 78932
[2018-08-23 00:37:02,491 INFO] Loading vectors from 35bptt_30epoch_outemb.txt
[2018-08-23 00:37:02,494 WARNING] Skipping token 9859 with 1-dimensional vector ['100']; likely a header
[2018-08-23 00:37:02,816 INFO] Saving vectors to ./35bptt_30epoch_outemb.txt.pt
[2018-08-23 00:37:12,319 INFO] | epoch   1 | train_loss  4.81 | val_ppl 102.49405 | time   5.2s
[2018-08-23 00:37:17,812 INFO] | epoch   2 | train_loss  4.41 | val_ppl 94.54054 | time   5.5s
[2018-08-23 00:37:23,276 INFO] | epoch   3 | train_loss  4.32 | val_ppl 91.48941 | time   5.5s
[2018-08-23 00:37:28,184 INFO] | epoch   4 | train_loss  4.27 | val_ppl 89.92030 | time   4.9s
[2018-08-23 00:37:33,391 INFO] | epoch   5 | train_loss  4.24 | val_ppl 88.98332 | time   5.2s
[2018-08-23 00:37:38,426 INFO] | epoch   6 | train_loss  4.21 | val_ppl 88.36001 | time   5.0s
[2018-08-23 00:37:43,484 INFO] | epoch   7 | train_loss  4.19 | val_ppl 87.90622 | time   5.1s
[2018-08-23 00:37:43,485 INFO] learning rate has been changed to 0.375
[2018-08-23 00:37:48,728 INFO] | epoch   8 | train_loss  4.17 | val_ppl 86.98204 | time   5.2s
[2018-08-23 00:37:53,629 INFO] | epoch   9 | train_loss  4.15 | val_ppl 86.78745 | time   4.9s
[2018-08-23 00:37:53,629 INFO] learning rate has been changed to 0.28125
[2018-08-23 00:37:58,824 INFO] | epoch  10 | train_loss  4.14 | val_ppl 86.18346 | time   5.2s
[2018-08-23 00:38:03,634 INFO] | epoch  11 | train_loss  4.13 | val_ppl 86.08359 | time   4.8s
[2018-08-23 00:38:03,634 INFO] learning rate has been changed to 0.2109375
[2018-08-23 00:38:08,665 INFO] | epoch  12 | train_loss  4.12 | val_ppl 85.66083 | time   5.0s
[2018-08-23 00:38:08,666 INFO] learning rate has been changed to 0.158203125
[2018-08-23 00:38:13,880 INFO] | epoch  13 | train_loss  4.11 | val_ppl 85.35460 | time   5.2s
[2018-08-23 00:38:13,880 INFO] learning rate has been changed to 0.11865234375
[2018-08-23 00:38:19,174 INFO] | epoch  14 | train_loss  4.10 | val_ppl 85.13622 | time   5.3s
[2018-08-23 00:38:19,175 INFO] learning rate has been changed to 0.0889892578125
[2018-08-23 00:38:24,144 INFO] | epoch  15 | train_loss  4.09 | val_ppl 84.98389 | time   5.0s
[2018-08-23 00:38:24,144 INFO] learning rate has been changed to 0.066741943359375
[2018-08-23 00:38:29,354 INFO] | epoch  16 | train_loss  4.09 | val_ppl 84.87904 | time   5.2s
[2018-08-23 00:38:29,354 INFO] learning rate has been changed to 0.05005645751953125
[2018-08-23 00:38:34,732 INFO] | epoch  17 | train_loss  4.09 | val_ppl 84.80514 | time   5.4s
[2018-08-23 00:38:34,733 INFO] learning rate has been changed to 0.03754234313964844
[2018-08-23 00:38:39,777 INFO] | epoch  18 | train_loss  4.08 | val_ppl 84.74887 | time   5.0s
[2018-08-23 00:38:39,777 INFO] learning rate has been changed to 0.028156757354736328
[2018-08-23 00:38:44,945 INFO] | epoch  19 | train_loss  4.08 | val_ppl 84.70192 | time   5.2s
[2018-08-23 00:38:44,946 INFO] learning rate has been changed to 0.021117568016052246
[2018-08-23 00:38:50,055 INFO] | epoch  20 | train_loss  4.08 | val_ppl 84.66100 | time   5.1s
[2018-08-23 00:38:50,055 INFO] learning rate has been changed to 0.015838176012039185
[2018-08-23 00:38:55,084 INFO] | epoch  21 | train_loss  4.08 | val_ppl 84.62601 | time   5.0s
[2018-08-23 00:38:55,084 INFO] learning rate has been changed to 0.011878632009029388
[2018-08-23 00:39:00,160 INFO] | epoch  22 | train_loss  4.08 | val_ppl 84.59759 | time   5.1s
[2018-08-23 00:39:00,161 INFO] learning rate has been changed to 0.008908974006772041
[2018-08-23 00:39:05,203 INFO] | epoch  23 | train_loss  4.08 | val_ppl 84.57553 | time   5.0s
[2018-08-23 00:39:05,203 INFO] learning rate has been changed to 0.006681730505079031
[2018-08-23 00:39:10,238 INFO] | epoch  24 | train_loss  4.08 | val_ppl 84.55853 | time   5.0s
[2018-08-23 00:39:10,238 INFO] learning rate has been changed to 0.005011297878809273
[2018-08-23 00:39:15,351 INFO] | epoch  25 | train_loss  4.08 | val_ppl 84.54499 | time   5.1s
[2018-08-23 00:39:15,352 INFO] learning rate has been changed to 0.003758473409106955
[2018-08-23 00:39:20,496 INFO] | epoch  26 | train_loss  4.08 | val_ppl 84.53389 | time   5.1s
[2018-08-23 00:39:20,497 INFO] learning rate has been changed to 0.002818855056830216
[2018-08-23 00:39:25,679 INFO] | epoch  27 | train_loss  4.08 | val_ppl 84.52494 | time   5.2s
[2018-08-23 00:39:25,680 INFO] learning rate has been changed to 0.002114141292622662
[2018-08-23 00:39:30,820 INFO] | epoch  28 | train_loss  4.08 | val_ppl 84.51812 | time   5.1s
[2018-08-23 00:39:30,821 INFO] learning rate has been changed to 0.0015856059694669966
[2018-08-23 00:39:36,218 INFO] | epoch  29 | train_loss  4.08 | val_ppl 84.51322 | time   5.4s
[2018-08-23 00:39:36,218 INFO] learning rate has been changed to 0.0011892044771002475
[2018-08-23 00:39:41,259 INFO] | epoch  30 | train_loss  4.08 | val_ppl 84.50983 | time   5.0s
[2018-08-23 00:39:41,259 INFO] learning rate has been changed to 0.0008919033578251856
[2018-08-23 00:39:41,420 INFO] test_ppl: 85.98910
[2018-08-23 01:02:27,237 INFO] -------------
[2018-08-23 01:02:27,237 INFO] Start training...
[2018-08-23 01:02:27,237 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=22, clip=None, data_type='ptb', decay=0.75, device='cuda:0', dropout=0.0, epoch=30, every_n_epoch_save=40, input_vector='~/common_corpus/1mlplen_8epoch_outemb.ptb.850d.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/1mlplen_8epoch_outemb.ptb.850d.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=240, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-23 01:02:32,352 INFO] train token: 994974
[2018-08-23 01:02:32,353 INFO] test token: 88160
[2018-08-23 01:02:32,353 INFO] valid token: 78932
[2018-08-23 01:02:32,895 INFO] Loading vectors from /home/lr/yukun/common_corpus/1mlplen_8epoch_outemb.ptb.850d.txt
[2018-08-23 01:02:32,899 WARNING] Skipping token 9860 with 1-dimensional vector ['850']; likely a header
[2018-08-23 01:02:35,672 INFO] Saving vectors to /home/lr/yukun/common_corpus/1mlplen_8epoch_outemb.ptb.850d.txt.pt
[2018-08-23 01:03:03,875 INFO] | epoch   1 | train_loss  5.31 | val_ppl 150.11494 | time  21.0s
[2018-08-23 01:03:25,009 INFO] | epoch   2 | train_loss  4.80 | val_ppl 123.35027 | time  21.1s
[2018-08-23 01:03:46,221 INFO] | epoch   3 | train_loss  4.60 | val_ppl 108.68611 | time  21.2s
[2018-08-23 01:04:07,509 INFO] | epoch   4 | train_loss  4.45 | val_ppl 100.06774 | time  21.3s
[2018-08-23 01:04:28,876 INFO] | epoch   5 | train_loss  4.33 | val_ppl 94.36077 | time  21.4s
[2018-08-23 01:04:50,380 INFO] | epoch   6 | train_loss  4.21 | val_ppl 90.78372 | time  21.5s
[2018-08-23 01:05:12,130 INFO] | epoch   7 | train_loss  4.11 | val_ppl 88.76381 | time  21.7s
[2018-08-23 01:05:33,889 INFO] | epoch   8 | train_loss  4.01 | val_ppl 87.86144 | time  21.8s
[2018-08-23 01:05:55,667 INFO] | epoch   9 | train_loss  3.91 | val_ppl 87.86494 | time  21.8s
[2018-08-23 01:05:55,668 INFO] learning rate has been changed to 0.375
[2018-08-23 01:06:17,411 INFO] | epoch  10 | train_loss  3.78 | val_ppl 85.70385 | time  21.7s
[2018-08-23 01:06:39,248 INFO] | epoch  11 | train_loss  3.70 | val_ppl 87.08079 | time  21.8s
[2018-08-23 01:06:39,248 INFO] learning rate has been changed to 0.28125
[2018-08-23 01:07:01,067 INFO] | epoch  12 | train_loss  3.59 | val_ppl 86.46582 | time  21.8s
[2018-08-23 01:07:22,909 INFO] | epoch  13 | train_loss  3.53 | val_ppl 88.51709 | time  21.8s
[2018-08-23 01:07:22,910 INFO] learning rate has been changed to 0.2109375
[2018-08-23 01:07:44,822 INFO] | epoch  14 | train_loss  3.44 | val_ppl 88.96721 | time  21.9s
[2018-08-23 01:07:44,823 INFO] learning rate has been changed to 0.158203125
[2018-08-23 01:08:06,801 INFO] | epoch  15 | train_loss  3.36 | val_ppl 89.64146 | time  22.0s
[2018-08-23 01:08:06,801 INFO] learning rate has been changed to 0.11865234375
[2018-08-23 01:08:28,676 INFO] | epoch  16 | train_loss  3.31 | val_ppl 90.30828 | time  21.9s
[2018-08-23 01:08:28,677 INFO] learning rate has been changed to 0.0889892578125
[2018-08-23 01:08:50,655 INFO] | epoch  17 | train_loss  3.26 | val_ppl 90.85869 | time  22.0s
[2018-08-23 01:08:50,656 INFO] learning rate has been changed to 0.066741943359375
[2018-08-23 01:09:12,665 INFO] | epoch  18 | train_loss  3.23 | val_ppl 91.24145 | time  22.0s
[2018-08-23 01:09:12,666 INFO] learning rate has been changed to 0.05005645751953125
[2018-08-23 01:09:34,671 INFO] | epoch  19 | train_loss  3.21 | val_ppl 91.44497 | time  22.0s
[2018-08-23 01:09:34,672 INFO] learning rate has been changed to 0.03754234313964844
[2018-08-23 01:09:56,599 INFO] | epoch  20 | train_loss  3.19 | val_ppl 91.50361 | time  21.9s
[2018-08-23 01:09:56,600 INFO] learning rate has been changed to 0.028156757354736328
[2018-08-23 01:10:18,709 INFO] | epoch  21 | train_loss  3.17 | val_ppl 91.47278 | time  22.1s
[2018-08-23 01:10:18,709 INFO] learning rate has been changed to 0.021117568016052246
[2018-08-23 01:10:40,688 INFO] | epoch  22 | train_loss  3.17 | val_ppl 91.40111 | time  22.0s
[2018-08-23 01:10:40,689 INFO] learning rate has been changed to 0.015838176012039185
[2018-08-23 01:11:02,660 INFO] | epoch  23 | train_loss  3.16 | val_ppl 91.32329 | time  22.0s
[2018-08-23 01:11:02,661 INFO] learning rate has been changed to 0.011878632009029388
[2018-08-23 01:11:24,633 INFO] | epoch  24 | train_loss  3.16 | val_ppl 91.25922 | time  22.0s
[2018-08-23 01:11:24,634 INFO] learning rate has been changed to 0.008908974006772041
[2018-08-23 01:11:46,667 INFO] | epoch  25 | train_loss  3.15 | val_ppl 91.21408 | time  22.0s
[2018-08-23 01:11:46,668 INFO] learning rate has been changed to 0.006681730505079031
[2018-08-23 01:12:08,673 INFO] | epoch  26 | train_loss  3.15 | val_ppl 91.18257 | time  22.0s
[2018-08-23 01:12:08,674 INFO] learning rate has been changed to 0.005011297878809273
[2018-08-23 01:12:30,681 INFO] | epoch  27 | train_loss  3.15 | val_ppl 91.15596 | time  22.0s
[2018-08-23 01:12:30,682 INFO] learning rate has been changed to 0.003758473409106955
[2018-08-23 01:12:52,830 INFO] | epoch  28 | train_loss  3.15 | val_ppl 91.12831 | time  22.1s
[2018-08-23 01:12:52,831 INFO] learning rate has been changed to 0.002818855056830216
[2018-08-23 01:13:14,855 INFO] | epoch  29 | train_loss  3.15 | val_ppl 91.09850 | time  22.0s
[2018-08-23 01:13:14,855 INFO] learning rate has been changed to 0.002114141292622662
[2018-08-23 01:13:36,860 INFO] | epoch  30 | train_loss  3.15 | val_ppl 91.06907 | time  22.0s
[2018-08-23 01:13:36,861 INFO] learning rate has been changed to 0.0015856059694669966
[2018-08-23 01:13:37,424 INFO] test_ppl: 94.41331
[2018-08-23 10:48:49,178 INFO] -------------


(randomly inited)
[2018-08-23 10:48:49,178 INFO] Start training...
[2018-08-23 10:48:49,179 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, data_type='wiki2', decay=0.75, device='cuda:0', dropout=0.0, epoch=40, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-23 10:49:00,632 INFO] train token: 2127402
[2018-08-23 10:49:00,633 INFO] test token: 250140
[2018-08-23 10:49:00,633 INFO] valid token: 221606
[2018-08-23 10:49:00,634 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt.pt
[2018-08-23 10:49:42,520 INFO] | epoch   1 | train_loss 21.72 | val_ppl 4162637.61411 | time  35.6s
[2018-08-23 10:49:42,520 INFO] learning rate has been changed to 0.375
[2018-08-23 10:50:18,468 INFO] | epoch   2 | train_loss 10.53 | val_ppl 3216171.87272 | time  35.9s
[2018-08-23 10:50:54,815 INFO] | epoch   3 | train_loss  8.84 | val_ppl 34586.01437 | time  36.3s
[2018-08-23 10:51:31,311 INFO] | epoch   4 | train_loss  7.92 | val_ppl 17228.81029 | time  36.5s
[2018-08-23 10:52:07,684 INFO] | epoch   5 | train_loss  7.38 | val_ppl 1840.06970 | time  36.4s
[2018-08-23 10:52:44,283 INFO] | epoch   6 | train_loss  6.97 | val_ppl 1310.16368 | time  36.6s
[2018-08-23 10:53:20,844 INFO] | epoch   7 | train_loss  6.66 | val_ppl 2026.42572 | time  36.6s
[2018-08-23 10:53:20,844 INFO] learning rate has been changed to 0.28125
[2018-08-23 10:53:57,451 INFO] | epoch   8 | train_loss  5.91 | val_ppl 1032.79890 | time  36.6s
[2018-08-23 10:54:33,925 INFO] | epoch   9 | train_loss  5.79 | val_ppl 602.08421 | time  36.5s
[2018-08-23 10:55:10,561 INFO] | epoch  10 | train_loss  5.71 | val_ppl 676.79614 | time  36.6s
[2018-08-23 10:55:10,561 INFO] learning rate has been changed to 0.2109375
[2018-08-23 10:55:47,188 INFO] | epoch  11 | train_loss  5.39 | val_ppl 454.35976 | time  36.6s
[2018-08-23 10:56:23,796 INFO] | epoch  12 | train_loss  5.33 | val_ppl 465.51313 | time  36.6s
[2018-08-23 10:56:23,796 INFO] learning rate has been changed to 0.158203125
[2018-08-23 10:57:00,533 INFO] | epoch  13 | train_loss  5.17 | val_ppl 370.19796 | time  36.7s
[2018-08-23 10:57:37,191 INFO] | epoch  14 | train_loss  5.14 | val_ppl 346.53748 | time  36.7s
[2018-08-23 10:58:13,984 INFO] | epoch  15 | train_loss  5.10 | val_ppl 338.93614 | time  36.8s
[2018-08-23 10:58:50,561 INFO] | epoch  16 | train_loss  5.07 | val_ppl 334.42945 | time  36.6s
[2018-08-23 10:59:27,235 INFO] | epoch  17 | train_loss  5.05 | val_ppl 327.75694 | time  36.7s
[2018-08-23 11:00:03,913 INFO] | epoch  18 | train_loss  5.01 | val_ppl 335.09496 | time  36.7s
[2018-08-23 11:00:03,914 INFO] learning rate has been changed to 0.11865234375
[2018-08-23 11:00:40,497 INFO] | epoch  19 | train_loss  4.88 | val_ppl 292.12500 | time  36.6s
[2018-08-23 11:01:17,287 INFO] | epoch  20 | train_loss  4.84 | val_ppl 275.81926 | time  36.8s
[2018-08-23 11:01:53,947 INFO] | epoch  21 | train_loss  4.81 | val_ppl 265.05813 | time  36.7s
[2018-08-23 11:02:30,620 INFO] | epoch  22 | train_loss  4.79 | val_ppl 254.40186 | time  36.7s
[2018-08-23 11:03:07,227 INFO] | epoch  23 | train_loss  4.77 | val_ppl 247.97637 | time  36.6s
[2018-08-23 11:03:43,902 INFO] | epoch  24 | train_loss  4.75 | val_ppl 241.29397 | time  36.7s
[2018-08-23 11:04:20,574 INFO] | epoch  25 | train_loss  4.73 | val_ppl 236.98269 | time  36.7s
[2018-08-23 11:04:57,197 INFO] | epoch  26 | train_loss  4.72 | val_ppl 233.96878 | time  36.6s
[2018-08-23 11:05:33,899 INFO] | epoch  27 | train_loss  4.70 | val_ppl 231.43758 | time  36.7s
[2018-08-23 11:06:10,577 INFO] | epoch  28 | train_loss  4.69 | val_ppl 229.12259 | time  36.7s
[2018-08-23 11:06:47,228 INFO] | epoch  29 | train_loss  4.67 | val_ppl 227.21009 | time  36.7s
[2018-08-23 11:07:23,828 INFO] | epoch  30 | train_loss  4.66 | val_ppl 225.84662 | time  36.6s
[2018-08-23 11:09:19,019 INFO] -------------
[2018-08-23 11:09:19,020 INFO] Start training...
[2018-08-23 11:09:19,020 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=0.25, data_type='wiki2', decay=0.75, device='cuda:0', dropout=0.0, epoch=40, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-23 11:09:30,561 INFO] train token: 2127402
[2018-08-23 11:09:30,561 INFO] test token: 250140
[2018-08-23 11:09:30,561 INFO] valid token: 221606
[2018-08-23 11:09:30,562 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt.pt
[2018-08-23 11:10:14,647 INFO] | epoch   1 | train_loss 14.00 | val_ppl 33074.76735 | time  38.0s
[2018-08-23 11:10:53,046 INFO] | epoch   2 | train_loss  9.44 | val_ppl 5405.13595 | time  38.4s
[2018-08-23 11:11:31,622 INFO] | epoch   3 | train_loss  8.00 | val_ppl 2780.83796 | time  38.6s
[2018-08-23 11:12:10,225 INFO] | epoch   4 | train_loss  7.15 | val_ppl 1324.29360 | time  38.6s
[2018-08-23 11:12:48,813 INFO] | epoch   5 | train_loss  6.58 | val_ppl 781.95591 | time  38.6s
[2018-08-23 11:13:27,561 INFO] | epoch   6 | train_loss  6.19 | val_ppl 577.26958 | time  38.7s
[2018-08-23 11:14:06,220 INFO] | epoch   7 | train_loss  5.90 | val_ppl 461.70263 | time  38.7s
[2018-08-23 11:14:45,014 INFO] | epoch   8 | train_loss  5.71 | val_ppl 391.58540 | time  38.8s
[2018-08-23 11:15:23,632 INFO] | epoch   9 | train_loss  5.56 | val_ppl 349.53472 | time  38.6s
[2018-08-23 11:16:02,297 INFO] | epoch  10 | train_loss  5.46 | val_ppl 319.48541 | time  38.7s
[2018-08-23 11:16:41,006 INFO] | epoch  11 | train_loss  5.39 | val_ppl 300.57943 | time  38.7s
[2018-08-23 11:17:19,612 INFO] | epoch  12 | train_loss  5.34 | val_ppl 287.67850 | time  38.6s
[2018-08-23 11:17:58,353 INFO] | epoch  13 | train_loss  5.30 | val_ppl 278.38616 | time  38.7s
[2018-08-23 11:18:37,037 INFO] | epoch  14 | train_loss  5.27 | val_ppl 271.60051 | time  38.7s
[2018-08-23 11:19:15,819 INFO] | epoch  15 | train_loss  5.24 | val_ppl 263.82519 | time  38.8s
[2018-08-23 11:19:54,434 INFO] | epoch  16 | train_loss  5.21 | val_ppl 261.82441 | time  38.6s
[2018-08-23 11:20:33,119 INFO] | epoch  17 | train_loss  5.19 | val_ppl 257.99460 | time  38.7s
[2018-08-23 11:21:11,811 INFO] | epoch  18 | train_loss  5.17 | val_ppl 254.13828 | time  38.7s
[2018-08-23 11:21:51,281 INFO] | epoch  19 | train_loss  5.15 | val_ppl 251.94925 | time  39.5s
[2018-08-23 11:22:30,172 INFO] | epoch  20 | train_loss  5.13 | val_ppl 247.01488 | time  38.9s
[2018-08-23 11:23:09,820 INFO] | epoch  21 | train_loss  5.12 | val_ppl 246.73361 | time  39.6s
[2018-08-23 11:23:09,821 INFO] learning rate has been changed to 0.375
[2018-08-23 11:24:25,887 INFO] -------------
[2018-08-23 11:24:25,887 INFO] Start training...
[2018-08-23 11:24:25,888 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=22, clip=0.25, data_type='ptb', decay=0.75, device='cuda:0', dropout=0.0, epoch=30, every_n_epoch_save=40, input_vector='~/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=240, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-23 11:24:30,987 INFO] train token: 994974
[2018-08-23 11:24:30,987 INFO] test token: 88160
[2018-08-23 11:24:30,987 INFO] valid token: 78932
[2018-08-23 11:24:30,988 INFO] Loading vectors from /home/lr/yukun/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt.pt
[2018-08-23 11:24:41,902 INFO] | epoch   1 | train_loss  7.66 | val_ppl 1309.89865 | time   6.9s
[2018-08-23 11:24:48,709 INFO] | epoch   2 | train_loss  7.03 | val_ppl 987.56744 | time   6.8s
[2018-08-23 11:24:55,213 INFO] | epoch   3 | train_loss  6.82 | val_ppl 835.87485 | time   6.5s
[2018-08-23 11:25:02,046 INFO] | epoch   4 | train_loss  6.68 | val_ppl 742.00100 | time   6.8s
[2018-08-23 11:25:08,843 INFO] | epoch   5 | train_loss  6.58 | val_ppl 676.15688 | time   6.8s
[2018-08-23 11:25:15,823 INFO] | epoch   6 | train_loss  6.50 | val_ppl 626.80289 | time   7.0s
[2018-08-23 11:25:22,087 INFO] | epoch   7 | train_loss  6.43 | val_ppl 588.20336 | time   6.3s
[2018-08-23 11:25:28,481 INFO] | epoch   8 | train_loss  6.37 | val_ppl 556.96893 | time   6.4s
[2018-08-23 11:25:35,546 INFO] | epoch   9 | train_loss  6.32 | val_ppl 530.96107 | time   7.1s
[2018-08-23 11:25:42,294 INFO] | epoch  10 | train_loss  6.28 | val_ppl 508.78268 | time   6.7s
[2018-08-23 11:25:48,856 INFO] | epoch  11 | train_loss  6.24 | val_ppl 489.49784 | time   6.6s
[2018-08-23 11:25:56,008 INFO] | epoch  12 | train_loss  6.20 | val_ppl 472.47531 | time   7.2s
[2018-08-23 11:26:02,369 INFO] | epoch  13 | train_loss  6.17 | val_ppl 457.27945 | time   6.4s
[2018-08-23 11:26:08,979 INFO] | epoch  14 | train_loss  6.14 | val_ppl 443.59243 | time   6.6s
[2018-08-23 11:26:15,601 INFO] | epoch  15 | train_loss  6.11 | val_ppl 431.17429 | time   6.6s
[2018-08-23 11:26:22,463 INFO] | epoch  16 | train_loss  6.08 | val_ppl 419.83875 | time   6.9s
[2018-08-23 11:26:29,639 INFO] | epoch  17 | train_loss  6.06 | val_ppl 409.43772 | time   7.2s
[2018-08-23 11:26:36,471 INFO] | epoch  18 | train_loss  6.04 | val_ppl 399.85126 | time   6.8s
[2018-08-23 11:26:43,219 INFO] | epoch  19 | train_loss  6.01 | val_ppl 390.98030 | time   6.7s
[2018-08-23 11:26:50,374 INFO] | epoch  20 | train_loss  5.99 | val_ppl 382.73629 | time   7.2s
[2018-08-23 11:26:56,989 INFO] | epoch  21 | train_loss  5.97 | val_ppl 375.03755 | time   6.6s
[2018-08-23 11:27:03,551 INFO] | epoch  22 | train_loss  5.95 | val_ppl 367.86510 | time   6.6s
[2018-08-23 11:27:10,224 INFO] | epoch  23 | train_loss  5.93 | val_ppl 361.15471 | time   6.7s
[2018-08-23 11:27:17,236 INFO] | epoch  24 | train_loss  5.92 | val_ppl 354.85252 | time   7.0s
[2018-08-23 11:27:23,937 INFO] | epoch  25 | train_loss  5.90 | val_ppl 348.91642 | time   6.7s
[2018-08-23 11:27:31,138 INFO] | epoch  26 | train_loss  5.88 | val_ppl 343.31005 | time   7.2s
[2018-08-23 11:27:37,640 INFO] | epoch  27 | train_loss  5.87 | val_ppl 338.00176 | time   6.5s
[2018-08-23 11:27:44,220 INFO] | epoch  28 | train_loss  5.85 | val_ppl 332.96397 | time   6.6s
[2018-08-23 11:27:50,513 INFO] | epoch  29 | train_loss  5.84 | val_ppl 328.17284 | time   6.3s
[2018-08-23 11:27:56,755 INFO] | epoch  30 | train_loss  5.82 | val_ppl 323.60770 | time   6.2s
[2018-08-23 11:27:56,926 INFO] test_ppl: 336.39514
[2018-08-23 11:29:46,974 INFO] -------------
[2018-08-23 11:29:46,974 INFO] Start training...
[2018-08-23 11:29:46,974 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=22, clip=0.25, data_type='ptb', decay=0.75, device='cuda:0', dropout=0.0, epoch=30, every_n_epoch_save=40, input_vector='~/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=240, tied=False, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-23 11:29:52,027 INFO] train token: 994974
[2018-08-23 11:29:52,027 INFO] test token: 88160
[2018-08-23 11:29:52,027 INFO] valid token: 78932
[2018-08-23 11:29:52,028 INFO] Loading vectors from /home/lr/yukun/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt.pt
[2018-08-23 11:30:01,593 INFO] | epoch   1 | train_loss  8.35 | val_ppl 3990.39043 | time   6.0s
[2018-08-23 11:30:07,569 INFO] | epoch   2 | train_loss  8.31 | val_ppl 3923.24539 | time   6.0s
[2018-08-23 11:30:13,628 INFO] | epoch   3 | train_loss  8.30 | val_ppl 3882.07010 | time   6.1s
[2018-08-23 11:30:20,210 INFO] | epoch   4 | train_loss  8.29 | val_ppl 3846.44396 | time   6.6s
[2018-08-23 11:30:26,243 INFO] | epoch   5 | train_loss  8.28 | val_ppl 3818.15105 | time   6.0s
[2018-08-23 11:30:32,269 INFO] | epoch   6 | train_loss  8.27 | val_ppl 3793.15792 | time   6.0s
[2018-08-23 11:30:38,530 INFO] | epoch   7 | train_loss  8.26 | val_ppl 3763.14315 | time   6.3s
[2018-08-23 11:30:44,576 INFO] | epoch   8 | train_loss  8.26 | val_ppl 3741.91793 | time   6.0s
[2018-08-23 11:30:50,364 INFO] | epoch   9 | train_loss  8.25 | val_ppl 3723.57270 | time   5.8s
[2018-08-23 11:30:56,371 INFO] | epoch  10 | train_loss  8.25 | val_ppl 3707.16883 | time   6.0s
[2018-08-23 11:31:02,418 INFO] | epoch  11 | train_loss  8.24 | val_ppl 3692.98120 | time   6.0s
[2018-08-23 11:31:08,536 INFO] | epoch  12 | train_loss  8.24 | val_ppl 3675.37136 | time   6.1s
[2018-08-23 11:31:14,336 INFO] | epoch  13 | train_loss  8.23 | val_ppl 3660.92038 | time   5.8s
[2018-08-23 11:31:20,436 INFO] | epoch  14 | train_loss  8.23 | val_ppl 3648.44404 | time   6.1s
[2018-08-23 11:31:27,162 INFO] | epoch  15 | train_loss  8.22 | val_ppl 3637.84048 | time   6.7s
[2018-08-23 11:31:33,429 INFO] | epoch  16 | train_loss  8.22 | val_ppl 3627.33517 | time   6.3s
[2018-08-23 11:31:39,886 INFO] | epoch  17 | train_loss  8.22 | val_ppl 3614.96604 | time   6.5s
[2018-08-23 11:31:46,314 INFO] | epoch  18 | train_loss  8.21 | val_ppl 3603.26626 | time   6.4s
[2018-08-23 11:31:52,286 INFO] | epoch  19 | train_loss  8.21 | val_ppl 3592.90185 | time   6.0s
[2018-08-23 11:31:58,334 INFO] | epoch  20 | train_loss  8.20 | val_ppl 3585.16477 | time   6.0s
[2018-08-23 11:32:04,194 INFO] | epoch  21 | train_loss  8.20 | val_ppl 3577.89963 | time   5.9s
[2018-08-23 11:32:10,187 INFO] | epoch  22 | train_loss  8.20 | val_ppl 3572.50629 | time   6.0s
[2018-08-23 11:32:15,946 INFO] | epoch  23 | train_loss  8.20 | val_ppl 3563.86960 | time   5.8s
[2018-08-23 11:32:22,130 INFO] | epoch  24 | train_loss  8.19 | val_ppl 3557.98240 | time   6.2s
[2018-08-23 11:32:28,205 INFO] | epoch  25 | train_loss  8.19 | val_ppl 3552.58871 | time   6.1s
[2018-08-23 11:33:14,504 INFO] -------------
[2018-08-23 11:33:14,504 INFO] Start training...
[2018-08-23 11:33:14,504 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=22, clip=0.25, data_type='ptb', decay=0.75, device='cuda:0', dropout=0.0, epoch=30, every_n_epoch_save=40, input_vector='~/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=240, tied=False, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-23 11:33:19,341 INFO] train token: 994974
[2018-08-23 11:33:19,341 INFO] test token: 88160
[2018-08-23 11:33:19,341 INFO] valid token: 78932
[2018-08-23 11:33:19,342 INFO] Loading vectors from /home/lr/yukun/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt.pt
[2018-08-23 11:33:27,715 INFO] | epoch   1 | train_loss  8.34 | val_ppl 3990.21867 | time   4.9s
[2018-08-23 11:33:32,443 INFO] | epoch   2 | train_loss  8.31 | val_ppl 3923.05295 | time   4.7s
[2018-08-23 11:33:36,850 INFO] | epoch   3 | train_loss  8.30 | val_ppl 3881.87144 | time   4.4s
[2018-08-23 11:33:41,659 INFO] | epoch   4 | train_loss  8.29 | val_ppl 3846.11966 | time   4.8s
[2018-08-23 11:33:46,381 INFO] | epoch   5 | train_loss  8.28 | val_ppl 3817.77039 | time   4.7s
[2018-08-23 11:33:50,969 INFO] | epoch   6 | train_loss  8.27 | val_ppl 3792.63228 | time   4.6s
[2018-08-23 11:33:55,440 INFO] | epoch   7 | train_loss  8.26 | val_ppl 3762.97981 | time   4.5s
[2018-08-23 11:34:00,196 INFO] | epoch   8 | train_loss  8.26 | val_ppl 3741.76845 | time   4.8s
[2018-08-23 11:34:04,577 INFO] | epoch   9 | train_loss  8.25 | val_ppl 3723.37684 | time   4.4s
[2018-08-23 11:34:09,160 INFO] | epoch  10 | train_loss  8.25 | val_ppl 3706.74380 | time   4.6s
[2018-08-23 11:34:13,770 INFO] | epoch  11 | train_loss  8.24 | val_ppl 3692.62209 | time   4.6s
[2018-08-23 11:34:18,216 INFO] | epoch  12 | train_loss  8.24 | val_ppl 3674.41153 | time   4.4s
[2018-08-23 11:34:22,977 INFO] | epoch  13 | train_loss  8.23 | val_ppl 3660.89746 | time   4.8s
[2018-08-23 11:34:27,844 INFO] | epoch  14 | train_loss  8.23 | val_ppl 3648.87032 | time   4.9s
[2018-08-23 11:34:32,540 INFO] | epoch  15 | train_loss  8.22 | val_ppl 3637.89017 | time   4.7s
[2018-08-23 11:34:37,164 INFO] | epoch  16 | train_loss  8.22 | val_ppl 3626.50767 | time   4.6s
[2018-08-23 11:35:14,042 INFO] -------------
[2018-08-23 11:35:14,042 INFO] Start training...

random outemb updating
[2018-08-23 11:35:14,042 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=22, clip=0.25, data_type='ptb', decay=0.75, device='cuda:0', dropout=0.0, epoch=30, every_n_epoch_save=40, input_vector='~/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=240, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-23 11:35:19,210 INFO] train token: 994974
[2018-08-23 11:35:19,210 INFO] test token: 88160
[2018-08-23 11:35:19,210 INFO] valid token: 78932
[2018-08-23 11:35:19,211 INFO] Loading vectors from /home/lr/yukun/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt.pt
[2018-08-23 11:35:28,302 INFO] | epoch   1 | train_loss  5.80 | val_ppl 224.93412 | time   5.0s
[2018-08-23 11:35:33,092 INFO] | epoch   2 | train_loss  5.32 | val_ppl 178.19411 | time   4.8s
[2018-08-23 11:35:37,894 INFO] | epoch   3 | train_loss  5.12 | val_ppl 155.54723 | time   4.8s
[2018-08-23 11:35:42,986 INFO] | epoch   4 | train_loss  4.99 | val_ppl 142.00252 | time   5.1s
[2018-08-23 11:35:47,845 INFO] | epoch   5 | train_loss  4.89 | val_ppl 132.92216 | time   4.9s
[2018-08-23 11:35:52,794 INFO] | epoch   6 | train_loss  4.81 | val_ppl 125.80318 | time   4.9s
[2018-08-23 11:35:57,797 INFO] | epoch   7 | train_loss  4.74 | val_ppl 120.03864 | time   5.0s
[2018-08-23 11:36:02,492 INFO] | epoch   8 | train_loss  4.69 | val_ppl 115.31295 | time   4.7s
[2018-08-23 11:36:07,279 INFO] | epoch   9 | train_loss  4.63 | val_ppl 111.39669 | time   4.8s
[2018-08-23 11:36:12,163 INFO] | epoch  10 | train_loss  4.59 | val_ppl 108.10543 | time   4.9s
[2018-08-23 11:36:17,747 INFO] | epoch  11 | train_loss  4.54 | val_ppl 105.34360 | time   5.6s
[2018-08-23 11:36:22,818 INFO] | epoch  12 | train_loss  4.51 | val_ppl 103.00772 | time   5.1s
[2018-08-23 11:36:27,970 INFO] | epoch  13 | train_loss  4.47 | val_ppl 101.01218 | time   5.2s
[2018-08-23 11:36:32,809 INFO] | epoch  14 | train_loss  4.44 | val_ppl 99.29280 | time   4.8s
[2018-08-23 11:36:37,773 INFO] | epoch  15 | train_loss  4.40 | val_ppl 97.80928 | time   5.0s
[2018-08-23 11:36:42,784 INFO] | epoch  16 | train_loss  4.37 | val_ppl 96.55340 | time   5.0s
[2018-08-23 11:36:47,751 INFO] | epoch  17 | train_loss  4.35 | val_ppl 95.51806 | time   5.0s
[2018-08-23 11:36:52,835 INFO] | epoch  18 | train_loss  4.32 | val_ppl 94.66854 | time   5.1s
[2018-08-23 11:36:58,025 INFO] | epoch  19 | train_loss  4.30 | val_ppl 93.96162 | time   5.2s
[2018-08-23 11:37:02,925 INFO] | epoch  20 | train_loss  4.27 | val_ppl 93.35335 | time   4.9s
[2018-08-23 11:37:07,789 INFO] | epoch  21 | train_loss  4.25 | val_ppl 92.81974 | time   4.9s
[2018-08-23 11:37:12,607 INFO] | epoch  22 | train_loss  4.23 | val_ppl 92.37189 | time   4.8s
[2018-08-23 11:37:12,607 INFO] learning rate has been changed to 0.375
[2018-08-23 11:37:17,535 INFO] | epoch  23 | train_loss  4.20 | val_ppl 90.99668 | time   4.9s
[2018-08-23 11:37:23,333 INFO] | epoch  24 | train_loss  4.18 | val_ppl 90.78487 | time   5.8s
[2018-08-23 11:37:23,334 INFO] learning rate has been changed to 0.28125
[2018-08-23 11:37:28,470 INFO] | epoch  25 | train_loss  4.16 | val_ppl 89.88345 | time   5.1s
[2018-08-23 11:37:33,898 INFO] | epoch  26 | train_loss  4.15 | val_ppl 89.77275 | time   5.4s
[2018-08-23 11:37:33,899 INFO] learning rate has been changed to 0.2109375
[2018-08-23 11:37:38,672 INFO] | epoch  27 | train_loss  4.13 | val_ppl 89.15524 | time   4.8s
[2018-08-23 11:37:43,481 INFO] | epoch  28 | train_loss  4.12 | val_ppl 89.09550 | time   4.8s
[2018-08-23 11:37:43,482 INFO] learning rate has been changed to 0.158203125
[2018-08-23 11:37:48,619 INFO] | epoch  29 | train_loss  4.11 | val_ppl 88.64374 | time   5.1s
[2018-08-23 11:37:48,619 INFO] learning rate has been changed to 0.11865234375
[2018-08-23 11:37:53,491 INFO] | epoch  30 | train_loss  4.10 | val_ppl 88.28872 | time   4.9s
[2018-08-23 11:37:53,491 INFO] learning rate has been changed to 0.0889892578125
[2018-08-23 11:37:53,659 INFO] test_ppl: 90.99533
[2018-08-23 11:39:24,749 INFO] -------------

input and output are randomly inited
[2018-08-23 11:39:24,749 INFO] Start training...
[2018-08-23 11:39:24,749 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=22, clip=0.25, data_type='ptb', decay=0.75, device='cuda:0', dropout=0.0, epoch=30, every_n_epoch_save=40, input_vector='~/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=240, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-23 11:39:29,567 INFO] train token: 994974
[2018-08-23 11:39:29,567 INFO] test token: 88160
[2018-08-23 11:39:29,567 INFO] valid token: 78932
[2018-08-23 11:39:29,568 INFO] Loading vectors from /home/lr/yukun/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt.pt
[2018-08-23 11:39:38,011 INFO] | epoch   1 | train_loss  5.80 | val_ppl 233.27315 | time   4.9s
[2018-08-23 11:39:43,595 INFO] | epoch   2 | train_loss  5.36 | val_ppl 191.28507 | time   5.6s
[2018-08-23 11:39:48,741 INFO] | epoch   3 | train_loss  5.20 | val_ppl 171.26207 | time   5.1s
[2018-08-23 11:39:53,646 INFO] | epoch   4 | train_loss  5.09 | val_ppl 159.09196 | time   4.9s
[2018-08-23 11:39:58,384 INFO] | epoch   5 | train_loss  5.01 | val_ppl 151.00244 | time   4.7s
[2018-08-23 11:40:03,469 INFO] | epoch   6 | train_loss  4.94 | val_ppl 145.44578 | time   5.1s
[2018-08-23 11:40:08,452 INFO] | epoch   7 | train_loss  4.89 | val_ppl 141.32152 | time   5.0s
[2018-08-23 11:40:13,371 INFO] | epoch   8 | train_loss  4.84 | val_ppl 138.00513 | time   4.9s
[2018-08-23 11:40:18,411 INFO] | epoch   9 | train_loss  4.80 | val_ppl 135.33742 | time   5.0s
[2018-08-23 11:40:23,388 INFO] | epoch  10 | train_loss  4.77 | val_ppl 133.10489 | time   5.0s
[2018-08-23 11:40:28,258 INFO] | epoch  11 | train_loss  4.74 | val_ppl 131.24992 | time   4.9s
[2018-08-23 11:40:33,291 INFO] | epoch  12 | train_loss  4.71 | val_ppl 129.57375 | time   5.0s
[2018-08-23 11:40:38,347 INFO] | epoch  13 | train_loss  4.68 | val_ppl 128.06943 | time   5.1s
[2018-08-23 11:40:43,309 INFO] | epoch  14 | train_loss  4.65 | val_ppl 126.75064 | time   5.0s
[2018-08-23 11:40:48,229 INFO] | epoch  15 | train_loss  4.63 | val_ppl 125.61476 | time   4.9s
[2018-08-23 11:40:53,185 INFO] | epoch  16 | train_loss  4.61 | val_ppl 124.57612 | time   5.0s
[2018-08-23 11:40:58,171 INFO] | epoch  17 | train_loss  4.59 | val_ppl 123.67841 | time   5.0s
[2018-08-23 11:41:03,059 INFO] | epoch  18 | train_loss  4.57 | val_ppl 122.91766 | time   4.9s
[2018-08-23 11:41:08,056 INFO] | epoch  19 | train_loss  4.55 | val_ppl 122.19369 | time   5.0s
[2018-08-23 11:41:12,869 INFO] | epoch  20 | train_loss  4.54 | val_ppl 121.53532 | time   4.8s
[2018-08-23 11:41:18,189 INFO] | epoch  21 | train_loss  4.52 | val_ppl 121.02008 | time   5.3s
[2018-08-23 11:41:23,581 INFO] | epoch  22 | train_loss  4.51 | val_ppl 120.55687 | time   5.4s
[2018-08-23 11:41:23,581 INFO] learning rate has been changed to 0.375
[2018-08-23 11:41:28,698 INFO] | epoch  23 | train_loss  4.48 | val_ppl 118.28473 | time   5.1s
[2018-08-23 11:41:33,713 INFO] | epoch  24 | train_loss  4.47 | val_ppl 118.03694 | time   5.0s
[2018-08-23 11:41:33,713 INFO] learning rate has been changed to 0.28125
[2018-08-23 11:41:38,705 INFO] | epoch  25 | train_loss  4.46 | val_ppl 116.56333 | time   5.0s
[2018-08-23 11:41:43,728 INFO] | epoch  26 | train_loss  4.45 | val_ppl 116.40124 | time   5.0s
[2018-08-23 11:41:43,729 INFO] learning rate has been changed to 0.2109375
[2018-08-23 11:41:48,730 INFO] | epoch  27 | train_loss  4.43 | val_ppl 115.45419 | time   5.0s
[2018-08-23 11:41:53,561 INFO] | epoch  28 | train_loss  4.43 | val_ppl 115.35246 | time   4.8s
[2018-08-23 11:41:53,562 INFO] learning rate has been changed to 0.158203125
[2018-08-23 11:41:58,615 INFO] | epoch  29 | train_loss  4.42 | val_ppl 114.66018 | time   5.1s
[2018-08-23 11:42:04,392 INFO] | epoch  30 | train_loss  4.41 | val_ppl 114.57297 | time   5.8s
[2018-08-23 11:42:04,460 INFO] learning rate has been changed to 0.11865234375
[2018-08-23 11:42:04,655 INFO] test_ppl: 118.18537
[2018-08-23 11:50:56,128 INFO] -------------
[2018-08-23 11:54:20,362 INFO] -------------

only outemb randomly 
[2018-08-23 11:54:20,362 INFO] Start training...
[2018-08-23 11:54:20,363 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, data_type='wiki2', decay=0.75, device='cuda:0', dropout=0.0, epoch=40, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-23 11:54:31,974 INFO] train token: 2127402
[2018-08-23 11:54:31,975 INFO] test token: 250140
[2018-08-23 11:54:31,975 INFO] valid token: 221606
[2018-08-23 11:54:31,976 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt.pt
[2018-08-23 11:55:11,816 INFO] | epoch   1 | train_loss  5.23 | val_ppl 120.56409 | time  36.1s
[2018-08-23 11:55:48,234 INFO] | epoch   2 | train_loss  4.67 | val_ppl 97.39093 | time  36.4s
[2018-08-23 11:56:25,026 INFO] | epoch   3 | train_loss  4.48 | val_ppl 85.01872 | time  36.8s
[2018-08-23 11:57:01,741 INFO] | epoch   4 | train_loss  4.35 | val_ppl 77.61546 | time  36.7s
[2018-08-23 11:57:38,464 INFO] | epoch   5 | train_loss  4.25 | val_ppl 72.66753 | time  36.7s
[2018-08-23 11:58:15,485 INFO] | epoch   6 | train_loss  4.17 | val_ppl 69.05432 | time  37.0s
[2018-08-23 11:58:52,356 INFO] | epoch   7 | train_loss  4.09 | val_ppl 66.10310 | time  36.9s
[2018-08-23 11:59:29,318 INFO] | epoch   8 | train_loss  4.03 | val_ppl 65.73591 | time  37.0s
[2018-08-23 11:59:29,319 INFO] learning rate has been changed to 0.375
[2018-08-23 12:00:06,135 INFO] | epoch   9 | train_loss  3.95 | val_ppl 61.35327 | time  36.8s
[2018-08-23 12:00:43,004 INFO] | epoch  10 | train_loss  3.91 | val_ppl 60.25621 | time  36.9s
[2018-08-23 12:01:19,960 INFO] | epoch  11 | train_loss  3.87 | val_ppl 59.33122 | time  37.0s
[2018-08-23 12:01:56,841 INFO] | epoch  12 | train_loss  3.83 | val_ppl 58.55412 | time  36.9s
[2018-08-23 12:02:34,089 INFO] | epoch  13 | train_loss  3.80 | val_ppl 57.90853 | time  37.2s
[2018-08-23 12:03:11,084 INFO] | epoch  14 | train_loss  3.76 | val_ppl 57.37140 | time  37.0s
[2018-08-23 12:03:48,111 INFO] | epoch  15 | train_loss  3.73 | val_ppl 56.93338 | time  37.0s
[2018-08-23 12:03:48,112 INFO] learning rate has been changed to 0.28125
[2018-08-23 12:04:25,067 INFO] | epoch  16 | train_loss  3.69 | val_ppl 55.86357 | time  37.0s
[2018-08-23 12:05:02,104 INFO] | epoch  17 | train_loss  3.66 | val_ppl 55.66654 | time  37.0s
[2018-08-23 12:05:02,105 INFO] learning rate has been changed to 0.2109375
[2018-08-23 12:05:39,251 INFO] | epoch  18 | train_loss  3.63 | val_ppl 54.93399 | time  37.1s
[2018-08-23 12:06:16,168 INFO] | epoch  19 | train_loss  3.62 | val_ppl 54.84592 | time  36.9s
[2018-08-23 12:06:16,169 INFO] learning rate has been changed to 0.158203125
[2018-08-23 12:06:53,301 INFO] | epoch  20 | train_loss  3.59 | val_ppl 54.32696 | time  37.1s
[2018-08-23 12:07:30,320 INFO] | epoch  21 | train_loss  3.58 | val_ppl 54.29108 | time  37.0s
[2018-08-23 12:07:30,321 INFO] learning rate has been changed to 0.11865234375
[2018-08-23 12:08:07,416 INFO] | epoch  22 | train_loss  3.56 | val_ppl 53.92416 | time  37.1s
[2018-08-23 12:08:07,416 INFO] learning rate has been changed to 0.0889892578125
[2018-08-23 12:08:44,391 INFO] | epoch  23 | train_loss  3.55 | val_ppl 53.64546 | time  37.0s
[2018-08-23 12:08:44,392 INFO] learning rate has been changed to 0.066741943359375
[2018-08-23 12:09:21,400 INFO] | epoch  24 | train_loss  3.54 | val_ppl 53.43917 | time  37.0s
[2018-08-23 12:09:21,400 INFO] learning rate has been changed to 0.05005645751953125
[2018-08-23 12:09:58,481 INFO] | epoch  25 | train_loss  3.54 | val_ppl 53.27716 | time  37.1s
[2018-08-23 12:09:58,482 INFO] learning rate has been changed to 0.03754234313964844
[2018-08-23 12:10:35,395 INFO] | epoch  26 | train_loss  3.53 | val_ppl 53.14840 | time  36.9s
[2018-08-23 12:10:35,395 INFO] learning rate has been changed to 0.028156757354736328
[2018-08-23 12:11:12,530 INFO] | epoch  27 | train_loss  3.53 | val_ppl 53.04103 | time  37.1s
[2018-08-23 12:11:12,530 INFO] learning rate has been changed to 0.021117568016052246
[2018-08-23 12:11:49,567 INFO] | epoch  28 | train_loss  3.53 | val_ppl 52.94984 | time  37.0s
[2018-08-23 12:11:49,568 INFO] learning rate has been changed to 0.015838176012039185
[2018-08-23 12:12:26,643 INFO] | epoch  29 | train_loss  3.52 | val_ppl 52.87181 | time  37.1s
[2018-08-23 12:12:26,643 INFO] learning rate has been changed to 0.011878632009029388
[2018-08-23 12:13:03,588 INFO] | epoch  30 | train_loss  3.52 | val_ppl 52.80676 | time  36.9s
[2018-08-23 12:13:03,588 INFO] learning rate has been changed to 0.008908974006772041
[2018-08-23 12:13:40,600 INFO] | epoch  31 | train_loss  3.52 | val_ppl 52.75582 | time  37.0s
[2018-08-23 12:13:40,601 INFO] learning rate has been changed to 0.006681730505079031
[2018-08-23 12:14:17,657 INFO] | epoch  32 | train_loss  3.52 | val_ppl 52.72011 | time  37.1s
[2018-08-23 12:14:17,658 INFO] learning rate has been changed to 0.005011297878809273
[2018-08-23 12:14:54,632 INFO] | epoch  33 | train_loss  3.52 | val_ppl 52.69765 | time  37.0s
[2018-08-23 12:14:54,633 INFO] learning rate has been changed to 0.003758473409106955
[2018-08-23 12:15:31,789 INFO] | epoch  34 | train_loss  3.52 | val_ppl 52.68432 | time  37.2s
[2018-08-23 12:15:31,789 INFO] learning rate has been changed to 0.002818855056830216
[2018-08-23 12:16:08,817 INFO] | epoch  35 | train_loss  3.52 | val_ppl 52.67604 | time  37.0s
[2018-08-23 12:16:08,817 INFO] learning rate has been changed to 0.002114141292622662
[2018-08-23 12:16:45,865 INFO] | epoch  36 | train_loss  3.52 | val_ppl 52.66970 | time  37.0s
[2018-08-23 12:16:45,866 INFO] learning rate has been changed to 0.0015856059694669966
[2018-08-23 12:17:22,825 INFO] | epoch  37 | train_loss  3.52 | val_ppl 52.66454 | time  37.0s
[2018-08-23 12:17:22,826 INFO] learning rate has been changed to 0.0011892044771002475
[2018-08-23 12:17:59,863 INFO] | epoch  38 | train_loss  3.52 | val_ppl 52.66061 | time  37.0s
[2018-08-23 12:17:59,864 INFO] learning rate has been changed to 0.0008919033578251856
[2018-08-23 12:18:36,923 INFO] | epoch  39 | train_loss  3.52 | val_ppl 52.65784 | time  37.1s
[2018-08-23 12:18:36,924 INFO] learning rate has been changed to 0.0006689275183688892
[2018-08-23 12:19:13,862 INFO] | epoch  40 | train_loss  3.52 | val_ppl 52.65606 | time  36.9s
[2018-08-23 12:19:13,863 INFO] learning rate has been changed to 0.0005016956387766669
[2018-08-23 12:19:13,863 INFO] start to save model on nnlm.model
[2018-08-23 12:19:16,337 INFO] test_ppl: 51.54093
[2018-08-23 12:21:52,154 INFO] -------------
[2018-08-23 12:21:52,154 INFO] Start training...

input randomly and output randomly
[2018-08-23 12:21:52,154 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, data_type='wiki2', decay=0.75, device='cuda:0', dropout=0.0, epoch=40, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-23 12:22:03,328 INFO] train token: 2127402
[2018-08-23 12:22:03,329 INFO] test token: 250140
[2018-08-23 12:22:03,329 INFO] valid token: 221606
[2018-08-23 12:22:03,330 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt.pt
[2018-08-23 12:22:43,762 INFO] | epoch   1 | train_loss  5.10 | val_ppl 117.26847 | time  36.4s
[2018-08-23 12:23:20,454 INFO] | epoch   2 | train_loss  4.57 | val_ppl 91.03503 | time  36.7s
[2018-08-23 12:23:57,398 INFO] | epoch   3 | train_loss  4.35 | val_ppl 79.69641 | time  36.9s
[2018-08-23 12:24:34,362 INFO] | epoch   4 | train_loss  4.18 | val_ppl 72.52464 | time  37.0s
[2018-08-23 12:25:11,408 INFO] | epoch   5 | train_loss  4.06 | val_ppl 68.10254 | time  37.0s
[2018-08-23 12:25:48,475 INFO] | epoch   6 | train_loss  3.95 | val_ppl 65.36335 | time  37.1s
[2018-08-23 12:26:25,536 INFO] | epoch   7 | train_loss  3.85 | val_ppl 63.69252 | time  37.1s
[2018-08-23 12:27:02,641 INFO] | epoch   8 | train_loss  3.76 | val_ppl 62.77553 | time  37.1s
[2018-08-23 12:27:39,693 INFO] | epoch   9 | train_loss  3.67 | val_ppl 63.67907 | time  37.1s
[2018-08-23 12:27:39,693 INFO] learning rate has been changed to 0.375
[2018-08-23 12:28:16,778 INFO] | epoch  10 | train_loss  3.57 | val_ppl 61.51534 | time  37.1s
[2018-08-23 12:28:53,895 INFO] | epoch  11 | train_loss  3.50 | val_ppl 62.16275 | time  37.1s
[2018-08-23 12:28:53,896 INFO] learning rate has been changed to 0.28125
[2018-08-23 12:29:30,857 INFO] | epoch  12 | train_loss  3.43 | val_ppl 61.88376 | time  37.0s
[2018-08-23 12:29:30,858 INFO] learning rate has been changed to 0.2109375
[2018-08-23 12:30:08,104 INFO] | epoch  13 | train_loss  3.37 | val_ppl 61.88604 | time  37.2s
[2018-08-23 12:30:08,104 INFO] learning rate has been changed to 0.158203125
[2018-08-23 12:30:45,234 INFO] | epoch  14 | train_loss  3.33 | val_ppl 61.94981 | time  37.1s
[2018-08-23 12:30:45,235 INFO] learning rate has been changed to 0.11865234375
[2018-08-23 12:31:22,392 INFO] | epoch  15 | train_loss  3.29 | val_ppl 62.05149 | time  37.2s
[2018-08-23 12:31:22,392 INFO] learning rate has been changed to 0.0889892578125
[2018-08-23 12:31:59,456 INFO] | epoch  16 | train_loss  3.27 | val_ppl 62.16808 | time  37.1s
[2018-08-23 12:31:59,457 INFO] learning rate has been changed to 0.066741943359375
[2018-08-23 12:32:36,574 INFO] | epoch  17 | train_loss  3.25 | val_ppl 62.27916 | time  37.1s
[2018-08-23 12:32:36,574 INFO] learning rate has been changed to 0.05005645751953125
[2018-08-23 12:33:13,671 INFO] | epoch  18 | train_loss  3.23 | val_ppl 62.37333 | time  37.1s
[2018-08-23 12:33:13,671 INFO] learning rate has been changed to 0.03754234313964844
[2018-08-23 12:33:50,722 INFO] | epoch  19 | train_loss  3.22 | val_ppl 62.44654 | time  37.1s
[2018-08-23 12:33:50,723 INFO] learning rate has been changed to 0.028156757354736328
[2018-08-23 12:34:27,850 INFO] | epoch  20 | train_loss  3.21 | val_ppl 62.49998 | time  37.1s
[2018-08-23 12:34:27,850 INFO] learning rate has been changed to 0.021117568016052246
[2018-08-23 12:35:04,974 INFO] | epoch  21 | train_loss  3.21 | val_ppl 62.53752 | time  37.1s
[2018-08-23 12:35:04,975 INFO] learning rate has been changed to 0.015838176012039185
[2018-08-23 12:35:42,186 INFO] | epoch  22 | train_loss  3.20 | val_ppl 62.56330 | time  37.2s
[2018-08-23 12:35:42,186 INFO] learning rate has been changed to 0.011878632009029388
[2018-08-23 12:36:19,233 INFO] | epoch  23 | train_loss  3.20 | val_ppl 62.58072 | time  37.0s
[2018-08-23 12:36:19,234 INFO] learning rate has been changed to 0.008908974006772041
[2018-08-23 12:36:56,414 INFO] | epoch  24 | train_loss  3.20 | val_ppl 62.59259 | time  37.2s
[2018-08-23 12:36:56,415 INFO] learning rate has been changed to 0.006681730505079031
[2018-08-23 12:37:33,559 INFO] | epoch  25 | train_loss  3.19 | val_ppl 62.60166 | time  37.1s
[2018-08-23 12:37:33,560 INFO] learning rate has been changed to 0.005011297878809273
[2018-08-23 12:38:10,538 INFO] | epoch  26 | train_loss  3.19 | val_ppl 62.60985 | time  37.0s
[2018-08-23 12:38:10,539 INFO] learning rate has been changed to 0.003758473409106955
[2018-08-23 12:38:47,660 INFO] | epoch  27 | train_loss  3.19 | val_ppl 62.61801 | time  37.1s
[2018-08-23 12:38:47,660 INFO] learning rate has been changed to 0.002818855056830216
[2018-08-23 12:39:24,765 INFO] | epoch  28 | train_loss  3.19 | val_ppl 62.62599 | time  37.1s
[2018-08-23 12:39:24,766 INFO] learning rate has been changed to 0.002114141292622662
[2018-08-23 12:40:01,893 INFO] | epoch  29 | train_loss  3.19 | val_ppl 62.63307 | time  37.1s
[2018-08-23 12:40:01,894 INFO] learning rate has been changed to 0.0015856059694669966
[2018-08-23 12:40:38,897 INFO] | epoch  30 | train_loss  3.19 | val_ppl 62.63879 | time  37.0s
[2018-08-23 12:40:38,897 INFO] learning rate has been changed to 0.0011892044771002475
[2018-08-23 12:41:16,228 INFO] | epoch  31 | train_loss  3.19 | val_ppl 62.64309 | time  37.3s
[2018-08-23 12:41:16,229 INFO] learning rate has been changed to 0.0008919033578251856
[2018-08-23 12:41:53,312 INFO] | epoch  32 | train_loss  3.19 | val_ppl 62.64615 | time  37.1s
[2018-08-23 12:41:53,313 INFO] learning rate has been changed to 0.0006689275183688892
[2018-08-23 12:42:30,608 INFO] | epoch  33 | train_loss  3.19 | val_ppl 62.64826 | time  37.3s
[2018-08-23 12:42:30,609 INFO] learning rate has been changed to 0.0005016956387766669
[2018-08-23 12:43:07,957 INFO] | epoch  34 | train_loss  3.19 | val_ppl 62.64971 | time  37.3s
[2018-08-23 12:43:07,957 INFO] learning rate has been changed to 0.00037627172908250017
[2018-08-23 12:43:45,078 INFO] | epoch  35 | train_loss  3.19 | val_ppl 62.65074 | time  37.1s
[2018-08-23 12:43:45,079 INFO] learning rate has been changed to 0.00028220379681187513
[2018-08-23 12:44:22,178 INFO] | epoch  36 | train_loss  3.19 | val_ppl 62.65151 | time  37.1s
[2018-08-23 12:44:22,179 INFO] learning rate has been changed to 0.00021165284760890635
[2018-08-23 12:44:59,426 INFO] | epoch  37 | train_loss  3.19 | val_ppl 62.65211 | time  37.2s
[2018-08-23 12:44:59,427 INFO] learning rate has been changed to 0.00015873963570667976
[2018-08-23 12:45:36,513 INFO] | epoch  38 | train_loss  3.19 | val_ppl 62.65257 | time  37.1s
[2018-08-23 12:45:36,513 INFO] learning rate has been changed to 0.00011905472678000982
[2018-08-23 12:46:13,812 INFO] | epoch  39 | train_loss  3.19 | val_ppl 62.65294 | time  37.3s
[2018-08-23 12:46:13,813 INFO] learning rate has been changed to 8.929104508500737e-05
[2018-08-23 12:46:50,783 INFO] | epoch  40 | train_loss  3.19 | val_ppl 62.65323 | time  37.0s
[2018-08-23 12:46:50,783 INFO] learning rate has been changed to 6.696828381375552e-05
[2018-08-23 12:46:50,783 INFO] start to save model on nnlm.model
[2018-08-23 12:46:53,102 INFO] test_ppl: 61.53573
[2018-08-23 17:02:31,305 INFO] -------------
[2018-08-23 17:06:24,167 INFO] -------------
[2018-08-23 17:12:53,601 INFO] -------------
[2018-08-23 17:13:13,548 INFO] -------------
[2018-08-23 19:34:40,781 INFO] -------------
[2018-08-23 19:34:40,781 INFO] Start training...


100d, input emb inited
[2018-08-23 19:34:40,781 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=22, clip=None, data_type='ptb', decay=0.75, device='cuda:0', dropout=0.0, epoch=30, every_n_epoch_save=40, input_vector='~/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=240, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-23 19:34:41,625 INFO] train token: 24
[2018-08-23 19:34:41,625 INFO] test token: 6
[2018-08-23 19:34:41,625 INFO] valid token: 14
[2018-08-23 19:34:41,626 INFO] Loading vectors from /home/lr/yukun/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt.pt
[2018-08-23 19:34:52,384 INFO] | epoch   1 | train_loss  6.25 | val_ppl 317.35633 | time   7.3s
[2018-08-23 19:34:59,015 INFO] | epoch   2 | train_loss  5.72 | val_ppl 245.87255 | time   6.6s
[2018-08-23 19:35:05,736 INFO] | epoch   3 | train_loss  5.50 | val_ppl 210.94806 | time   6.7s
[2018-08-23 19:35:12,424 INFO] | epoch   4 | train_loss  5.35 | val_ppl 191.63088 | time   6.7s
[2018-08-23 19:35:19,171 INFO] | epoch   5 | train_loss  5.23 | val_ppl 177.96206 | time   6.7s
[2018-08-23 19:35:35,621 INFO] | epoch   6 | train_loss  5.14 | val_ppl 168.70664 | time  16.4s
[2018-08-23 19:35:47,391 INFO] | epoch   7 | train_loss  5.06 | val_ppl 161.12762 | time  11.8s
[2018-08-23 19:35:54,253 INFO] | epoch   8 | train_loss  4.99 | val_ppl 154.87041 | time   6.9s
[2018-08-23 19:36:01,228 INFO] | epoch   9 | train_loss  4.93 | val_ppl 148.31225 | time   7.0s
[2018-08-23 19:36:08,257 INFO] | epoch  10 | train_loss  4.88 | val_ppl 144.23246 | time   7.0s
[2018-08-23 19:36:15,106 INFO] | epoch  11 | train_loss  4.83 | val_ppl 142.40717 | time   6.8s
[2018-08-23 19:36:22,002 INFO] | epoch  12 | train_loss  4.78 | val_ppl 138.66901 | time   6.9s
[2018-08-23 19:36:28,845 INFO] | epoch  13 | train_loss  4.74 | val_ppl 136.27940 | time   6.8s
[2018-08-23 19:36:35,429 INFO] | epoch  14 | train_loss  4.70 | val_ppl 134.23964 | time   6.6s
[2018-08-23 19:36:42,467 INFO] | epoch  15 | train_loss  4.66 | val_ppl 131.29005 | time   7.0s
[2018-08-23 19:36:49,173 INFO] | epoch  16 | train_loss  4.63 | val_ppl 131.11769 | time   6.7s
[2018-08-23 19:36:49,174 INFO] learning rate has been changed to 0.375
[2018-08-23 19:36:55,764 INFO] | epoch  17 | train_loss  4.59 | val_ppl 128.69774 | time   6.6s
[2018-08-23 19:37:08,987 INFO] | epoch  18 | train_loss  4.56 | val_ppl 128.29028 | time  13.2s
[2018-08-23 19:37:08,988 INFO] learning rate has been changed to 0.28125
[2018-08-23 19:37:21,902 INFO] | epoch  19 | train_loss  4.53 | val_ppl 127.07759 | time  12.9s
[2018-08-23 19:37:28,706 INFO] | epoch  20 | train_loss  4.51 | val_ppl 126.37000 | time   6.8s
[2018-08-23 19:37:35,404 INFO] | epoch  21 | train_loss  4.49 | val_ppl 126.38046 | time   6.7s
[2018-08-23 19:37:35,404 INFO] learning rate has been changed to 0.2109375
[2018-08-23 19:37:42,180 INFO] | epoch  22 | train_loss  4.47 | val_ppl 125.99283 | time   6.8s
[2018-08-23 19:37:42,180 INFO] learning rate has been changed to 0.158203125
[2018-08-23 19:37:48,964 INFO] | epoch  23 | train_loss  4.45 | val_ppl 125.64267 | time   6.8s
[2018-08-23 19:37:48,965 INFO] learning rate has been changed to 0.11865234375
[2018-08-23 19:38:00,138 INFO] | epoch  24 | train_loss  4.43 | val_ppl 125.31452 | time  11.2s
[2018-08-23 19:38:00,139 INFO] learning rate has been changed to 0.0889892578125
[2018-08-23 19:38:15,059 INFO] | epoch  25 | train_loss  4.42 | val_ppl 125.09300 | time  14.9s
[2018-08-23 19:38:15,134 INFO] learning rate has been changed to 0.066741943359375
[2018-08-23 19:38:21,756 INFO] | epoch  26 | train_loss  4.42 | val_ppl 125.10182 | time   6.6s
[2018-08-23 19:38:21,757 INFO] learning rate has been changed to 0.05005645751953125
[2018-08-23 19:38:28,495 INFO] | epoch  27 | train_loss  4.41 | val_ppl 125.13722 | time   6.7s
[2018-08-23 19:38:28,495 INFO] learning rate has been changed to 0.03754234313964844
[2018-08-23 19:38:35,218 INFO] | epoch  28 | train_loss  4.40 | val_ppl 125.02113 | time   6.7s
[2018-08-23 19:38:35,219 INFO] learning rate has been changed to 0.028156757354736328
[2018-08-23 19:39:29,922 INFO] -------------

(randomly both in and out)
[2018-08-23 19:39:29,922 INFO] Start training...
[2018-08-23 19:39:29,922 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=22, clip=None, data_type='ptb', decay=0.75, device='cuda:0', dropout=0.0, epoch=30, every_n_epoch_save=40, input_vector='~/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=240, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-23 19:39:30,770 INFO] train token: 24
[2018-08-23 19:39:30,770 INFO] test token: 6
[2018-08-23 19:39:30,770 INFO] valid token: 14
[2018-08-23 19:39:30,771 INFO] Loading vectors from /home/lr/yukun/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt.pt
[2018-08-23 19:39:40,697 INFO] | epoch   1 | train_loss  6.20 | val_ppl 308.56261 | time   6.8s
[2018-08-23 19:39:48,124 INFO] | epoch   2 | train_loss  5.71 | val_ppl 251.69835 | time   7.4s
[2018-08-23 19:40:03,311 INFO] | epoch   3 | train_loss  5.53 | val_ppl 228.65049 | time  15.2s
[2018-08-23 19:40:12,584 INFO] | epoch   4 | train_loss  5.41 | val_ppl 212.89801 | time   9.3s
[2018-08-23 19:40:19,295 INFO] | epoch   5 | train_loss  5.32 | val_ppl 204.40830 | time   6.7s
[2018-08-23 19:40:25,970 INFO] | epoch   6 | train_loss  5.25 | val_ppl 195.39101 | time   6.7s
[2018-08-23 19:40:32,595 INFO] | epoch   7 | train_loss  5.19 | val_ppl 190.03971 | time   6.6s
[2018-08-23 19:40:39,348 INFO] | epoch   8 | train_loss  5.13 | val_ppl 184.60526 | time   6.8s
[2018-08-23 19:40:53,380 INFO] | epoch   9 | train_loss  5.09 | val_ppl 180.81202 | time  14.0s
[2018-08-23 19:41:05,005 INFO] | epoch  10 | train_loss  5.05 | val_ppl 178.39430 | time  11.6s
[2018-08-23 19:41:11,797 INFO] | epoch  11 | train_loss  5.01 | val_ppl 175.64836 | time   6.8s
[2018-08-23 19:41:18,384 INFO] | epoch  12 | train_loss  4.98 | val_ppl 172.42083 | time   6.6s
[2018-08-23 19:41:25,206 INFO] | epoch  13 | train_loss  4.95 | val_ppl 170.75503 | time   6.8s
[2018-08-23 19:41:31,947 INFO] | epoch  14 | train_loss  4.92 | val_ppl 169.60565 | time   6.7s
[2018-08-23 19:41:42,667 INFO] | epoch  15 | train_loss  4.89 | val_ppl 167.67923 | time  10.7s
[2018-08-23 19:41:57,240 INFO] | epoch  16 | train_loss  4.86 | val_ppl 167.64712 | time  14.6s
[2018-08-23 19:41:57,240 INFO] learning rate has been changed to 0.375
[2018-08-23 19:42:03,879 INFO] | epoch  17 | train_loss  4.83 | val_ppl 166.24352 | time   6.6s
[2018-08-23 19:42:10,372 INFO] | epoch  18 | train_loss  4.81 | val_ppl 164.10872 | time   6.5s
[2018-08-23 19:42:17,161 INFO] | epoch  19 | train_loss  4.79 | val_ppl 163.89264 | time   6.8s
[2018-08-23 19:42:17,162 INFO] learning rate has been changed to 0.28125
[2018-08-23 19:42:24,058 INFO] | epoch  20 | train_loss  4.76 | val_ppl 163.74638 | time   6.9s
[2018-08-23 19:42:24,058 INFO] learning rate has been changed to 0.2109375
[2018-08-23 19:42:32,142 INFO] | epoch  21 | train_loss  4.74 | val_ppl 162.12735 | time   8.1s
[2018-08-23 19:42:48,760 INFO] | epoch  22 | train_loss  4.73 | val_ppl 162.03546 | time  16.6s
[2018-08-23 19:42:48,761 INFO] learning rate has been changed to 0.158203125
[2018-08-23 19:42:56,646 INFO] | epoch  23 | train_loss  4.72 | val_ppl 161.67975 | time   7.9s
[2018-08-23 19:42:56,646 INFO] learning rate has been changed to 0.11865234375
[2018-08-23 19:43:03,420 INFO] | epoch  24 | train_loss  4.71 | val_ppl 161.58215 | time   6.8s
[2018-08-23 19:43:03,420 INFO] learning rate has been changed to 0.0889892578125
[2018-08-23 19:43:10,229 INFO] | epoch  25 | train_loss  4.70 | val_ppl 161.36706 | time   6.8s
[2018-08-23 19:43:10,229 INFO] learning rate has been changed to 0.066741943359375
[2018-08-23 19:43:17,054 INFO] | epoch  26 | train_loss  4.69 | val_ppl 161.08231 | time   6.8s
[2018-08-23 19:43:17,055 INFO] learning rate has been changed to 0.05005645751953125
[2018-08-23 19:43:23,705 INFO] | epoch  27 | train_loss  4.69 | val_ppl 160.91231 | time   6.7s
[2018-08-23 19:43:23,705 INFO] learning rate has been changed to 0.03754234313964844
[2018-08-23 19:43:38,828 INFO] | epoch  28 | train_loss  4.68 | val_ppl 160.94806 | time  15.1s
[2018-08-23 19:43:38,828 INFO] learning rate has been changed to 0.028156757354736328
[2018-08-23 19:43:49,294 INFO] | epoch  29 | train_loss  4.68 | val_ppl 160.84601 | time  10.5s
[2018-08-23 19:43:49,295 INFO] learning rate has been changed to 0.021117568016052246
[2018-08-23 19:43:55,935 INFO] | epoch  30 | train_loss  4.68 | val_ppl 160.93624 | time   6.6s
[2018-08-23 19:43:55,936 INFO] learning rate has been changed to 0.015838176012039185
[2018-08-23 19:43:56,178 INFO] test_ppl: 168.22591
[2018-08-23 19:52:24,882 INFO] -------------
[2018-08-23 19:52:58,848 INFO] -------------
[2018-08-23 20:22:31,824 INFO] -------------

tied updating outemb
[2018-08-23 20:22:31,824 INFO] Start training...
[2018-08-23 20:22:31,824 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=22, clip=None, data_type='ptb', decay=0.75, device='cuda:0', dropout=0.0, epoch=30, every_n_epoch_save=40, input_vector='~/common_corpus/1mlplen_8epoch_outemb.ptb.850d.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/1mlplen_8epoch_outemb.ptb.850d.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=240, tied=True, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-23 20:22:32,650 INFO] train token: 24
[2018-08-23 20:22:32,650 INFO] test token: 6
[2018-08-23 20:22:32,650 INFO] valid token: 14
[2018-08-23 20:22:32,651 INFO] Loading vectors from /home/lr/yukun/common_corpus/1mlplen_8epoch_outemb.ptb.850d.txt.pt
[2018-08-23 20:23:09,271 INFO] | epoch   1 | train_loss  5.80 | val_ppl 199.38320 | time  30.0s
[2018-08-23 20:23:32,542 INFO] | epoch   2 | train_loss  5.19 | val_ppl 161.35910 | time  23.3s
[2018-08-23 20:23:57,326 INFO] | epoch   3 | train_loss  4.98 | val_ppl 144.02540 | time  24.8s
[2018-08-23 20:24:25,677 INFO] | epoch   4 | train_loss  4.82 | val_ppl 132.45218 | time  28.4s
[2018-08-23 20:24:45,663 INFO] | epoch   5 | train_loss  4.69 | val_ppl 125.11166 | time  20.0s
[2018-08-23 20:25:19,509 INFO] | epoch   6 | train_loss  4.58 | val_ppl 119.42428 | time  33.8s
[2018-08-23 20:25:39,430 INFO] | epoch   7 | train_loss  4.47 | val_ppl 116.46479 | time  19.9s
[2018-08-23 20:26:13,542 INFO] | epoch   8 | train_loss  4.37 | val_ppl 114.56055 | time  34.1s
[2018-08-23 20:26:33,544 INFO] | epoch   9 | train_loss  4.27 | val_ppl 112.67604 | time  20.0s
[2018-08-23 20:26:53,666 INFO] | epoch  10 | train_loss  4.17 | val_ppl 113.32260 | time  20.1s
[2018-08-23 20:26:53,667 INFO] learning rate has been changed to 0.375
[2018-08-23 20:27:13,562 INFO] | epoch  11 | train_loss  4.03 | val_ppl 114.28203 | time  19.9s
[2018-08-23 20:27:13,562 INFO] learning rate has been changed to 0.28125
[2018-08-23 20:27:33,365 INFO] | epoch  12 | train_loss  3.91 | val_ppl 115.20789 | time  19.8s
[2018-08-23 20:27:33,366 INFO] learning rate has been changed to 0.2109375
[2018-08-23 20:27:53,080 INFO] | epoch  13 | train_loss  3.81 | val_ppl 115.81616 | time  19.7s
[2018-08-23 20:27:53,081 INFO] learning rate has been changed to 0.158203125
[2018-08-23 20:28:12,908 INFO] | epoch  14 | train_loss  3.74 | val_ppl 116.97941 | time  19.8s
[2018-08-23 20:28:12,908 INFO] learning rate has been changed to 0.11865234375
[2018-08-23 20:28:32,795 INFO] | epoch  15 | train_loss  3.67 | val_ppl 119.07774 | time  19.9s
[2018-08-23 20:28:32,795 INFO] learning rate has been changed to 0.0889892578125
[2018-08-23 20:28:52,729 INFO] | epoch  16 | train_loss  3.63 | val_ppl 120.51296 | time  19.9s
[2018-08-23 20:28:52,729 INFO] learning rate has been changed to 0.066741943359375
[2018-08-23 20:29:12,642 INFO] | epoch  17 | train_loss  3.59 | val_ppl 121.48847 | time  19.9s
[2018-08-23 20:29:12,643 INFO] learning rate has been changed to 0.05005645751953125
[2018-08-23 20:29:32,427 INFO] | epoch  18 | train_loss  3.56 | val_ppl 122.76799 | time  19.8s
[2018-08-23 20:29:32,427 INFO] learning rate has been changed to 0.03754234313964844
[2018-08-23 20:29:52,263 INFO] | epoch  19 | train_loss  3.54 | val_ppl 123.65239 | time  19.8s
[2018-08-23 20:29:52,264 INFO] learning rate has been changed to 0.028156757354736328
[2018-08-23 20:30:12,216 INFO] | epoch  20 | train_loss  3.52 | val_ppl 124.17517 | time  20.0s
[2018-08-23 20:30:12,217 INFO] learning rate has been changed to 0.021117568016052246
[2018-08-23 20:30:32,079 INFO] | epoch  21 | train_loss  3.50 | val_ppl 125.05326 | time  19.9s
[2018-08-23 20:30:32,079 INFO] learning rate has been changed to 0.015838176012039185
[2018-08-23 20:30:51,862 INFO] | epoch  22 | train_loss  3.49 | val_ppl 125.23622 | time  19.8s
[2018-08-23 20:30:51,863 INFO] learning rate has been changed to 0.011878632009029388
[2018-08-23 20:31:11,672 INFO] | epoch  23 | train_loss  3.49 | val_ppl 125.57367 | time  19.8s
[2018-08-23 20:31:11,673 INFO] learning rate has been changed to 0.008908974006772041
[2018-08-23 20:31:31,510 INFO] | epoch  24 | train_loss  3.48 | val_ppl 125.99788 | time  19.8s
[2018-08-23 20:31:31,511 INFO] learning rate has been changed to 0.006681730505079031
[2018-08-23 20:47:29,704 INFO] -------------
[2018-08-23 20:47:29,705 INFO] Start training...
[2018-08-23 20:49:49,672 INFO] -------------
[2018-08-23 20:49:49,672 INFO] Start training...
[2018-08-23 20:49:49,672 INFO] Namespace(batch_size=1, bidirectional=False, bptt_len=22, clip=None, data_type='ptb', decay=0.75, device='cuda:0', dropout=0.0, epoch=30, every_n_epoch_save=40, input_vector='~/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=240, tied=True, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-23 20:49:50,503 INFO] train token: 24
[2018-08-23 20:49:50,504 INFO] test token: 6
[2018-08-23 20:49:50,504 INFO] valid token: 14
[2018-08-23 20:49:50,505 INFO] Loading vectors from /home/lr/yukun/common_corpus/1mlplen_8epoch_outemb.100d.ptb.txt.pt
[2018-08-23 20:51:03,667 INFO] | epoch   1 | train_loss  5.32 | val_ppl 163.73362 | time  69.9s
[2018-08-23 20:52:12,437 INFO] | epoch   2 | train_loss  4.97 | val_ppl 154.37332 | time  68.8s
[2018-08-23 20:53:22,608 INFO] | epoch   3 | train_loss  4.84 | val_ppl 158.41203 | time  70.2s
[2018-08-23 20:53:22,609 INFO] learning rate has been changed to 0.375
[2018-08-23 20:54:31,411 INFO] | epoch   4 | train_loss  4.64 | val_ppl 141.95907 | time  68.8s
[2018-08-23 20:55:41,678 INFO] | epoch   5 | train_loss  4.58 | val_ppl 144.96144 | time  70.3s
[2018-08-23 20:55:41,679 INFO] learning rate has been changed to 0.28125
[2018-08-23 20:56:50,750 INFO] | epoch   6 | train_loss  4.43 | val_ppl 139.68944 | time  69.1s
[2018-08-23 20:58:00,660 INFO] | epoch   7 | train_loss  4.39 | val_ppl 142.79969 | time  69.9s
[2018-08-23 20:58:00,661 INFO] learning rate has been changed to 0.2109375
[2018-08-23 20:59:09,888 INFO] | epoch   8 | train_loss  4.27 | val_ppl 138.57207 | time  69.2s
[2018-08-23 21:00:20,184 INFO] | epoch   9 | train_loss  4.24 | val_ppl 141.11878 | time  70.3s
[2018-08-23 21:00:20,185 INFO] learning rate has been changed to 0.158203125
[2018-08-23 21:01:29,799 INFO] | epoch  10 | train_loss  4.15 | val_ppl 139.60424 | time  69.6s
[2018-08-23 21:02:39,263 INFO] | epoch  11 | train_loss  4.12 | val_ppl 141.61244 | time  69.5s
[2018-08-23 21:02:39,264 INFO] learning rate has been changed to 0.11865234375
[2018-08-23 21:03:48,885 INFO] | epoch  12 | train_loss  4.05 | val_ppl 141.39582 | time  69.6s
[2018-08-23 21:03:48,886 INFO] learning rate has been changed to 0.0889892578125
[2018-08-23 21:04:58,325 INFO] | epoch  13 | train_loss  3.99 | val_ppl 142.91376 | time  69.4s
[2018-08-23 21:04:58,326 INFO] learning rate has been changed to 0.066741943359375
[2018-08-23 21:06:07,352 INFO] | epoch  14 | train_loss  3.94 | val_ppl 143.34138 | time  69.0s
[2018-08-23 21:06:07,352 INFO] learning rate has been changed to 0.05005645751953125
[2018-08-23 21:07:16,971 INFO] | epoch  15 | train_loss  3.90 | val_ppl 144.59883 | time  69.6s
[2018-08-23 21:07:16,971 INFO] learning rate has been changed to 0.03754234313964844
[2018-08-23 21:08:26,558 INFO] | epoch  16 | train_loss  3.86 | val_ppl 145.38410 | time  69.6s
[2018-08-23 21:08:26,559 INFO] learning rate has been changed to 0.028156757354736328
[2018-08-23 21:09:36,107 INFO] | epoch  17 | train_loss  3.84 | val_ppl 147.80699 | time  69.5s
[2018-08-23 21:09:36,108 INFO] learning rate has been changed to 0.021117568016052246
[2018-08-23 21:10:44,669 INFO] | epoch  18 | train_loss  3.82 | val_ppl 149.41903 | time  68.6s
[2018-08-23 21:10:44,670 INFO] learning rate has been changed to 0.015838176012039185
[2018-08-23 21:11:53,956 INFO] | epoch  19 | train_loss  3.80 | val_ppl 149.56946 | time  69.3s
[2018-08-23 21:11:53,957 INFO] learning rate has been changed to 0.011878632009029388
[2018-08-23 21:13:04,220 INFO] | epoch  20 | train_loss  3.79 | val_ppl 150.28818 | time  70.3s
[2018-08-23 21:13:04,220 INFO] learning rate has been changed to 0.008908974006772041
[2018-08-23 21:29:07,205 INFO] -------------
[2018-08-23 21:29:07,205 INFO] Start training...
[2018-08-23 21:29:07,206 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, data_type='wiki3', decay=0.75, device='cuda:0', dropout=0.0, epoch=40, every_n_epoch_save=8, input_vector='~/common_corpus/wikitext-103/wikitext-103/wiki.train.tokens.preprocessed.cbow.850d', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-103/wikitext-103/wiki.train.tokens.preprocessed.cbow.850d', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-23 21:29:50,579 INFO] -------------
[2018-08-23 21:29:50,579 INFO] Start training...
[2018-08-23 21:29:50,580 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, data_type='wiki3', decay=0.75, device='cuda:0', dropout=0.0, epoch=40, every_n_epoch_save=8, input_vector='~/common_corpus/wikitext-103/wikitext-103/wiki.train.tokens.preprocessed.cbow.850d', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-103/wikitext-103/wiki.train.tokens.preprocessed.cbow.850d', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-23 21:32:50,707 INFO] -------------
[2018-08-23 21:32:50,708 INFO] Start training...
[2018-08-23 21:32:50,708 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=80, clip=None, data_type='wiki3', decay=0.75, device='cuda:0', dropout=0.0, epoch=40, every_n_epoch_save=8, input_vector='~/common_corpus/wikitext-103/wikitext-103/wiki.train.tokens.preprocessed.cbow.850d', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='~/common_corpus/wikitext-103/wikitext-103/wiki.train.tokens.preprocessed.cbow.850d', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1, tied=True, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-23 21:41:08,415 INFO] train token: 105136768
[2018-08-23 21:41:08,418 INFO] test token: 250195
[2018-08-23 21:41:08,418 INFO] valid token: 221640
[2018-08-23 21:41:18,812 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-103/wikitext-103/wiki.train.tokens.preprocessed.cbow.850d
[2018-08-23 21:41:18,846 WARNING] Skipping token 67003 with 1-dimensional vector ['850']; likely a header
[2018-08-23 21:41:35,408 INFO] Saving vectors to /home/lr/yukun/common_corpus/wikitext-103/wikitext-103/wiki.train.tokens.preprocessed.cbow.850d.pt
[2018-08-23 23:24:10,451 INFO] | epoch   1 | train_loss  4.86 | val_ppl 120.32737 | time 6142.0s
[2018-08-24 01:04:24,406 INFO] | epoch   2 | train_loss  4.20 | val_ppl 73.12571 | time 6014.0s
[2018-08-24 03:00:41,577 INFO] | epoch   3 | train_loss  4.05 | val_ppl 59.70228 | time 6977.2s
[2018-08-24 04:45:51,137 INFO] | epoch   4 | train_loss  3.97 | val_ppl 54.06343 | time 6309.5s
[2018-08-24 06:40:34,988 INFO] | epoch   5 | train_loss  3.90 | val_ppl 50.78619 | time 6883.8s
[2018-08-24 08:36:13,344 INFO] | epoch   6 | train_loss  3.85 | val_ppl 48.33298 | time 6938.3s
[2018-08-24 10:31:18,329 INFO] | epoch   7 | train_loss  3.80 | val_ppl 46.43325 | time 6905.0s
