[2018-07-11 11:57:23,593 INFO] Start training...
[2018-07-11 11:57:23,593 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=4, every_n_epoch_save=4, input_embeddings_trainable=True, log_file='log', lr=1.0, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, vector_type='glove.6B.100d')
[2018-07-11 11:57:36,856 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-11 11:58:35,398 INFO] | epoch   1 | train_loss  5.36 | val_ppl   162.03 | time  53.9s
[2018-07-11 11:59:29,589 INFO] | epoch   2 | train_loss  4.91 | val_ppl   141.38 | time  54.2s
[2018-07-11 12:00:23,862 INFO] | epoch   3 | train_loss  4.76 | val_ppl   135.60 | time  54.3s
[2018-07-11 12:01:17,954 INFO] | epoch   4 | train_loss  4.67 | val_ppl   132.10 | time  54.1s
[2018-07-11 12:01:17,954 INFO] start to save model on nnlm.model
[2018-07-11 12:01:20,663 INFO] test_ppl: 121.5
[2018-07-11 12:01:52,326 INFO] Start training...
[2018-07-11 12:01:52,326 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=4, every_n_epoch_save=4, input_embeddings_trainable=True, log_file='log', lr=1.0, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, vector_type='glove.6B.100d')
[2018-07-11 12:02:04,668 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-11 12:03:03,107 INFO] | epoch   1 | train_loss  5.36 | val_ppl   162.03 | time  54.1s
[2018-07-11 12:03:57,274 INFO] | epoch   2 | train_loss  4.91 | val_ppl   141.38 | time  54.2s
[2018-07-11 12:04:51,551 INFO] | epoch   3 | train_loss  4.76 | val_ppl   135.60 | time  54.3s
[2018-07-11 12:05:45,834 INFO] | epoch   4 | train_loss  4.67 | val_ppl   132.10 | time  54.3s
[2018-07-11 12:05:45,835 INFO] start to save model on nnlm.model
[2018-07-11 12:05:48,531 INFO] test_ppl: 121.5
[2018-07-11 12:13:51,900 INFO] Start training...
[2018-07-11 12:13:51,901 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=4, every_n_epoch_save=4, input_embeddings_trainable=True, log_file='log', lr=1.0, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=True, vector_type='glove.6B.100d')
[2018-07-11 12:14:03,920 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-11 12:14:30,772 INFO] Start training...
[2018-07-11 12:14:30,773 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=4, every_n_epoch_save=4, input_embeddings_trainable=True, log_file='log', lr=1.0, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=True, vector_type='glove.6B.100d')
[2018-07-11 12:14:44,150 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-11 12:15:15,018 INFO] Start training...
[2018-07-11 12:15:15,018 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=4, every_n_epoch_save=4, input_embeddings_trainable=True, log_file='log', lr=1.0, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=True, vector_type='glove.6B.100d')
[2018-07-11 12:15:28,133 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-11 12:16:25,528 INFO] | epoch   1 | train_loss  5.97 | val_ppl   227.08 | time  52.2s
[2018-07-11 12:17:17,273 INFO] | epoch   2 | train_loss  5.30 | val_ppl   198.76 | time  51.7s
[2018-07-11 12:18:08,877 INFO] | epoch   3 | train_loss  5.18 | val_ppl   185.42 | time  51.6s
[2018-07-11 12:19:00,652 INFO] | epoch   4 | train_loss  5.10 | val_ppl   175.43 | time  51.8s
[2018-07-11 12:19:00,652 INFO] start to save model on nnlm.model
[2018-07-11 12:19:03,120 INFO] test_ppl: 161.4
[2018-07-28 22:55:08,800 INFO] Start training...
[2018-07-28 22:55:08,800 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=4, input_embeddings_trainable=1, log_file='log', lr=0.5, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-07-28 22:55:24,865 INFO] train token: 2127402
[2018-07-28 22:55:24,866 INFO] test token: 250140
[2018-07-28 22:55:24,866 INFO] valid token: 221606
[2018-07-28 22:55:25,372 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-28 22:56:28,014 INFO] | epoch   1 | train_loss  5.48 | val_ppl   174.45 | time  58.2s
[2018-07-28 22:57:26,507 INFO] | epoch   2 | train_loss  5.03 | val_ppl   148.51 | time  58.5s
[2018-07-28 22:58:25,131 INFO] | epoch   3 | train_loss  4.89 | val_ppl   137.81 | time  58.6s
[2018-07-28 22:59:23,791 INFO] | epoch   4 | train_loss  4.80 | val_ppl   132.02 | time  58.7s
[2018-07-28 22:59:23,791 INFO] start to save model on nnlm.model
[2018-07-28 23:00:23,383 INFO] | epoch   5 | train_loss  4.73 | val_ppl   128.47 | time  58.9s
[2018-07-28 23:01:22,137 INFO] | epoch   6 | train_loss  4.68 | val_ppl   126.19 | time  58.8s
[2018-07-28 23:02:20,923 INFO] | epoch   7 | train_loss  4.63 | val_ppl   124.58 | time  58.8s
[2018-07-28 23:03:19,775 INFO] | epoch   8 | train_loss  4.59 | val_ppl   123.33 | time  58.9s
[2018-07-28 23:03:19,775 INFO] start to save model on nnlm.model
[2018-07-28 23:05:54,299 INFO] test_ppl: 113.9

(explanation: during testing, I changed the trained emb both input and output to the raw
pre-trained word emb. And get 2554 ppl on test data)
[2018-07-31 14:09:14,392 INFO] Start training...
[2018-07-31 14:09:14,392 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, input_embeddings_trainable=1, log_file='log', lr=0.5, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-07-31 14:09:25,980 INFO] train token: 2127402
[2018-07-31 14:09:25,980 INFO] test token: 250140
[2018-07-31 14:09:25,980 INFO] valid token: 221606
[2018-07-31 14:09:26,425 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-31 14:10:37,426 INFO] | epoch   1 | train_loss  5.62 | val_ppl   202.87 | time  67.0s
[2018-07-31 14:11:45,479 INFO] | epoch   2 | train_loss  5.26 | val_ppl   182.92 | time  68.1s
[2018-07-31 14:12:53,601 INFO] | epoch   3 | train_loss  5.17 | val_ppl   173.45 | time  68.1s
[2018-07-31 14:14:02,259 INFO] | epoch   4 | train_loss  5.11 | val_ppl   167.48 | time  68.7s
[2018-07-31 14:15:10,687 INFO] | epoch   5 | train_loss  5.07 | val_ppl   163.20 | time  68.4s
[2018-07-31 14:16:19,743 INFO] | epoch   6 | train_loss  5.03 | val_ppl   159.85 | time  69.1s
[2018-07-31 14:17:27,937 INFO] | epoch   7 | train_loss  5.00 | val_ppl   157.40 | time  68.2s
[2018-07-31 14:18:36,343 INFO] | epoch   8 | train_loss  4.97 | val_ppl   155.19 | time  68.4s
[2018-07-31 14:18:38,957 INFO] test_ppl: 2554.4

(explanation: during testing, I only changed the output train emb to the input and raw pre-trained)
[2018-07-31 14:30:17,872 INFO] Start training...
[2018-07-31 14:30:17,872 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, input_embeddings_trainable=1, log_file='log', lr=0.5, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-07-31 14:30:29,691 INFO] train token: 2127402
[2018-07-31 14:30:29,692 INFO] test token: 250140
[2018-07-31 14:30:29,692 INFO] valid token: 221606
[2018-07-31 14:30:30,120 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-31 14:31:41,477 INFO] | epoch   1 | train_loss  5.62 | val_ppl   202.87 | time  67.3s
[2018-07-31 14:32:49,501 INFO] | epoch   2 | train_loss  5.26 | val_ppl   182.92 | time  68.0s
[2018-07-31 14:33:57,168 INFO] | epoch   3 | train_loss  5.17 | val_ppl   173.45 | time  67.7s
[2018-07-31 14:35:05,325 INFO] | epoch   4 | train_loss  5.11 | val_ppl   167.48 | time  68.2s
[2018-07-31 14:36:13,854 INFO] | epoch   5 | train_loss  5.07 | val_ppl   163.20 | time  68.5s
[2018-07-31 14:37:22,128 INFO] | epoch   6 | train_loss  5.03 | val_ppl   159.85 | time  68.3s
[2018-07-31 14:38:30,394 INFO] | epoch   7 | train_loss  5.00 | val_ppl   157.40 | time  68.3s
[2018-07-31 14:39:38,630 INFO] | epoch   8 | train_loss  4.97 | val_ppl   155.19 | time  68.2s
[2018-07-31 14:39:41,242 INFO] out emb from pre-trained emb, test_ppl: 1557.8
[2018-07-31 14:39:43,849 INFO] out emb from input trained emb, test_ppl: 1864.3

(explanation: both input and output emb are randomly inited. but latter poor similarity on input
emb is observed, but good performance on output emb)
[2018-07-31 14:54:30,371 INFO] Start training...
[2018-07-31 14:54:30,371 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, input_embeddings_trainable=1, log_file='log', lr=0.5, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-07-31 14:54:42,263 INFO] train token: 2127402
[2018-07-31 14:54:42,263 INFO] test token: 250140
[2018-07-31 14:54:42,263 INFO] valid token: 221606
[2018-07-31 14:54:42,697 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-31 14:55:53,816 INFO] | epoch   1 | train_loss  5.73 | val_ppl   217.15 | time  67.2s
[2018-07-31 14:57:01,955 INFO] | epoch   2 | train_loss  5.30 | val_ppl   191.46 | time  68.1s
[2018-07-31 14:58:09,843 INFO] | epoch   3 | train_loss  5.16 | val_ppl   179.09 | time  67.9s
[2018-07-31 14:59:18,046 INFO] | epoch   4 | train_loss  5.07 | val_ppl   172.12 | time  68.2s
[2018-07-31 15:00:26,312 INFO] | epoch   5 | train_loss  5.01 | val_ppl   167.67 | time  68.3s
[2018-07-31 15:01:34,973 INFO] | epoch   6 | train_loss  4.95 | val_ppl   164.24 | time  68.7s
[2018-07-31 15:02:43,250 INFO] | epoch   7 | train_loss  4.91 | val_ppl   161.55 | time  68.3s
[2018-07-31 15:03:51,422 INFO] | epoch   8 | train_loss  4.87 | val_ppl   159.90 | time  68.2s
[2018-07-31 15:03:54,032 INFO] test_ppl: 146.8
[2018-07-31 15:28:57,698 INFO] Start training...

(explanation: change random seed to observe above xianxiang)
[2018-07-31 15:28:57,698 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, input_embeddings_trainable=1, log_file='log', lr=0.5, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=2, tied=False, vector_type='glove.6B.100d')
[2018-07-31 15:29:09,650 INFO] train token: 2127402
[2018-07-31 15:29:09,650 INFO] test token: 250140
[2018-07-31 15:29:09,650 INFO] valid token: 221606
[2018-07-31 15:29:10,092 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-31 15:30:21,567 INFO] | epoch   1 | train_loss  5.72 | val_ppl   211.07 | time  67.5s
[2018-07-31 15:31:29,211 INFO] | epoch   2 | train_loss  5.30 | val_ppl   188.27 | time  67.6s
[2018-07-31 15:32:37,209 INFO] | epoch   3 | train_loss  5.16 | val_ppl   177.49 | time  68.0s
[2018-07-31 15:33:44,926 INFO] | epoch   4 | train_loss  5.07 | val_ppl   171.14 | time  67.7s
[2018-07-31 15:34:53,238 INFO] | epoch   5 | train_loss  5.01 | val_ppl   166.88 | time  68.3s
[2018-07-31 15:36:01,612 INFO] | epoch   6 | train_loss  4.96 | val_ppl   163.86 | time  68.4s
[2018-07-31 15:37:09,962 INFO] | epoch   7 | train_loss  4.91 | val_ppl   161.72 | time  68.4s
[2018-07-31 15:38:18,200 INFO] | epoch   8 | train_loss  4.87 | val_ppl   160.12 | time  68.2s
[2018-07-31 15:38:20,809 INFO] test_ppl: 147.1

(explanation: tied, randomly inited)
[2018-07-31 16:04:23,671 INFO] Start training...
[2018-07-31 16:04:23,672 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, input_embeddings_trainable=1, log_file='log', lr=0.5, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=True, vector_type='glove.6B.100d')
[2018-07-31 16:04:35,709 INFO] train token: 2127402
[2018-07-31 16:04:35,709 INFO] test token: 250140
[2018-07-31 16:04:35,710 INFO] valid token: 221606
[2018-07-31 16:04:36,135 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-31 16:05:44,870 INFO] | epoch   1 | train_loss  6.71 | val_ppl   513.26 | time  64.8s
[2018-07-31 16:06:49,821 INFO] | epoch   2 | train_loss  6.21 | val_ppl   405.96 | time  65.0s
[2018-07-31 16:07:55,041 INFO] | epoch   3 | train_loss  6.04 | val_ppl   357.50 | time  65.2s
[2018-07-31 16:08:59,693 INFO] | epoch   4 | train_loss  5.93 | val_ppl   328.33 | time  64.7s
[2018-07-31 16:10:05,344 INFO] | epoch   5 | train_loss  5.85 | val_ppl   308.08 | time  65.7s
[2018-07-31 16:11:10,503 INFO] | epoch   6 | train_loss  5.79 | val_ppl   292.92 | time  65.2s
[2018-07-31 16:12:16,001 INFO] | epoch   7 | train_loss  5.74 | val_ppl   281.16 | time  65.5s
[2018-07-31 16:13:21,448 INFO] | epoch   8 | train_loss  5.70 | val_ppl   271.68 | time  65.4s
[2018-07-31 16:13:24,054 INFO] test_ppl: 250.3


(explanation: input will be updated. output is fixed using pre-trained emb)
[2018-07-31 19:49:39,046 INFO] Start training...
[2018-07-31 19:49:39,046 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, input_embeddings_trainable=1, log_file='log', lr=0.5, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-07-31 19:49:50,588 INFO] train token: 2127402
[2018-07-31 19:49:50,589 INFO] test token: 250140
[2018-07-31 19:49:50,589 INFO] valid token: 221606
[2018-07-31 19:49:51,008 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-31 19:51:03,078 INFO] | epoch   1 | train_loss  5.62 | val_ppl   202.87 | time  68.1s
[2018-07-31 19:52:11,188 INFO] | epoch   2 | train_loss  5.26 | val_ppl   182.92 | time  68.1s
[2018-07-31 19:53:19,355 INFO] | epoch   3 | train_loss  5.17 | val_ppl   173.45 | time  68.2s
[2018-07-31 19:54:28,062 INFO] | epoch   4 | train_loss  5.11 | val_ppl   167.48 | time  68.7s
[2018-07-31 19:55:36,061 INFO] | epoch   5 | train_loss  5.07 | val_ppl   163.20 | time  68.0s
[2018-07-31 19:56:45,114 INFO] | epoch   6 | train_loss  5.03 | val_ppl   159.85 | time  69.1s
[2018-07-31 19:57:53,615 INFO] | epoch   7 | train_loss  5.00 | val_ppl   157.40 | time  68.5s
[2018-07-31 19:59:01,928 INFO] | epoch   8 | train_loss  4.97 | val_ppl   155.19 | time  68.3s
[2018-07-31 19:59:04,521 INFO] test_ppl: 143.7

(explanation: I disabled both input and output embeddings from pre-trained. it still works)
[2018-07-31 21:58:56,589 INFO] Start training...
[2018-07-31 21:58:56,589 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=True, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-07-31 21:59:08,303 INFO] train token: 2127402
[2018-07-31 21:59:08,303 INFO] test token: 250140
[2018-07-31 21:59:08,303 INFO] valid token: 221606
[2018-07-31 21:59:08,747 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-31 22:00:20,066 INFO] | epoch   1 | train_loss  5.62 | val_ppl   202.87 | time  67.3s
[2018-07-31 22:01:27,876 INFO] | epoch   2 | train_loss  5.26 | val_ppl   182.92 | time  67.8s
[2018-07-31 22:02:36,551 INFO] | epoch   3 | train_loss  5.17 | val_ppl   173.45 | time  68.7s
[2018-07-31 22:03:45,416 INFO] | epoch   4 | train_loss  5.11 | val_ppl   167.48 | time  68.9s
[2018-07-31 22:04:53,778 INFO] | epoch   5 | train_loss  5.07 | val_ppl   163.20 | time  68.4s
[2018-07-31 22:06:02,175 INFO] | epoch   6 | train_loss  5.03 | val_ppl   159.85 | time  68.4s
[2018-07-31 22:07:10,262 INFO] | epoch   7 | train_loss  5.00 | val_ppl   157.40 | time  68.1s
[2018-07-31 22:08:18,607 INFO] | epoch   8 | train_loss  4.97 | val_ppl   155.19 | time  68.3s
[2018-07-31 22:08:21,205 INFO] test_ppl: 143.7

(explanation: I disabled output update, enable input, but result is same. strange mark here)
[2018-07-31 22:16:48,673 INFO] Start training...
[2018-07-31 22:16:48,673 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-07-31 22:17:00,997 INFO] train token: 2127402
[2018-07-31 22:17:00,997 INFO] test token: 250140
[2018-07-31 22:17:00,997 INFO] valid token: 221606
[2018-07-31 22:17:01,473 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-07-31 22:17:05,825 INFO] embeddings input emb requries_grad:True
[2018-07-31 22:18:12,708 INFO] | epoch   1 | train_loss  5.62 | val_ppl   202.87 | time  66.9s
[2018-07-31 22:19:20,513 INFO] | epoch   2 | train_loss  5.26 | val_ppl   182.92 | time  67.8s
[2018-07-31 22:20:28,542 INFO] | epoch   3 | train_loss  5.17 | val_ppl   173.45 | time  68.0s
[2018-07-31 22:21:36,978 INFO] | epoch   4 | train_loss  5.11 | val_ppl   167.48 | time  68.4s
[2018-07-31 22:22:44,891 INFO] | epoch   5 | train_loss  5.07 | val_ppl   163.20 | time  67.9s
[2018-07-31 22:23:53,138 INFO] | epoch   6 | train_loss  5.03 | val_ppl   159.85 | time  68.2s
[2018-07-31 22:25:01,365 INFO] | epoch   7 | train_loss  5.00 | val_ppl   157.40 | time  68.2s
[2018-07-31 22:26:10,235 INFO] | epoch   8 | train_loss  4.97 | val_ppl   155.19 | time  68.9s
[2018-07-31 22:26:12,711 INFO] test_ppl: 143.7
[2018-08-03 16:20:08,523 INFO] Start training...

(explanation: using trained cbow on same training data. the output emb is fixed, input is updating.
al most obtain the best result)
[2018-08-03 16:20:08,523 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:1', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-03 16:20:19,495 INFO] train token: 2127402
[2018-08-03 16:20:19,495 INFO] test token: 250140
[2018-08-03 16:20:19,495 INFO] valid token: 221606
[2018-08-03 16:20:19,683 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt
[2018-08-03 16:20:19,687 WARNING] Skipping token 23380 with 1-dimensional vector ['100']; likely a header
[2018-08-03 16:20:20,509 INFO] Saving vectors to /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-03 16:20:28,049 INFO] embeddings input emb requries_grad:True
[2018-08-03 16:20:52,152 INFO] | epoch   1 | train_loss  5.28 | val_ppl   164.29 | time  24.1s
[2018-08-03 16:21:16,072 INFO] | epoch   2 | train_loss  4.96 | val_ppl   145.30 | time  23.9s
[2018-08-03 16:21:40,427 INFO] | epoch   3 | train_loss  4.84 | val_ppl   136.03 | time  24.4s
[2018-08-03 16:22:04,642 INFO] | epoch   4 | train_loss  4.75 | val_ppl   130.40 | time  24.2s
[2018-08-03 16:22:28,586 INFO] | epoch   5 | train_loss  4.68 | val_ppl   126.64 | time  23.9s
[2018-08-03 16:22:53,095 INFO] | epoch   6 | train_loss  4.62 | val_ppl   124.04 | time  24.5s
[2018-08-03 16:23:17,185 INFO] | epoch   7 | train_loss  4.58 | val_ppl   122.21 | time  24.1s
[2018-08-03 16:23:41,889 INFO] | epoch   8 | train_loss  4.53 | val_ppl   120.94 | time  24.7s
[2018-08-03 16:23:42,887 INFO] test_ppl: 116.5
[2018-08-04 16:38:43,055 INFO] -------------
explanation: val_ppl and test_ppl are -consine. wiki2 trained cbow to fix out emb and update in emb
[2018-08-04 16:38:43,056 INFO] Start training...
[2018-08-04 16:38:43,056 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-04 16:38:54,264 INFO] train token: 2127402
[2018-08-04 16:38:54,264 INFO] test token: 250140
[2018-08-04 16:38:54,265 INFO] valid token: 221606
[2018-08-04 16:38:54,482 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-04 16:39:22,428 INFO] | epoch   1 | train_loss  5.28 | val_ppl    -0.21 | time  23.7s
[2018-08-04 16:39:45,128 INFO] | epoch   2 | train_loss  4.96 | val_ppl    -0.22 | time  22.7s
[2018-08-04 16:40:08,614 INFO] | epoch   3 | train_loss  4.84 | val_ppl    -0.23 | time  23.5s
[2018-08-04 16:40:32,137 INFO] | epoch   4 | train_loss  4.75 | val_ppl    -0.23 | time  23.5s
[2018-08-04 16:40:55,733 INFO] | epoch   5 | train_loss  4.68 | val_ppl    -0.23 | time  23.6s
[2018-08-04 16:41:19,158 INFO] | epoch   6 | train_loss  4.62 | val_ppl    -0.23 | time  23.4s
[2018-08-04 16:41:42,629 INFO] | epoch   7 | train_loss  4.58 | val_ppl    -0.24 | time  23.5s
[2018-08-04 16:42:05,937 INFO] | epoch   8 | train_loss  4.53 | val_ppl    -0.24 | time  23.3s
[2018-08-04 16:42:06,589 INFO] test_ppl:  -0.2
[2018-08-04 16:49:32,227 INFO] -------------
(explanation: the same as above one. I changed the float point of cosine)
[2018-08-04 16:49:32,227 INFO] Start training...
[2018-08-04 16:49:32,227 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-04 16:49:43,473 INFO] train token: 2127402
[2018-08-04 16:49:43,473 INFO] test token: 250140
[2018-08-04 16:49:43,474 INFO] valid token: 221606
[2018-08-04 16:49:43,619 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-04 16:50:10,367 INFO] | epoch   1 | train_loss  5.28 | val_ppl -0.21334 | time  23.3s
[2018-08-04 16:50:33,777 INFO] | epoch   2 | train_loss  4.96 | val_ppl -0.22230 | time  23.4s
[2018-08-04 16:50:56,918 INFO] | epoch   3 | train_loss  4.84 | val_ppl -0.22630 | time  23.1s
[2018-08-04 16:51:20,258 INFO] | epoch   4 | train_loss  4.75 | val_ppl -0.22975 | time  23.3s
[2018-08-04 16:51:43,789 INFO] | epoch   5 | train_loss  4.68 | val_ppl -0.23230 | time  23.5s
[2018-08-04 16:52:07,929 INFO] | epoch   6 | train_loss  4.62 | val_ppl -0.23413 | time  24.1s
[2018-08-04 16:52:31,161 INFO] | epoch   7 | train_loss  4.58 | val_ppl -0.23547 | time  23.2s
[2018-08-04 16:52:54,546 INFO] | epoch   8 | train_loss  4.53 | val_ppl -0.23652 | time  23.4s
[2018-08-04 16:52:55,215 INFO] test_ppl: -0.23469


(explanation: full-softmax norm hidden output and pretrained norm out emb from the start, all is same as before
the result shows it performs a slightly bad than non-norm one. But note fixing out emb, still works)
[2018-08-11 10:11:52,834 INFO] -------------
[2018-08-11 10:11:52,834 INFO] Start training...
[2018-08-11 10:11:52,834 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 10:12:03,779 INFO] train token: 2127402
[2018-08-11 10:12:03,779 INFO] test token: 250140
[2018-08-11 10:12:03,779 INFO] valid token: 221606
[2018-08-11 10:12:03,918 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 10:12:31,943 INFO] | epoch   1 | train_loss  5.69 | val_ppl 212.15373 | time  24.6s
[2018-08-11 10:12:56,157 INFO] | epoch   2 | train_loss  5.32 | val_ppl 180.26816 | time  24.2s
[2018-08-11 10:13:21,018 INFO] | epoch   3 | train_loss  5.18 | val_ppl 164.25467 | time  24.9s
[2018-08-11 10:13:45,154 INFO] | epoch   4 | train_loss  5.10 | val_ppl 154.49554 | time  24.1s
[2018-08-11 10:14:09,838 INFO] | epoch   5 | train_loss  5.03 | val_ppl 147.72783 | time  24.7s
[2018-08-11 10:14:35,549 INFO] | epoch   6 | train_loss  4.98 | val_ppl 142.51899 | time  25.7s
[2018-08-11 10:15:00,965 INFO] | epoch   7 | train_loss  4.94 | val_ppl 138.56315 | time  25.4s
[2018-08-11 10:15:25,451 INFO] | epoch   8 | train_loss  4.91 | val_ppl 135.48768 | time  24.5s
[2018-08-11 10:15:26,474 INFO] test_ppl: 131.53229


(explanation: randomly out emb, updating. this is the PPL result)
[2018-08-11 10:40:34,481 INFO] -------------
[2018-08-11 10:40:34,481 INFO] Start training...
[2018-08-11 10:40:34,481 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 10:40:45,832 INFO] train token: 2127402
[2018-08-11 10:40:45,832 INFO] test token: 250140
[2018-08-11 10:40:45,832 INFO] valid token: 221606
[2018-08-11 10:40:45,972 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 10:41:13,416 INFO] | epoch   1 | train_loss  5.21 | val_ppl 154.21461 | time  23.9s
[2018-08-11 10:41:37,165 INFO] | epoch   2 | train_loss  4.85 | val_ppl 134.51386 | time  23.7s
[2018-08-11 10:42:01,007 INFO] | epoch   3 | train_loss  4.73 | val_ppl 124.98321 | time  23.8s
[2018-08-11 10:42:25,112 INFO] | epoch   4 | train_loss  4.64 | val_ppl 119.01536 | time  24.1s
[2018-08-11 10:42:48,558 INFO] | epoch   5 | train_loss  4.58 | val_ppl 115.04513 | time  23.4s
[2018-08-11 10:43:12,139 INFO] | epoch   6 | train_loss  4.53 | val_ppl 112.35071 | time  23.6s
[2018-08-11 10:43:35,855 INFO] | epoch   7 | train_loss  4.49 | val_ppl 110.55550 | time  23.7s
[2018-08-11 10:43:59,139 INFO] | epoch   8 | train_loss  4.45 | val_ppl 109.30011 | time  23.3s
[2018-08-11 10:44:00,116 INFO] test_ppl: 105.30712


(explanation: randomly out emb, fixed, the totally same result!. any bug? how it could be!)
[2018-08-11 10:52:13,115 INFO] -------------
[2018-08-11 10:52:13,115 INFO] Start training...
[2018-08-11 10:52:13,116 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 10:52:24,324 INFO] train token: 2127402
[2018-08-11 10:52:24,324 INFO] test token: 250140
[2018-08-11 10:52:24,324 INFO] valid token: 221606
[2018-08-11 10:52:24,464 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 10:52:51,258 INFO] | epoch   1 | train_loss  5.21 | val_ppl 154.21461 | time  23.8s
[2018-08-11 10:53:14,410 INFO] | epoch   2 | train_loss  4.85 | val_ppl 134.51386 | time  23.2s
[2018-08-11 10:53:37,993 INFO] | epoch   3 | train_loss  4.73 | val_ppl 124.98321 | time  23.6s
[2018-08-11 10:54:01,673 INFO] | epoch   4 | train_loss  4.64 | val_ppl 119.01536 | time  23.7s
[2018-08-11 10:54:25,475 INFO] | epoch   5 | train_loss  4.58 | val_ppl 115.04513 | time  23.8s
[2018-08-11 10:54:48,660 INFO] | epoch   6 | train_loss  4.53 | val_ppl 112.35071 | time  23.2s
[2018-08-11 10:55:12,417 INFO] | epoch   7 | train_loss  4.49 | val_ppl 110.55550 | time  23.8s
[2018-08-11 10:55:35,869 INFO] | epoch   8 | train_loss  4.45 | val_ppl 109.30011 | time  23.5s
[2018-08-11 10:55:36,836 INFO] test_ppl: 105.30712


----------------
-  split line  -
----------------

After I found the reason of a bug in my program. The above result have to be ignored for
non-updating setting.
------------------------------------------
-----------------------------------------


(explanation: standard. pretrained out in, updating both)
[2018-08-11 11:42:02,033 INFO] -------------
[2018-08-11 11:42:02,033 INFO] Start training...
[2018-08-11 11:42:02,033 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 11:42:13,059 INFO] train token: 2127402
[2018-08-11 11:42:13,060 INFO] test token: 250140
[2018-08-11 11:42:13,060 INFO] valid token: 221606
[2018-08-11 11:42:13,294 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 11:42:40,425 INFO] | epoch   1 | train_loss  5.28 | val_ppl 164.29145 | time  23.7s
[2018-08-11 11:43:03,660 INFO] | epoch   2 | train_loss  4.96 | val_ppl 145.29785 | time  23.2s
[2018-08-11 11:43:28,005 INFO] | epoch   3 | train_loss  4.84 | val_ppl 136.03464 | time  24.3s
[2018-08-11 11:43:51,476 INFO] | epoch   4 | train_loss  4.75 | val_ppl 130.40298 | time  23.5s
[2018-08-11 11:44:15,149 INFO] | epoch   5 | train_loss  4.68 | val_ppl 126.63874 | time  23.7s
[2018-08-11 11:44:38,460 INFO] | epoch   6 | train_loss  4.62 | val_ppl 124.03754 | time  23.3s
[2018-08-11 11:45:01,810 INFO] | epoch   7 | train_loss  4.58 | val_ppl 122.20709 | time  23.3s
[2018-08-11 11:45:25,251 INFO] | epoch   8 | train_loss  4.53 | val_ppl 120.94260 | time  23.4s
[2018-08-11 11:45:26,214 INFO] test_ppl: 116.48836
[2018-08-11 11:47:09,263 INFO] -------------
[2018-08-11 11:47:09,263 INFO] Start training...
[2018-08-11 11:47:09,263 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 11:47:20,770 INFO] train token: 2127402
[2018-08-11 11:47:20,771 INFO] test token: 250140
[2018-08-11 11:47:20,771 INFO] valid token: 221606
[2018-08-11 11:47:20,914 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt

(explanation: no bias term in softmax output)
[2018-08-11 11:53:32,440 INFO] -------------
[2018-08-11 11:53:32,440 INFO] Start training...
[2018-08-11 11:53:32,440 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 11:53:43,587 INFO] train token: 2127402
[2018-08-11 11:53:43,587 INFO] test token: 250140
[2018-08-11 11:53:43,587 INFO] valid token: 221606
[2018-08-11 11:53:43,730 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 11:54:09,951 INFO] | epoch   1 | train_loss  5.27 | val_ppl 167.26648 | time  22.9s
[2018-08-11 11:54:32,207 INFO] | epoch   2 | train_loss  4.96 | val_ppl 146.64552 | time  22.3s
[2018-08-11 11:54:54,706 INFO] | epoch   3 | train_loss  4.84 | val_ppl 137.08501 | time  22.5s
[2018-08-11 11:55:17,098 INFO] | epoch   4 | train_loss  4.75 | val_ppl 131.19981 | time  22.4s
[2018-08-11 11:55:39,398 INFO] | epoch   5 | train_loss  4.68 | val_ppl 127.14218 | time  22.3s
[2018-08-11 11:56:02,100 INFO] | epoch   6 | train_loss  4.63 | val_ppl 124.31848 | time  22.7s
[2018-08-11 11:56:24,560 INFO] | epoch   7 | train_loss  4.58 | val_ppl 122.25929 | time  22.5s
[2018-08-11 11:56:46,903 INFO] | epoch   8 | train_loss  4.53 | val_ppl 120.73668 | time  22.3s
[2018-08-11 11:56:47,783 INFO] test_ppl: 116.25565
[2018-08-11 11:58:12,622 INFO] -------------

explanation: this not updating pretrained emb
[2018-08-11 11:58:12,622 INFO] Start training...
[2018-08-11 11:58:12,622 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 11:58:23,951 INFO] train token: 2127402
[2018-08-11 11:58:23,951 INFO] test token: 250140
[2018-08-11 11:58:23,951 INFO] valid token: 221606
[2018-08-11 11:58:24,093 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 11:58:47,852 INFO] | epoch   1 | train_loss  5.69 | val_ppl 252.04634 | time  20.5s
[2018-08-11 11:59:07,940 INFO] | epoch   2 | train_loss  5.42 | val_ppl 230.61994 | time  20.1s
[2018-08-11 11:59:28,003 INFO] | epoch   3 | train_loss  5.33 | val_ppl 221.23442 | time  20.1s
[2018-08-11 11:59:48,386 INFO] | epoch   4 | train_loss  5.27 | val_ppl 215.90383 | time  20.4s
[2018-08-11 12:00:08,196 INFO] | epoch   5 | train_loss  5.23 | val_ppl 213.32098 | time  19.8s
[2018-08-11 12:00:28,499 INFO] | epoch   6 | train_loss  5.19 | val_ppl 211.77433 | time  20.3s
[2018-08-11 12:00:48,346 INFO] | epoch   7 | train_loss  5.16 | val_ppl 211.10733 | time  19.8s
[2018-08-11 12:01:08,003 INFO] | epoch   8 | train_loss  5.13 | val_ppl 210.85058 | time  19.7s
[2018-08-11 12:01:08,865 INFO] test_ppl: 202.07194
[2018-08-11 12:10:28,346 INFO] -------------

(explanation: following above setting ,updating bias)
[2018-08-11 12:10:28,346 INFO] Start training...
[2018-08-11 12:10:28,346 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 12:10:39,566 INFO] train token: 2127402
[2018-08-11 12:10:39,566 INFO] test token: 250140
[2018-08-11 12:10:39,566 INFO] valid token: 221606
[2018-08-11 12:10:39,710 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 12:11:04,395 INFO] | epoch   1 | train_loss  5.50 | val_ppl 205.60689 | time  21.4s
[2018-08-11 12:11:25,967 INFO] | epoch   2 | train_loss  5.23 | val_ppl 184.87383 | time  21.6s
[2018-08-11 12:11:47,460 INFO] | epoch   3 | train_loss  5.13 | val_ppl 176.79595 | time  21.5s
[2018-08-11 12:12:08,994 INFO] | epoch   4 | train_loss  5.07 | val_ppl 172.47004 | time  21.5s
[2018-08-11 12:12:30,035 INFO] | epoch   5 | train_loss  5.02 | val_ppl 169.36231 | time  21.0s
[2018-08-11 12:12:51,509 INFO] | epoch   6 | train_loss  4.98 | val_ppl 167.69087 | time  21.5s
[2018-08-11 12:13:12,369 INFO] | epoch   7 | train_loss  4.95 | val_ppl 166.89307 | time  20.9s
[2018-08-11 12:13:33,561 INFO] | epoch   8 | train_loss  4.92 | val_ppl 166.55194 | time  21.2s
[2018-08-11 12:13:34,523 INFO] test_ppl: 160.89592
[2018-08-11 12:23:11,616 INFO] -------------

(explanation: norm hidden, and norm fixed out emb)
[2018-08-11 12:23:11,616 INFO] Start training...
[2018-08-11 12:23:11,616 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 12:23:23,430 INFO] train token: 2127402
[2018-08-11 12:23:23,430 INFO] test token: 250140
[2018-08-11 12:23:23,431 INFO] valid token: 221606
[2018-08-11 12:23:23,664 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 12:23:48,735 INFO] | epoch   1 | train_loss  9.15 | val_ppl 9215.55642 | time  21.1s
[2018-08-11 12:24:09,707 INFO] | epoch   2 | train_loss  9.13 | val_ppl 9158.74265 | time  21.0s
[2018-08-11 12:24:30,987 INFO] | epoch   3 | train_loss  9.13 | val_ppl 9132.80471 | time  21.3s
[2018-08-11 12:24:51,834 INFO] | epoch   4 | train_loss  9.12 | val_ppl 9107.43428 | time  20.8s
[2018-08-11 12:25:13,540 INFO] | epoch   5 | train_loss  9.12 | val_ppl 9082.90436 | time  21.7s
[2018-08-11 12:25:34,020 INFO] | epoch   6 | train_loss  9.12 | val_ppl 9064.22266 | time  20.5s
[2018-08-11 12:25:54,297 INFO] | epoch   7 | train_loss  9.12 | val_ppl 9051.11456 | time  20.3s
[2018-08-11 12:26:15,181 INFO] | epoch   8 | train_loss  9.11 | val_ppl 9039.41527 | time  20.9s
[2018-08-11 12:26:16,114 INFO] test_ppl: 8990.28242

(same as above, updating normed emb. norm is only done at start)
[2018-08-11 12:27:20,148 INFO] -------------
[2018-08-11 12:27:20,148 INFO] Start training...
[2018-08-11 12:27:20,148 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 12:27:31,261 INFO] train token: 2127402
[2018-08-11 12:27:31,261 INFO] test token: 250140
[2018-08-11 12:27:31,261 INFO] valid token: 221606
[2018-08-11 12:27:31,405 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 12:27:57,805 INFO] | epoch   1 | train_loss  5.74 | val_ppl 220.63858 | time  23.0s
[2018-08-11 12:28:20,458 INFO] | epoch   2 | train_loss  5.36 | val_ppl 187.76345 | time  22.7s
[2018-08-11 12:28:43,665 INFO] | epoch   3 | train_loss  5.23 | val_ppl 171.58674 | time  23.2s
[2018-08-11 12:29:07,140 INFO] | epoch   4 | train_loss  5.15 | val_ppl 161.98186 | time  23.5s
[2018-08-11 12:29:30,515 INFO] | epoch   5 | train_loss  5.09 | val_ppl 155.08981 | time  23.4s
[2018-08-11 12:29:53,424 INFO] | epoch   6 | train_loss  5.04 | val_ppl 149.91193 | time  22.9s
[2018-08-11 12:30:16,597 INFO] | epoch   7 | train_loss  5.00 | val_ppl 145.86725 | time  23.2s
[2018-08-11 12:30:39,851 INFO] | epoch   8 | train_loss  4.97 | val_ppl 142.65083 | time  23.3s
[2018-08-11 12:30:40,802 INFO] test_ppl: 138.79193
[2018-08-11 13:00:50,147 INFO] -------------

(explanation: very standard. but norm pretrained out emb only at the start. note it's better than
non-norm)
[2018-08-11 13:00:50,148 INFO] Start training...
[2018-08-11 13:00:50,148 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 13:01:01,498 INFO] train token: 2127402
[2018-08-11 13:01:01,498 INFO] test token: 250140
[2018-08-11 13:01:01,498 INFO] valid token: 221606
[2018-08-11 13:01:01,641 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 13:01:27,496 INFO] | epoch   1 | train_loss  5.02 | val_ppl 134.90114 | time  22.5s
[2018-08-11 13:01:49,384 INFO] | epoch   2 | train_loss  4.75 | val_ppl 121.95061 | time  21.9s
[2018-08-11 13:02:11,900 INFO] | epoch   3 | train_loss  4.64 | val_ppl 116.06429 | time  22.5s
[2018-08-11 13:02:34,016 INFO] | epoch   4 | train_loss  4.57 | val_ppl 112.46828 | time  22.1s
[2018-08-11 13:02:56,513 INFO] | epoch   5 | train_loss  4.51 | val_ppl 110.15242 | time  22.5s
[2018-08-11 13:03:19,218 INFO] | epoch   6 | train_loss  4.47 | val_ppl 108.63990 | time  22.7s
[2018-08-11 13:03:41,388 INFO] | epoch   7 | train_loss  4.43 | val_ppl 107.69256 | time  22.2s
[2018-08-11 13:04:03,769 INFO] | epoch   8 | train_loss  4.39 | val_ppl 107.06490 | time  22.4s
[2018-08-11 13:04:04,630 INFO] test_ppl: 102.58162
[2018-08-11 13:12:22,848 INFO] -------------

(explanation: using the above pretrained out emb. convergence is faster but the final result keeps
same, the random seed is 0 at default)
[2018-08-11 13:12:22,848 INFO] Start training...
[2018-08-11 13:12:22,848 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 13:12:34,108 INFO] train token: 2127402
[2018-08-11 13:12:34,108 INFO] test token: 250140
[2018-08-11 13:12:34,108 INFO] valid token: 221606
[2018-08-11 13:12:34,251 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 13:13:00,180 INFO] | epoch   1 | train_loss  4.65 | val_ppl 115.26202 | time  22.0s
[2018-08-11 13:13:22,113 INFO] | epoch   2 | train_loss  4.50 | val_ppl 110.10633 | time  21.9s
[2018-08-11 13:13:44,565 INFO] | epoch   3 | train_loss  4.44 | val_ppl 107.72182 | time  22.5s
[2018-08-11 13:14:07,534 INFO] | epoch   4 | train_loss  4.39 | val_ppl 106.52273 | time  23.0s
[2018-08-11 13:14:29,769 INFO] | epoch   5 | train_loss  4.36 | val_ppl 105.91639 | time  22.2s
[2018-08-11 13:14:52,266 INFO] | epoch   6 | train_loss  4.33 | val_ppl 105.59615 | time  22.5s
[2018-08-11 13:15:14,607 INFO] | epoch   7 | train_loss  4.30 | val_ppl 105.50029 | time  22.3s
[2018-08-11 13:15:37,100 INFO] | epoch   8 | train_loss  4.27 | val_ppl 105.59313 | time  22.5s
[2018-08-11 13:15:38,098 INFO] test_ppl: 101.27162
[2018-08-11 13:17:06,753 INFO] -------------
[2018-08-11 13:17:06,753 INFO] Start training...

(explanation: using the above pretrained out emb. but keep fixed out emb. good result. preprae to
change the seed)
[2018-08-11 13:17:06,753 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=0, tied=False, vector_type='glove.6B.100d')
[2018-08-11 13:17:18,100 INFO] train token: 2127402
[2018-08-11 13:17:18,100 INFO] test token: 250140
[2018-08-11 13:17:18,100 INFO] valid token: 221606
[2018-08-11 13:17:18,242 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 13:17:42,749 INFO] | epoch   1 | train_loss  4.68 | val_ppl 112.72466 | time  20.4s
[2018-08-11 13:18:02,840 INFO] | epoch   2 | train_loss  4.53 | val_ppl 107.48921 | time  20.1s
[2018-08-11 13:18:23,101 INFO] | epoch   3 | train_loss  4.47 | val_ppl 105.31551 | time  20.3s
[2018-08-11 13:18:43,373 INFO] | epoch   4 | train_loss  4.44 | val_ppl 104.21897 | time  20.3s
[2018-08-11 13:19:03,549 INFO] | epoch   5 | train_loss  4.42 | val_ppl 103.66151 | time  20.2s
[2018-08-11 13:19:23,560 INFO] | epoch   6 | train_loss  4.40 | val_ppl 103.42313 | time  20.0s
[2018-08-11 13:19:44,342 INFO] | epoch   7 | train_loss  4.38 | val_ppl 103.29771 | time  20.8s
[2018-08-11 13:20:03,684 INFO] | epoch   8 | train_loss  4.37 | val_ppl 103.26707 | time  19.3s
[2018-08-11 13:20:04,560 INFO] test_ppl: 99.43876
[2018-08-11 13:21:46,779 INFO] -------------


(explanation: change seed. also keep fixed)
[2018-08-11 13:21:46,779 INFO] Start training...
[2018-08-11 13:21:46,780 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=10, tied=False, vector_type='glove.6B.100d')
[2018-08-11 13:21:57,939 INFO] train token: 2127402
[2018-08-11 13:21:57,939 INFO] test token: 250140
[2018-08-11 13:21:57,939 INFO] valid token: 221606
[2018-08-11 13:21:58,084 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 13:22:22,159 INFO] | epoch   1 | train_loss  4.69 | val_ppl 113.21638 | time  20.1s
[2018-08-11 13:22:42,222 INFO] | epoch   2 | train_loss  4.53 | val_ppl 107.68032 | time  20.1s
[2018-08-11 13:23:02,361 INFO] | epoch   3 | train_loss  4.48 | val_ppl 105.51221 | time  20.1s
[2018-08-11 13:23:22,120 INFO] | epoch   4 | train_loss  4.44 | val_ppl 104.41606 | time  19.8s
[2018-08-11 13:23:41,592 INFO] | epoch   5 | train_loss  4.42 | val_ppl 103.77690 | time  19.5s
[2018-08-11 13:24:01,753 INFO] | epoch   6 | train_loss  4.40 | val_ppl 103.42696 | time  20.2s
[2018-08-11 13:24:21,934 INFO] | epoch   7 | train_loss  4.38 | val_ppl 103.27184 | time  20.2s
[2018-08-11 13:24:41,712 INFO] | epoch   8 | train_loss  4.37 | val_ppl 103.23466 | time  19.8s
[2018-08-11 13:24:42,595 INFO] test_ppl: 99.29384

(continue to change the seed)
[2018-08-11 13:27:20,508 INFO] -------------
[2018-08-11 13:27:20,508 INFO] Start training...
[2018-08-11 13:27:20,508 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=100, tied=False, vector_type='glove.6B.100d')
[2018-08-11 13:27:31,661 INFO] train token: 2127402
[2018-08-11 13:27:31,661 INFO] test token: 250140
[2018-08-11 13:27:31,661 INFO] valid token: 221606
[2018-08-11 13:27:31,804 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 13:27:55,863 INFO] | epoch   1 | train_loss  4.69 | val_ppl 113.05575 | time  20.1s
[2018-08-11 13:28:15,902 INFO] | epoch   2 | train_loss  4.53 | val_ppl 107.66544 | time  20.0s
[2018-08-11 13:28:31,819 INFO] -------------
[2018-08-11 13:28:31,820 INFO] Start training...
[2018-08-11 13:28:31,820 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=4, tied=False, vector_type='glove.6B.100d')
[2018-08-11 13:28:43,686 INFO] train token: 2127402
[2018-08-11 13:28:43,687 INFO] test token: 250140
[2018-08-11 13:28:43,687 INFO] valid token: 221606
[2018-08-11 13:28:43,917 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 13:29:08,846 INFO] | epoch   1 | train_loss  4.69 | val_ppl 113.29452 | time  20.0s
[2018-08-11 13:29:29,050 INFO] | epoch   2 | train_loss  4.53 | val_ppl 107.81881 | time  20.2s
[2018-08-11 13:35:34,447 INFO] -------------


(explanation: norm pretrained out emb at the start. and keep fixed)
[2018-08-11 13:35:34,448 INFO] Start training...
[2018-08-11 13:35:34,448 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=3, tied=False, vector_type='glove.6B.100d')
[2018-08-11 13:35:45,395 INFO] train token: 2127402
[2018-08-11 13:35:45,395 INFO] test token: 250140
[2018-08-11 13:35:45,395 INFO] valid token: 221606
[2018-08-11 13:35:45,538 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-11 13:36:09,685 INFO] | epoch   1 | train_loss  5.94 | val_ppl 359.35717 | time  19.9s
[2018-08-11 13:36:29,654 INFO] | epoch   2 | train_loss  5.82 | val_ppl 340.28645 | time  20.0s
[2018-08-11 13:36:50,377 INFO] | epoch   3 | train_loss  5.77 | val_ppl 329.54376 | time  20.7s
[2018-08-11 13:37:10,706 INFO] | epoch   4 | train_loss  5.74 | val_ppl 322.69101 | time  20.3s
[2018-08-11 13:37:30,906 INFO] | epoch   5 | train_loss  5.72 | val_ppl 317.95991 | time  20.2s
[2018-08-11 13:37:50,825 INFO] | epoch   6 | train_loss  5.70 | val_ppl 314.86632 | time  19.9s
[2018-08-11 13:38:10,834 INFO] | epoch   7 | train_loss  5.69 | val_ppl 312.33242 | time  20.0s
[2018-08-11 13:38:30,577 INFO] | epoch   8 | train_loss  5.68 | val_ppl 310.29353 | time  19.7s
[2018-08-11 13:38:31,589 INFO] test_ppl: 307.08927


(explanation: loss is simple dot product. output emb is that nnlm pretrained one and fixed. out emb
normed at the start)
[2018-08-12 13:38:36,794 INFO] -------------
[2018-08-12 13:38:36,795 INFO] Start training...
[2018-08-12 13:38:36,795 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=3, tied=False, vector_type='glove.6B.100d')
[2018-08-12 13:38:48,458 INFO] train token: 2127402
[2018-08-12 13:38:48,458 INFO] test token: 250140
[2018-08-12 13:38:48,458 INFO] valid token: 221606
[2018-08-12 13:38:48,601 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-12 13:39:11,139 INFO] | epoch   1 | train_loss -3.55 | val_ppl 902.03348 | time  18.6s
[2018-08-12 13:39:28,424 INFO] | epoch   2 | train_loss -3.70 | val_ppl 866.56355 | time  17.3s
[2018-08-12 13:39:45,747 INFO] | epoch   3 | train_loss -3.76 | val_ppl 845.51901 | time  17.3s
[2018-08-12 13:40:03,768 INFO] | epoch   4 | train_loss -3.80 | val_ppl 841.61535 | time  18.0s
[2018-08-12 13:40:22,131 INFO] | epoch   5 | train_loss -3.82 | val_ppl 819.03383 | time  18.4s
[2018-08-12 13:40:40,539 INFO] | epoch   6 | train_loss -3.84 | val_ppl 818.78845 | time  18.4s
[2018-08-12 13:40:58,867 INFO] | epoch   7 | train_loss -3.85 | val_ppl 809.34811 | time  18.3s
[2018-08-12 13:41:15,157 INFO] | epoch   8 | train_loss -3.87 | val_ppl 801.43664 | time  16.3s
[2018-08-12 13:41:16,123 INFO] test_ppl: 795.94193

(explanation: not norm compared with above. it seems norm is better. But for full softmax version,
when fixing, norm is bad. for this experiment, i guess when norming, the stride for a hidden unit
will be small and more suitable if you compare when full softmax when back-prop)
[2018-08-12 13:53:27,821 INFO] -------------
[2018-08-12 13:53:27,822 INFO] Start training...
[2018-08-12 13:53:27,822 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=3, tied=False, vector_type='glove.6B.100d')
[2018-08-12 13:53:39,090 INFO] train token: 2127402
[2018-08-12 13:53:39,091 INFO] test token: 250140
[2018-08-12 13:53:39,091 INFO] valid token: 221606
[2018-08-12 13:53:39,236 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-12 13:53:59,210 INFO] | epoch   1 | train_loss -10.42 | val_ppl 4703.98806 | time  16.0s
[2018-08-12 13:54:16,775 INFO] | epoch   2 | train_loss -10.78 | val_ppl 3909.26306 | time  17.6s
[2018-08-12 13:54:34,432 INFO] | epoch   3 | train_loss -10.89 | val_ppl 3547.13782 | time  17.7s

(explanation: norm both hidden and out emb at start. the result goes bwteen the two.)
[2018-08-12 14:00:25,822 INFO] -------------
[2018-08-12 14:00:25,823 INFO] Start training...
[2018-08-12 14:00:25,823 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=3, tied=False, vector_type='glove.6B.100d')
[2018-08-12 14:00:37,250 INFO] train token: 2127402
[2018-08-12 14:00:37,250 INFO] test token: 250140
[2018-08-12 14:00:37,250 INFO] valid token: 221606
[2018-08-12 14:00:37,395 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-12 14:00:59,944 INFO] | epoch   1 | train_loss -0.36 | val_ppl 1092.42733 | time  18.4s
[2018-08-12 14:01:18,524 INFO] | epoch   2 | train_loss -0.37 | val_ppl 1024.11733 | time  18.6s
[2018-08-12 14:01:38,811 INFO] | epoch   3 | train_loss -0.37 | val_ppl 990.05335 | time  20.3s
[2018-08-12 14:01:57,473 INFO] | epoch   4 | train_loss -0.37 | val_ppl 979.25515 | time  18.7s
[2018-08-12 14:02:16,616 INFO] | epoch   5 | train_loss -0.37 | val_ppl 965.26287 | time  19.1s
[2018-08-12 14:02:35,281 INFO] | epoch   6 | train_loss -0.37 | val_ppl 955.85656 | time  18.7s
[2018-08-12 14:02:53,052 INFO] | epoch   7 | train_loss -0.38 | val_ppl 931.40796 | time  17.8s
[2018-08-12 14:03:12,398 INFO] | epoch   8 | train_loss -0.38 | val_ppl 919.60420 | time  19.3s
[2018-08-12 14:03:13,277 INFO] test_ppl: 913.41454


-------------------back to full softmax

(explanation: randomly inited out emb but updating)
[2018-08-12 15:10:43,158 INFO] Start training...
[2018-08-12 15:10:43,158 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=3, tied=False, vector_type='glove.6B.100d')
[2018-08-12 15:10:54,353 INFO] train token: 2127402
[2018-08-12 15:10:54,354 INFO] test token: 250140
[2018-08-12 15:10:54,354 INFO] valid token: 221606
[2018-08-12 15:10:54,498 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-12 15:11:20,834 INFO] | epoch   1 | train_loss  5.22 | val_ppl 152.47683 | time  23.1s
[2018-08-12 15:11:43,099 INFO] | epoch   2 | train_loss  4.86 | val_ppl 133.09695 | time  22.3s
[2018-08-12 15:13:25,405 INFO] -------------

(explanation: randomly inited out emb and fixed)
[2018-08-12 15:13:25,405 INFO] Start training...
[2018-08-12 15:13:25,406 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=3, tied=False, vector_type='glove.6B.100d')
[2018-08-12 15:13:36,460 INFO] train token: 2127402
[2018-08-12 15:13:36,461 INFO] test token: 250140
[2018-08-12 15:13:36,461 INFO] valid token: 221606
[2018-08-12 15:13:36,603 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-12 15:13:59,873 INFO] | epoch   1 | train_loss  9.09 | val_ppl 8095.25724 | time  20.0s
[2018-08-12 15:14:19,652 INFO] | epoch   2 | train_loss  9.01 | val_ppl 7807.98528 | time  19.8s
[2018-08-12 15:14:38,841 INFO] | epoch   3 | train_loss  8.98 | val_ppl 7628.68300 | time  19.2s
[2018-08-12 15:14:58,953 INFO] | epoch   4 | train_loss  8.96 | val_ppl 7494.81667 | time  20.1s
[2018-08-12 15:15:18,921 INFO] | epoch   5 | train_loss  8.95 | val_ppl 7407.63110 | time  20.0s
[2018-08-12 15:15:39,257 INFO] | epoch   6 | train_loss  8.93 | val_ppl 7335.21253 | time  20.3s
[2018-08-12 15:15:59,558 INFO] | epoch   7 | train_loss  8.92 | val_ppl 7282.63652 | time  20.3s
[2018-08-12 15:16:19,543 INFO] | epoch   8 | train_loss  8.91 | val_ppl 7235.73265 | time  20.0s
[2018-08-12 15:16:20,424 INFO] test_ppl: 7238.00396
[2018-08-13 16:24:38,947 INFO] -------------


(using cbow pretrained, and updating. we see the iteration and convergence is not as good as
self-pretrained out emb)
[2018-08-13 16:24:38,947 INFO] Start training...
[2018-08-13 16:24:38,947 INFO] Namespace(batch_size=20, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=3, tied=False, vector_type='glove.6B.100d')
[2018-08-13 16:24:50,271 INFO] train token: 2127402
[2018-08-13 16:24:50,272 INFO] test token: 250140
[2018-08-13 16:24:50,272 INFO] valid token: 221606
[2018-08-13 16:24:50,416 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-13 16:25:15,438 INFO] | epoch   1 | train_loss  5.27 | val_ppl 165.04891 | time  21.7s
[2018-08-13 16:25:37,089 INFO] | epoch   2 | train_loss  4.95 | val_ppl 144.93556 | time  21.7s
[2018-08-13 16:25:58,673 INFO] | epoch   3 | train_loss  4.83 | val_ppl 135.73802 | time  21.6s
[2018-08-13 16:26:20,276 INFO] | epoch   4 | train_loss  4.75 | val_ppl 130.26771 | time  21.6s
[2018-08-13 16:26:41,811 INFO] | epoch   5 | train_loss  4.68 | val_ppl 126.51464 | time  21.5s
[2018-08-13 16:27:03,395 INFO] | epoch   6 | train_loss  4.63 | val_ppl 123.82593 | time  21.6s
[2018-08-13 16:27:25,024 INFO] | epoch   7 | train_loss  4.58 | val_ppl 121.83505 | time  21.6s
[2018-08-13 16:27:46,537 INFO] | epoch   8 | train_loss  4.54 | val_ppl 120.44894 | time  21.5s
[2018-08-13 16:27:47,502 INFO] test_ppl: 116.50455
[2018-08-13 16:52:38,523 INFO] -------------

(see the param, batch_size and bptt_len are changed. self-pretrained out emb is fixed. bad news. it
 is my falut. bug. ignore this log)
[2018-08-13 16:52:38,523 INFO] Start training...
[2018-08-13 16:52:38,523 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=13, tied=False, vector_type='glove.6B.100d')
[2018-08-13 16:52:49,536 INFO] train token: 2127402
[2018-08-13 16:52:49,536 INFO] test token: 250140
[2018-08-13 16:52:49,536 INFO] valid token: 221606
[2018-08-13 16:52:49,679 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-13 16:53:07,622 INFO] | epoch   1 | train_loss  9.18 | val_ppl 8721.82832 | time  13.8s
[2018-08-13 16:53:21,387 INFO] | epoch   2 | train_loss  9.09 | val_ppl 8403.62200 | time  13.8s
[2018-08-13 16:53:35,386 INFO] | epoch   3 | train_loss  9.06 | val_ppl 8196.37181 | time  14.0s
[2018-08-13 16:53:49,355 INFO] | epoch   4 | train_loss  9.04 | val_ppl 8035.85206 | time  14.0s
[2018-08-13 16:55:14,810 INFO] -------------

(strange. using cbow, fixing. better. so strange)
[2018-08-13 16:55:14,810 INFO] Start training...
[2018-08-13 16:55:14,810 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=13, tied=False, vector_type='glove.6B.100d')
[2018-08-13 16:55:25,824 INFO] train token: 2127402
[2018-08-13 16:55:25,824 INFO] test token: 250140
[2018-08-13 16:55:25,824 INFO] valid token: 221606
[2018-08-13 16:55:26,046 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-13 16:55:43,578 INFO] | epoch   1 | train_loss  5.80 | val_ppl 293.62222 | time  14.1s
[2018-08-13 16:55:57,461 INFO] | epoch   2 | train_loss  5.48 | val_ppl 251.13946 | time  13.9s
[2018-08-13 16:56:11,362 INFO] | epoch   3 | train_loss  5.37 | val_ppl 232.11815 | time  13.9s
[2018-08-13 16:56:25,285 INFO] | epoch   4 | train_loss  5.30 | val_ppl 222.09285 | time  13.9s
[2018-08-13 16:56:39,367 INFO] | epoch   5 | train_loss  5.25 | val_ppl 215.73520 | time  14.1s
[2018-08-13 16:56:53,416 INFO] | epoch   6 | train_loss  5.22 | val_ppl 211.88669 | time  14.0s
[2018-08-13 16:57:07,516 INFO] | epoch   7 | train_loss  5.18 | val_ppl 209.26152 | time  14.1s
[2018-08-13 16:57:21,564 INFO] | epoch   8 | train_loss  5.16 | val_ppl 207.60089 | time  14.0s
[2018-08-13 16:57:22,227 INFO] test_ppl: 199.19498
[2018-08-13 16:59:22,997 INFO] -------------

(self-pretrained out emb. fixed. normed at start)
[2018-08-13 16:59:22,997 INFO] Start training...
[2018-08-13 16:59:22,997 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=13, tied=False, vector_type='glove.6B.100d')
[2018-08-13 16:59:34,302 INFO] train token: 2127402
[2018-08-13 16:59:34,302 INFO] test token: 250140
[2018-08-13 16:59:34,302 INFO] valid token: 221606
[2018-08-13 16:59:34,446 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-13 16:59:52,571 INFO] | epoch   1 | train_loss  5.97 | val_ppl 364.23271 | time  14.3s
[2018-08-13 17:00:06,687 INFO] | epoch   2 | train_loss  5.85 | val_ppl 346.86880 | time  14.1s
[2018-08-13 17:00:20,755 INFO] | epoch   3 | train_loss  5.81 | val_ppl 336.85057 | time  14.1s
[2018-08-13 17:00:34,858 INFO] | epoch   4 | train_loss  5.78 | val_ppl 329.78721 | time  14.1s
[2018-08-13 17:05:20,052 INFO] -------------


(this using non-normed out pretrained emb. fixed. this exp can shows even though bptt and batch is
changed. pretrained out emb is still usefull)
[2018-08-13 17:05:20,052 INFO] Start training...
[2018-08-13 17:05:20,052 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=13, tied=False, vector_type='glove.6B.100d')
[2018-08-13 17:05:31,079 INFO] train token: 2127402
[2018-08-13 17:05:31,079 INFO] test token: 250140
[2018-08-13 17:05:31,080 INFO] valid token: 221606
[2018-08-13 17:05:31,304 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-13 17:05:49,265 INFO] | epoch   1 | train_loss  4.73 | val_ppl 112.73530 | time  13.8s
[2018-08-13 17:06:03,141 INFO] | epoch   2 | train_loss  4.56 | val_ppl 105.95881 | time  13.9s
[2018-08-13 17:06:17,245 INFO] | epoch   3 | train_loss  4.51 | val_ppl 102.51871 | time  14.1s
[2018-08-13 17:06:31,180 INFO] | epoch   4 | train_loss  4.47 | val_ppl 100.56969 | time  13.9s
[2018-08-13 17:06:45,098 INFO] | epoch   5 | train_loss  4.44 | val_ppl 99.31948 | time  13.9s
[2018-08-13 17:06:58,934 INFO] | epoch   6 | train_loss  4.42 | val_ppl 98.47506 | time  13.8s
[2018-08-13 17:07:12,717 INFO] | epoch   7 | train_loss  4.40 | val_ppl 97.88738 | time  13.8s
[2018-08-13 17:07:26,792 INFO] | epoch   8 | train_loss  4.39 | val_ppl 97.47671 | time  14.1s
[2018-08-13 17:07:27,471 INFO] test_ppl: 94.64213
[2018-08-13 17:09:44,318 INFO] -------------

(explanation: randomly update out emb)
[2018-08-13 17:09:44,319 INFO] Start training...
[2018-08-13 17:09:44,319 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=13, tied=False, vector_type='glove.6B.100d')
[2018-08-13 17:09:55,422 INFO] train token: 2127402
[2018-08-13 17:09:55,422 INFO] test token: 250140
[2018-08-13 17:09:55,422 INFO] valid token: 221606
[2018-08-13 17:09:55,565 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-13 17:10:14,933 INFO] | epoch   1 | train_loss  5.37 | val_ppl 182.90919 | time  16.0s
[2018-08-13 17:10:31,049 INFO] | epoch   2 | train_loss  4.98 | val_ppl 155.57486 | time  16.1s
[2018-08-13 17:10:47,181 INFO] | epoch   3 | train_loss  4.85 | val_ppl 140.24403 | time  16.1s
[2018-08-13 17:11:03,209 INFO] | epoch   4 | train_loss  4.76 | val_ppl 130.84001 | time  16.0s
[2018-08-13 17:11:19,271 INFO] | epoch   5 | train_loss  4.70 | val_ppl 124.66550 | time  16.1s
[2018-08-13 17:11:35,406 INFO] | epoch   6 | train_loss  4.64 | val_ppl 119.58827 | time  16.1s
[2018-08-13 17:11:51,487 INFO] | epoch   7 | train_loss  4.60 | val_ppl 115.53022 | time  16.1s
[2018-08-13 17:12:07,420 INFO] | epoch   8 | train_loss  4.56 | val_ppl 112.59746 | time  15.9s
[2018-08-13 17:12:08,084 INFO] test_ppl: 110.07493
[2018-08-14 00:26:35,867 INFO] -------------

(out emb updating. almost same with non-updating)
[2018-08-14 00:26:35,867 INFO] Start training...
[2018-08-14 00:26:35,867 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, not_update_input_emb=False, num_layers=1, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=13, tied=False, vector_type='glove.6B.100d')
[2018-08-14 00:26:46,793 INFO] train token: 2127402
[2018-08-14 00:26:46,793 INFO] test token: 250140
[2018-08-14 00:26:46,793 INFO] valid token: 221606
[2018-08-14 00:26:46,953 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 00:27:06,921 INFO] | epoch   1 | train_loss  4.70 | val_ppl 114.00223 | time  16.0s
[2018-08-14 00:27:22,702 INFO] | epoch   2 | train_loss  4.53 | val_ppl 106.66522 | time  15.8s
[2018-08-14 00:27:38,743 INFO] | epoch   3 | train_loss  4.46 | val_ppl 102.97266 | time  16.0s
[2018-08-14 00:27:54,870 INFO] | epoch   4 | train_loss  4.42 | val_ppl 100.83983 | time  16.1s
[2018-08-14 00:28:10,811 INFO] | epoch   5 | train_loss  4.38 | val_ppl 99.36605 | time  15.9s
[2018-08-14 00:28:26,703 INFO] | epoch   6 | train_loss  4.36 | val_ppl 98.32752 | time  15.9s
[2018-08-14 00:28:42,841 INFO] | epoch   7 | train_loss  4.33 | val_ppl 97.56077 | time  16.1s
[2018-08-14 00:28:58,964 INFO] | epoch   8 | train_loss  4.31 | val_ppl 96.98207 | time  16.1s
[2018-08-14 00:28:59,627 INFO] test_ppl: 94.79493
[2018-08-14 00:46:50,244 INFO] -------------

(change opt. validate)
[2018-08-14 01:03:04,358 INFO] Start training...
[2018-08-14 01:03:04,358 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=13, tied=False, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-14 01:03:15,982 INFO] train token: 2127402
[2018-08-14 01:03:15,982 INFO] test token: 250140
[2018-08-14 01:03:15,982 INFO] valid token: 221606
[2018-08-14 01:03:16,204 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 01:03:34,764 INFO] | epoch   1 | train_loss  4.73 | val_ppl 112.73530 | time  14.0s
[2018-08-14 01:03:48,707 INFO] | epoch   2 | train_loss  4.56 | val_ppl 105.95881 | time  13.9s
[2018-08-14 01:04:02,874 INFO] | epoch   3 | train_loss  4.51 | val_ppl 102.51871 | time  14.2s
[2018-08-14 01:04:16,761 INFO] | epoch   4 | train_loss  4.47 | val_ppl 100.56969 | time  13.9s
[2018-08-14 01:06:47,582 INFO] -------------
[2018-08-14 01:08:03,300 INFO] -------------
[2018-08-14 01:13:50,533 INFO] -------------
[2018-08-14 01:13:50,533 INFO] Start training...
[2018-08-14 01:13:50,533 INFO] Namespace(batch_size=50, bidirectional=False, bptt_len=3, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=1, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-14 01:14:02,070 INFO] train token: 2127402
[2018-08-14 01:14:02,071 INFO] test token: 250140
[2018-08-14 01:14:02,071 INFO] valid token: 221606
[2018-08-14 01:14:02,218 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 01:14:29,242 INFO] | epoch   1 | train_loss  5.27 | val_ppl 156.47944 | time  23.6s
[2018-08-14 01:14:52,701 INFO] | epoch   2 | train_loss  4.95 | val_ppl 140.95941 | time  23.5s
[2018-08-14 01:15:16,191 INFO] | epoch   3 | train_loss  4.84 | val_ppl 134.11807 | time  23.5s
[2018-08-14 01:15:40,139 INFO] | epoch   4 | train_loss  4.77 | val_ppl 130.37092 | time  23.9s
[2018-08-14 01:16:03,617 INFO] | epoch   5 | train_loss  4.72 | val_ppl 128.05745 | time  23.5s
[2018-08-14 01:16:27,464 INFO] | epoch   6 | train_loss  4.67 | val_ppl 126.60108 | time  23.8s
[2018-08-14 01:16:51,434 INFO] | epoch   7 | train_loss  4.64 | val_ppl 125.73044 | time  24.0s
[2018-08-14 01:17:15,374 INFO] | epoch   8 | train_loss  4.60 | val_ppl 125.26940 | time  23.9s
[2018-08-14 01:17:16,320 INFO] test_ppl: 122.01947
[2018-08-14 01:27:48,938 INFO] -------------

(3bpt trained, good result)
[2018-08-14 01:27:48,938 INFO] Start training...
[2018-08-14 01:27:48,938 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./3bptt_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=13, tied=False, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-14 01:27:59,994 INFO] train token: 2127402
[2018-08-14 01:27:59,995 INFO] test token: 250140
[2018-08-14 01:27:59,995 INFO] valid token: 221606
[2018-08-14 01:28:00,215 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 01:28:18,434 INFO] | epoch   1 | train_loss  4.77 | val_ppl 118.58513 | time  14.1s
[2018-08-14 01:28:32,339 INFO] | epoch   2 | train_loss  4.62 | val_ppl 111.69263 | time  13.9s
[2018-08-14 01:28:46,220 INFO] | epoch   3 | train_loss  4.57 | val_ppl 108.31642 | time  13.9s
[2018-08-14 01:29:00,198 INFO] | epoch   4 | train_loss  4.53 | val_ppl 106.34086 | time  14.0s
[2018-08-14 01:29:14,212 INFO] | epoch   5 | train_loss  4.51 | val_ppl 104.97084 | time  14.0s
[2018-08-14 01:29:28,159 INFO] | epoch   6 | train_loss  4.49 | val_ppl 104.04239 | time  13.9s
[2018-08-14 01:29:42,201 INFO] | epoch   7 | train_loss  4.47 | val_ppl 103.41987 | time  14.0s
[2018-08-14 01:29:56,000 INFO] | epoch   8 | train_loss  4.46 | val_ppl 102.98950 | time  13.8s
[2018-08-14 01:29:56,737 INFO] test_ppl: 100.35828
[2018-08-14 01:33:07,994 INFO] -------------

(change seed validate)
[2018-08-14 01:33:07,995 INFO] Start training...
[2018-08-14 01:33:07,995 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./3bptt_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=90, tied=False, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-14 01:33:19,014 INFO] train token: 2127402
[2018-08-14 01:33:19,014 INFO] test token: 250140
[2018-08-14 01:33:19,014 INFO] valid token: 221606
[2018-08-14 01:33:19,158 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 01:33:37,219 INFO] | epoch   1 | train_loss  4.78 | val_ppl 118.63744 | time  14.1s
[2018-08-14 01:33:51,135 INFO] | epoch   2 | train_loss  4.63 | val_ppl 111.69728 | time  13.9s
[2018-08-14 01:34:05,183 INFO] | epoch   3 | train_loss  4.57 | val_ppl 108.26682 | time  14.0s
[2018-08-14 01:34:19,139 INFO] | epoch   4 | train_loss  4.54 | val_ppl 106.25249 | time  14.0s
[2018-08-14 01:34:33,313 INFO] | epoch   5 | train_loss  4.51 | val_ppl 104.86318 | time  14.2s
[2018-08-14 01:34:46,999 INFO] | epoch   6 | train_loss  4.49 | val_ppl 103.95396 | time  13.7s
[2018-08-14 01:35:00,760 INFO] | epoch   7 | train_loss  4.47 | val_ppl 103.32631 | time  13.8s
[2018-08-14 01:35:14,692 INFO] | epoch   8 | train_loss  4.46 | val_ppl 102.86615 | time  13.9s
[2018-08-14 01:35:15,348 INFO] test_ppl: 100.31762
[2018-08-14 01:38:36,077 INFO] -------------

(updating out emb)
[2018-08-14 01:38:36,077 INFO] Start training...
[2018-08-14 01:38:36,077 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./3bptt_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=90, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-14 01:38:46,739 INFO] train token: 2127402
[2018-08-14 01:38:46,739 INFO] test token: 250140
[2018-08-14 01:38:46,739 INFO] valid token: 221606
[2018-08-14 01:38:46,881 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 01:39:06,903 INFO] | epoch   1 | train_loss  4.74 | val_ppl 120.00567 | time  16.0s
[2018-08-14 01:39:22,948 INFO] | epoch   2 | train_loss  4.57 | val_ppl 111.88744 | time  16.0s
[2018-08-14 01:39:38,970 INFO] | epoch   3 | train_loss  4.51 | val_ppl 108.00286 | time  16.0s
[2018-08-14 01:39:55,005 INFO] | epoch   4 | train_loss  4.46 | val_ppl 105.65375 | time  16.0s
[2018-08-14 01:40:11,221 INFO] | epoch   5 | train_loss  4.43 | val_ppl 103.91337 | time  16.2s
[2018-08-14 01:40:27,237 INFO] | epoch   6 | train_loss  4.40 | val_ppl 102.61590 | time  16.0s
[2018-08-14 01:40:43,376 INFO] | epoch   7 | train_loss  4.37 | val_ppl 101.64003 | time  16.1s
[2018-08-14 01:40:59,414 INFO] | epoch   8 | train_loss  4.35 | val_ppl 100.88852 | time  16.0s
[2018-08-14 01:41:00,161 INFO] test_ppl: 98.33608
[2018-08-14 01:44:12,508 INFO] -------------

(for generating)
[2018-08-14 01:44:12,508 INFO] Start training...
[2018-08-14 01:44:12,508 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=2, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=11, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-14 01:44:23,573 INFO] train token: 2127402
[2018-08-14 01:44:23,574 INFO] test token: 250140
[2018-08-14 01:44:23,574 INFO] valid token: 221606
[2018-08-14 01:44:23,717 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 01:45:23,474 INFO] | epoch   1 | train_loss  5.13 | val_ppl 159.03160 | time  56.3s
[2018-08-14 01:46:18,650 INFO] | epoch   2 | train_loss  4.86 | val_ppl 148.82331 | time  55.2s
[2018-08-14 01:47:13,750 INFO] | epoch   3 | train_loss  4.76 | val_ppl 146.30748 | time  55.1s
[2018-08-14 01:48:09,485 INFO] | epoch   4 | train_loss  4.69 | val_ppl 145.77872 | time  55.7s
[2018-08-14 01:49:05,616 INFO] | epoch   5 | train_loss  4.64 | val_ppl 146.43325 | time  56.1s
[2018-08-14 01:50:01,385 INFO] | epoch   6 | train_loss  4.60 | val_ppl 147.95566 | time  55.8s
[2018-08-14 01:50:56,995 INFO] | epoch   7 | train_loss  4.56 | val_ppl 149.79260 | time  55.6s
[2018-08-14 01:51:53,227 INFO] | epoch   8 | train_loss  4.52 | val_ppl 152.01536 | time  56.2s
[2018-08-14 01:51:55,161 INFO] test_ppl: 149.65753
[2018-08-14 01:53:08,285 INFO] -------------

(2bptt pretrained)
[2018-08-14 01:53:08,285 INFO] Start training...
[2018-08-14 01:53:08,285 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./2bptt_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=190, tied=False, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-14 01:53:19,366 INFO] train token: 2127402
[2018-08-14 01:53:19,366 INFO] test token: 250140
[2018-08-14 01:53:19,366 INFO] valid token: 221606
[2018-08-14 01:53:19,511 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 01:53:37,261 INFO] | epoch   1 | train_loss  4.77 | val_ppl 126.87310 | time  13.8s
[2018-08-14 01:53:50,993 INFO] | epoch   2 | train_loss  4.61 | val_ppl 118.57411 | time  13.7s
[2018-08-14 01:54:04,890 INFO] | epoch   3 | train_loss  4.55 | val_ppl 114.36236 | time  13.9s
[2018-08-14 01:54:19,013 INFO] | epoch   4 | train_loss  4.50 | val_ppl 112.01659 | time  14.1s
[2018-08-14 01:54:33,152 INFO] | epoch   5 | train_loss  4.47 | val_ppl 110.38251 | time  14.1s
[2018-08-14 01:54:47,151 INFO] | epoch   6 | train_loss  4.44 | val_ppl 109.36511 | time  14.0s
[2018-08-14 01:55:01,183 INFO] | epoch   7 | train_loss  4.42 | val_ppl 108.61115 | time  14.0s
[2018-08-14 01:55:15,054 INFO] | epoch   8 | train_loss  4.40 | val_ppl 108.11990 | time  13.9s
[2018-08-14 01:55:15,712 INFO] test_ppl: 106.21488
[2018-08-14 02:00:59,366 INFO] -------------
[2018-08-14 02:00:59,366 INFO] Start training...
[2018-08-14 02:00:59,366 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=3, device='cuda:0', dropout=0.0, epoch=2, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=11, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-14 02:01:10,404 INFO] train token: 2127402
[2018-08-14 02:01:10,404 INFO] test token: 250140
[2018-08-14 02:01:10,404 INFO] valid token: 221606
[2018-08-14 02:01:10,548 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 02:01:54,832 INFO] | epoch   1 | train_loss  5.14 | val_ppl 154.96312 | time  40.9s
[2018-08-14 02:02:36,001 INFO] | epoch   2 | train_loss  4.84 | val_ppl 141.18390 | time  41.2s
[2018-08-14 02:02:37,586 INFO] test_ppl: 138.59411
[2018-08-14 02:05:52,816 INFO] -------------
[2018-08-14 02:05:52,816 INFO] Start training...

(2epoch pretrained. good result)
[2018-08-14 02:05:52,816 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./3bptt_2epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=190, tied=False, update_inputemb=True, update_out_emb=False, vector_type='glove.6B.100d')
[2018-08-14 02:06:04,327 INFO] train token: 2127402
[2018-08-14 02:06:04,327 INFO] test token: 250140
[2018-08-14 02:06:04,328 INFO] valid token: 221606
[2018-08-14 02:06:04,473 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 02:06:22,731 INFO] | epoch   1 | train_loss  4.87 | val_ppl 124.26746 | time  14.0s
[2018-08-14 02:06:36,678 INFO] | epoch   2 | train_loss  4.73 | val_ppl 117.67876 | time  13.9s
[2018-08-14 02:06:50,563 INFO] | epoch   3 | train_loss  4.68 | val_ppl 114.20064 | time  13.9s
[2018-08-14 02:07:04,496 INFO] | epoch   4 | train_loss  4.65 | val_ppl 112.10386 | time  13.9s
[2018-08-14 02:07:18,357 INFO] | epoch   5 | train_loss  4.63 | val_ppl 110.65113 | time  13.9s
[2018-08-14 02:07:32,403 INFO] | epoch   6 | train_loss  4.61 | val_ppl 109.63534 | time  14.0s
[2018-08-14 02:07:46,259 INFO] | epoch   7 | train_loss  4.60 | val_ppl 108.87460 | time  13.9s
[2018-08-14 02:08:00,294 INFO] | epoch   8 | train_loss  4.58 | val_ppl 108.31211 | time  14.0s
[2018-08-14 02:08:00,963 INFO] test_ppl: 106.19774
[2018-08-14 02:11:11,969 INFO] -------------

(update_out_emb)
[2018-08-14 02:11:11,969 INFO] Start training...
[2018-08-14 02:11:11,969 INFO] Namespace(batch_size=25, bidirectional=False, bptt_len=15, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./3bptt_2epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=190, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d')
[2018-08-14 02:11:23,125 INFO] train token: 2127402
[2018-08-14 02:11:23,125 INFO] test token: 250140
[2018-08-14 02:11:23,125 INFO] valid token: 221606
[2018-08-14 02:11:23,271 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 02:11:43,478 INFO] | epoch   1 | train_loss  4.81 | val_ppl 124.05484 | time  15.9s
[2018-08-14 02:11:59,322 INFO] | epoch   2 | train_loss  4.65 | val_ppl 115.16294 | time  15.8s
[2018-08-14 02:12:15,414 INFO] | epoch   3 | train_loss  4.58 | val_ppl 110.32851 | time  16.1s
[2018-08-14 02:12:31,272 INFO] | epoch   4 | train_loss  4.53 | val_ppl 107.24493 | time  15.9s
[2018-08-14 02:12:47,468 INFO] | epoch   5 | train_loss  4.49 | val_ppl 104.96506 | time  16.2s
[2018-08-14 02:13:03,595 INFO] | epoch   6 | train_loss  4.46 | val_ppl 103.24610 | time  16.1s
[2018-08-14 02:13:19,718 INFO] | epoch   7 | train_loss  4.43 | val_ppl 101.95085 | time  16.1s
[2018-08-14 02:13:35,734 INFO] | epoch   8 | train_loss  4.40 | val_ppl 100.97340 | time  16.0s
[2018-08-14 02:13:36,403 INFO] test_ppl: 98.82227
[2018-08-14 13:07:20,974 INFO] train token: 2127402
[2018-08-14 13:07:20,974 INFO] test token: 250140
[2018-08-14 13:07:20,974 INFO] valid token: 221606
[2018-08-14 13:07:21,117 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 13:43:39,181 INFO] -------------

(for generating)
[2018-08-14 16:53:25,357 INFO] -------------
[2018-08-14 16:53:25,357 INFO] Start training...
[2018-08-14 16:53:25,357 INFO] Namespace(batch_size=200, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=19, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d', window_len=4, word_dim=50)
[2018-08-14 16:53:36,116 INFO] train token: 2127402
[2018-08-14 16:53:36,117 INFO] test token: 250140
[2018-08-14 16:53:36,117 INFO] valid token: 221606
[2018-08-14 16:53:36,337 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 16:53:53,367 INFO] | epoch   1 | train_loss  6.08 | val_ppl 296.34668 | time  13.7s
[2018-08-14 16:54:07,007 INFO] | epoch   2 | train_loss  5.45 | val_ppl 257.77884 | time  13.6s
[2018-08-14 16:54:20,718 INFO] | epoch   3 | train_loss  5.22 | val_ppl 241.62983 | time  13.7s
[2018-08-14 16:54:34,448 INFO] | epoch   4 | train_loss  5.07 | val_ppl 229.50040 | time  13.7s
[2018-08-14 16:54:48,184 INFO] | epoch   5 | train_loss  4.95 | val_ppl 223.17870 | time  13.7s
[2018-08-14 16:55:02,032 INFO] | epoch   6 | train_loss  4.86 | val_ppl 219.85915 | time  13.8s
[2018-08-14 16:55:15,830 INFO] | epoch   7 | train_loss  4.78 | val_ppl 218.06179 | time  13.8s
[2018-08-14 16:55:29,699 INFO] | epoch   8 | train_loss  4.71 | val_ppl 217.23845 | time  13.9s
[2018-08-14 16:55:30,211 INFO] test_ppl: 212.89048
[2018-08-14 17:10:25,937 INFO] -------------

(for generating)
[2018-08-14 17:10:25,937 INFO] Start training...
[2018-08-14 17:10:25,938 INFO] Namespace(batch_size=200, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=19, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d', window_len=2, word_dim=50)
[2018-08-14 17:10:37,508 INFO] train token: 2127402
[2018-08-14 17:10:37,509 INFO] test token: 250140
[2018-08-14 17:10:37,509 INFO] valid token: 221606
[2018-08-14 17:10:37,653 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 17:10:54,366 INFO] | epoch   1 | train_loss  6.03 | val_ppl 279.12409 | time  13.4s
[2018-08-14 17:11:07,728 INFO] | epoch   2 | train_loss  5.42 | val_ppl 230.86703 | time  13.4s
[2018-08-14 17:11:21,170 INFO] | epoch   3 | train_loss  5.22 | val_ppl 208.32609 | time  13.4s
[2018-08-14 17:11:34,810 INFO] | epoch   4 | train_loss  5.10 | val_ppl 193.75914 | time  13.6s
[2018-08-14 17:11:48,304 INFO] | epoch   5 | train_loss  5.01 | val_ppl 184.75959 | time  13.5s
[2018-08-14 17:12:02,034 INFO] | epoch   6 | train_loss  4.95 | val_ppl 180.54095 | time  13.7s
[2018-08-14 17:12:15,727 INFO] | epoch   7 | train_loss  4.89 | val_ppl 178.02165 | time  13.7s
[2018-08-14 17:12:29,287 INFO] | epoch   8 | train_loss  4.85 | val_ppl 176.16627 | time  13.6s
[2018-08-14 17:12:29,775 INFO] test_ppl: 172.82621
[2018-08-14 17:15:55,489 INFO] -------------

(use cbow as input)
[2018-08-14 17:15:55,489 INFO] Start training...
[2018-08-14 17:15:55,489 INFO] Namespace(batch_size=200, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=19, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d', window_len=2, word_dim=100)
[2018-08-14 17:16:06,567 INFO] train token: 2127402
[2018-08-14 17:16:06,567 INFO] test token: 250140
[2018-08-14 17:16:06,567 INFO] valid token: 221606
[2018-08-14 17:16:06,711 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 17:16:27,837 INFO] | epoch   1 | train_loss  5.42 | val_ppl 169.07991 | time  17.7s
[2018-08-14 17:16:45,582 INFO] | epoch   2 | train_loss  4.96 | val_ppl 157.48142 | time  17.7s
[2018-08-14 17:17:03,461 INFO] | epoch   3 | train_loss  4.82 | val_ppl 152.67345 | time  17.9s
[2018-08-14 17:17:21,363 INFO] | epoch   4 | train_loss  4.73 | val_ppl 147.81433 | time  17.9s
[2018-08-14 17:17:39,296 INFO] | epoch   5 | train_loss  4.66 | val_ppl 142.18499 | time  17.9s
[2018-08-14 17:17:57,318 INFO] | epoch   6 | train_loss  4.60 | val_ppl 141.89540 | time  18.0s
[2018-08-14 17:18:15,344 INFO] | epoch   7 | train_loss  4.55 | val_ppl 143.53074 | time  18.0s
[2018-08-14 17:18:33,383 INFO] | epoch   8 | train_loss  4.51 | val_ppl 145.59608 | time  18.0s
[2018-08-14 17:18:33,993 INFO] test_ppl: 143.01214
[2018-08-14 17:23:23,479 INFO] -------------

(only one token similar to skip-gram with all noises)
[2018-08-14 17:23:23,479 INFO] Start training...
[2018-08-14 17:23:23,479 INFO] Namespace(batch_size=400, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=19, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d', window_len=1, word_dim=100)
[2018-08-14 17:23:34,958 INFO] train token: 2127402
[2018-08-14 17:23:34,958 INFO] test token: 250140
[2018-08-14 17:23:34,958 INFO] valid token: 221606
[2018-08-14 17:23:35,102 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 17:23:50,259 INFO] | epoch   1 | train_loss  5.60 | val_ppl 200.64726 | time  11.8s
[2018-08-14 17:24:02,056 INFO] | epoch   2 | train_loss  5.22 | val_ppl 174.21698 | time  11.8s
[2018-08-14 17:24:13,945 INFO] | epoch   3 | train_loss  5.11 | val_ppl 165.95055 | time  11.9s
[2018-08-14 17:24:25,817 INFO] | epoch   4 | train_loss  5.04 | val_ppl 161.84225 | time  11.9s
[2018-08-14 17:24:37,743 INFO] | epoch   5 | train_loss  4.99 | val_ppl 158.92914 | time  11.9s
[2018-08-14 17:24:49,659 INFO] | epoch   6 | train_loss  4.95 | val_ppl 157.17144 | time  11.9s
[2018-08-14 17:25:01,579 INFO] | epoch   7 | train_loss  4.92 | val_ppl 156.18770 | time  11.9s
[2018-08-14 17:25:13,535 INFO] | epoch   8 | train_loss  4.89 | val_ppl 155.74281 | time  12.0s
[2018-08-14 17:25:14,070 INFO] test_ppl: 152.89515
[2018-08-14 17:29:09,232 INFO] -------------
[2018-08-14 17:31:43,699 INFO] -------------

(outemb and inputemb both use cbow and updating)
[2018-08-14 17:31:43,699 INFO] Start training...
[2018-08-14 17:31:43,699 INFO] Namespace(batch_size=400, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=40, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./wiki.train.tokens.100d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='nnlm.model', seed=19, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d', window_len=1, word_dim=100)
[2018-08-14 17:31:54,700 INFO] train token: 2127402
[2018-08-14 17:31:54,700 INFO] test token: 250140
[2018-08-14 17:31:54,700 INFO] valid token: 221606
[2018-08-14 17:31:54,843 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-14 17:32:10,819 INFO] | epoch   1 | train_loss  6.45 | val_ppl 198.50339 | time  11.8s
[2018-08-14 17:32:22,721 INFO] | epoch   2 | train_loss  5.21 | val_ppl 171.10911 | time  11.9s
[2018-08-14 17:32:34,548 INFO] | epoch   3 | train_loss  5.08 | val_ppl 161.58858 | time  11.8s
[2018-08-14 17:32:46,423 INFO] | epoch   4 | train_loss  5.01 | val_ppl 156.94727 | time  11.9s
[2018-08-14 17:32:58,306 INFO] | epoch   5 | train_loss  4.97 | val_ppl 154.79554 | time  11.9s
[2018-08-14 17:33:10,196 INFO] | epoch   6 | train_loss  4.93 | val_ppl 153.86024 | time  11.9s
[2018-08-14 17:33:22,102 INFO] | epoch   7 | train_loss  4.90 | val_ppl 153.54663 | time  11.9s
[2018-08-14 17:33:34,023 INFO] | epoch   8 | train_loss  4.88 | val_ppl 153.57180 | time  11.9s
[2018-08-14 17:33:34,503 INFO] test_ppl: 150.47444
[2018-08-16 16:22:34,640 INFO] -------------
[2018-08-16 16:36:01,954 INFO] -------------
[2018-08-16 16:36:01,954 INFO] Start training...
[2018-08-16 16:36:01,954 INFO] Namespace(batch_size=200, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=8, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='../common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.200d.cbow.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='mlp.model', seed=99, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d', window_len=2, word_dim=100)
[2018-08-16 16:36:13,953 INFO] train token: 2127402
[2018-08-16 16:36:13,953 INFO] test token: 250140
[2018-08-16 16:36:13,953 INFO] valid token: 221606
[2018-08-16 16:36:14,175 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-16 16:36:36,512 INFO] | epoch   1 | train_loss  5.49 | val_ppl 171.23717 | time  17.6s
[2018-08-16 16:36:54,263 INFO] | epoch   2 | train_loss  4.96 | val_ppl 159.69584 | time  17.8s
[2018-08-16 16:37:12,100 INFO] | epoch   3 | train_loss  4.82 | val_ppl 154.17969 | time  17.8s
[2018-08-16 16:37:29,942 INFO] | epoch   4 | train_loss  4.72 | val_ppl 146.32837 | time  17.8s
[2018-08-16 16:37:47,978 INFO] | epoch   5 | train_loss  4.65 | val_ppl 141.71028 | time  18.0s
[2018-08-16 16:38:05,952 INFO] | epoch   6 | train_loss  4.60 | val_ppl 141.50335 | time  18.0s
[2018-08-16 16:38:23,936 INFO] | epoch   7 | train_loss  4.55 | val_ppl 142.67969 | time  18.0s
[2018-08-16 16:38:41,943 INFO] | epoch   8 | train_loss  4.51 | val_ppl 144.40819 | time  18.0s
[2018-08-16 16:38:41,943 INFO] start to save model on mlp.model
[2018-08-16 16:38:42,993 INFO] test_ppl: 141.95403
[2018-08-16 16:46:52,651 INFO] -------------
[2018-08-16 16:48:52,928 INFO] -------------
[2018-08-16 16:52:42,460 INFO] -------------

(big batch_size)
[2018-08-16 16:52:42,460 INFO] Start training...
[2018-08-16 16:52:42,460 INFO] Namespace(batch_size=800, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_save=8, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='mlp.model', seed=9099, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d', window_len=2, word_dim=100)
[2018-08-16 16:52:54,052 INFO] train token: 2127402
[2018-08-16 16:52:54,052 INFO] test token: 250140
[2018-08-16 16:52:54,052 INFO] valid token: 221606
[2018-08-16 16:52:54,198 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-16 16:53:10,188 INFO] | epoch   1 | train_loss  5.55 | val_ppl 189.27845 | time  12.6s
[2018-08-16 16:53:22,810 INFO] | epoch   2 | train_loss  5.13 | val_ppl 159.12781 | time  12.6s
[2018-08-16 16:53:35,453 INFO] | epoch   3 | train_loss  4.99 | val_ppl 149.05304 | time  12.6s
[2018-08-16 16:53:48,185 INFO] | epoch   4 | train_loss  4.90 | val_ppl 143.65452 | time  12.7s
[2018-08-16 16:54:00,895 INFO] | epoch   5 | train_loss  4.84 | val_ppl 140.26069 | time  12.7s
[2018-08-16 16:54:13,635 INFO] | epoch   6 | train_loss  4.79 | val_ppl 137.98615 | time  12.7s
[2018-08-16 16:54:26,378 INFO] | epoch   7 | train_loss  4.75 | val_ppl 136.14842 | time  12.7s
[2018-08-16 16:54:39,153 INFO] | epoch   8 | train_loss  4.71 | val_ppl 134.80460 | time  12.8s
[2018-08-16 16:54:39,154 INFO] start to save model on mlp.model
[2018-08-16 16:54:40,039 INFO] test_ppl: 133.11336
[2018-08-16 17:31:01,331 INFO] -------------
[2018-08-16 17:31:01,331 INFO] Start training...
[2018-08-16 17:31:01,331 INFO] Namespace(batch_size=800, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=7, every_n_epoch_save=7, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='mlp.model', seed=9099, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d', window_len=2, word_dim=100)
[2018-08-16 17:31:12,810 INFO] train token: 2127402
[2018-08-16 17:31:12,810 INFO] test token: 250140
[2018-08-16 17:31:12,810 INFO] valid token: 221606
[2018-08-16 17:31:12,954 INFO] Loading vectors from /home/lr/yukun/common_corpus/glove.6B.100d.txt.pt
[2018-08-16 17:31:28,966 INFO] | epoch   1 | train_loss  5.55 | val_ppl 189.27845 | time  12.5s
[2018-08-16 17:31:41,465 INFO] | epoch   2 | train_loss  5.13 | val_ppl 159.12781 | time  12.5s
[2018-08-16 17:31:54,031 INFO] | epoch   3 | train_loss  4.99 | val_ppl 149.05304 | time  12.6s
[2018-08-16 17:32:06,740 INFO] | epoch   4 | train_loss  4.90 | val_ppl 143.65452 | time  12.7s
[2018-08-16 17:32:19,442 INFO] | epoch   5 | train_loss  4.84 | val_ppl 140.26069 | time  12.7s
[2018-08-16 17:32:32,135 INFO] | epoch   6 | train_loss  4.79 | val_ppl 137.98615 | time  12.7s
[2018-08-16 17:32:44,952 INFO] | epoch   7 | train_loss  4.75 | val_ppl 136.14842 | time  12.8s
[2018-08-16 17:32:44,953 INFO] start to save model on mlp.model
[2018-08-16 17:32:45,867 INFO] test_ppl: 134.46331
[2018-08-19 21:30:25,737 INFO] -------------
[2018-08-19 21:33:11,199 INFO] -------------
[2018-08-19 21:33:11,199 INFO] Start training...
[2018-08-19 21:33:11,199 INFO] Namespace(batch_size=800, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='mlp.model', seed=999, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d', window_len=2)
[2018-08-19 21:33:22,714 INFO] train token: 2127402
[2018-08-19 21:33:22,715 INFO] test token: 250140
[2018-08-19 21:33:22,715 INFO] valid token: 221606
[2018-08-19 21:33:22,716 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt.pt
[2018-08-19 21:33:38,811 INFO] | epoch   1 | train_loss  5.55 | val_ppl 190.08136 | time  12.5s
[2018-08-19 21:33:51,295 INFO] | epoch   2 | train_loss  5.13 | val_ppl 159.23547 | time  12.5s
[2018-08-19 21:34:03,858 INFO] | epoch   3 | train_loss  4.99 | val_ppl 149.19095 | time  12.6s
[2018-08-19 21:34:16,487 INFO] | epoch   4 | train_loss  4.90 | val_ppl 143.75418 | time  12.6s
[2018-08-19 21:34:29,255 INFO] | epoch   5 | train_loss  4.84 | val_ppl 140.50300 | time  12.8s
[2018-08-19 21:34:41,960 INFO] | epoch   6 | train_loss  4.79 | val_ppl 138.20954 | time  12.7s
[2018-08-19 21:34:54,711 INFO] | epoch   7 | train_loss  4.75 | val_ppl 136.42485 | time  12.8s
[2018-08-19 21:35:07,457 INFO] learning rate has been changed to 0.25
[2018-08-19 21:35:07,457 INFO] | epoch   8 | train_loss  4.71 | val_ppl 135.05579 | time  12.7s
[2018-08-19 21:35:07,937 INFO] test_ppl: 133.37755
[2018-08-19 21:38:15,419 INFO] -------------
[2018-08-19 21:38:15,419 INFO] Start training...
[2018-08-19 21:38:15,419 INFO] Namespace(batch_size=800, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=False, resources_dir='~/common_corpus/', rnn_type='GRU', save='mlp.model', seed=999, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d', window_len=5)
[2018-08-19 21:38:26,838 INFO] train token: 2127402
[2018-08-19 21:38:26,839 INFO] test token: 250140
[2018-08-19 21:38:26,839 INFO] valid token: 221606
[2018-08-19 21:38:26,840 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt.pt
[2018-08-19 21:38:55,394 INFO] -------------

here it is the same. lowered cbow is not so good as non-lowered one.
[2018-08-19 21:38:55,395 INFO] Start training...
[2018-08-19 21:38:55,395 INFO] Namespace(batch_size=800, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='mlp.model', seed=999, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d', window_len=2)
[2018-08-19 21:39:07,151 INFO] train token: 2127402
[2018-08-19 21:39:07,151 INFO] test token: 250140
[2018-08-19 21:39:07,151 INFO] valid token: 221606
[2018-08-19 21:39:07,152 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.100d.cbow.lower.txt.pt
[2018-08-19 21:39:22,316 INFO] | epoch   1 | train_loss  5.99 | val_ppl 272.21468 | time  11.0s
[2018-08-19 21:39:33,440 INFO] | epoch   2 | train_loss  5.57 | val_ppl 243.78372 | time  11.1s
[2018-08-19 21:39:44,476 INFO] | epoch   3 | train_loss  5.42 | val_ppl 232.66754 | time  11.0s
[2018-08-19 21:39:55,564 INFO] | epoch   4 | train_loss  5.33 | val_ppl 222.37175 | time  11.1s
[2018-08-19 21:40:06,658 INFO] | epoch   5 | train_loss  5.25 | val_ppl 216.00681 | time  11.1s
[2018-08-19 21:40:17,800 INFO] | epoch   6 | train_loss  5.19 | val_ppl 212.01806 | time  11.1s
[2018-08-19 21:40:29,062 INFO] | epoch   7 | train_loss  5.14 | val_ppl 209.64716 | time  11.3s
[2018-08-19 21:40:40,234 INFO] learning rate has been changed to 0.25
[2018-08-19 21:40:40,235 INFO] | epoch   8 | train_loss  5.10 | val_ppl 208.32088 | time  11.2s
[2018-08-19 21:40:40,668 INFO] test_ppl: 198.38516
[2018-08-19 21:45:39,052 INFO] -------------
[2018-08-19 21:45:39,052 INFO] Start training...
[2018-08-19 21:45:39,052 INFO] Namespace(batch_size=800, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector=None, log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='mlp.model', seed=989, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d', window_len=2)
[2018-08-19 21:45:50,305 INFO] train token: 2127402
[2018-08-19 21:45:50,306 INFO] test token: 250140
[2018-08-19 21:45:50,306 INFO] valid token: 221606
[2018-08-19 21:46:49,947 INFO] -------------


(all is from random)
[2018-08-19 21:46:49,947 INFO] Start training...
[2018-08-19 21:46:49,947 INFO] Namespace(batch_size=800, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='mlp.model', seed=989, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d', window_len=2)
[2018-08-19 21:47:01,722 INFO] train token: 2127402
[2018-08-19 21:47:01,722 INFO] test token: 250140
[2018-08-19 21:47:01,722 INFO] valid token: 221606
[2018-08-19 21:47:01,723 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.tokens.100d.cbow.txt.pt
[2018-08-19 21:47:17,988 INFO] | epoch   1 | train_loss  6.31 | val_ppl 322.31718 | time  12.5s
[2018-08-19 21:47:30,531 INFO] | epoch   2 | train_loss  5.62 | val_ppl 257.07319 | time  12.5s
[2018-08-19 21:47:43,132 INFO] | epoch   3 | train_loss  5.38 | val_ppl 229.74228 | time  12.6s
[2018-08-19 21:47:55,893 INFO] | epoch   4 | train_loss  5.23 | val_ppl 215.17767 | time  12.8s
[2018-08-19 21:48:08,586 INFO] | epoch   5 | train_loss  5.13 | val_ppl 206.50005 | time  12.7s
[2018-08-19 21:48:21,433 INFO] | epoch   6 | train_loss  5.05 | val_ppl 200.90878 | time  12.8s
[2018-08-19 21:48:34,188 INFO] | epoch   7 | train_loss  4.99 | val_ppl 197.08577 | time  12.8s
[2018-08-19 21:48:46,951 INFO] learning rate has been changed to 0.25
[2018-08-19 21:48:46,951 INFO] | epoch   8 | train_loss  4.93 | val_ppl 194.25111 | time  12.8s
[2018-08-19 21:48:47,432 INFO] test_ppl: 191.55490
[2018-08-19 21:51:36,379 INFO] -------------
[2018-08-19 21:51:36,379 INFO] Start training...
[2018-08-19 21:51:36,379 INFO] Namespace(batch_size=800, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.325d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='mlp.model', seed=9089, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d', window_len=2)
[2018-08-19 21:51:47,914 INFO] train token: 2127402
[2018-08-19 21:51:47,914 INFO] test token: 250140
[2018-08-19 21:51:47,914 INFO] valid token: 221606
[2018-08-19 21:51:48,539 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.325d.cbow.txt
[2018-08-19 21:51:48,543 WARNING] Skipping token 23380 with 1-dimensional vector ['325']; likely a header
[2018-08-19 21:51:51,020 INFO] Saving vectors to /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.325d.cbow.txt.pt
[2018-08-19 21:52:22,683 INFO] | epoch   1 | train_loss  5.53 | val_ppl 190.57477 | time  27.3s
[2018-08-19 21:52:50,361 INFO] | epoch   2 | train_loss  5.13 | val_ppl 159.29638 | time  27.7s
[2018-08-19 21:53:18,186 INFO] | epoch   3 | train_loss  4.99 | val_ppl 149.09333 | time  27.8s
[2018-08-19 21:53:46,020 INFO] | epoch   4 | train_loss  4.90 | val_ppl 143.62697 | time  27.8s
[2018-08-19 21:54:13,891 INFO] | epoch   5 | train_loss  4.84 | val_ppl 140.34052 | time  27.9s
[2018-08-19 21:54:41,892 INFO] | epoch   6 | train_loss  4.79 | val_ppl 137.89890 | time  28.0s
[2018-08-19 21:55:09,802 INFO] | epoch   7 | train_loss  4.74 | val_ppl 136.18945 | time  27.9s
[2018-08-19 21:55:37,854 INFO] learning rate has been changed to 0.25
[2018-08-19 21:55:37,855 INFO] | epoch   8 | train_loss  4.71 | val_ppl 134.74835 | time  28.1s
[2018-08-19 21:55:38,858 INFO] test_ppl: 132.94059
[2018-08-20 20:04:34,116 INFO] -------------
[2018-08-20 20:04:34,116 INFO] Start training...
[2018-08-20 20:04:34,116 INFO] Namespace(batch_size=800, bidirectional=False, bptt_len=10, device='cuda:1', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.850d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='mlp.model', seed=90, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d', window_len=1)
[2018-08-20 20:04:45,506 INFO] train token: 2127402
[2018-08-20 20:04:45,506 INFO] test token: 250140
[2018-08-20 20:04:45,506 INFO] valid token: 221606
[2018-08-20 20:04:45,683 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.850d.cbow.txt
[2018-08-20 20:04:45,687 WARNING] Skipping token 23380 with 1-dimensional vector ['850']; likely a header
[2018-08-20 20:04:51,820 INFO] Saving vectors to /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.850d.cbow.txt.pt
[2018-08-20 20:05:39,009 INFO] | epoch   1 | train_loss  5.70 | val_ppl 218.73756 | time  38.0s
[2018-08-20 20:06:17,733 INFO] | epoch   2 | train_loss  5.31 | val_ppl 186.67771 | time  38.7s
[2018-08-20 20:06:56,718 INFO] | epoch   3 | train_loss  5.19 | val_ppl 175.26562 | time  39.0s
[2018-08-20 20:07:35,822 INFO] | epoch   4 | train_loss  5.12 | val_ppl 168.39601 | time  39.1s
[2018-08-20 20:08:15,176 INFO] | epoch   5 | train_loss  5.06 | val_ppl 162.89016 | time  39.4s
[2018-08-20 20:08:55,014 INFO] | epoch   6 | train_loss  5.02 | val_ppl 158.95421 | time  39.8s
[2018-08-20 20:09:35,044 INFO] | epoch   7 | train_loss  4.99 | val_ppl 155.76819 | time  40.0s
[2018-08-20 20:10:15,287 INFO] learning rate has been changed to 0.25
[2018-08-20 20:10:15,288 INFO] | epoch   8 | train_loss  4.96 | val_ppl 153.47690 | time  40.2s
[2018-08-20 20:10:16,732 INFO] test_ppl: 151.98943
[2018-08-22 13:33:01,619 INFO] -------------
[2018-08-22 13:33:01,619 INFO] Start training...
[2018-08-22 13:33:01,619 INFO] Namespace(batch_size=800, bidirectional=False, bptt_len=10, device='cuda:1', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.850d.cbow.upremoved.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='mlp.model', seed=90, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d', window_len=1)
[2018-08-22 13:33:12,980 INFO] train token: 2127402
[2018-08-22 13:33:12,980 INFO] test token: 250140
[2018-08-22 13:33:12,981 INFO] valid token: 221606
[2018-08-22 13:33:13,080 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.850d.cbow.upremoved.txt
[2018-08-22 13:33:13,082 WARNING] Skipping token 23380 with 1-dimensional vector ['850']; likely a header
[2018-08-22 13:33:16,888 INFO] Saving vectors to /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.850d.cbow.upremoved.txt.pt
[2018-08-22 13:34:18,707 INFO] | epoch   1 | train_loss  5.61 | val_ppl 205.51933 | time  53.4s
[2018-08-22 13:35:12,466 INFO] | epoch   2 | train_loss  5.27 | val_ppl 178.39065 | time  53.8s
[2018-08-22 13:36:06,068 INFO] | epoch   3 | train_loss  5.16 | val_ppl 170.42072 | time  53.6s
[2018-08-22 13:36:59,932 INFO] | epoch   4 | train_loss  5.09 | val_ppl 162.77568 | time  53.9s
[2018-08-22 13:37:53,697 INFO] | epoch   5 | train_loss  5.04 | val_ppl 159.03740 | time  53.8s
[2018-08-22 13:38:47,464 INFO] | epoch   6 | train_loss  5.01 | val_ppl 156.21647 | time  53.8s
[2018-08-22 13:39:41,149 INFO] | epoch   7 | train_loss  4.98 | val_ppl 153.64568 | time  53.7s
[2018-08-22 13:40:34,915 INFO] learning rate has been changed to 0.25
[2018-08-22 13:40:34,916 INFO] | epoch   8 | train_loss  4.95 | val_ppl 151.87516 | time  53.8s
[2018-08-22 13:40:37,092 INFO] test_ppl: 150.36990
[2018-08-22 13:50:29,829 INFO] -------------
[2018-08-22 13:50:29,829 INFO] Start training...
[2018-08-22 13:50:29,830 INFO] Namespace(batch_size=800, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.850d.cbow.upremoved.numremoved.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='mlp.model', seed=90, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d', window_len=1)
[2018-08-22 13:50:40,693 INFO] train token: 2127402
[2018-08-22 13:50:40,694 INFO] test token: 250140
[2018-08-22 13:50:40,694 INFO] valid token: 221606
[2018-08-22 13:50:40,878 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.850d.cbow.upremoved.numremoved.txt
[2018-08-22 13:50:44,573 INFO] Saving vectors to /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.850d.cbow.upremoved.numremoved.txt.pt
[2018-08-22 13:51:11,852 INFO] | epoch   1 | train_loss  5.42 | val_ppl 168.01949 | time  22.7s
[2018-08-22 13:51:34,725 INFO] | epoch   2 | train_loss  5.10 | val_ppl 149.66203 | time  22.9s
[2018-08-22 13:51:57,929 INFO] | epoch   3 | train_loss  4.99 | val_ppl 140.21071 | time  23.2s
[2018-08-22 13:52:21,200 INFO] | epoch   4 | train_loss  4.93 | val_ppl 136.05145 | time  23.3s
[2018-08-22 13:52:44,398 INFO] | epoch   5 | train_loss  4.88 | val_ppl 132.40515 | time  23.2s
[2018-08-22 13:53:07,764 INFO] | epoch   6 | train_loss  4.85 | val_ppl 130.38795 | time  23.4s
[2018-08-22 13:53:31,027 INFO] | epoch   7 | train_loss  4.83 | val_ppl 130.60381 | time  23.3s
[2018-08-22 13:53:54,331 INFO] learning rate has been changed to 0.25
[2018-08-22 13:53:54,332 INFO] | epoch   8 | train_loss  4.80 | val_ppl 128.60296 | time  23.3s
[2018-08-22 13:53:55,172 INFO] test_ppl: 126.63749
[2018-08-22 15:02:45,414 INFO] -------------
[2018-08-22 15:02:45,414 INFO] Start training...
[2018-08-22 15:02:45,414 INFO] Namespace(batch_size=800, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.preprocessed.850d.5freq.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='mlp.model', seed=90, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d', window_len=1)
[2018-08-22 15:02:57,199 INFO] train token: 2127402
[2018-08-22 15:02:57,200 INFO] test token: 250140
[2018-08-22 15:02:57,200 INFO] valid token: 221606
[2018-08-22 15:02:57,329 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.preprocessed.850d.cbow.txt
[2018-08-22 15:02:57,332 WARNING] Skipping token 17532 with 1-dimensional vector ['850']; likely a header
[2018-08-22 15:03:01,904 INFO] Saving vectors to /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.preprocessed.850d.cbow.txt.pt
[2018-08-22 15:03:35,395 INFO] | epoch   1 | train_loss  5.91 | val_ppl 255.46156 | time  28.5s
[2018-08-22 15:04:03,708 INFO] | epoch   2 | train_loss  5.56 | val_ppl 225.86781 | time  28.3s
[2018-08-22 15:04:32,373 INFO] | epoch   3 | train_loss  5.44 | val_ppl 210.84073 | time  28.7s
[2018-08-22 15:05:03,104 INFO] | epoch   4 | train_loss  5.37 | val_ppl 204.61286 | time  30.7s
[2018-08-22 15:05:38,625 INFO] | epoch   5 | train_loss  5.31 | val_ppl 199.28830 | time  35.5s
[2018-08-22 15:10:29,687 INFO] -------------
[2018-08-22 15:10:29,687 INFO] Start training...
[2018-08-22 15:10:29,687 INFO] Namespace(batch_size=800, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.preprocessed.10freq.850d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='mlp.model', seed=90, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d', window_len=1)
[2018-08-22 15:10:41,030 INFO] train token: 2127402
[2018-08-22 15:10:41,030 INFO] test token: 250140
[2018-08-22 15:10:41,030 INFO] valid token: 221606
[2018-08-22 15:10:41,198 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.preprocessed.10freq.850d.cbow.txt
[2018-08-22 15:10:41,203 WARNING] Skipping token 11715 with 1-dimensional vector ['850']; likely a header
[2018-08-22 15:10:44,432 INFO] Saving vectors to /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.preprocessed.10freq.850d.cbow.txt.pt
[2018-08-22 15:11:08,172 INFO] | epoch   1 | train_loss  5.59 | val_ppl 192.60315 | time  19.2s
[2018-08-22 15:11:27,935 INFO] | epoch   2 | train_loss  5.29 | val_ppl 173.78872 | time  19.8s
[2018-08-22 15:11:47,451 INFO] | epoch   3 | train_loss  5.20 | val_ppl 166.96312 | time  19.5s
[2018-08-22 15:12:07,038 INFO] | epoch   4 | train_loss  5.14 | val_ppl 162.50060 | time  19.6s
[2018-08-22 15:12:26,944 INFO] | epoch   5 | train_loss  5.09 | val_ppl 159.67045 | time  19.9s
[2018-08-22 15:12:46,674 INFO] | epoch   6 | train_loss  5.06 | val_ppl 157.19817 | time  19.7s
[2018-08-22 15:13:06,405 INFO] | epoch   7 | train_loss  5.03 | val_ppl 155.45119 | time  19.7s
[2018-08-22 16:19:53,856 INFO] -------------
[2018-08-22 16:21:58,675 INFO] -------------
[2018-08-22 16:21:58,675 INFO] Start training...
[2018-08-22 16:21:58,675 INFO] Namespace(batch_size=800, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.preprocessed.7freq.850d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='mlp.model', seed=90, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d', window_len=1)
[2018-08-22 16:22:10,511 INFO] train token: 2127402
[2018-08-22 16:22:10,512 INFO] test token: 250140
[2018-08-22 16:22:10,512 INFO] valid token: 221606
[2018-08-22 16:22:11,525 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.preprocessed.7freq.850d.cbow.txt
[2018-08-22 16:22:11,528 WARNING] Skipping token 14524 with 1-dimensional vector ['850']; likely a header
[2018-08-22 16:22:15,491 INFO] Saving vectors to /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.preprocessed.7freq.850d.cbow.txt.pt
[2018-08-22 16:22:43,767 INFO] | epoch   1 | train_loss  5.76 | val_ppl 225.37871 | time  23.4s
[2018-08-22 16:23:07,401 INFO] | epoch   2 | train_loss  5.43 | val_ppl 204.03496 | time  23.6s
[2018-08-22 16:23:31,312 INFO] | epoch   3 | train_loss  5.33 | val_ppl 191.53437 | time  23.9s
[2018-08-22 16:23:55,234 INFO] | epoch   4 | train_loss  5.26 | val_ppl 185.13984 | time  23.9s
[2018-08-22 16:24:19,202 INFO] | epoch   5 | train_loss  5.21 | val_ppl 180.04365 | time  24.0s
[2018-08-22 16:24:43,218 INFO] | epoch   6 | train_loss  5.17 | val_ppl 176.66925 | time  24.0s
[2018-08-22 16:25:07,389 INFO] | epoch   7 | train_loss  5.14 | val_ppl 174.22657 | time  24.2s
[2018-08-22 16:25:31,476 INFO] learning rate has been changed to 0.25
[2018-08-22 16:25:31,477 INFO] | epoch   8 | train_loss  5.12 | val_ppl 172.32574 | time  24.1s
[2018-08-22 16:25:32,353 INFO] test_ppl: 162.72448
[2018-08-22 16:34:13,468 INFO] -------------
[2018-08-22 16:34:13,468 INFO] Start training...
[2018-08-22 16:34:13,468 INFO] Namespace(batch_size=800, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.only.preprocessed.850d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='mlp.model', seed=90, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d', window_len=1)
[2018-08-22 16:34:24,841 INFO] train token: 2127402
[2018-08-22 16:34:24,841 INFO] test token: 250140
[2018-08-22 16:34:24,841 INFO] valid token: 221606
[2018-08-22 16:34:24,944 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.only.preprocessed.850d.cbow.txt
[2018-08-22 16:34:24,945 WARNING] Skipping token 13981 with 1-dimensional vector ['850']; likely a header
[2018-08-22 16:34:28,655 INFO] Saving vectors to /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.only.preprocessed.850d.cbow.txt.pt
[2018-08-22 16:34:56,143 INFO] | epoch   1 | train_loss  5.40 | val_ppl 162.66246 | time  22.8s
[2018-08-22 16:35:19,076 INFO] | epoch   2 | train_loss  5.08 | val_ppl 144.59705 | time  22.9s
[2018-08-22 16:35:42,163 INFO] | epoch   3 | train_loss  4.98 | val_ppl 139.20214 | time  23.1s
[2018-08-22 16:36:05,343 INFO] | epoch   4 | train_loss  4.92 | val_ppl 135.32074 | time  23.2s
[2018-08-22 16:36:28,569 INFO] | epoch   5 | train_loss  4.88 | val_ppl 131.94315 | time  23.2s
[2018-08-22 16:36:51,836 INFO] | epoch   6 | train_loss  4.85 | val_ppl 129.21605 | time  23.3s
[2018-08-22 16:37:15,112 INFO] | epoch   7 | train_loss  4.82 | val_ppl 127.27194 | time  23.3s
[2018-08-22 16:37:38,418 INFO] learning rate has been changed to 0.25
[2018-08-22 16:37:38,419 INFO] | epoch   8 | train_loss  4.79 | val_ppl 125.81266 | time  23.3s
[2018-08-22 16:37:39,263 INFO] test_ppl: 123.88560
[2018-08-22 16:56:42,579 INFO] -------------
[2018-08-22 16:56:42,579 INFO] Start training...
[2018-08-22 16:56:42,579 INFO] Namespace(batch_size=800, bidirectional=False, bptt_len=10, device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='mlp.model', seed=90, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d', window_len=1)
[2018-08-22 16:56:53,966 INFO] train token: 2127402
[2018-08-22 16:56:53,966 INFO] test token: 250140
[2018-08-22 16:56:53,967 INFO] valid token: 221606
[2018-08-22 16:56:54,105 INFO] Loading vectors from /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt
[2018-08-22 16:56:54,107 WARNING] Skipping token 10527 with 1-dimensional vector ['850']; likely a header
[2018-08-22 16:56:56,854 INFO] Saving vectors to /home/lr/yukun/common_corpus/wikitext-2/wikitext-2/wiki.train.numupper.freq3.preprocessed.850d.cbow.txt.pt
[2018-08-22 16:57:18,310 INFO] | epoch   1 | train_loss  5.22 | val_ppl 142.75008 | time  17.4s
[2018-08-22 16:57:35,738 INFO] | epoch   2 | train_loss  4.93 | val_ppl 127.18869 | time  17.4s
[2018-08-22 16:57:53,304 INFO] | epoch   3 | train_loss  4.84 | val_ppl 122.14784 | time  17.6s
[2018-08-22 16:58:10,960 INFO] | epoch   4 | train_loss  4.79 | val_ppl 118.52398 | time  17.7s
[2018-08-22 16:58:28,672 INFO] | epoch   5 | train_loss  4.75 | val_ppl 115.72211 | time  17.7s
[2018-08-22 16:58:46,511 INFO] | epoch   6 | train_loss  4.72 | val_ppl 113.95858 | time  17.8s
[2018-08-22 16:59:04,359 INFO] | epoch   7 | train_loss  4.70 | val_ppl 112.72040 | time  17.8s
[2018-08-22 16:59:22,129 INFO] learning rate has been changed to 0.25
[2018-08-22 16:59:22,129 INFO] | epoch   8 | train_loss  4.68 | val_ppl 111.76576 | time  17.8s
[2018-08-22 16:59:22,776 INFO] test_ppl: 110.65574
[2018-08-23 00:04:32,153 INFO] -------------
[2018-08-23 00:04:32,153 INFO] Start training...
[2018-08-23 00:04:32,153 INFO] Namespace(batch_size=800, bidirectional=False, bptt_len=10, data_type='ptb', device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/penn-treebank/ptb.train.txt.preprocessed.cbow.100d', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='mlp.model', seed=10, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d', window_len=1)
[2018-08-23 00:04:38,368 INFO] train token: 994974
[2018-08-23 00:04:38,368 INFO] test token: 88160
[2018-08-23 00:04:38,368 INFO] valid token: 78932
[2018-08-23 00:04:38,452 INFO] Loading vectors from /home/lr/yukun/common_corpus/penn-treebank/ptb.train.txt.preprocessed.cbow.100d
[2018-08-23 00:04:38,456 WARNING] Skipping token 9858 with 1-dimensional vector ['100']; likely a header
[2018-08-23 00:04:38,884 INFO] Saving vectors to /home/lr/yukun/common_corpus/penn-treebank/ptb.train.txt.preprocessed.cbow.100d.pt
[2018-08-23 00:04:48,386 INFO] | epoch   1 | train_loss  5.83 | val_ppl 226.02103 | time   5.2s
[2018-08-23 00:04:53,549 INFO] | epoch   2 | train_loss  5.42 | val_ppl 197.74074 | time   5.2s
[2018-08-23 00:04:58,759 INFO] | epoch   3 | train_loss  5.29 | val_ppl 180.63231 | time   5.2s
[2018-08-23 00:05:01,679 INFO] | epoch   4 | train_loss  5.21 | val_ppl 171.39508 | time   2.9s
[2018-08-23 00:05:04,618 INFO] | epoch   5 | train_loss  5.15 | val_ppl 165.62140 | time   2.9s
[2018-08-23 00:05:07,565 INFO] | epoch   6 | train_loss  5.11 | val_ppl 163.70314 | time   2.9s
[2018-08-23 00:05:10,474 INFO] | epoch   7 | train_loss  5.07 | val_ppl 160.34633 | time   2.9s
[2018-08-23 00:05:13,435 INFO] learning rate has been changed to 0.25
[2018-08-23 00:05:13,435 INFO] | epoch   8 | train_loss  5.03 | val_ppl 155.86595 | time   3.0s
[2018-08-23 00:05:13,526 INFO] test_ppl: 155.24921
[2018-08-23 00:50:47,843 INFO] -------------
[2018-08-23 00:51:37,549 INFO] -------------
[2018-08-23 00:51:37,549 INFO] Start training...
[2018-08-23 00:51:37,550 INFO] Namespace(batch_size=800, bidirectional=False, bptt_len=10, data_type='ptb', device='cuda:0', dropout=0.0, epoch=8, every_n_epoch_decay=8, every_n_epoch_save=40, input_vector='~/common_corpus/penn-treebank/ptb.train.txt.cbow.850d', log_file='log', lr=0.5, norm_out_emb=False, num_layers=1, out_emb_path='./10bptt_8epoch_outemb.txt', random_outemb=True, resources_dir='~/common_corpus/', rnn_type='GRU', save='mlp.model', seed=1000, tied=False, update_inputemb=True, update_out_emb=True, vector_type='glove.6B.100d', window_len=1)
[2018-08-23 00:51:42,667 INFO] train token: 994974
[2018-08-23 00:51:42,667 INFO] test token: 88160
[2018-08-23 00:51:42,667 INFO] valid token: 78932
[2018-08-23 00:51:42,668 INFO] Loading vectors from /home/lr/yukun/common_corpus/penn-treebank/ptb.train.txt.cbow.850d.pt
[2018-08-23 00:51:55,683 INFO] | epoch   1 | train_loss  5.82 | val_ppl 232.22919 | time   8.4s
[2018-08-23 00:52:04,089 INFO] | epoch   2 | train_loss  5.44 | val_ppl 202.50594 | time   8.4s
[2018-08-23 00:52:12,521 INFO] | epoch   3 | train_loss  5.31 | val_ppl 185.36641 | time   8.4s
[2018-08-23 00:52:21,012 INFO] | epoch   4 | train_loss  5.23 | val_ppl 176.56258 | time   8.5s
[2018-08-23 00:52:29,562 INFO] | epoch   5 | train_loss  5.17 | val_ppl 170.38805 | time   8.5s
[2018-08-23 00:52:38,137 INFO] | epoch   6 | train_loss  5.12 | val_ppl 165.22679 | time   8.6s
[2018-08-23 00:52:46,703 INFO] | epoch   7 | train_loss  5.08 | val_ppl 161.20808 | time   8.6s
[2018-08-23 00:52:55,388 INFO] learning rate has been changed to 0.25
[2018-08-23 00:52:55,388 INFO] | epoch   8 | train_loss  5.05 | val_ppl 158.25242 | time   8.7s
[2018-08-23 00:52:55,620 INFO] test_ppl: 157.68299
